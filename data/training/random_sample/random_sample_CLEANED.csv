Link to paper,Score,Text,Cleaned,unigrams,bigrams,trigrams
https://link.springer.com/content/pdf/10.1140/epjds/s13688-017-0110-z.pdf,1,Data collection was crowdsourced using Amazon’s Mechanical Turk (MTurk) crowdwork platform. Separate surveys were created for depressed and healthy individuals. In the depressed survey participants were invited to complete a survey that involved passing a series of inclusion criteria responding to a standardized clinical depression survey answering questions related to demographics and history of depression and sharing social media history. We used the CES-D (Center for Epidemiologic Studies Depression Scale) questionnaire to screen participant depression levels []. CES-D assessment quality has been demonstrated as on-par with other depression inventories including the Beck Depression Inventory and the Kellner Symptom Questionnaire [ ]. Healthy participants were screened to ensure no history of depression and active Instagram use. See Additional file  for actual survey text. Qualified participants were asked to share their Instagram usernames and history. An app embedded in the survey allowed participants to securely log into their Instagram accounts and agree to share their data.b Upon securing consent we made a one-time collection of participants’ entire Instagram posting history. In total we collected  photographs from  Instagram users  of whom had a history of depression. We asked a different set of MTurk crowdworkers to rate the Instagram photographs collected. This new task asked participants to rate a random selection of  photos from the data we collected. Raters were asked to judge how interesting likable happy and sad each photo seemed on a continuous - scale. Each photo was rated by at least three different raters and ratings were averaged across raters. Raters were not informed that photos were from Instagram nor were they given any information about the study participants who provided the photos including mental health status. Each ratings category showed good inter-rater agreement. Only a subset of participant Instagram photos were rated (N = ). We limited ratings data to a subset because this task was time-consuming for crowdworkers and so proved a costly form of data collection. For the depressed sample ratings were only made for photos posted within a year in either direction of the date of first depression diagnosis. Within this subset for each user the nearest  posts prior to the diagnosis date were rated. For the control population the most recent  photos from each user’s date of participation in this study were rated.,data collection wa crowdsourced using amazon mechanical turk mturk crowdwork platform separate survey were created for depressed and healthy individual in the depressed survey participant were invited to complete a survey that involved passing a series of inclusion criterion responding to a standardized clinical depression survey answering question related to demographic and history of depression and sharing social medium history we used the cesd center for epidemiologic study depression scale questionnaire to screen participant depression level cesd assessment quality ha been demonstrated a onpar with other depression inventory including the beck depression inventory and the kellner symptom questionnaire healthy participant were screened to ensure no history of depression and active instagram use see additional file for actual survey text qualified participant were asked to share their instagram usernames and history an app embedded in the survey allowed participant to securely log into their instagram account and agree to share their datab upon securing consent we made a onetime collection of participant entire instagram posting history in total we collected photograph from instagram user of whom had a history of depression we asked a different set of mturk crowdworkers to rate the instagram photograph collected this new task asked participant to rate a random selection of photo from the data we collected raters were asked to judge how interesting likable happy and sad each photo seemed on a continuous scale each photo wa rated by at least three different raters and rating were averaged across raters raters were not informed that photo were from instagram nor were they given any information about the study participant who provided the photo including mental health status each rating category showed good interrater agreement only a subset of participant instagram photo were rated n we limited rating data to a subset because this task wa timeconsuming for crowdworkers and so proved a costly form of data collection for the depressed sample rating were only made for photo posted within a year in either direction of the date of first depression diagnosis within this subset for each user the nearest post prior to the diagnosis date were rated for the control population the most recent photo from each user date of participation in this study were rated,"['collection', 'crowdsourced', 'using', 'amazon', 'mechanical', 'turk', 'mturk', 'crowdwork', 'platform', 'separate', 'survey', 'created', 'depressed', 'healthy', 'individual', 'depressed', 'survey', 'invited', 'complete', 'survey', 'involved', 'passing', 'series', 'inclusion', 'criterion', 'responding', 'standardized', 'clinical', 'survey', 'answering', 'question', 'related', 'demographic', 'history', 'sharing', 'social', 'medium', 'history', 'cesd', 'center', 'epidemiologic', 'study', 'scale', 'questionnaire', 'screen', 'level', 'cesd', 'assessment', 'quality', 'ha', 'demonstrated', 'onpar', 'inventory', 'including', 'beck', 'inventory', 'kellner', 'symptom', 'questionnaire', 'healthy', 'screened', 'ensure', 'history', 'active', 'instagram', 'use', 'see', 'additional', 'file', 'actual', 'survey', 'text', 'qualified', 'asked', 'share', 'instagram', 'usernames', 'history', 'app', 'embedded', 'survey', 'allowed', 'securely', 'log', 'instagram', 'account', 'agree', 'share', 'datab', 'upon', 'securing', 'consent', 'made', 'onetime', 'collection', 'entire', 'instagram', 'posting', 'history', 'total', 'collected', 'photograph', 'instagram', 'history', 'asked', 'different', 'set', 'mturk', 'crowdworkers', 'rate', 'instagram', 'photograph', 'collected', 'new', 'task', 'asked', 'rate', 'random', 'selection', 'photo', 'collected', 'raters', 'asked', 'judge', 'interesting', 'likable', 'happy', 'sad', 'photo', 'seemed', 'continuous', 'scale', 'photo', 'rated', 'least', 'three', 'different', 'raters', 'rating', 'averaged', 'across', 'raters', 'raters', 'informed', 'photo', 'instagram', 'given', 'information', 'study', 'provided', 'photo', 'including', 'status', 'rating', 'category', 'showed', 'good', 'interrater', 'agreement', 'subset', 'instagram', 'photo', 'rated', 'n', 'limited', 'rating', 'subset', 'task', 'timeconsuming', 'crowdworkers', 'proved', 'costly', 'form', 'collection', 'depressed', 'sample', 'rating', 'made', 'photo', 'posted', 'within', 'year', 'either', 'direction', 'date', 'first', 'diagnosis', 'within', 'subset', 'nearest', 'prior', 'diagnosis', 'date', 'rated', 'population', 'recent', 'photo', 'date', 'participation', 'study', 'rated']","['collection crowdsourced', 'crowdsourced using', 'using amazon', 'amazon mechanical', 'mechanical turk', 'turk mturk', 'mturk crowdwork', 'crowdwork platform', 'platform separate', 'separate survey', 'survey created', 'created depressed', 'depressed healthy', 'healthy individual', 'individual depressed', 'depressed survey', 'survey invited', 'invited complete', 'complete survey', 'survey involved', 'involved passing', 'passing series', 'series inclusion', 'inclusion criterion', 'criterion responding', 'responding standardized', 'standardized clinical', 'clinical survey', 'survey answering', 'answering question', 'question related', 'related demographic', 'demographic history', 'history sharing', 'sharing social', 'social medium', 'medium history', 'history cesd', 'cesd center', 'center epidemiologic', 'epidemiologic study', 'study scale', 'scale questionnaire', 'questionnaire screen', 'screen level', 'level cesd', 'cesd assessment', 'assessment quality', 'quality ha', 'ha demonstrated', 'demonstrated onpar', 'onpar inventory', 'inventory including', 'including beck', 'beck inventory', 'inventory kellner', 'kellner symptom', 'symptom questionnaire', 'questionnaire healthy', 'healthy screened', 'screened ensure', 'ensure history', 'history active', 'active instagram', 'instagram use', 'use see', 'see additional', 'additional file', 'file actual', 'actual survey', 'survey text', 'text qualified', 'qualified asked', 'asked share', 'share instagram', 'instagram usernames', 'usernames history', 'history app', 'app embedded', 'embedded survey', 'survey allowed', 'allowed securely', 'securely log', 'log instagram', 'instagram account', 'account agree', 'agree share', 'share datab', 'datab upon', 'upon securing', 'securing consent', 'consent made', 'made onetime', 'onetime collection', 'collection entire', 'entire instagram', 'instagram posting', 'posting history', 'history total', 'total collected', 'collected photograph', 'photograph instagram', 'instagram history', 'history asked', 'asked different', 'different set', 'set mturk', 'mturk crowdworkers', 'crowdworkers rate', 'rate instagram', 'instagram photograph', 'photograph collected', 'collected new', 'new task', 'task asked', 'asked rate', 'rate random', 'random selection', 'selection photo', 'photo collected', 'collected raters', 'raters asked', 'asked judge', 'judge interesting', 'interesting likable', 'likable happy', 'happy sad', 'sad photo', 'photo seemed', 'seemed continuous', 'continuous scale', 'scale photo', 'photo rated', 'rated least', 'least three', 'three different', 'different raters', 'raters rating', 'rating averaged', 'averaged across', 'across raters', 'raters raters', 'raters informed', 'informed photo', 'photo instagram', 'instagram given', 'given information', 'information study', 'study provided', 'provided photo', 'photo including', 'including status', 'status rating', 'rating category', 'category showed', 'showed good', 'good interrater', 'interrater agreement', 'agreement subset', 'subset instagram', 'instagram photo', 'photo rated', 'rated n', 'n limited', 'limited rating', 'rating subset', 'subset task', 'task timeconsuming', 'timeconsuming crowdworkers', 'crowdworkers proved', 'proved costly', 'costly form', 'form collection', 'collection depressed', 'depressed sample', 'sample rating', 'rating made', 'made photo', 'photo posted', 'posted within', 'within year', 'year either', 'either direction', 'direction date', 'date first', 'first diagnosis', 'diagnosis within', 'within subset', 'subset nearest', 'nearest prior', 'prior diagnosis', 'diagnosis date', 'date rated', 'rated population', 'population recent', 'recent photo', 'photo date', 'date participation', 'participation study', 'study rated']","['collection crowdsourced using', 'crowdsourced using amazon', 'using amazon mechanical', 'amazon mechanical turk', 'mechanical turk mturk', 'turk mturk crowdwork', 'mturk crowdwork platform', 'crowdwork platform separate', 'platform separate survey', 'separate survey created', 'survey created depressed', 'created depressed healthy', 'depressed healthy individual', 'healthy individual depressed', 'individual depressed survey', 'depressed survey invited', 'survey invited complete', 'invited complete survey', 'complete survey involved', 'survey involved passing', 'involved passing series', 'passing series inclusion', 'series inclusion criterion', 'inclusion criterion responding', 'criterion responding standardized', 'responding standardized clinical', 'standardized clinical survey', 'clinical survey answering', 'survey answering question', 'answering question related', 'question related demographic', 'related demographic history', 'demographic history sharing', 'history sharing social', 'sharing social medium', 'social medium history', 'medium history cesd', 'history cesd center', 'cesd center epidemiologic', 'center epidemiologic study', 'epidemiologic study scale', 'study scale questionnaire', 'scale questionnaire screen', 'questionnaire screen level', 'screen level cesd', 'level cesd assessment', 'cesd assessment quality', 'assessment quality ha', 'quality ha demonstrated', 'ha demonstrated onpar', 'demonstrated onpar inventory', 'onpar inventory including', 'inventory including beck', 'including beck inventory', 'beck inventory kellner', 'inventory kellner symptom', 'kellner symptom questionnaire', 'symptom questionnaire healthy', 'questionnaire healthy screened', 'healthy screened ensure', 'screened ensure history', 'ensure history active', 'history active instagram', 'active instagram use', 'instagram use see', 'use see additional', 'see additional file', 'additional file actual', 'file actual survey', 'actual survey text', 'survey text qualified', 'text qualified asked', 'qualified asked share', 'asked share instagram', 'share instagram usernames', 'instagram usernames history', 'usernames history app', 'history app embedded', 'app embedded survey', 'embedded survey allowed', 'survey allowed securely', 'allowed securely log', 'securely log instagram', 'log instagram account', 'instagram account agree', 'account agree share', 'agree share datab', 'share datab upon', 'datab upon securing', 'upon securing consent', 'securing consent made', 'consent made onetime', 'made onetime collection', 'onetime collection entire', 'collection entire instagram', 'entire instagram posting', 'instagram posting history', 'posting history total', 'history total collected', 'total collected photograph', 'collected photograph instagram', 'photograph instagram history', 'instagram history asked', 'history asked different', 'asked different set', 'different set mturk', 'set mturk crowdworkers', 'mturk crowdworkers rate', 'crowdworkers rate instagram', 'rate instagram photograph', 'instagram photograph collected', 'photograph collected new', 'collected new task', 'new task asked', 'task asked rate', 'asked rate random', 'rate random selection', 'random selection photo', 'selection photo collected', 'photo collected raters', 'collected raters asked', 'raters asked judge', 'asked judge interesting', 'judge interesting likable', 'interesting likable happy', 'likable happy sad', 'happy sad photo', 'sad photo seemed', 'photo seemed continuous', 'seemed continuous scale', 'continuous scale photo', 'scale photo rated', 'photo rated least', 'rated least three', 'least three different', 'three different raters', 'different raters rating', 'raters rating averaged', 'rating averaged across', 'averaged across raters', 'across raters raters', 'raters raters informed', 'raters informed photo', 'informed photo instagram', 'photo instagram given', 'instagram given information', 'given information study', 'information study provided', 'study provided photo', 'provided photo including', 'photo including status', 'including status rating', 'status rating category', 'rating category showed', 'category showed good', 'showed good interrater', 'good interrater agreement', 'interrater agreement subset', 'agreement subset instagram', 'subset instagram photo', 'instagram photo rated', 'photo rated n', 'rated n limited', 'n limited rating', 'limited rating subset', 'rating subset task', 'subset task timeconsuming', 'task timeconsuming crowdworkers', 'timeconsuming crowdworkers proved', 'crowdworkers proved costly', 'proved costly form', 'costly form collection', 'form collection depressed', 'collection depressed sample', 'depressed sample rating', 'sample rating made', 'rating made photo', 'made photo posted', 'photo posted within', 'posted within year', 'within year either', 'year either direction', 'either direction date', 'direction date first', 'date first diagnosis', 'first diagnosis within', 'diagnosis within subset', 'within subset nearest', 'subset nearest prior', 'nearest prior diagnosis', 'prior diagnosis date', 'diagnosis date rated', 'date rated population', 'rated population recent', 'population recent photo', 'recent photo date', 'photo date participation', 'date participation study', 'participation study rated']"
https://dl.acm.org/doi/abs/10.1145/2858036.2858207 ,1,We split our data into two sequential time periods (t1 from Feb 11 2014 to Aug 11 2014 and t2 from Aug 12 2014 to November 11 2014). Using these two time periods we created two sets of users. Note that since Reddit does not enforce the real name rule of having exactly one account per person our reference to “users” in this paper is equivalent to “user accounts”. First we identified those users that posted on MHs during t1 but did not post on SW during t1 or t2 (i.e. users that discuss mental health topics but not on SW; hereafter “MH”). The second class included those who posted on MHs during t1 and posted in SW during t2 (i.e. users that discuss mental health topics originally not related to suicide but eventually transition to talk about suicide; hereafter “MH → SW”). Figure 1 shows a schematic description of our user class construction. Note that by focusing on users that initiate at least one post on SW or the MHs as opposed to only commenting we can focus on those frequenting the communities for support disregarding those primarily providing help through commentary. This split yielded 440 MH → SW users; which is 1.52% of the total number of 28831 accounts who posted in MHs but never on SW during either of the periods. To construct a MH cohort of equal size who did not post on SW in either period we randomly sampled a set of 440 users from the 28831 users. Note although MH users did not post on SW during our timeframe of analysis they may have done so outside the bounds of our analysis. To support our goal of characterizing differences between the MH → SW and MH users we obtained via Reddit’s API the timeline of posts and comments authored by the 880 users (the API only provides the last 1000 public posts and comments for a user). For each post we obtained their associated metadata (e.g. vote difference or score) and comments. Our final dataset contained 4731 posts and 46949 comments from the 440 MH → SW users and 8318 posts and 54086 comments from the 440 MH users. We note an important concern: individuals may post suicidal thoughts on MHs never engaging on SW and thus “corrupting” the MHs data with discussions of suicidal ideation. We argue against this possibility. (1) SW is a prominent suicide support forum and the role of this community in suicide prevention and in acting as an inoculator of vulnerable thoughts is well-recognized [31]. (2) Most MHs (e.g. r/depression) clearly specify in their guidelines that suicidal thoughts should go to SW: “It’s usually better to post anything that specifically involves suicidal thoughts or intent in /r/SuicideWatch rather than here. If you’re concerned about someone else who may be at risk for suicide please check out their talking tips and risk assessment guide.” (3) Finally discussions with the moderators of SW confirmed that active steps are taken to move all suicidal ideation related content to SW. Given these considerations we expect that few suicidal ideation posts appear on subreddits outside of SW.,we split our data into two sequential time period t from feb to aug and t from aug to november using these two time period we created two set of user note that since reddit doe not enforce the real name rule of having exactly one account per person our reference to user in this paper is equivalent to user account first we identified those user that posted on mhs during t but did not post on sw during t or t ie user that discus mental health topic but not on sw hereafter mh the second class included those who posted on mhs during t and posted in sw during t ie user that discus mental health topic originally not related to suicide but eventually transition to talk about suicide hereafter mh sw figure show a schematic description of our user class construction note that by focusing on user that initiate at least one post on sw or the mhs a opposed to only commenting we can focus on those frequenting the community for support disregarding those primarily providing help through commentary this split yielded mh sw user which is of the total number of account who posted in mhs but never on sw during either of the period to construct a mh cohort of equal size who did not post on sw in either period we randomly sampled a set of user from the user note although mh user did not post on sw during our timeframe of analysis they may have done so outside the bound of our analysis to support our goal of characterizing difference between the mh sw and mh user we obtained via reddits api the timeline of post and comment authored by the user the api only provides the last public post and comment for a user for each post we obtained their associated metadata eg vote difference or score and comment our final dataset contained post and comment from the mh sw user and post and comment from the mh user we note an important concern individual may post suicidal thought on mhs never engaging on sw and thus corrupting the mhs data with discussion of suicidal ideation we argue against this possibility sw is a prominent suicide support forum and the role of this community in suicide prevention and in acting a an inoculator of vulnerable thought is wellrecognized most mhs eg rdepression clearly specify in their guideline that suicidal thought should go to sw it usually better to post anything that specifically involves suicidal thought or intent in rsuicidewatch rather than here if youre concerned about someone else who may be at risk for suicide please check out their talking tip and risk assessment guide finally discussion with the moderator of sw confirmed that active step are taken to move all suicidal ideation related content to sw given these consideration we expect that few suicidal ideation post appear on subreddits outside of sw,"['split', 'two', 'sequential', 'time', 'period', 'feb', 'aug', 'aug', 'november', 'using', 'two', 'time', 'period', 'created', 'two', 'set', 'note', 'since', 'reddit', 'doe', 'enforce', 'real', 'name', 'rule', 'exactly', 'one', 'account', 'per', 'person', 'reference', 'paper', 'equivalent', 'account', 'first', 'identified', 'posted', 'mhs', 'sw', 'ie', 'discus', 'topic', 'sw', 'hereafter', 'mh', 'second', 'class', 'included', 'posted', 'mhs', 'posted', 'sw', 'ie', 'discus', 'topic', 'originally', 'related', 'suicide', 'eventually', 'transition', 'talk', 'suicide', 'hereafter', 'mh', 'sw', 'figure', 'show', 'schematic', 'description', 'class', 'construction', 'note', 'focusing', 'initiate', 'least', 'one', 'sw', 'mhs', 'opposed', 'commenting', 'focus', 'frequenting', 'community', 'support', 'disregarding', 'primarily', 'providing', 'help', 'commentary', 'split', 'yielded', 'mh', 'sw', 'total', 'number', 'account', 'posted', 'mhs', 'never', 'sw', 'either', 'period', 'construct', 'mh', 'cohort', 'equal', 'size', 'sw', 'either', 'period', 'randomly', 'sampled', 'set', 'note', 'although', 'mh', 'sw', 'timeframe', 'analysis', 'may', 'done', 'outside', 'bound', 'analysis', 'support', 'goal', 'characterizing', 'difference', 'mh', 'sw', 'mh', 'obtained', 'via', 'reddits', 'api', 'timeline', 'comment', 'authored', 'api', 'provides', 'last', 'public', 'comment', 'obtained', 'associated', 'metadata', 'eg', 'vote', 'difference', 'score', 'comment', 'final', 'dataset', 'contained', 'comment', 'mh', 'sw', 'comment', 'mh', 'note', 'important', 'concern', 'individual', 'may', 'suicidal', 'thought', 'mhs', 'never', 'engaging', 'sw', 'thus', 'corrupting', 'mhs', 'discussion', 'suicidal', 'ideation', 'argue', 'possibility', 'sw', 'prominent', 'suicide', 'support', 'forum', 'role', 'community', 'suicide', 'prevention', 'acting', 'inoculator', 'vulnerable', 'thought', 'wellrecognized', 'mhs', 'eg', 'rdepression', 'clearly', 'specify', 'guideline', 'suicidal', 'thought', 'go', 'sw', 'usually', 'better', 'anything', 'specifically', 'involves', 'suicidal', 'thought', 'intent', 'rsuicidewatch', 'rather', 'youre', 'concerned', 'someone', 'else', 'may', 'risk', 'suicide', 'please', 'check', 'talking', 'tip', 'risk', 'assessment', 'guide', 'finally', 'discussion', 'moderator', 'sw', 'confirmed', 'active', 'step', 'taken', 'move', 'suicidal', 'ideation', 'related', 'content', 'sw', 'given', 'consideration', 'expect', 'suicidal', 'ideation', 'appear', 'subreddits', 'outside', 'sw']","['split two', 'two sequential', 'sequential time', 'time period', 'period feb', 'feb aug', 'aug aug', 'aug november', 'november using', 'using two', 'two time', 'time period', 'period created', 'created two', 'two set', 'set note', 'note since', 'since reddit', 'reddit doe', 'doe enforce', 'enforce real', 'real name', 'name rule', 'rule exactly', 'exactly one', 'one account', 'account per', 'per person', 'person reference', 'reference paper', 'paper equivalent', 'equivalent account', 'account first', 'first identified', 'identified posted', 'posted mhs', 'mhs sw', 'sw ie', 'ie discus', 'discus topic', 'topic sw', 'sw hereafter', 'hereafter mh', 'mh second', 'second class', 'class included', 'included posted', 'posted mhs', 'mhs posted', 'posted sw', 'sw ie', 'ie discus', 'discus topic', 'topic originally', 'originally related', 'related suicide', 'suicide eventually', 'eventually transition', 'transition talk', 'talk suicide', 'suicide hereafter', 'hereafter mh', 'mh sw', 'sw figure', 'figure show', 'show schematic', 'schematic description', 'description class', 'class construction', 'construction note', 'note focusing', 'focusing initiate', 'initiate least', 'least one', 'one sw', 'sw mhs', 'mhs opposed', 'opposed commenting', 'commenting focus', 'focus frequenting', 'frequenting community', 'community support', 'support disregarding', 'disregarding primarily', 'primarily providing', 'providing help', 'help commentary', 'commentary split', 'split yielded', 'yielded mh', 'mh sw', 'sw total', 'total number', 'number account', 'account posted', 'posted mhs', 'mhs never', 'never sw', 'sw either', 'either period', 'period construct', 'construct mh', 'mh cohort', 'cohort equal', 'equal size', 'size sw', 'sw either', 'either period', 'period randomly', 'randomly sampled', 'sampled set', 'set note', 'note although', 'although mh', 'mh sw', 'sw timeframe', 'timeframe analysis', 'analysis may', 'may done', 'done outside', 'outside bound', 'bound analysis', 'analysis support', 'support goal', 'goal characterizing', 'characterizing difference', 'difference mh', 'mh sw', 'sw mh', 'mh obtained', 'obtained via', 'via reddits', 'reddits api', 'api timeline', 'timeline comment', 'comment authored', 'authored api', 'api provides', 'provides last', 'last public', 'public comment', 'comment obtained', 'obtained associated', 'associated metadata', 'metadata eg', 'eg vote', 'vote difference', 'difference score', 'score comment', 'comment final', 'final dataset', 'dataset contained', 'contained comment', 'comment mh', 'mh sw', 'sw comment', 'comment mh', 'mh note', 'note important', 'important concern', 'concern individual', 'individual may', 'may suicidal', 'suicidal thought', 'thought mhs', 'mhs never', 'never engaging', 'engaging sw', 'sw thus', 'thus corrupting', 'corrupting mhs', 'mhs discussion', 'discussion suicidal', 'suicidal ideation', 'ideation argue', 'argue possibility', 'possibility sw', 'sw prominent', 'prominent suicide', 'suicide support', 'support forum', 'forum role', 'role community', 'community suicide', 'suicide prevention', 'prevention acting', 'acting inoculator', 'inoculator vulnerable', 'vulnerable thought', 'thought wellrecognized', 'wellrecognized mhs', 'mhs eg', 'eg rdepression', 'rdepression clearly', 'clearly specify', 'specify guideline', 'guideline suicidal', 'suicidal thought', 'thought go', 'go sw', 'sw usually', 'usually better', 'better anything', 'anything specifically', 'specifically involves', 'involves suicidal', 'suicidal thought', 'thought intent', 'intent rsuicidewatch', 'rsuicidewatch rather', 'rather youre', 'youre concerned', 'concerned someone', 'someone else', 'else may', 'may risk', 'risk suicide', 'suicide please', 'please check', 'check talking', 'talking tip', 'tip risk', 'risk assessment', 'assessment guide', 'guide finally', 'finally discussion', 'discussion moderator', 'moderator sw', 'sw confirmed', 'confirmed active', 'active step', 'step taken', 'taken move', 'move suicidal', 'suicidal ideation', 'ideation related', 'related content', 'content sw', 'sw given', 'given consideration', 'consideration expect', 'expect suicidal', 'suicidal ideation', 'ideation appear', 'appear subreddits', 'subreddits outside', 'outside sw']","['split two sequential', 'two sequential time', 'sequential time period', 'time period feb', 'period feb aug', 'feb aug aug', 'aug aug november', 'aug november using', 'november using two', 'using two time', 'two time period', 'time period created', 'period created two', 'created two set', 'two set note', 'set note since', 'note since reddit', 'since reddit doe', 'reddit doe enforce', 'doe enforce real', 'enforce real name', 'real name rule', 'name rule exactly', 'rule exactly one', 'exactly one account', 'one account per', 'account per person', 'per person reference', 'person reference paper', 'reference paper equivalent', 'paper equivalent account', 'equivalent account first', 'account first identified', 'first identified posted', 'identified posted mhs', 'posted mhs sw', 'mhs sw ie', 'sw ie discus', 'ie discus topic', 'discus topic sw', 'topic sw hereafter', 'sw hereafter mh', 'hereafter mh second', 'mh second class', 'second class included', 'class included posted', 'included posted mhs', 'posted mhs posted', 'mhs posted sw', 'posted sw ie', 'sw ie discus', 'ie discus topic', 'discus topic originally', 'topic originally related', 'originally related suicide', 'related suicide eventually', 'suicide eventually transition', 'eventually transition talk', 'transition talk suicide', 'talk suicide hereafter', 'suicide hereafter mh', 'hereafter mh sw', 'mh sw figure', 'sw figure show', 'figure show schematic', 'show schematic description', 'schematic description class', 'description class construction', 'class construction note', 'construction note focusing', 'note focusing initiate', 'focusing initiate least', 'initiate least one', 'least one sw', 'one sw mhs', 'sw mhs opposed', 'mhs opposed commenting', 'opposed commenting focus', 'commenting focus frequenting', 'focus frequenting community', 'frequenting community support', 'community support disregarding', 'support disregarding primarily', 'disregarding primarily providing', 'primarily providing help', 'providing help commentary', 'help commentary split', 'commentary split yielded', 'split yielded mh', 'yielded mh sw', 'mh sw total', 'sw total number', 'total number account', 'number account posted', 'account posted mhs', 'posted mhs never', 'mhs never sw', 'never sw either', 'sw either period', 'either period construct', 'period construct mh', 'construct mh cohort', 'mh cohort equal', 'cohort equal size', 'equal size sw', 'size sw either', 'sw either period', 'either period randomly', 'period randomly sampled', 'randomly sampled set', 'sampled set note', 'set note although', 'note although mh', 'although mh sw', 'mh sw timeframe', 'sw timeframe analysis', 'timeframe analysis may', 'analysis may done', 'may done outside', 'done outside bound', 'outside bound analysis', 'bound analysis support', 'analysis support goal', 'support goal characterizing', 'goal characterizing difference', 'characterizing difference mh', 'difference mh sw', 'mh sw mh', 'sw mh obtained', 'mh obtained via', 'obtained via reddits', 'via reddits api', 'reddits api timeline', 'api timeline comment', 'timeline comment authored', 'comment authored api', 'authored api provides', 'api provides last', 'provides last public', 'last public comment', 'public comment obtained', 'comment obtained associated', 'obtained associated metadata', 'associated metadata eg', 'metadata eg vote', 'eg vote difference', 'vote difference score', 'difference score comment', 'score comment final', 'comment final dataset', 'final dataset contained', 'dataset contained comment', 'contained comment mh', 'comment mh sw', 'mh sw comment', 'sw comment mh', 'comment mh note', 'mh note important', 'note important concern', 'important concern individual', 'concern individual may', 'individual may suicidal', 'may suicidal thought', 'suicidal thought mhs', 'thought mhs never', 'mhs never engaging', 'never engaging sw', 'engaging sw thus', 'sw thus corrupting', 'thus corrupting mhs', 'corrupting mhs discussion', 'mhs discussion suicidal', 'discussion suicidal ideation', 'suicidal ideation argue', 'ideation argue possibility', 'argue possibility sw', 'possibility sw prominent', 'sw prominent suicide', 'prominent suicide support', 'suicide support forum', 'support forum role', 'forum role community', 'role community suicide', 'community suicide prevention', 'suicide prevention acting', 'prevention acting inoculator', 'acting inoculator vulnerable', 'inoculator vulnerable thought', 'vulnerable thought wellrecognized', 'thought wellrecognized mhs', 'wellrecognized mhs eg', 'mhs eg rdepression', 'eg rdepression clearly', 'rdepression clearly specify', 'clearly specify guideline', 'specify guideline suicidal', 'guideline suicidal thought', 'suicidal thought go', 'thought go sw', 'go sw usually', 'sw usually better', 'usually better anything', 'better anything specifically', 'anything specifically involves', 'specifically involves suicidal', 'involves suicidal thought', 'suicidal thought intent', 'thought intent rsuicidewatch', 'intent rsuicidewatch rather', 'rsuicidewatch rather youre', 'rather youre concerned', 'youre concerned someone', 'concerned someone else', 'someone else may', 'else may risk', 'may risk suicide', 'risk suicide please', 'suicide please check', 'please check talking', 'check talking tip', 'talking tip risk', 'tip risk assessment', 'risk assessment guide', 'assessment guide finally', 'guide finally discussion', 'finally discussion moderator', 'discussion moderator sw', 'moderator sw confirmed', 'sw confirmed active', 'confirmed active step', 'active step taken', 'step taken move', 'taken move suicidal', 'move suicidal ideation', 'suicidal ideation related', 'ideation related content', 'related content sw', 'content sw given', 'sw given consideration', 'given consideration expect', 'consideration expect suicidal', 'expect suicidal ideation', 'suicidal ideation appear', 'ideation appear subreddits', 'appear subreddits outside', 'subreddits outside sw']"
https://dl.acm.org/doi/abs/10.1145/2702613.2732733,1,Automatic detection of self-disclosure levels in posts necessitates obtaining gold standard labels on self-disclosure in essence “ground truth”. For the purpose two raters familiar with Reddit and its mental health communities in particular independently rated a small random sample (50 posts) with equal proportions from mental health and control subreddits for three levels of self-disclosure – no selfdisclosure low and high self-disclosure. These three classes of self-disclosure were chosen based on categorization by Bak et al in [10]. The raters mutually discussed their labels thereafter and thus came up with a set of rules for rating. The rules were further aligned with observations in prior work [9 10 11]. Per the rules: Posts that either reveal personal information (e.g. age location gender etc.) or divulge sensitive or vulnerable thoughts beliefs or embarrassing/confessional experiences were to be considered to be indicative of high self-disclosure. Joinson [10] characterized sensitive disclosure in terms of the extent of “revealed vulnerability”. Posts about self but not disclosing any personal or emotionally vulnerable content was to be considered of low self-disclosure. No self-disclosure posts were those which were about people or things other than the posting author and which divulged information unrelated to the self. Following these mutually agreed upon rules the previous two raters and an additional rater familiar with Reddit independently coded a larger sample of 800 posts to create a training set for the purposes of classification. The raters had good agreement in their ratings: Fleiss’ Kappa was found to be .73. However given the subjective nature of characterization of self-disclosure we considered only those posts in the training set for which we had agreement across all three raters – this gave us 627 posts. Across the three categories the coded set consisted of 38% posts of high selfdisclosure 35% posts of low self-disclosure and 27% with no self-disclosure. Table 3 gives examples of mental health post excerpts with high self-disclosure while Table 4 and 5 provide examples of low and no self-disclosure posts. Note that including non-mental health posts in the training set was essential so as to let the detector learn on posts of low and no self-disclosure and on those not mental health related.We used Reddit's official API to collect posts comments on posts and associated metadata from several mental health focused subreddits. We build on the data collection methodology we used in [4]. In order to arrive at a comprehensive list of subreddits to focus on we utilized Reddit's native subreddit search feature (http://www.reddit.com/reddits). We searched for subreddits on “mental health”. Two researchers familiar with Reddit employed an initial filtering step on the search results returned so that we “seed” on high precision subreddits discussing mental health concerns. Thereafter we focused on a snowball approach to compile a second list of “related” or “similar” subreddits that are mentioned in the profile pages of the seed subreddits. Sample of subreddits (31 in all) we crawled are given in Table 1. Note all of these subreddits host public content. For the purposes of self-disclosure detection we also identified subreddits (sample listed in Table 2) as our control group (total of 12 subreddits) – meaning they are unrelated to mental health topics. For sanity check we randomly sampled a set of 200 posts from the control subreddits and two researchers familiar with Reddit manually checked their content for presence of any mental health content. We found that 97% of subreddit content in our sample were not about any mental health concern (Cohen’s Kappa for inter-rater agreement was .84). In all our dataset had 32509 posts from 23807 users in the mental health subreddits and 15383 posts from 13216 users in the control forums. For each of the unique users in the mental health forums we further collected all of their Reddit post/comment histories (last 1000 posts/comments per Reddit API limits) if their number of posts and comments in our dataset was five or more – this gave us 7248 users and 4.1M posts/comments,automatic detection of selfdisclosure level in post necessitates obtaining gold standard label on selfdisclosure in essence ground truth for the purpose two raters familiar with reddit and it mental health community in particular independently rated a small random sample post with equal proportion from mental health and control subreddits for three level of selfdisclosure no selfdisclosure low and high selfdisclosure these three class of selfdisclosure were chosen based on categorization by bak et al in the raters mutually discussed their label thereafter and thus came up with a set of rule for rating the rule were further aligned with observation in prior work per the rule post that either reveal personal information eg age location gender etc or divulge sensitive or vulnerable thought belief or embarrassingconfessional experience were to be considered to be indicative of high selfdisclosure joinson characterized sensitive disclosure in term of the extent of revealed vulnerability post about self but not disclosing any personal or emotionally vulnerable content wa to be considered of low selfdisclosure no selfdisclosure post were those which were about people or thing other than the posting author and which divulged information unrelated to the self following these mutually agreed upon rule the previous two raters and an additional rater familiar with reddit independently coded a larger sample of post to create a training set for the purpose of classification the raters had good agreement in their rating fleiss kappa wa found to be however given the subjective nature of characterization of selfdisclosure we considered only those post in the training set for which we had agreement across all three raters this gave u post across the three category the coded set consisted of post of high selfdisclosure post of low selfdisclosure and with no selfdisclosure table give example of mental health post excerpt with high selfdisclosure while table and provide example of low and no selfdisclosure post note that including nonmental health post in the training set wa essential so a to let the detector learn on post of low and no selfdisclosure and on those not mental health relatedwe used reddits official api to collect post comment on post and associated metadata from several mental health focused subreddits we build on the data collection methodology we used in in order to arrive at a comprehensive list of subreddits to focus on we utilized reddits native subreddit search feature httpwwwredditcomreddits we searched for subreddits on mental health two researcher familiar with reddit employed an initial filtering step on the search result returned so that we seed on high precision subreddits discussing mental health concern thereafter we focused on a snowball approach to compile a second list of related or similar subreddits that are mentioned in the profile page of the seed subreddits sample of subreddits in all we crawled are given in table note all of these subreddits host public content for the purpose of selfdisclosure detection we also identified subreddits sample listed in table a our control group total of subreddits meaning they are unrelated to mental health topic for sanity check we randomly sampled a set of post from the control subreddits and two researcher familiar with reddit manually checked their content for presence of any mental health content we found that of subreddit content in our sample were not about any mental health concern cohens kappa for interrater agreement wa in all our dataset had post from user in the mental health subreddits and post from user in the control forum for each of the unique user in the mental health forum we further collected all of their reddit postcomment history last postscomments per reddit api limit if their number of post and comment in our dataset wa five or more this gave u user and m postscomments,"['automatic', 'detection', 'selfdisclosure', 'level', 'necessitates', 'obtaining', 'gold', 'standard', 'label', 'selfdisclosure', 'essence', 'ground', 'truth', 'purpose', 'two', 'raters', 'familiar', 'reddit', 'community', 'particular', 'independently', 'rated', 'small', 'random', 'sample', 'equal', 'proportion', 'subreddits', 'three', 'level', 'selfdisclosure', 'selfdisclosure', 'low', 'high', 'selfdisclosure', 'three', 'class', 'selfdisclosure', 'chosen', 'based', 'categorization', 'bak', 'et', 'al', 'raters', 'mutually', 'discussed', 'label', 'thereafter', 'thus', 'came', 'set', 'rule', 'rating', 'rule', 'aligned', 'observation', 'prior', 'work', 'per', 'rule', 'either', 'reveal', 'personal', 'information', 'eg', 'age', 'location', 'gender', 'etc', 'divulge', 'sensitive', 'vulnerable', 'thought', 'belief', 'embarrassingconfessional', 'experience', 'considered', 'indicative', 'high', 'selfdisclosure', 'joinson', 'characterized', 'sensitive', 'disclosure', 'term', 'extent', 'revealed', 'vulnerability', 'self', 'disclosing', 'personal', 'emotionally', 'vulnerable', 'content', 'considered', 'low', 'selfdisclosure', 'selfdisclosure', 'people', 'thing', 'posting', 'author', 'divulged', 'information', 'unrelated', 'self', 'following', 'mutually', 'agreed', 'upon', 'rule', 'previous', 'two', 'raters', 'additional', 'rater', 'familiar', 'reddit', 'independently', 'coded', 'larger', 'sample', 'create', 'training', 'set', 'purpose', 'classification', 'raters', 'good', 'agreement', 'rating', 'fleiss', 'kappa', 'found', 'however', 'given', 'subjective', 'nature', 'characterization', 'selfdisclosure', 'considered', 'training', 'set', 'agreement', 'across', 'three', 'raters', 'gave', 'u', 'across', 'three', 'category', 'coded', 'set', 'consisted', 'high', 'selfdisclosure', 'low', 'selfdisclosure', 'selfdisclosure', 'table', 'give', 'example', 'excerpt', 'high', 'selfdisclosure', 'table', 'provide', 'example', 'low', 'selfdisclosure', 'note', 'including', 'nonmental', 'training', 'set', 'essential', 'let', 'detector', 'learn', 'low', 'selfdisclosure', 'relatedwe', 'reddits', 'official', 'api', 'collect', 'comment', 'associated', 'metadata', 'several', 'focused', 'subreddits', 'build', 'collection', 'methodology', 'order', 'arrive', 'comprehensive', 'list', 'subreddits', 'focus', 'utilized', 'reddits', 'native', 'subreddit', 'search', 'feature', 'httpwwwredditcomreddits', 'searched', 'subreddits', 'two', 'researcher', 'familiar', 'reddit', 'employed', 'initial', 'filtering', 'step', 'search', 'result', 'returned', 'seed', 'high', 'precision', 'subreddits', 'discussing', 'concern', 'thereafter', 'focused', 'snowball', 'approach', 'compile', 'second', 'list', 'related', 'similar', 'subreddits', 'mentioned', 'profile', 'page', 'seed', 'subreddits', 'sample', 'subreddits', 'crawled', 'given', 'table', 'note', 'subreddits', 'host', 'public', 'content', 'purpose', 'selfdisclosure', 'detection', 'also', 'identified', 'subreddits', 'sample', 'listed', 'table', 'group', 'total', 'subreddits', 'meaning', 'unrelated', 'topic', 'sanity', 'check', 'randomly', 'sampled', 'set', 'subreddits', 'two', 'researcher', 'familiar', 'reddit', 'manually', 'checked', 'content', 'presence', 'content', 'found', 'subreddit', 'content', 'sample', 'concern', 'cohens', 'kappa', 'interrater', 'agreement', 'dataset', 'subreddits', 'forum', 'unique', 'forum', 'collected', 'reddit', 'postcomment', 'history', 'last', 'postscomments', 'per', 'reddit', 'api', 'limit', 'number', 'comment', 'dataset', 'five', 'gave', 'u', 'postscomments']","['automatic detection', 'detection selfdisclosure', 'selfdisclosure level', 'level necessitates', 'necessitates obtaining', 'obtaining gold', 'gold standard', 'standard label', 'label selfdisclosure', 'selfdisclosure essence', 'essence ground', 'ground truth', 'truth purpose', 'purpose two', 'two raters', 'raters familiar', 'familiar reddit', 'reddit community', 'community particular', 'particular independently', 'independently rated', 'rated small', 'small random', 'random sample', 'sample equal', 'equal proportion', 'proportion subreddits', 'subreddits three', 'three level', 'level selfdisclosure', 'selfdisclosure selfdisclosure', 'selfdisclosure low', 'low high', 'high selfdisclosure', 'selfdisclosure three', 'three class', 'class selfdisclosure', 'selfdisclosure chosen', 'chosen based', 'based categorization', 'categorization bak', 'bak et', 'et al', 'al raters', 'raters mutually', 'mutually discussed', 'discussed label', 'label thereafter', 'thereafter thus', 'thus came', 'came set', 'set rule', 'rule rating', 'rating rule', 'rule aligned', 'aligned observation', 'observation prior', 'prior work', 'work per', 'per rule', 'rule either', 'either reveal', 'reveal personal', 'personal information', 'information eg', 'eg age', 'age location', 'location gender', 'gender etc', 'etc divulge', 'divulge sensitive', 'sensitive vulnerable', 'vulnerable thought', 'thought belief', 'belief embarrassingconfessional', 'embarrassingconfessional experience', 'experience considered', 'considered indicative', 'indicative high', 'high selfdisclosure', 'selfdisclosure joinson', 'joinson characterized', 'characterized sensitive', 'sensitive disclosure', 'disclosure term', 'term extent', 'extent revealed', 'revealed vulnerability', 'vulnerability self', 'self disclosing', 'disclosing personal', 'personal emotionally', 'emotionally vulnerable', 'vulnerable content', 'content considered', 'considered low', 'low selfdisclosure', 'selfdisclosure selfdisclosure', 'selfdisclosure people', 'people thing', 'thing posting', 'posting author', 'author divulged', 'divulged information', 'information unrelated', 'unrelated self', 'self following', 'following mutually', 'mutually agreed', 'agreed upon', 'upon rule', 'rule previous', 'previous two', 'two raters', 'raters additional', 'additional rater', 'rater familiar', 'familiar reddit', 'reddit independently', 'independently coded', 'coded larger', 'larger sample', 'sample create', 'create training', 'training set', 'set purpose', 'purpose classification', 'classification raters', 'raters good', 'good agreement', 'agreement rating', 'rating fleiss', 'fleiss kappa', 'kappa found', 'found however', 'however given', 'given subjective', 'subjective nature', 'nature characterization', 'characterization selfdisclosure', 'selfdisclosure considered', 'considered training', 'training set', 'set agreement', 'agreement across', 'across three', 'three raters', 'raters gave', 'gave u', 'u across', 'across three', 'three category', 'category coded', 'coded set', 'set consisted', 'consisted high', 'high selfdisclosure', 'selfdisclosure low', 'low selfdisclosure', 'selfdisclosure selfdisclosure', 'selfdisclosure table', 'table give', 'give example', 'example excerpt', 'excerpt high', 'high selfdisclosure', 'selfdisclosure table', 'table provide', 'provide example', 'example low', 'low selfdisclosure', 'selfdisclosure note', 'note including', 'including nonmental', 'nonmental training', 'training set', 'set essential', 'essential let', 'let detector', 'detector learn', 'learn low', 'low selfdisclosure', 'selfdisclosure relatedwe', 'relatedwe reddits', 'reddits official', 'official api', 'api collect', 'collect comment', 'comment associated', 'associated metadata', 'metadata several', 'several focused', 'focused subreddits', 'subreddits build', 'build collection', 'collection methodology', 'methodology order', 'order arrive', 'arrive comprehensive', 'comprehensive list', 'list subreddits', 'subreddits focus', 'focus utilized', 'utilized reddits', 'reddits native', 'native subreddit', 'subreddit search', 'search feature', 'feature httpwwwredditcomreddits', 'httpwwwredditcomreddits searched', 'searched subreddits', 'subreddits two', 'two researcher', 'researcher familiar', 'familiar reddit', 'reddit employed', 'employed initial', 'initial filtering', 'filtering step', 'step search', 'search result', 'result returned', 'returned seed', 'seed high', 'high precision', 'precision subreddits', 'subreddits discussing', 'discussing concern', 'concern thereafter', 'thereafter focused', 'focused snowball', 'snowball approach', 'approach compile', 'compile second', 'second list', 'list related', 'related similar', 'similar subreddits', 'subreddits mentioned', 'mentioned profile', 'profile page', 'page seed', 'seed subreddits', 'subreddits sample', 'sample subreddits', 'subreddits crawled', 'crawled given', 'given table', 'table note', 'note subreddits', 'subreddits host', 'host public', 'public content', 'content purpose', 'purpose selfdisclosure', 'selfdisclosure detection', 'detection also', 'also identified', 'identified subreddits', 'subreddits sample', 'sample listed', 'listed table', 'table group', 'group total', 'total subreddits', 'subreddits meaning', 'meaning unrelated', 'unrelated topic', 'topic sanity', 'sanity check', 'check randomly', 'randomly sampled', 'sampled set', 'set subreddits', 'subreddits two', 'two researcher', 'researcher familiar', 'familiar reddit', 'reddit manually', 'manually checked', 'checked content', 'content presence', 'presence content', 'content found', 'found subreddit', 'subreddit content', 'content sample', 'sample concern', 'concern cohens', 'cohens kappa', 'kappa interrater', 'interrater agreement', 'agreement dataset', 'dataset subreddits', 'subreddits forum', 'forum unique', 'unique forum', 'forum collected', 'collected reddit', 'reddit postcomment', 'postcomment history', 'history last', 'last postscomments', 'postscomments per', 'per reddit', 'reddit api', 'api limit', 'limit number', 'number comment', 'comment dataset', 'dataset five', 'five gave', 'gave u', 'u postscomments']","['automatic detection selfdisclosure', 'detection selfdisclosure level', 'selfdisclosure level necessitates', 'level necessitates obtaining', 'necessitates obtaining gold', 'obtaining gold standard', 'gold standard label', 'standard label selfdisclosure', 'label selfdisclosure essence', 'selfdisclosure essence ground', 'essence ground truth', 'ground truth purpose', 'truth purpose two', 'purpose two raters', 'two raters familiar', 'raters familiar reddit', 'familiar reddit community', 'reddit community particular', 'community particular independently', 'particular independently rated', 'independently rated small', 'rated small random', 'small random sample', 'random sample equal', 'sample equal proportion', 'equal proportion subreddits', 'proportion subreddits three', 'subreddits three level', 'three level selfdisclosure', 'level selfdisclosure selfdisclosure', 'selfdisclosure selfdisclosure low', 'selfdisclosure low high', 'low high selfdisclosure', 'high selfdisclosure three', 'selfdisclosure three class', 'three class selfdisclosure', 'class selfdisclosure chosen', 'selfdisclosure chosen based', 'chosen based categorization', 'based categorization bak', 'categorization bak et', 'bak et al', 'et al raters', 'al raters mutually', 'raters mutually discussed', 'mutually discussed label', 'discussed label thereafter', 'label thereafter thus', 'thereafter thus came', 'thus came set', 'came set rule', 'set rule rating', 'rule rating rule', 'rating rule aligned', 'rule aligned observation', 'aligned observation prior', 'observation prior work', 'prior work per', 'work per rule', 'per rule either', 'rule either reveal', 'either reveal personal', 'reveal personal information', 'personal information eg', 'information eg age', 'eg age location', 'age location gender', 'location gender etc', 'gender etc divulge', 'etc divulge sensitive', 'divulge sensitive vulnerable', 'sensitive vulnerable thought', 'vulnerable thought belief', 'thought belief embarrassingconfessional', 'belief embarrassingconfessional experience', 'embarrassingconfessional experience considered', 'experience considered indicative', 'considered indicative high', 'indicative high selfdisclosure', 'high selfdisclosure joinson', 'selfdisclosure joinson characterized', 'joinson characterized sensitive', 'characterized sensitive disclosure', 'sensitive disclosure term', 'disclosure term extent', 'term extent revealed', 'extent revealed vulnerability', 'revealed vulnerability self', 'vulnerability self disclosing', 'self disclosing personal', 'disclosing personal emotionally', 'personal emotionally vulnerable', 'emotionally vulnerable content', 'vulnerable content considered', 'content considered low', 'considered low selfdisclosure', 'low selfdisclosure selfdisclosure', 'selfdisclosure selfdisclosure people', 'selfdisclosure people thing', 'people thing posting', 'thing posting author', 'posting author divulged', 'author divulged information', 'divulged information unrelated', 'information unrelated self', 'unrelated self following', 'self following mutually', 'following mutually agreed', 'mutually agreed upon', 'agreed upon rule', 'upon rule previous', 'rule previous two', 'previous two raters', 'two raters additional', 'raters additional rater', 'additional rater familiar', 'rater familiar reddit', 'familiar reddit independently', 'reddit independently coded', 'independently coded larger', 'coded larger sample', 'larger sample create', 'sample create training', 'create training set', 'training set purpose', 'set purpose classification', 'purpose classification raters', 'classification raters good', 'raters good agreement', 'good agreement rating', 'agreement rating fleiss', 'rating fleiss kappa', 'fleiss kappa found', 'kappa found however', 'found however given', 'however given subjective', 'given subjective nature', 'subjective nature characterization', 'nature characterization selfdisclosure', 'characterization selfdisclosure considered', 'selfdisclosure considered training', 'considered training set', 'training set agreement', 'set agreement across', 'agreement across three', 'across three raters', 'three raters gave', 'raters gave u', 'gave u across', 'u across three', 'across three category', 'three category coded', 'category coded set', 'coded set consisted', 'set consisted high', 'consisted high selfdisclosure', 'high selfdisclosure low', 'selfdisclosure low selfdisclosure', 'low selfdisclosure selfdisclosure', 'selfdisclosure selfdisclosure table', 'selfdisclosure table give', 'table give example', 'give example excerpt', 'example excerpt high', 'excerpt high selfdisclosure', 'high selfdisclosure table', 'selfdisclosure table provide', 'table provide example', 'provide example low', 'example low selfdisclosure', 'low selfdisclosure note', 'selfdisclosure note including', 'note including nonmental', 'including nonmental training', 'nonmental training set', 'training set essential', 'set essential let', 'essential let detector', 'let detector learn', 'detector learn low', 'learn low selfdisclosure', 'low selfdisclosure relatedwe', 'selfdisclosure relatedwe reddits', 'relatedwe reddits official', 'reddits official api', 'official api collect', 'api collect comment', 'collect comment associated', 'comment associated metadata', 'associated metadata several', 'metadata several focused', 'several focused subreddits', 'focused subreddits build', 'subreddits build collection', 'build collection methodology', 'collection methodology order', 'methodology order arrive', 'order arrive comprehensive', 'arrive comprehensive list', 'comprehensive list subreddits', 'list subreddits focus', 'subreddits focus utilized', 'focus utilized reddits', 'utilized reddits native', 'reddits native subreddit', 'native subreddit search', 'subreddit search feature', 'search feature httpwwwredditcomreddits', 'feature httpwwwredditcomreddits searched', 'httpwwwredditcomreddits searched subreddits', 'searched subreddits two', 'subreddits two researcher', 'two researcher familiar', 'researcher familiar reddit', 'familiar reddit employed', 'reddit employed initial', 'employed initial filtering', 'initial filtering step', 'filtering step search', 'step search result', 'search result returned', 'result returned seed', 'returned seed high', 'seed high precision', 'high precision subreddits', 'precision subreddits discussing', 'subreddits discussing concern', 'discussing concern thereafter', 'concern thereafter focused', 'thereafter focused snowball', 'focused snowball approach', 'snowball approach compile', 'approach compile second', 'compile second list', 'second list related', 'list related similar', 'related similar subreddits', 'similar subreddits mentioned', 'subreddits mentioned profile', 'mentioned profile page', 'profile page seed', 'page seed subreddits', 'seed subreddits sample', 'subreddits sample subreddits', 'sample subreddits crawled', 'subreddits crawled given', 'crawled given table', 'given table note', 'table note subreddits', 'note subreddits host', 'subreddits host public', 'host public content', 'public content purpose', 'content purpose selfdisclosure', 'purpose selfdisclosure detection', 'selfdisclosure detection also', 'detection also identified', 'also identified subreddits', 'identified subreddits sample', 'subreddits sample listed', 'sample listed table', 'listed table group', 'table group total', 'group total subreddits', 'total subreddits meaning', 'subreddits meaning unrelated', 'meaning unrelated topic', 'unrelated topic sanity', 'topic sanity check', 'sanity check randomly', 'check randomly sampled', 'randomly sampled set', 'sampled set subreddits', 'set subreddits two', 'subreddits two researcher', 'two researcher familiar', 'researcher familiar reddit', 'familiar reddit manually', 'reddit manually checked', 'manually checked content', 'checked content presence', 'content presence content', 'presence content found', 'content found subreddit', 'found subreddit content', 'subreddit content sample', 'content sample concern', 'sample concern cohens', 'concern cohens kappa', 'cohens kappa interrater', 'kappa interrater agreement', 'interrater agreement dataset', 'agreement dataset subreddits', 'dataset subreddits forum', 'subreddits forum unique', 'forum unique forum', 'unique forum collected', 'forum collected reddit', 'collected reddit postcomment', 'reddit postcomment history', 'postcomment history last', 'history last postscomments', 'last postscomments per', 'postscomments per reddit', 'per reddit api', 'reddit api limit', 'api limit number', 'limit number comment', 'number comment dataset', 'comment dataset five', 'dataset five gave', 'five gave u', 'gave u postscomments']"
https://dl.acm.org/doi/abs/10.1145/2702123.2702280,0,In this study we gathered information on depression levels of Twitter users and their activity histories. To do this we published a website to administer a questionnaire and disseminated information about the website over Twitter1. In contrast to De Choudhury et al. [14] who collected data from Englishspeaking users through crowdsourcing this study collected data from Japanese-speaking volunteers. This approach was used to investigate the extent to which depression risk can be estimated for a population different from the population considered by the prior research [14]. Figure 1 shows a screenshot of our website. The website collected the responses to a questionnaire to evaluate the degree of depression of the Twitter users who participated (hereinafter the participants) and to collect the histories of participants activities on Twitter. The activity histories of participants were collected through the Twitter application programming interface (API)2 and the questionnaires to determine degree of depression were completed by participants through their web browsers. Before data collection visitors to the website were presented with a written explanation of the aims of the experiment the information that would be collected and how that information would be handled. Those who consented to become participants after receiving the explanation logged into their individual Twitter accounts through the OAuth authorization process. Next participants were surveyed on gender age occupation and history of depression following which they answered a questionnaire designed to evaluate degree of depression. A message called the “kokoro score” (“kokoro” is a Japanese word meaning “heart”) determined on the basis of answers to the questionnaire and information in the collected tweets was displayed to participants after completion of the questionnaire (Fig. 2). Experiment participants were able to tweet the message displayed which made it possible to promote the website over Twitter by word-of-mouth in a type of snowball sampling. The CES-D questionnaire was used to evaluate the degree of depression [30]. In the CES-D test participants answered 20 questions on a Likert-type 4-point scale. Each answer was assigned a score of 0-3 points with the sum of the points from all answers used as the score to estimate likelihood of depression. Several standards exist by which to determine the appropriate cutoff score for identifying depression. In this research we regarded a score of 22 points or higher as indicating active depression and a score of 21 points or lower as indicating no active depression; these are the same values as used in [14] and give a cutoff score of 22. In addition answers to BDI [2] a depression scale used with characteristics similar to CESD were collected to ensure the reliability of data. For each participant scores were calculated on both scales with poor correlation regarded as indicating unreliable answers. The time taken to answer the questionnaires was also recorded and those completed in too brief a time were excluded. After each participant answered the questionnaire the activity history of that participant on Twitter was collected from Twitter by using the API. At most 3200 tweets were collected for each participant and the number of users following the participant and being followed by the participant were recorded. Tweets published after the questionnaire was taken were discarded. The website was opened to the public on 4 December 2013 at which time the authors publicized it on their Twitter accounts. Between 4 December 2013 and 8 February 2014 219 people participated in the experiment. After eliminating participants who did not tweet and participants who answered the questionnaire in fewer than 30 seconds (as previously mentioned to ensure the reliability of the questionnaire answers) 214 sets of answers remained. Only the first set of answers was used for participants who completed the questionnaire more than once. As a result data about 209 experiment participants (male: 121; female: 88) aged 16 to 55 (mean: 28.8 years; standard deviation: 8.2 years) were analyzed. The correlations between CES-D score and BDI score for these participants were high 0.87 and there were no participants with uncorrelated scores so the data for all 209 participants were used; excluded datasets are not discussed any further. Figure 3 shows the histogram of CES-D scores of 209 participants. Among the participants 81 (resp. 128) were estimated to have (resp. not have) active depression for an incidence of approximately 39%. This incidence is similar to that found by De Choudhury et al. [14] who identified depression in approximately 36% of participants. Table 1 gives statistics on the activity histories of participants.,in this study we gathered information on depression level of twitter user and their activity history to do this we published a website to administer a questionnaire and disseminated information about the website over twitter in contrast to de choudhury et al who collected data from englishspeaking user through crowdsourcing this study collected data from japanesespeaking volunteer this approach wa used to investigate the extent to which depression risk can be estimated for a population different from the population considered by the prior research figure show a screenshot of our website the website collected the response to a questionnaire to evaluate the degree of depression of the twitter user who participated hereinafter the participant and to collect the history of participant activity on twitter the activity history of participant were collected through the twitter application programming interface api and the questionnaire to determine degree of depression were completed by participant through their web browser before data collection visitor to the website were presented with a written explanation of the aim of the experiment the information that would be collected and how that information would be handled those who consented to become participant after receiving the explanation logged into their individual twitter account through the oauth authorization process next participant were surveyed on gender age occupation and history of depression following which they answered a questionnaire designed to evaluate degree of depression a message called the kokoro score kokoro is a japanese word meaning heart determined on the basis of answer to the questionnaire and information in the collected tweet wa displayed to participant after completion of the questionnaire fig experiment participant were able to tweet the message displayed which made it possible to promote the website over twitter by wordofmouth in a type of snowball sampling the cesd questionnaire wa used to evaluate the degree of depression in the cesd test participant answered question on a likerttype point scale each answer wa assigned a score of point with the sum of the point from all answer used a the score to estimate likelihood of depression several standard exist by which to determine the appropriate cutoff score for identifying depression in this research we regarded a score of point or higher a indicating active depression and a score of point or lower a indicating no active depression these are the same value a used in and give a cutoff score of in addition answer to bdi a depression scale used with characteristic similar to cesd were collected to ensure the reliability of data for each participant score were calculated on both scale with poor correlation regarded a indicating unreliable answer the time taken to answer the questionnaire wa also recorded and those completed in too brief a time were excluded after each participant answered the questionnaire the activity history of that participant on twitter wa collected from twitter by using the api at most tweet were collected for each participant and the number of user following the participant and being followed by the participant were recorded tweet published after the questionnaire wa taken were discarded the website wa opened to the public on december at which time the author publicized it on their twitter account between december and february people participated in the experiment after eliminating participant who did not tweet and participant who answered the questionnaire in fewer than second a previously mentioned to ensure the reliability of the questionnaire answer set of answer remained only the first set of answer wa used for participant who completed the questionnaire more than once a a result data about experiment participant male female aged to mean year standard deviation year were analyzed the correlation between cesd score and bdi score for these participant were high and there were no participant with uncorrelated score so the data for all participant were used excluded datasets are not discussed any further figure show the histogram of cesd score of participant among the participant resp were estimated to have resp not have active depression for an incidence of approximately this incidence is similar to that found by de choudhury et al who identified depression in approximately of participant table give statistic on the activity history of participant,"['study', 'gathered', 'information', 'level', 'activity', 'history', 'published', 'website', 'administer', 'questionnaire', 'disseminated', 'information', 'website', 'contrast', 'de', 'choudhury', 'et', 'al', 'collected', 'englishspeaking', 'crowdsourcing', 'study', 'collected', 'japanesespeaking', 'volunteer', 'approach', 'investigate', 'extent', 'risk', 'estimated', 'population', 'different', 'population', 'considered', 'prior', 'research', 'figure', 'show', 'screenshot', 'website', 'website', 'collected', 'response', 'questionnaire', 'evaluate', 'degree', 'participated', 'hereinafter', 'collect', 'history', 'activity', 'activity', 'history', 'collected', 'application', 'programming', 'interface', 'api', 'questionnaire', 'determine', 'degree', 'completed', 'web', 'browser', 'collection', 'visitor', 'website', 'presented', 'written', 'explanation', 'aim', 'experiment', 'information', 'would', 'collected', 'information', 'would', 'handled', 'consented', 'become', 'receiving', 'explanation', 'logged', 'individual', 'account', 'oauth', 'authorization', 'process', 'next', 'surveyed', 'gender', 'age', 'occupation', 'history', 'following', 'answered', 'questionnaire', 'designed', 'evaluate', 'degree', 'message', 'called', 'kokoro', 'score', 'kokoro', 'japanese', 'meaning', 'heart', 'determined', 'basis', 'answer', 'questionnaire', 'information', 'collected', 'displayed', 'completion', 'questionnaire', 'fig', 'experiment', 'able', 'message', 'displayed', 'made', 'possible', 'promote', 'website', 'wordofmouth', 'type', 'snowball', 'sampling', 'cesd', 'questionnaire', 'evaluate', 'degree', 'cesd', 'test', 'answered', 'question', 'likerttype', 'point', 'scale', 'answer', 'assigned', 'score', 'point', 'sum', 'point', 'answer', 'score', 'estimate', 'likelihood', 'several', 'standard', 'exist', 'determine', 'appropriate', 'cutoff', 'score', 'identifying', 'research', 'regarded', 'score', 'point', 'higher', 'indicating', 'active', 'score', 'point', 'lower', 'indicating', 'active', 'value', 'give', 'cutoff', 'score', 'addition', 'answer', 'bdi', 'scale', 'characteristic', 'similar', 'cesd', 'collected', 'ensure', 'reliability', 'score', 'calculated', 'scale', 'poor', 'correlation', 'regarded', 'indicating', 'unreliable', 'answer', 'time', 'taken', 'answer', 'questionnaire', 'also', 'recorded', 'completed', 'brief', 'time', 'excluded', 'answered', 'questionnaire', 'activity', 'history', 'collected', 'using', 'api', 'collected', 'number', 'following', 'followed', 'recorded', 'published', 'questionnaire', 'taken', 'discarded', 'website', 'opened', 'public', 'december', 'time', 'author', 'publicized', 'account', 'december', 'february', 'people', 'participated', 'experiment', 'eliminating', 'answered', 'questionnaire', 'fewer', 'second', 'previously', 'mentioned', 'ensure', 'reliability', 'questionnaire', 'answer', 'set', 'answer', 'remained', 'first', 'set', 'answer', 'completed', 'questionnaire', 'result', 'experiment', 'male', 'female', 'aged', 'mean', 'year', 'standard', 'deviation', 'year', 'analyzed', 'correlation', 'cesd', 'score', 'bdi', 'score', 'high', 'uncorrelated', 'score', 'excluded', 'datasets', 'discussed', 'figure', 'show', 'histogram', 'cesd', 'score', 'among', 'resp', 'estimated', 'resp', 'active', 'incidence', 'approximately', 'incidence', 'similar', 'found', 'de', 'choudhury', 'et', 'al', 'identified', 'approximately', 'table', 'give', 'statistic', 'activity', 'history']","['study gathered', 'gathered information', 'information level', 'level activity', 'activity history', 'history published', 'published website', 'website administer', 'administer questionnaire', 'questionnaire disseminated', 'disseminated information', 'information website', 'website contrast', 'contrast de', 'de choudhury', 'choudhury et', 'et al', 'al collected', 'collected englishspeaking', 'englishspeaking crowdsourcing', 'crowdsourcing study', 'study collected', 'collected japanesespeaking', 'japanesespeaking volunteer', 'volunteer approach', 'approach investigate', 'investigate extent', 'extent risk', 'risk estimated', 'estimated population', 'population different', 'different population', 'population considered', 'considered prior', 'prior research', 'research figure', 'figure show', 'show screenshot', 'screenshot website', 'website website', 'website collected', 'collected response', 'response questionnaire', 'questionnaire evaluate', 'evaluate degree', 'degree participated', 'participated hereinafter', 'hereinafter collect', 'collect history', 'history activity', 'activity activity', 'activity history', 'history collected', 'collected application', 'application programming', 'programming interface', 'interface api', 'api questionnaire', 'questionnaire determine', 'determine degree', 'degree completed', 'completed web', 'web browser', 'browser collection', 'collection visitor', 'visitor website', 'website presented', 'presented written', 'written explanation', 'explanation aim', 'aim experiment', 'experiment information', 'information would', 'would collected', 'collected information', 'information would', 'would handled', 'handled consented', 'consented become', 'become receiving', 'receiving explanation', 'explanation logged', 'logged individual', 'individual account', 'account oauth', 'oauth authorization', 'authorization process', 'process next', 'next surveyed', 'surveyed gender', 'gender age', 'age occupation', 'occupation history', 'history following', 'following answered', 'answered questionnaire', 'questionnaire designed', 'designed evaluate', 'evaluate degree', 'degree message', 'message called', 'called kokoro', 'kokoro score', 'score kokoro', 'kokoro japanese', 'japanese meaning', 'meaning heart', 'heart determined', 'determined basis', 'basis answer', 'answer questionnaire', 'questionnaire information', 'information collected', 'collected displayed', 'displayed completion', 'completion questionnaire', 'questionnaire fig', 'fig experiment', 'experiment able', 'able message', 'message displayed', 'displayed made', 'made possible', 'possible promote', 'promote website', 'website wordofmouth', 'wordofmouth type', 'type snowball', 'snowball sampling', 'sampling cesd', 'cesd questionnaire', 'questionnaire evaluate', 'evaluate degree', 'degree cesd', 'cesd test', 'test answered', 'answered question', 'question likerttype', 'likerttype point', 'point scale', 'scale answer', 'answer assigned', 'assigned score', 'score point', 'point sum', 'sum point', 'point answer', 'answer score', 'score estimate', 'estimate likelihood', 'likelihood several', 'several standard', 'standard exist', 'exist determine', 'determine appropriate', 'appropriate cutoff', 'cutoff score', 'score identifying', 'identifying research', 'research regarded', 'regarded score', 'score point', 'point higher', 'higher indicating', 'indicating active', 'active score', 'score point', 'point lower', 'lower indicating', 'indicating active', 'active value', 'value give', 'give cutoff', 'cutoff score', 'score addition', 'addition answer', 'answer bdi', 'bdi scale', 'scale characteristic', 'characteristic similar', 'similar cesd', 'cesd collected', 'collected ensure', 'ensure reliability', 'reliability score', 'score calculated', 'calculated scale', 'scale poor', 'poor correlation', 'correlation regarded', 'regarded indicating', 'indicating unreliable', 'unreliable answer', 'answer time', 'time taken', 'taken answer', 'answer questionnaire', 'questionnaire also', 'also recorded', 'recorded completed', 'completed brief', 'brief time', 'time excluded', 'excluded answered', 'answered questionnaire', 'questionnaire activity', 'activity history', 'history collected', 'collected using', 'using api', 'api collected', 'collected number', 'number following', 'following followed', 'followed recorded', 'recorded published', 'published questionnaire', 'questionnaire taken', 'taken discarded', 'discarded website', 'website opened', 'opened public', 'public december', 'december time', 'time author', 'author publicized', 'publicized account', 'account december', 'december february', 'february people', 'people participated', 'participated experiment', 'experiment eliminating', 'eliminating answered', 'answered questionnaire', 'questionnaire fewer', 'fewer second', 'second previously', 'previously mentioned', 'mentioned ensure', 'ensure reliability', 'reliability questionnaire', 'questionnaire answer', 'answer set', 'set answer', 'answer remained', 'remained first', 'first set', 'set answer', 'answer completed', 'completed questionnaire', 'questionnaire result', 'result experiment', 'experiment male', 'male female', 'female aged', 'aged mean', 'mean year', 'year standard', 'standard deviation', 'deviation year', 'year analyzed', 'analyzed correlation', 'correlation cesd', 'cesd score', 'score bdi', 'bdi score', 'score high', 'high uncorrelated', 'uncorrelated score', 'score excluded', 'excluded datasets', 'datasets discussed', 'discussed figure', 'figure show', 'show histogram', 'histogram cesd', 'cesd score', 'score among', 'among resp', 'resp estimated', 'estimated resp', 'resp active', 'active incidence', 'incidence approximately', 'approximately incidence', 'incidence similar', 'similar found', 'found de', 'de choudhury', 'choudhury et', 'et al', 'al identified', 'identified approximately', 'approximately table', 'table give', 'give statistic', 'statistic activity', 'activity history']","['study gathered information', 'gathered information level', 'information level activity', 'level activity history', 'activity history published', 'history published website', 'published website administer', 'website administer questionnaire', 'administer questionnaire disseminated', 'questionnaire disseminated information', 'disseminated information website', 'information website contrast', 'website contrast de', 'contrast de choudhury', 'de choudhury et', 'choudhury et al', 'et al collected', 'al collected englishspeaking', 'collected englishspeaking crowdsourcing', 'englishspeaking crowdsourcing study', 'crowdsourcing study collected', 'study collected japanesespeaking', 'collected japanesespeaking volunteer', 'japanesespeaking volunteer approach', 'volunteer approach investigate', 'approach investigate extent', 'investigate extent risk', 'extent risk estimated', 'risk estimated population', 'estimated population different', 'population different population', 'different population considered', 'population considered prior', 'considered prior research', 'prior research figure', 'research figure show', 'figure show screenshot', 'show screenshot website', 'screenshot website website', 'website website collected', 'website collected response', 'collected response questionnaire', 'response questionnaire evaluate', 'questionnaire evaluate degree', 'evaluate degree participated', 'degree participated hereinafter', 'participated hereinafter collect', 'hereinafter collect history', 'collect history activity', 'history activity activity', 'activity activity history', 'activity history collected', 'history collected application', 'collected application programming', 'application programming interface', 'programming interface api', 'interface api questionnaire', 'api questionnaire determine', 'questionnaire determine degree', 'determine degree completed', 'degree completed web', 'completed web browser', 'web browser collection', 'browser collection visitor', 'collection visitor website', 'visitor website presented', 'website presented written', 'presented written explanation', 'written explanation aim', 'explanation aim experiment', 'aim experiment information', 'experiment information would', 'information would collected', 'would collected information', 'collected information would', 'information would handled', 'would handled consented', 'handled consented become', 'consented become receiving', 'become receiving explanation', 'receiving explanation logged', 'explanation logged individual', 'logged individual account', 'individual account oauth', 'account oauth authorization', 'oauth authorization process', 'authorization process next', 'process next surveyed', 'next surveyed gender', 'surveyed gender age', 'gender age occupation', 'age occupation history', 'occupation history following', 'history following answered', 'following answered questionnaire', 'answered questionnaire designed', 'questionnaire designed evaluate', 'designed evaluate degree', 'evaluate degree message', 'degree message called', 'message called kokoro', 'called kokoro score', 'kokoro score kokoro', 'score kokoro japanese', 'kokoro japanese meaning', 'japanese meaning heart', 'meaning heart determined', 'heart determined basis', 'determined basis answer', 'basis answer questionnaire', 'answer questionnaire information', 'questionnaire information collected', 'information collected displayed', 'collected displayed completion', 'displayed completion questionnaire', 'completion questionnaire fig', 'questionnaire fig experiment', 'fig experiment able', 'experiment able message', 'able message displayed', 'message displayed made', 'displayed made possible', 'made possible promote', 'possible promote website', 'promote website wordofmouth', 'website wordofmouth type', 'wordofmouth type snowball', 'type snowball sampling', 'snowball sampling cesd', 'sampling cesd questionnaire', 'cesd questionnaire evaluate', 'questionnaire evaluate degree', 'evaluate degree cesd', 'degree cesd test', 'cesd test answered', 'test answered question', 'answered question likerttype', 'question likerttype point', 'likerttype point scale', 'point scale answer', 'scale answer assigned', 'answer assigned score', 'assigned score point', 'score point sum', 'point sum point', 'sum point answer', 'point answer score', 'answer score estimate', 'score estimate likelihood', 'estimate likelihood several', 'likelihood several standard', 'several standard exist', 'standard exist determine', 'exist determine appropriate', 'determine appropriate cutoff', 'appropriate cutoff score', 'cutoff score identifying', 'score identifying research', 'identifying research regarded', 'research regarded score', 'regarded score point', 'score point higher', 'point higher indicating', 'higher indicating active', 'indicating active score', 'active score point', 'score point lower', 'point lower indicating', 'lower indicating active', 'indicating active value', 'active value give', 'value give cutoff', 'give cutoff score', 'cutoff score addition', 'score addition answer', 'addition answer bdi', 'answer bdi scale', 'bdi scale characteristic', 'scale characteristic similar', 'characteristic similar cesd', 'similar cesd collected', 'cesd collected ensure', 'collected ensure reliability', 'ensure reliability score', 'reliability score calculated', 'score calculated scale', 'calculated scale poor', 'scale poor correlation', 'poor correlation regarded', 'correlation regarded indicating', 'regarded indicating unreliable', 'indicating unreliable answer', 'unreliable answer time', 'answer time taken', 'time taken answer', 'taken answer questionnaire', 'answer questionnaire also', 'questionnaire also recorded', 'also recorded completed', 'recorded completed brief', 'completed brief time', 'brief time excluded', 'time excluded answered', 'excluded answered questionnaire', 'answered questionnaire activity', 'questionnaire activity history', 'activity history collected', 'history collected using', 'collected using api', 'using api collected', 'api collected number', 'collected number following', 'number following followed', 'following followed recorded', 'followed recorded published', 'recorded published questionnaire', 'published questionnaire taken', 'questionnaire taken discarded', 'taken discarded website', 'discarded website opened', 'website opened public', 'opened public december', 'public december time', 'december time author', 'time author publicized', 'author publicized account', 'publicized account december', 'account december february', 'december february people', 'february people participated', 'people participated experiment', 'participated experiment eliminating', 'experiment eliminating answered', 'eliminating answered questionnaire', 'answered questionnaire fewer', 'questionnaire fewer second', 'fewer second previously', 'second previously mentioned', 'previously mentioned ensure', 'mentioned ensure reliability', 'ensure reliability questionnaire', 'reliability questionnaire answer', 'questionnaire answer set', 'answer set answer', 'set answer remained', 'answer remained first', 'remained first set', 'first set answer', 'set answer completed', 'answer completed questionnaire', 'completed questionnaire result', 'questionnaire result experiment', 'result experiment male', 'experiment male female', 'male female aged', 'female aged mean', 'aged mean year', 'mean year standard', 'year standard deviation', 'standard deviation year', 'deviation year analyzed', 'year analyzed correlation', 'analyzed correlation cesd', 'correlation cesd score', 'cesd score bdi', 'score bdi score', 'bdi score high', 'score high uncorrelated', 'high uncorrelated score', 'uncorrelated score excluded', 'score excluded datasets', 'excluded datasets discussed', 'datasets discussed figure', 'discussed figure show', 'figure show histogram', 'show histogram cesd', 'histogram cesd score', 'cesd score among', 'score among resp', 'among resp estimated', 'resp estimated resp', 'estimated resp active', 'resp active incidence', 'active incidence approximately', 'incidence approximately incidence', 'approximately incidence similar', 'incidence similar found', 'similar found de', 'found de choudhury', 'de choudhury et', 'choudhury et al', 'et al identified', 'al identified approximately', 'identified approximately table', 'approximately table give', 'table give statistic', 'give statistic activity', 'statistic activity history']"
https://www.nature.com/articles/s41598-017-12961-9,1,We trained supervised machine learning classifiers to discriminate between affected and healthy sample members’ observations. Classifiers were trained on a randomly-selected 70% of total observations and tested on the remaining 30%. Out of several candidate algorithms a 1200-tree Random Forests classifier demonstrated best performance. Stratified five-fold cross-validation was used to optimize Random Forests hyperparameters and final accuracy scores were averaged over five separate randomized runs. See Supplementary Information section III for optimization details. Precision recall specificity negative predictive value and F1 accuracy scores are reported and general practitioners’ unassisted diagnostic accuracy rates as reported in Mitchell Vaze and Rao28 (MVR) and Taubman-Ben-Ari et al.22 (TBA) are used as informal benchmarks for depression and PTSD respectively. In addition to the fact that our results are drawn from different samples using different observational units than our chosen comparisons comparing point estimates of accuracy metrics is not a statistically formal means of model comparison. We felt it was more meaningful to frame our findings in a realistic context however informal rather than to benchmark against a naive statistical model that simply predicted the majority class for all observations.,we trained supervised machine learning classifier to discriminate between affected and healthy sample member observation classifier were trained on a randomlyselected of total observation and tested on the remaining out of several candidate algorithm a tree random forest classifier demonstrated best performance stratified fivefold crossvalidation wa used to optimize random forest hyperparameters and final accuracy score were averaged over five separate randomized run see supplementary information section iii for optimization detail precision recall specificity negative predictive value and f accuracy score are reported and general practitioner unassisted diagnostic accuracy rate a reported in mitchell vaze and rao mvr and taubmanbenari et al tba are used a informal benchmark for depression and ptsd respectively in addition to the fact that our result are drawn from different sample using different observational unit than our chosen comparison comparing point estimate of accuracy metric is not a statistically formal mean of model comparison we felt it wa more meaningful to frame our finding in a realistic context however informal rather than to benchmark against a naive statistical model that simply predicted the majority class for all observation,"['trained', 'supervised', 'machine', 'learning', 'classifier', 'discriminate', 'affected', 'healthy', 'sample', 'member', 'observation', 'classifier', 'trained', 'randomlyselected', 'total', 'observation', 'tested', 'remaining', 'several', 'candidate', 'algorithm', 'tree', 'random', 'forest', 'classifier', 'demonstrated', 'best', 'performance', 'stratified', 'fivefold', 'crossvalidation', 'optimize', 'random', 'forest', 'hyperparameters', 'final', 'accuracy', 'score', 'averaged', 'five', 'separate', 'randomized', 'run', 'see', 'supplementary', 'information', 'section', 'iii', 'optimization', 'detail', 'precision', 'recall', 'specificity', 'negative', 'predictive', 'value', 'f', 'accuracy', 'score', 'reported', 'general', 'practitioner', 'unassisted', 'diagnostic', 'accuracy', 'rate', 'reported', 'mitchell', 'vaze', 'rao', 'mvr', 'taubmanbenari', 'et', 'al', 'tba', 'informal', 'benchmark', 'ptsd', 'respectively', 'addition', 'fact', 'result', 'drawn', 'different', 'sample', 'using', 'different', 'observational', 'unit', 'chosen', 'comparison', 'comparing', 'point', 'estimate', 'accuracy', 'metric', 'statistically', 'formal', 'mean', 'model', 'comparison', 'felt', 'meaningful', 'frame', 'finding', 'realistic', 'context', 'however', 'informal', 'rather', 'benchmark', 'naive', 'statistical', 'model', 'simply', 'predicted', 'majority', 'class', 'observation']","['trained supervised', 'supervised machine', 'machine learning', 'learning classifier', 'classifier discriminate', 'discriminate affected', 'affected healthy', 'healthy sample', 'sample member', 'member observation', 'observation classifier', 'classifier trained', 'trained randomlyselected', 'randomlyselected total', 'total observation', 'observation tested', 'tested remaining', 'remaining several', 'several candidate', 'candidate algorithm', 'algorithm tree', 'tree random', 'random forest', 'forest classifier', 'classifier demonstrated', 'demonstrated best', 'best performance', 'performance stratified', 'stratified fivefold', 'fivefold crossvalidation', 'crossvalidation optimize', 'optimize random', 'random forest', 'forest hyperparameters', 'hyperparameters final', 'final accuracy', 'accuracy score', 'score averaged', 'averaged five', 'five separate', 'separate randomized', 'randomized run', 'run see', 'see supplementary', 'supplementary information', 'information section', 'section iii', 'iii optimization', 'optimization detail', 'detail precision', 'precision recall', 'recall specificity', 'specificity negative', 'negative predictive', 'predictive value', 'value f', 'f accuracy', 'accuracy score', 'score reported', 'reported general', 'general practitioner', 'practitioner unassisted', 'unassisted diagnostic', 'diagnostic accuracy', 'accuracy rate', 'rate reported', 'reported mitchell', 'mitchell vaze', 'vaze rao', 'rao mvr', 'mvr taubmanbenari', 'taubmanbenari et', 'et al', 'al tba', 'tba informal', 'informal benchmark', 'benchmark ptsd', 'ptsd respectively', 'respectively addition', 'addition fact', 'fact result', 'result drawn', 'drawn different', 'different sample', 'sample using', 'using different', 'different observational', 'observational unit', 'unit chosen', 'chosen comparison', 'comparison comparing', 'comparing point', 'point estimate', 'estimate accuracy', 'accuracy metric', 'metric statistically', 'statistically formal', 'formal mean', 'mean model', 'model comparison', 'comparison felt', 'felt meaningful', 'meaningful frame', 'frame finding', 'finding realistic', 'realistic context', 'context however', 'however informal', 'informal rather', 'rather benchmark', 'benchmark naive', 'naive statistical', 'statistical model', 'model simply', 'simply predicted', 'predicted majority', 'majority class', 'class observation']","['trained supervised machine', 'supervised machine learning', 'machine learning classifier', 'learning classifier discriminate', 'classifier discriminate affected', 'discriminate affected healthy', 'affected healthy sample', 'healthy sample member', 'sample member observation', 'member observation classifier', 'observation classifier trained', 'classifier trained randomlyselected', 'trained randomlyselected total', 'randomlyselected total observation', 'total observation tested', 'observation tested remaining', 'tested remaining several', 'remaining several candidate', 'several candidate algorithm', 'candidate algorithm tree', 'algorithm tree random', 'tree random forest', 'random forest classifier', 'forest classifier demonstrated', 'classifier demonstrated best', 'demonstrated best performance', 'best performance stratified', 'performance stratified fivefold', 'stratified fivefold crossvalidation', 'fivefold crossvalidation optimize', 'crossvalidation optimize random', 'optimize random forest', 'random forest hyperparameters', 'forest hyperparameters final', 'hyperparameters final accuracy', 'final accuracy score', 'accuracy score averaged', 'score averaged five', 'averaged five separate', 'five separate randomized', 'separate randomized run', 'randomized run see', 'run see supplementary', 'see supplementary information', 'supplementary information section', 'information section iii', 'section iii optimization', 'iii optimization detail', 'optimization detail precision', 'detail precision recall', 'precision recall specificity', 'recall specificity negative', 'specificity negative predictive', 'negative predictive value', 'predictive value f', 'value f accuracy', 'f accuracy score', 'accuracy score reported', 'score reported general', 'reported general practitioner', 'general practitioner unassisted', 'practitioner unassisted diagnostic', 'unassisted diagnostic accuracy', 'diagnostic accuracy rate', 'accuracy rate reported', 'rate reported mitchell', 'reported mitchell vaze', 'mitchell vaze rao', 'vaze rao mvr', 'rao mvr taubmanbenari', 'mvr taubmanbenari et', 'taubmanbenari et al', 'et al tba', 'al tba informal', 'tba informal benchmark', 'informal benchmark ptsd', 'benchmark ptsd respectively', 'ptsd respectively addition', 'respectively addition fact', 'addition fact result', 'fact result drawn', 'result drawn different', 'drawn different sample', 'different sample using', 'sample using different', 'using different observational', 'different observational unit', 'observational unit chosen', 'unit chosen comparison', 'chosen comparison comparing', 'comparison comparing point', 'comparing point estimate', 'point estimate accuracy', 'estimate accuracy metric', 'accuracy metric statistically', 'metric statistically formal', 'statistically formal mean', 'formal mean model', 'mean model comparison', 'model comparison felt', 'comparison felt meaningful', 'felt meaningful frame', 'meaningful frame finding', 'frame finding realistic', 'finding realistic context', 'realistic context however', 'context however informal', 'however informal rather', 'informal rather benchmark', 'rather benchmark naive', 'benchmark naive statistical', 'naive statistical model', 'statistical model simply', 'model simply predicted', 'simply predicted majority', 'predicted majority class', 'majority class observation']"
https://aclanthology.org/W14-3214.pdf,1,We used a dataset of 28749 nonclinical users who opted into a Facebook application (“MyPersonality”; Kosinski and Stillwell 2012) between June 2009 and March 2011 completed a 100-item personality questionnaire (an International Personality Item Pool (IPIP) proxy to the NEO-PI-R (Goldberg 1999) and shared access to their status updates containing at least 500 words. Users wrote on average of 4236 words (69917624 total word instances) and a subset of 16507 users provided gender and age in which 57.0% were female and the mean age was 24.8. The dataset was divided into training and testing samples. In particular the testing sample consisted of a random set of 1000 users who wrote at least 1000 words and completed the personality measure while the training set contained the 27749 remaining users.,we used a dataset of nonclinical user who opted into a facebook application mypersonality kosinski and stillwell between june and march completed a item personality questionnaire an international personality item pool ipip proxy to the neopir goldberg and shared access to their status update containing at least word user wrote on average of word total word instance and a subset of user provided gender and age in which were female and the mean age wa the dataset wa divided into training and testing sample in particular the testing sample consisted of a random set of user who wrote at least word and completed the personality measure while the training set contained the remaining user,"['dataset', 'nonclinical', 'opted', 'facebook', 'application', 'mypersonality', 'kosinski', 'stillwell', 'june', 'march', 'completed', 'item', 'personality', 'questionnaire', 'international', 'personality', 'item', 'pool', 'ipip', 'proxy', 'neopir', 'goldberg', 'shared', 'access', 'status', 'update', 'containing', 'least', 'wrote', 'average', 'total', 'instance', 'subset', 'provided', 'gender', 'age', 'female', 'mean', 'age', 'dataset', 'divided', 'training', 'testing', 'sample', 'particular', 'testing', 'sample', 'consisted', 'random', 'set', 'wrote', 'least', 'completed', 'personality', 'measure', 'training', 'set', 'contained', 'remaining']","['dataset nonclinical', 'nonclinical opted', 'opted facebook', 'facebook application', 'application mypersonality', 'mypersonality kosinski', 'kosinski stillwell', 'stillwell june', 'june march', 'march completed', 'completed item', 'item personality', 'personality questionnaire', 'questionnaire international', 'international personality', 'personality item', 'item pool', 'pool ipip', 'ipip proxy', 'proxy neopir', 'neopir goldberg', 'goldberg shared', 'shared access', 'access status', 'status update', 'update containing', 'containing least', 'least wrote', 'wrote average', 'average total', 'total instance', 'instance subset', 'subset provided', 'provided gender', 'gender age', 'age female', 'female mean', 'mean age', 'age dataset', 'dataset divided', 'divided training', 'training testing', 'testing sample', 'sample particular', 'particular testing', 'testing sample', 'sample consisted', 'consisted random', 'random set', 'set wrote', 'wrote least', 'least completed', 'completed personality', 'personality measure', 'measure training', 'training set', 'set contained', 'contained remaining']","['dataset nonclinical opted', 'nonclinical opted facebook', 'opted facebook application', 'facebook application mypersonality', 'application mypersonality kosinski', 'mypersonality kosinski stillwell', 'kosinski stillwell june', 'stillwell june march', 'june march completed', 'march completed item', 'completed item personality', 'item personality questionnaire', 'personality questionnaire international', 'questionnaire international personality', 'international personality item', 'personality item pool', 'item pool ipip', 'pool ipip proxy', 'ipip proxy neopir', 'proxy neopir goldberg', 'neopir goldberg shared', 'goldberg shared access', 'shared access status', 'access status update', 'status update containing', 'update containing least', 'containing least wrote', 'least wrote average', 'wrote average total', 'average total instance', 'total instance subset', 'instance subset provided', 'subset provided gender', 'provided gender age', 'gender age female', 'age female mean', 'female mean age', 'mean age dataset', 'age dataset divided', 'dataset divided training', 'divided training testing', 'training testing sample', 'testing sample particular', 'sample particular testing', 'particular testing sample', 'testing sample consisted', 'sample consisted random', 'consisted random set', 'random set wrote', 'set wrote least', 'wrote least completed', 'least completed personality', 'completed personality measure', 'personality measure training', 'measure training set', 'training set contained', 'set contained remaining']"
https://ieeexplore.ieee.org/abstract/document/6784326,0,a) CLINICAL Communities: Communities who are interested in ‘depression’ and with at least 200 posts are extracted from LiveJournal. This is identified through the ‘Search communities by interest’2 provided by LiveJournal and results in 24 communities with 38401 posts. The CLINICAL communities are grouped based on name and description of the individual community: depression bipolar self-harm attachment/separation and suicide (See Table 1 for statistics). The earliest community creation date was in 2001 thus our data set spans over 10 years. b) CONTROL communities: We constructed a CONTROL data set using five popular categories of communities in the LiveJournal Directory.3 We select communities who have at least 200 posts resulting in 23 communities with 229563 posts. This set is called CONTROL and the statistics of these 23 communities and their description are shown in Table 2.To characterize the difference between CLINICAL and CONTROL communities a variety of features are extracted: Affective features: We use the lexicon—Affective Norms for English Words (ANEW) [5]—to extract the sentiment conveyed in the content. This lexicon consists of 1034 words rated in terms of valence and arousal and is thus suitable for a quantitative estimation. The valence of ANEW words is on a scale of 1 (very unpleasant) to 9 (very pleasant). The arousal is measured on the same scale—1 (least active) to 9 (most active). A cloud visualization of ANEW words used in the blog posts made by CLINICAL and CONTROL groups is illustrated in Fig. 1. Mood tags: LiveJournal provides a mechanism for users to tag their posts from a list of 132 pre-defined mood labels.4 Thus in addition to the emotion expressed in the text of posts the mood tag produced allows us direct access to the user sentiment. A cloud visualization of moods tagged on blog posts made by CLINICAL and CONTROL communities is illustrated in Fig. 2. LIWC features: We examine the proportions of words in psycholinguistic categories as defined in the LIWC package [27]: linguistic social affective cognitive perceptual biological relativity personal concerns and spoken.5 Table 3 presents the mean of these LIWC psycholinguistic processes for the CLINICAL and CONTROL communities. Whilst similar in the use words with positive emotion people in the CLINICAL communities tend to use words with more negative emotion—as examples anxiety anger and sadness. Further they discuss more issues about health and death in comparison with the CONTROL group. On the other hand the users in the CONTROL group discuss more neutral life related topics—ingestion home and leisure words. Topics: For extracting topics latent Dirichlet allocation (LDA) [4] is used as a Bayesian probabilistic modelling framework. LDA extracts the probabilities pðvocabulary jtopicÞ—that is words in a topic and then assigns a topic to each word in a document. For the inference part we implemented Gibbs inference detailed in [10]. We set the number of topics to 50 run the Gibbs for 5000 samples and use the last Gibbs sample to interpret the results.,a clinical community community who are interested in depression and with at least post are extracted from livejournal this is identified through the search community by interest provided by livejournal and result in community with post the clinical community are grouped based on name and description of the individual community depression bipolar selfharm attachmentseparation and suicide see table for statistic the earliest community creation date wa in thus our data set span over year b control community we constructed a control data set using five popular category of community in the livejournal directory we select community who have at least post resulting in community with post this set is called control and the statistic of these community and their description are shown in table to characterize the difference between clinical and control community a variety of feature are extracted affective feature we use the lexiconaffective norm for english word anew to extract the sentiment conveyed in the content this lexicon consists of word rated in term of valence and arousal and is thus suitable for a quantitative estimation the valence of anew word is on a scale of very unpleasant to very pleasant the arousal is measured on the same scale least active to most active a cloud visualization of anew word used in the blog post made by clinical and control group is illustrated in fig mood tag livejournal provides a mechanism for user to tag their post from a list of predefined mood label thus in addition to the emotion expressed in the text of post the mood tag produced allows u direct access to the user sentiment a cloud visualization of mood tagged on blog post made by clinical and control community is illustrated in fig liwc feature we examine the proportion of word in psycholinguistic category a defined in the liwc package linguistic social affective cognitive perceptual biological relativity personal concern and spoken table present the mean of these liwc psycholinguistic process for the clinical and control community whilst similar in the use word with positive emotion people in the clinical community tend to use word with more negative emotionas example anxiety anger and sadness further they discus more issue about health and death in comparison with the control group on the other hand the user in the control group discus more neutral life related topicsingestion home and leisure word topic for extracting topic latent dirichlet allocation lda is used a a bayesian probabilistic modelling framework lda extract the probability pvocabulary jtopicthat is word in a topic and then assigns a topic to each word in a document for the inference part we implemented gibbs inference detailed in we set the number of topic to run the gibbs for sample and use the last gibbs sample to interpret the result,"['clinical', 'community', 'community', 'interested', 'least', 'extracted', 'livejournal', 'identified', 'search', 'community', 'interest', 'provided', 'livejournal', 'result', 'community', 'clinical', 'community', 'grouped', 'based', 'name', 'description', 'individual', 'community', 'bipolar', 'selfharm', 'attachmentseparation', 'suicide', 'see', 'table', 'statistic', 'earliest', 'community', 'creation', 'date', 'thus', 'set', 'span', 'year', 'b', 'community', 'constructed', 'set', 'using', 'five', 'popular', 'category', 'community', 'livejournal', 'directory', 'select', 'community', 'least', 'resulting', 'community', 'set', 'called', 'statistic', 'community', 'description', 'shown', 'table', 'characterize', 'difference', 'clinical', 'community', 'variety', 'feature', 'extracted', 'affective', 'feature', 'use', 'lexiconaffective', 'norm', 'english', 'anew', 'extract', 'sentiment', 'conveyed', 'content', 'lexicon', 'consists', 'rated', 'term', 'valence', 'arousal', 'thus', 'suitable', 'quantitative', 'estimation', 'valence', 'anew', 'scale', 'unpleasant', 'pleasant', 'arousal', 'measured', 'scale', 'least', 'active', 'active', 'cloud', 'visualization', 'anew', 'blog', 'made', 'clinical', 'group', 'illustrated', 'fig', 'mood', 'tag', 'livejournal', 'provides', 'mechanism', 'tag', 'list', 'predefined', 'mood', 'label', 'thus', 'addition', 'emotion', 'expressed', 'text', 'mood', 'tag', 'produced', 'allows', 'u', 'direct', 'access', 'sentiment', 'cloud', 'visualization', 'mood', 'tagged', 'blog', 'made', 'clinical', 'community', 'illustrated', 'fig', 'liwc', 'feature', 'examine', 'proportion', 'psycholinguistic', 'category', 'defined', 'liwc', 'package', 'linguistic', 'social', 'affective', 'cognitive', 'perceptual', 'biological', 'relativity', 'personal', 'concern', 'spoken', 'table', 'present', 'mean', 'liwc', 'psycholinguistic', 'process', 'clinical', 'community', 'whilst', 'similar', 'use', 'positive', 'emotion', 'people', 'clinical', 'community', 'tend', 'use', 'negative', 'emotionas', 'example', 'anxiety', 'anger', 'sadness', 'discus', 'issue', 'death', 'comparison', 'group', 'hand', 'group', 'discus', 'neutral', 'life', 'related', 'topicsingestion', 'home', 'leisure', 'topic', 'extracting', 'topic', 'latent', 'dirichlet', 'allocation', 'lda', 'bayesian', 'probabilistic', 'modelling', 'framework', 'lda', 'extract', 'probability', 'pvocabulary', 'jtopicthat', 'topic', 'assigns', 'topic', 'document', 'inference', 'part', 'implemented', 'gibbs', 'inference', 'detailed', 'set', 'number', 'topic', 'run', 'gibbs', 'sample', 'use', 'last', 'gibbs', 'sample', 'interpret', 'result']","['clinical community', 'community community', 'community interested', 'interested least', 'least extracted', 'extracted livejournal', 'livejournal identified', 'identified search', 'search community', 'community interest', 'interest provided', 'provided livejournal', 'livejournal result', 'result community', 'community clinical', 'clinical community', 'community grouped', 'grouped based', 'based name', 'name description', 'description individual', 'individual community', 'community bipolar', 'bipolar selfharm', 'selfharm attachmentseparation', 'attachmentseparation suicide', 'suicide see', 'see table', 'table statistic', 'statistic earliest', 'earliest community', 'community creation', 'creation date', 'date thus', 'thus set', 'set span', 'span year', 'year b', 'b community', 'community constructed', 'constructed set', 'set using', 'using five', 'five popular', 'popular category', 'category community', 'community livejournal', 'livejournal directory', 'directory select', 'select community', 'community least', 'least resulting', 'resulting community', 'community set', 'set called', 'called statistic', 'statistic community', 'community description', 'description shown', 'shown table', 'table characterize', 'characterize difference', 'difference clinical', 'clinical community', 'community variety', 'variety feature', 'feature extracted', 'extracted affective', 'affective feature', 'feature use', 'use lexiconaffective', 'lexiconaffective norm', 'norm english', 'english anew', 'anew extract', 'extract sentiment', 'sentiment conveyed', 'conveyed content', 'content lexicon', 'lexicon consists', 'consists rated', 'rated term', 'term valence', 'valence arousal', 'arousal thus', 'thus suitable', 'suitable quantitative', 'quantitative estimation', 'estimation valence', 'valence anew', 'anew scale', 'scale unpleasant', 'unpleasant pleasant', 'pleasant arousal', 'arousal measured', 'measured scale', 'scale least', 'least active', 'active active', 'active cloud', 'cloud visualization', 'visualization anew', 'anew blog', 'blog made', 'made clinical', 'clinical group', 'group illustrated', 'illustrated fig', 'fig mood', 'mood tag', 'tag livejournal', 'livejournal provides', 'provides mechanism', 'mechanism tag', 'tag list', 'list predefined', 'predefined mood', 'mood label', 'label thus', 'thus addition', 'addition emotion', 'emotion expressed', 'expressed text', 'text mood', 'mood tag', 'tag produced', 'produced allows', 'allows u', 'u direct', 'direct access', 'access sentiment', 'sentiment cloud', 'cloud visualization', 'visualization mood', 'mood tagged', 'tagged blog', 'blog made', 'made clinical', 'clinical community', 'community illustrated', 'illustrated fig', 'fig liwc', 'liwc feature', 'feature examine', 'examine proportion', 'proportion psycholinguistic', 'psycholinguistic category', 'category defined', 'defined liwc', 'liwc package', 'package linguistic', 'linguistic social', 'social affective', 'affective cognitive', 'cognitive perceptual', 'perceptual biological', 'biological relativity', 'relativity personal', 'personal concern', 'concern spoken', 'spoken table', 'table present', 'present mean', 'mean liwc', 'liwc psycholinguistic', 'psycholinguistic process', 'process clinical', 'clinical community', 'community whilst', 'whilst similar', 'similar use', 'use positive', 'positive emotion', 'emotion people', 'people clinical', 'clinical community', 'community tend', 'tend use', 'use negative', 'negative emotionas', 'emotionas example', 'example anxiety', 'anxiety anger', 'anger sadness', 'sadness discus', 'discus issue', 'issue death', 'death comparison', 'comparison group', 'group hand', 'hand group', 'group discus', 'discus neutral', 'neutral life', 'life related', 'related topicsingestion', 'topicsingestion home', 'home leisure', 'leisure topic', 'topic extracting', 'extracting topic', 'topic latent', 'latent dirichlet', 'dirichlet allocation', 'allocation lda', 'lda bayesian', 'bayesian probabilistic', 'probabilistic modelling', 'modelling framework', 'framework lda', 'lda extract', 'extract probability', 'probability pvocabulary', 'pvocabulary jtopicthat', 'jtopicthat topic', 'topic assigns', 'assigns topic', 'topic document', 'document inference', 'inference part', 'part implemented', 'implemented gibbs', 'gibbs inference', 'inference detailed', 'detailed set', 'set number', 'number topic', 'topic run', 'run gibbs', 'gibbs sample', 'sample use', 'use last', 'last gibbs', 'gibbs sample', 'sample interpret', 'interpret result']","['clinical community community', 'community community interested', 'community interested least', 'interested least extracted', 'least extracted livejournal', 'extracted livejournal identified', 'livejournal identified search', 'identified search community', 'search community interest', 'community interest provided', 'interest provided livejournal', 'provided livejournal result', 'livejournal result community', 'result community clinical', 'community clinical community', 'clinical community grouped', 'community grouped based', 'grouped based name', 'based name description', 'name description individual', 'description individual community', 'individual community bipolar', 'community bipolar selfharm', 'bipolar selfharm attachmentseparation', 'selfharm attachmentseparation suicide', 'attachmentseparation suicide see', 'suicide see table', 'see table statistic', 'table statistic earliest', 'statistic earliest community', 'earliest community creation', 'community creation date', 'creation date thus', 'date thus set', 'thus set span', 'set span year', 'span year b', 'year b community', 'b community constructed', 'community constructed set', 'constructed set using', 'set using five', 'using five popular', 'five popular category', 'popular category community', 'category community livejournal', 'community livejournal directory', 'livejournal directory select', 'directory select community', 'select community least', 'community least resulting', 'least resulting community', 'resulting community set', 'community set called', 'set called statistic', 'called statistic community', 'statistic community description', 'community description shown', 'description shown table', 'shown table characterize', 'table characterize difference', 'characterize difference clinical', 'difference clinical community', 'clinical community variety', 'community variety feature', 'variety feature extracted', 'feature extracted affective', 'extracted affective feature', 'affective feature use', 'feature use lexiconaffective', 'use lexiconaffective norm', 'lexiconaffective norm english', 'norm english anew', 'english anew extract', 'anew extract sentiment', 'extract sentiment conveyed', 'sentiment conveyed content', 'conveyed content lexicon', 'content lexicon consists', 'lexicon consists rated', 'consists rated term', 'rated term valence', 'term valence arousal', 'valence arousal thus', 'arousal thus suitable', 'thus suitable quantitative', 'suitable quantitative estimation', 'quantitative estimation valence', 'estimation valence anew', 'valence anew scale', 'anew scale unpleasant', 'scale unpleasant pleasant', 'unpleasant pleasant arousal', 'pleasant arousal measured', 'arousal measured scale', 'measured scale least', 'scale least active', 'least active active', 'active active cloud', 'active cloud visualization', 'cloud visualization anew', 'visualization anew blog', 'anew blog made', 'blog made clinical', 'made clinical group', 'clinical group illustrated', 'group illustrated fig', 'illustrated fig mood', 'fig mood tag', 'mood tag livejournal', 'tag livejournal provides', 'livejournal provides mechanism', 'provides mechanism tag', 'mechanism tag list', 'tag list predefined', 'list predefined mood', 'predefined mood label', 'mood label thus', 'label thus addition', 'thus addition emotion', 'addition emotion expressed', 'emotion expressed text', 'expressed text mood', 'text mood tag', 'mood tag produced', 'tag produced allows', 'produced allows u', 'allows u direct', 'u direct access', 'direct access sentiment', 'access sentiment cloud', 'sentiment cloud visualization', 'cloud visualization mood', 'visualization mood tagged', 'mood tagged blog', 'tagged blog made', 'blog made clinical', 'made clinical community', 'clinical community illustrated', 'community illustrated fig', 'illustrated fig liwc', 'fig liwc feature', 'liwc feature examine', 'feature examine proportion', 'examine proportion psycholinguistic', 'proportion psycholinguistic category', 'psycholinguistic category defined', 'category defined liwc', 'defined liwc package', 'liwc package linguistic', 'package linguistic social', 'linguistic social affective', 'social affective cognitive', 'affective cognitive perceptual', 'cognitive perceptual biological', 'perceptual biological relativity', 'biological relativity personal', 'relativity personal concern', 'personal concern spoken', 'concern spoken table', 'spoken table present', 'table present mean', 'present mean liwc', 'mean liwc psycholinguistic', 'liwc psycholinguistic process', 'psycholinguistic process clinical', 'process clinical community', 'clinical community whilst', 'community whilst similar', 'whilst similar use', 'similar use positive', 'use positive emotion', 'positive emotion people', 'emotion people clinical', 'people clinical community', 'clinical community tend', 'community tend use', 'tend use negative', 'use negative emotionas', 'negative emotionas example', 'emotionas example anxiety', 'example anxiety anger', 'anxiety anger sadness', 'anger sadness discus', 'sadness discus issue', 'discus issue death', 'issue death comparison', 'death comparison group', 'comparison group hand', 'group hand group', 'hand group discus', 'group discus neutral', 'discus neutral life', 'neutral life related', 'life related topicsingestion', 'related topicsingestion home', 'topicsingestion home leisure', 'home leisure topic', 'leisure topic extracting', 'topic extracting topic', 'extracting topic latent', 'topic latent dirichlet', 'latent dirichlet allocation', 'dirichlet allocation lda', 'allocation lda bayesian', 'lda bayesian probabilistic', 'bayesian probabilistic modelling', 'probabilistic modelling framework', 'modelling framework lda', 'framework lda extract', 'lda extract probability', 'extract probability pvocabulary', 'probability pvocabulary jtopicthat', 'pvocabulary jtopicthat topic', 'jtopicthat topic assigns', 'topic assigns topic', 'assigns topic document', 'topic document inference', 'document inference part', 'inference part implemented', 'part implemented gibbs', 'implemented gibbs inference', 'gibbs inference detailed', 'inference detailed set', 'detailed set number', 'set number topic', 'number topic run', 'topic run gibbs', 'run gibbs sample', 'gibbs sample use', 'sample use last', 'use last gibbs', 'last gibbs sample', 'gibbs sample interpret', 'sample interpret result']"
https://www.jmir.org/2017/7/e243/,1,A Web-based survey of Weibo users was conducted to assess the respondents’ suicide risk and emotional distress (ie depression anxiety and stress). The invitation letter to participate in this survey was widely sent out to general Weibo users by various promotion activities. For a Weibo user to be eligible for the study she or he had to be 18 years or older (by self-report). A 30 Renminbi incentive for each complete survey was provided to boost the respond rate. With the respondents’ consent their Weibo posts that were posted in the public domain during the 12 months before the survey were downloaded by calling Weibo API. The survey fulfilled the Checklist for Reporting Results of Internet E-Surveys (CHERRIES) checklist and details of the procedure have been reported in previous publications [2232]. In addition when multiple survey feedback were submitted from the same Internet protocol addresses only the first submission was used to avoid duplicate participation. In contrast to a previous study [32] this study excluded those who posted nothing throughout the 12 months but not those who posted fewer than 100 posts. Eventually data provided by 974 respondents remained for further analyses. The study has obtained ethical approvals from the Human Research Ethical Review Committee at the University of Hong Kong and the Institute Review Board of the Institute of Psychology at the Chinese Academy of Sciences. The survey measured respondents’ suicide probability score depression anxiety stress and Weibo suicide communication (WSC) as the outcome variables. In addition the respondents’ Weibo posts language features were extracted as independent variables or features for machine learning. The details of how those data were obtained are elaborated in the following subsections.,a webbased survey of weibo user wa conducted to ass the respondent suicide risk and emotional distress ie depression anxiety and stress the invitation letter to participate in this survey wa widely sent out to general weibo user by various promotion activity for a weibo user to be eligible for the study she or he had to be year or older by selfreport a renminbi incentive for each complete survey wa provided to boost the respond rate with the respondent consent their weibo post that were posted in the public domain during the month before the survey were downloaded by calling weibo api the survey fulfilled the checklist for reporting result of internet esurveys cherry checklist and detail of the procedure have been reported in previous publication in addition when multiple survey feedback were submitted from the same internet protocol address only the first submission wa used to avoid duplicate participation in contrast to a previous study this study excluded those who posted nothing throughout the month but not those who posted fewer than post eventually data provided by respondent remained for further analysis the study ha obtained ethical approval from the human research ethical review committee at the university of hong kong and the institute review board of the institute of psychology at the chinese academy of science the survey measured respondent suicide probability score depression anxiety stress and weibo suicide communication wsc a the outcome variable in addition the respondent weibo post language feature were extracted a independent variable or feature for machine learning the detail of how those data were obtained are elaborated in the following subsection,"['webbased', 'survey', 'weibo', 'conducted', 'ass', 'respondent', 'suicide', 'risk', 'emotional', 'distress', 'ie', 'anxiety', 'stress', 'invitation', 'letter', 'participate', 'survey', 'widely', 'sent', 'general', 'weibo', 'various', 'promotion', 'activity', 'weibo', 'eligible', 'study', 'year', 'older', 'selfreport', 'renminbi', 'incentive', 'complete', 'survey', 'provided', 'boost', 'respond', 'rate', 'respondent', 'consent', 'weibo', 'posted', 'public', 'domain', 'month', 'survey', 'downloaded', 'calling', 'weibo', 'api', 'survey', 'fulfilled', 'checklist', 'reporting', 'result', 'internet', 'esurveys', 'cherry', 'checklist', 'detail', 'procedure', 'reported', 'previous', 'publication', 'addition', 'multiple', 'survey', 'feedback', 'submitted', 'internet', 'protocol', 'address', 'first', 'submission', 'avoid', 'duplicate', 'participation', 'contrast', 'previous', 'study', 'study', 'excluded', 'posted', 'nothing', 'throughout', 'month', 'posted', 'fewer', 'eventually', 'provided', 'respondent', 'remained', 'analysis', 'study', 'ha', 'obtained', 'ethical', 'approval', 'human', 'research', 'ethical', 'review', 'committee', 'university', 'hong', 'kong', 'institute', 'review', 'board', 'institute', 'psychology', 'chinese', 'academy', 'science', 'survey', 'measured', 'respondent', 'suicide', 'probability', 'score', 'anxiety', 'stress', 'weibo', 'suicide', 'communication', 'wsc', 'outcome', 'variable', 'addition', 'respondent', 'weibo', 'language', 'feature', 'extracted', 'independent', 'variable', 'feature', 'machine', 'learning', 'detail', 'obtained', 'elaborated', 'following', 'subsection']","['webbased survey', 'survey weibo', 'weibo conducted', 'conducted ass', 'ass respondent', 'respondent suicide', 'suicide risk', 'risk emotional', 'emotional distress', 'distress ie', 'ie anxiety', 'anxiety stress', 'stress invitation', 'invitation letter', 'letter participate', 'participate survey', 'survey widely', 'widely sent', 'sent general', 'general weibo', 'weibo various', 'various promotion', 'promotion activity', 'activity weibo', 'weibo eligible', 'eligible study', 'study year', 'year older', 'older selfreport', 'selfreport renminbi', 'renminbi incentive', 'incentive complete', 'complete survey', 'survey provided', 'provided boost', 'boost respond', 'respond rate', 'rate respondent', 'respondent consent', 'consent weibo', 'weibo posted', 'posted public', 'public domain', 'domain month', 'month survey', 'survey downloaded', 'downloaded calling', 'calling weibo', 'weibo api', 'api survey', 'survey fulfilled', 'fulfilled checklist', 'checklist reporting', 'reporting result', 'result internet', 'internet esurveys', 'esurveys cherry', 'cherry checklist', 'checklist detail', 'detail procedure', 'procedure reported', 'reported previous', 'previous publication', 'publication addition', 'addition multiple', 'multiple survey', 'survey feedback', 'feedback submitted', 'submitted internet', 'internet protocol', 'protocol address', 'address first', 'first submission', 'submission avoid', 'avoid duplicate', 'duplicate participation', 'participation contrast', 'contrast previous', 'previous study', 'study study', 'study excluded', 'excluded posted', 'posted nothing', 'nothing throughout', 'throughout month', 'month posted', 'posted fewer', 'fewer eventually', 'eventually provided', 'provided respondent', 'respondent remained', 'remained analysis', 'analysis study', 'study ha', 'ha obtained', 'obtained ethical', 'ethical approval', 'approval human', 'human research', 'research ethical', 'ethical review', 'review committee', 'committee university', 'university hong', 'hong kong', 'kong institute', 'institute review', 'review board', 'board institute', 'institute psychology', 'psychology chinese', 'chinese academy', 'academy science', 'science survey', 'survey measured', 'measured respondent', 'respondent suicide', 'suicide probability', 'probability score', 'score anxiety', 'anxiety stress', 'stress weibo', 'weibo suicide', 'suicide communication', 'communication wsc', 'wsc outcome', 'outcome variable', 'variable addition', 'addition respondent', 'respondent weibo', 'weibo language', 'language feature', 'feature extracted', 'extracted independent', 'independent variable', 'variable feature', 'feature machine', 'machine learning', 'learning detail', 'detail obtained', 'obtained elaborated', 'elaborated following', 'following subsection']","['webbased survey weibo', 'survey weibo conducted', 'weibo conducted ass', 'conducted ass respondent', 'ass respondent suicide', 'respondent suicide risk', 'suicide risk emotional', 'risk emotional distress', 'emotional distress ie', 'distress ie anxiety', 'ie anxiety stress', 'anxiety stress invitation', 'stress invitation letter', 'invitation letter participate', 'letter participate survey', 'participate survey widely', 'survey widely sent', 'widely sent general', 'sent general weibo', 'general weibo various', 'weibo various promotion', 'various promotion activity', 'promotion activity weibo', 'activity weibo eligible', 'weibo eligible study', 'eligible study year', 'study year older', 'year older selfreport', 'older selfreport renminbi', 'selfreport renminbi incentive', 'renminbi incentive complete', 'incentive complete survey', 'complete survey provided', 'survey provided boost', 'provided boost respond', 'boost respond rate', 'respond rate respondent', 'rate respondent consent', 'respondent consent weibo', 'consent weibo posted', 'weibo posted public', 'posted public domain', 'public domain month', 'domain month survey', 'month survey downloaded', 'survey downloaded calling', 'downloaded calling weibo', 'calling weibo api', 'weibo api survey', 'api survey fulfilled', 'survey fulfilled checklist', 'fulfilled checklist reporting', 'checklist reporting result', 'reporting result internet', 'result internet esurveys', 'internet esurveys cherry', 'esurveys cherry checklist', 'cherry checklist detail', 'checklist detail procedure', 'detail procedure reported', 'procedure reported previous', 'reported previous publication', 'previous publication addition', 'publication addition multiple', 'addition multiple survey', 'multiple survey feedback', 'survey feedback submitted', 'feedback submitted internet', 'submitted internet protocol', 'internet protocol address', 'protocol address first', 'address first submission', 'first submission avoid', 'submission avoid duplicate', 'avoid duplicate participation', 'duplicate participation contrast', 'participation contrast previous', 'contrast previous study', 'previous study study', 'study study excluded', 'study excluded posted', 'excluded posted nothing', 'posted nothing throughout', 'nothing throughout month', 'throughout month posted', 'month posted fewer', 'posted fewer eventually', 'fewer eventually provided', 'eventually provided respondent', 'provided respondent remained', 'respondent remained analysis', 'remained analysis study', 'analysis study ha', 'study ha obtained', 'ha obtained ethical', 'obtained ethical approval', 'ethical approval human', 'approval human research', 'human research ethical', 'research ethical review', 'ethical review committee', 'review committee university', 'committee university hong', 'university hong kong', 'hong kong institute', 'kong institute review', 'institute review board', 'review board institute', 'board institute psychology', 'institute psychology chinese', 'psychology chinese academy', 'chinese academy science', 'academy science survey', 'science survey measured', 'survey measured respondent', 'measured respondent suicide', 'respondent suicide probability', 'suicide probability score', 'probability score anxiety', 'score anxiety stress', 'anxiety stress weibo', 'stress weibo suicide', 'weibo suicide communication', 'suicide communication wsc', 'communication wsc outcome', 'wsc outcome variable', 'outcome variable addition', 'variable addition respondent', 'addition respondent weibo', 'respondent weibo language', 'weibo language feature', 'language feature extracted', 'feature extracted independent', 'extracted independent variable', 'independent variable feature', 'variable feature machine', 'feature machine learning', 'machine learning detail', 'learning detail obtained', 'detail obtained elaborated', 'obtained elaborated following', 'elaborated following subsection']"
https://dl.acm.org/doi/abs/10.1145/3025453.3025909,1,We note it is possible that the type of students who frequent the university subreddits could be consistently different from the student body at the same university. To examine the representativeness of our university subreddit data we employed a random sample of 500 posts distributed across the subreddits and the years for manual examination of demographics. Two researchers then independently coded these posts for self-reported gender race or academic stage (undergraduate/graduate). For instance from the post “I’m a junior transfer and this will be my second semester” the researchers identified the post author to be an undergraduate whereas from “Hi all! I’m a new grad student (male 22) here the gender of the author can be inferred to be male. We found the interrater agreement to be high: Cohen’s  = .84. The relative ratios between the gender race and academic stage distributions of the coded posts and the university student body (obtained based on our methodology in the subsection “University Data”) showed significant positive correlation: The mean undergrad/grad ratio in our labeled data was 2.9 while it was 2.6 in the universities. A two-sample test of equivalence gave p-values of .016 and .011 respectively with respect to the difference interval [.4 .4]. The sex (male/female) ratio for our labeled data was 1.6 also observed to be statistically equivalent to that of the student body 1.1 (p = .02 p = .03 w.r.t. the difference interval [.5 .5]). This establishes the validity of our acquired Reddit data as a representative data source for studying mental health disclosures in university campuses.We gained access to a sample of 63485 public posts from 35038 unique users shared between 2014 and 2016 in a variety of mental health subreddits—this repository of posts has been used in prior work to study mental health selfdisclosure and support seeking manifested in social media [18 50 39 20]. This dataset includes posts and associated metadata spanning 14 mental health related subreddits such as r/depression r/mentalhealth and r/traumatoolbox r/bipolarreddit. From this corpus we excluded posts that contained only a title without a post body. This gave us 21734 posts. We refer to these posts as MH posts. Our control data also relied on a dataset compiled and utilized in prior work [50]; it contains posts from subreddits such as r/WorldNews r/food and r/AskReddit. We randomly sampled an equal number of posts (21734) as the MH posts above for our control dataset. We refer to these posts as CL posts.,we note it is possible that the type of student who frequent the university subreddits could be consistently different from the student body at the same university to examine the representativeness of our university subreddit data we employed a random sample of post distributed across the subreddits and the year for manual examination of demographic two researcher then independently coded these post for selfreported gender race or academic stage undergraduategraduate for instance from the post im a junior transfer and this will be my second semester the researcher identified the post author to be an undergraduate whereas from hi all im a new grad student male here the gender of the author can be inferred to be male we found the interrater agreement to be high cohens the relative ratio between the gender race and academic stage distribution of the coded post and the university student body obtained based on our methodology in the subsection university data showed significant positive correlation the mean undergradgrad ratio in our labeled data wa while it wa in the university a twosample test of equivalence gave pvalues of and respectively with respect to the difference interval the sex malefemale ratio for our labeled data wa also observed to be statistically equivalent to that of the student body p p wrt the difference interval this establishes the validity of our acquired reddit data a a representative data source for studying mental health disclosure in university campuseswe gained access to a sample of public post from unique user shared between and in a variety of mental health subredditsthis repository of post ha been used in prior work to study mental health selfdisclosure and support seeking manifested in social medium this dataset includes post and associated metadata spanning mental health related subreddits such a rdepression rmentalhealth and rtraumatoolbox rbipolarreddit from this corpus we excluded post that contained only a title without a post body this gave u post we refer to these post a mh post our control data also relied on a dataset compiled and utilized in prior work it contains post from subreddits such a rworldnews rfood and raskreddit we randomly sampled an equal number of post a the mh post above for our control dataset we refer to these post a cl post,"['note', 'possible', 'type', 'student', 'frequent', 'university', 'subreddits', 'could', 'consistently', 'different', 'student', 'body', 'university', 'examine', 'representativeness', 'university', 'subreddit', 'employed', 'random', 'sample', 'distributed', 'across', 'subreddits', 'year', 'manual', 'examination', 'demographic', 'two', 'researcher', 'independently', 'coded', 'selfreported', 'gender', 'race', 'academic', 'stage', 'undergraduategraduate', 'instance', 'im', 'junior', 'transfer', 'second', 'semester', 'researcher', 'identified', 'author', 'undergraduate', 'whereas', 'hi', 'im', 'new', 'grad', 'student', 'male', 'gender', 'author', 'inferred', 'male', 'found', 'interrater', 'agreement', 'high', 'cohens', 'relative', 'ratio', 'gender', 'race', 'academic', 'stage', 'distribution', 'coded', 'university', 'student', 'body', 'obtained', 'based', 'methodology', 'subsection', 'university', 'showed', 'significant', 'positive', 'correlation', 'mean', 'undergradgrad', 'ratio', 'labeled', 'university', 'twosample', 'test', 'equivalence', 'gave', 'pvalues', 'respectively', 'respect', 'difference', 'interval', 'sex', 'malefemale', 'ratio', 'labeled', 'also', 'observed', 'statistically', 'equivalent', 'student', 'body', 'p', 'p', 'wrt', 'difference', 'interval', 'establishes', 'validity', 'acquired', 'reddit', 'representative', 'source', 'studying', 'disclosure', 'university', 'campuseswe', 'gained', 'access', 'sample', 'public', 'unique', 'shared', 'variety', 'subredditsthis', 'repository', 'ha', 'prior', 'work', 'study', 'selfdisclosure', 'support', 'seeking', 'manifested', 'social', 'medium', 'dataset', 'includes', 'associated', 'metadata', 'spanning', 'related', 'subreddits', 'rdepression', 'rmentalhealth', 'rtraumatoolbox', 'rbipolarreddit', 'corpus', 'excluded', 'contained', 'title', 'without', 'body', 'gave', 'u', 'refer', 'mh', 'also', 'relied', 'dataset', 'compiled', 'utilized', 'prior', 'work', 'contains', 'subreddits', 'rworldnews', 'rfood', 'raskreddit', 'randomly', 'sampled', 'equal', 'number', 'mh', 'dataset', 'refer', 'cl']","['note possible', 'possible type', 'type student', 'student frequent', 'frequent university', 'university subreddits', 'subreddits could', 'could consistently', 'consistently different', 'different student', 'student body', 'body university', 'university examine', 'examine representativeness', 'representativeness university', 'university subreddit', 'subreddit employed', 'employed random', 'random sample', 'sample distributed', 'distributed across', 'across subreddits', 'subreddits year', 'year manual', 'manual examination', 'examination demographic', 'demographic two', 'two researcher', 'researcher independently', 'independently coded', 'coded selfreported', 'selfreported gender', 'gender race', 'race academic', 'academic stage', 'stage undergraduategraduate', 'undergraduategraduate instance', 'instance im', 'im junior', 'junior transfer', 'transfer second', 'second semester', 'semester researcher', 'researcher identified', 'identified author', 'author undergraduate', 'undergraduate whereas', 'whereas hi', 'hi im', 'im new', 'new grad', 'grad student', 'student male', 'male gender', 'gender author', 'author inferred', 'inferred male', 'male found', 'found interrater', 'interrater agreement', 'agreement high', 'high cohens', 'cohens relative', 'relative ratio', 'ratio gender', 'gender race', 'race academic', 'academic stage', 'stage distribution', 'distribution coded', 'coded university', 'university student', 'student body', 'body obtained', 'obtained based', 'based methodology', 'methodology subsection', 'subsection university', 'university showed', 'showed significant', 'significant positive', 'positive correlation', 'correlation mean', 'mean undergradgrad', 'undergradgrad ratio', 'ratio labeled', 'labeled university', 'university twosample', 'twosample test', 'test equivalence', 'equivalence gave', 'gave pvalues', 'pvalues respectively', 'respectively respect', 'respect difference', 'difference interval', 'interval sex', 'sex malefemale', 'malefemale ratio', 'ratio labeled', 'labeled also', 'also observed', 'observed statistically', 'statistically equivalent', 'equivalent student', 'student body', 'body p', 'p p', 'p wrt', 'wrt difference', 'difference interval', 'interval establishes', 'establishes validity', 'validity acquired', 'acquired reddit', 'reddit representative', 'representative source', 'source studying', 'studying disclosure', 'disclosure university', 'university campuseswe', 'campuseswe gained', 'gained access', 'access sample', 'sample public', 'public unique', 'unique shared', 'shared variety', 'variety subredditsthis', 'subredditsthis repository', 'repository ha', 'ha prior', 'prior work', 'work study', 'study selfdisclosure', 'selfdisclosure support', 'support seeking', 'seeking manifested', 'manifested social', 'social medium', 'medium dataset', 'dataset includes', 'includes associated', 'associated metadata', 'metadata spanning', 'spanning related', 'related subreddits', 'subreddits rdepression', 'rdepression rmentalhealth', 'rmentalhealth rtraumatoolbox', 'rtraumatoolbox rbipolarreddit', 'rbipolarreddit corpus', 'corpus excluded', 'excluded contained', 'contained title', 'title without', 'without body', 'body gave', 'gave u', 'u refer', 'refer mh', 'mh also', 'also relied', 'relied dataset', 'dataset compiled', 'compiled utilized', 'utilized prior', 'prior work', 'work contains', 'contains subreddits', 'subreddits rworldnews', 'rworldnews rfood', 'rfood raskreddit', 'raskreddit randomly', 'randomly sampled', 'sampled equal', 'equal number', 'number mh', 'mh dataset', 'dataset refer', 'refer cl']","['note possible type', 'possible type student', 'type student frequent', 'student frequent university', 'frequent university subreddits', 'university subreddits could', 'subreddits could consistently', 'could consistently different', 'consistently different student', 'different student body', 'student body university', 'body university examine', 'university examine representativeness', 'examine representativeness university', 'representativeness university subreddit', 'university subreddit employed', 'subreddit employed random', 'employed random sample', 'random sample distributed', 'sample distributed across', 'distributed across subreddits', 'across subreddits year', 'subreddits year manual', 'year manual examination', 'manual examination demographic', 'examination demographic two', 'demographic two researcher', 'two researcher independently', 'researcher independently coded', 'independently coded selfreported', 'coded selfreported gender', 'selfreported gender race', 'gender race academic', 'race academic stage', 'academic stage undergraduategraduate', 'stage undergraduategraduate instance', 'undergraduategraduate instance im', 'instance im junior', 'im junior transfer', 'junior transfer second', 'transfer second semester', 'second semester researcher', 'semester researcher identified', 'researcher identified author', 'identified author undergraduate', 'author undergraduate whereas', 'undergraduate whereas hi', 'whereas hi im', 'hi im new', 'im new grad', 'new grad student', 'grad student male', 'student male gender', 'male gender author', 'gender author inferred', 'author inferred male', 'inferred male found', 'male found interrater', 'found interrater agreement', 'interrater agreement high', 'agreement high cohens', 'high cohens relative', 'cohens relative ratio', 'relative ratio gender', 'ratio gender race', 'gender race academic', 'race academic stage', 'academic stage distribution', 'stage distribution coded', 'distribution coded university', 'coded university student', 'university student body', 'student body obtained', 'body obtained based', 'obtained based methodology', 'based methodology subsection', 'methodology subsection university', 'subsection university showed', 'university showed significant', 'showed significant positive', 'significant positive correlation', 'positive correlation mean', 'correlation mean undergradgrad', 'mean undergradgrad ratio', 'undergradgrad ratio labeled', 'ratio labeled university', 'labeled university twosample', 'university twosample test', 'twosample test equivalence', 'test equivalence gave', 'equivalence gave pvalues', 'gave pvalues respectively', 'pvalues respectively respect', 'respectively respect difference', 'respect difference interval', 'difference interval sex', 'interval sex malefemale', 'sex malefemale ratio', 'malefemale ratio labeled', 'ratio labeled also', 'labeled also observed', 'also observed statistically', 'observed statistically equivalent', 'statistically equivalent student', 'equivalent student body', 'student body p', 'body p p', 'p p wrt', 'p wrt difference', 'wrt difference interval', 'difference interval establishes', 'interval establishes validity', 'establishes validity acquired', 'validity acquired reddit', 'acquired reddit representative', 'reddit representative source', 'representative source studying', 'source studying disclosure', 'studying disclosure university', 'disclosure university campuseswe', 'university campuseswe gained', 'campuseswe gained access', 'gained access sample', 'access sample public', 'sample public unique', 'public unique shared', 'unique shared variety', 'shared variety subredditsthis', 'variety subredditsthis repository', 'subredditsthis repository ha', 'repository ha prior', 'ha prior work', 'prior work study', 'work study selfdisclosure', 'study selfdisclosure support', 'selfdisclosure support seeking', 'support seeking manifested', 'seeking manifested social', 'manifested social medium', 'social medium dataset', 'medium dataset includes', 'dataset includes associated', 'includes associated metadata', 'associated metadata spanning', 'metadata spanning related', 'spanning related subreddits', 'related subreddits rdepression', 'subreddits rdepression rmentalhealth', 'rdepression rmentalhealth rtraumatoolbox', 'rmentalhealth rtraumatoolbox rbipolarreddit', 'rtraumatoolbox rbipolarreddit corpus', 'rbipolarreddit corpus excluded', 'corpus excluded contained', 'excluded contained title', 'contained title without', 'title without body', 'without body gave', 'body gave u', 'gave u refer', 'u refer mh', 'refer mh also', 'mh also relied', 'also relied dataset', 'relied dataset compiled', 'dataset compiled utilized', 'compiled utilized prior', 'utilized prior work', 'prior work contains', 'work contains subreddits', 'contains subreddits rworldnews', 'subreddits rworldnews rfood', 'rworldnews rfood raskreddit', 'rfood raskreddit randomly', 'raskreddit randomly sampled', 'randomly sampled equal', 'sampled equal number', 'equal number mh', 'number mh dataset', 'mh dataset refer', 'dataset refer cl']"
https://ieeexplore.ieee.org/abstract/document/7752434,1,To train our models we require information from two different types of users: patients and non-patients. Therefore we employed a combined - manual effort and keyword matching - data collection approach to efficiently collect data for these users. For the collection of patients we manually collect the community portals relevant to both mental disorders. 2 From these portals' followers list we select the self-reported users who explicitly state in their profile description that they suffer from a mental illness; i.e. for a given user we are checking if his/her profile contains any keyword related to a target disorder (e.g. “borderline” “bpd” “bipolar”). Non-patients are referred to as random active Twitter users who are not explicitly stating that they are suffering from Bipolar disorder (hereinafter referred to as “BD”) or Borderline Personality Disorder (hereinafter referred to as “BPD”). To obtain these users we randomly sampled Twitter IDs. Thereafter we proceeded to download the tweets from the selected IDs. After the users have been identified we manually label them into one of two categories: 1) Patient: a person who is suffering from a mental disorder 2) Not-related: any user who we don't consider to be a patient. Lastly after having obtained the final list of patients we retrieve their tweets. These steps are applied for the collection of both BPD and BD patient datasets.In this study we collected 17 BPD and 12 BD community portals. 5000 followers for each portal was collected for a total of 145000 accounts. From these accounts we manually picked a subset and annotated each user into positive examples (patient) or not-related examples. After filtering we gathered a total of 278 BD accounts and 203 BPD accounts. A total of 548 random samples (negative examples) were obtained directly from the Twitter REST API. We experimentally chose Random Forest Classifier to be our main learning model. Consequently we trained separate classifiers one for each mental disorder and equally distributed the random samples to each. We used a 10-fold cross validation to evaluate our models. Applying only the TD-IDF features we achieved a precision of 96% for both the BP and BPD models. On the other hand by applying the pattern of life features we achieved a precision of 91% and 92% for the BD and BPD models respectively. All models were further pre-trained and prepared as a REST-API service which produce statistical outputs further converted into insightful visuals.,to train our model we require information from two different type of user patient and nonpatients therefore we employed a combined manual effort and keyword matching data collection approach to efficiently collect data for these user for the collection of patient we manually collect the community portal relevant to both mental disorder from these portal follower list we select the selfreported user who explicitly state in their profile description that they suffer from a mental illness ie for a given user we are checking if hisher profile contains any keyword related to a target disorder eg borderline bpd bipolar nonpatients are referred to a random active twitter user who are not explicitly stating that they are suffering from bipolar disorder hereinafter referred to a bd or borderline personality disorder hereinafter referred to a bpd to obtain these user we randomly sampled twitter id thereafter we proceeded to download the tweet from the selected id after the user have been identified we manually label them into one of two category patient a person who is suffering from a mental disorder notrelated any user who we dont consider to be a patient lastly after having obtained the final list of patient we retrieve their tweet these step are applied for the collection of both bpd and bd patient datasetsin this study we collected bpd and bd community portal follower for each portal wa collected for a total of account from these account we manually picked a subset and annotated each user into positive example patient or notrelated example after filtering we gathered a total of bd account and bpd account a total of random sample negative example were obtained directly from the twitter rest api we experimentally chose random forest classifier to be our main learning model consequently we trained separate classifier one for each mental disorder and equally distributed the random sample to each we used a fold cross validation to evaluate our model applying only the tdidf feature we achieved a precision of for both the bp and bpd model on the other hand by applying the pattern of life feature we achieved a precision of and for the bd and bpd model respectively all model were further pretrained and prepared a a restapi service which produce statistical output further converted into insightful visuals,"['train', 'model', 'require', 'information', 'two', 'different', 'type', 'patient', 'nonpatients', 'therefore', 'employed', 'combined', 'manual', 'effort', 'keyword', 'matching', 'collection', 'approach', 'efficiently', 'collect', 'collection', 'patient', 'manually', 'collect', 'community', 'portal', 'relevant', 'disorder', 'portal', 'follower', 'list', 'select', 'selfreported', 'explicitly', 'state', 'profile', 'description', 'suffer', 'illness', 'ie', 'given', 'checking', 'hisher', 'profile', 'contains', 'keyword', 'related', 'target', 'disorder', 'eg', 'borderline', 'bpd', 'bipolar', 'nonpatients', 'referred', 'random', 'active', 'explicitly', 'stating', 'suffering', 'bipolar', 'disorder', 'hereinafter', 'referred', 'bd', 'borderline', 'personality', 'disorder', 'hereinafter', 'referred', 'bpd', 'obtain', 'randomly', 'sampled', 'id', 'thereafter', 'proceeded', 'download', 'selected', 'id', 'identified', 'manually', 'label', 'one', 'two', 'category', 'patient', 'person', 'suffering', 'disorder', 'notrelated', 'dont', 'consider', 'patient', 'lastly', 'obtained', 'final', 'list', 'patient', 'retrieve', 'step', 'applied', 'collection', 'bpd', 'bd', 'patient', 'datasetsin', 'study', 'collected', 'bpd', 'bd', 'community', 'portal', 'follower', 'portal', 'collected', 'total', 'account', 'account', 'manually', 'picked', 'subset', 'annotated', 'positive', 'example', 'patient', 'notrelated', 'example', 'filtering', 'gathered', 'total', 'bd', 'account', 'bpd', 'account', 'total', 'random', 'sample', 'negative', 'example', 'obtained', 'directly', 'rest', 'api', 'experimentally', 'chose', 'random', 'forest', 'classifier', 'main', 'learning', 'model', 'consequently', 'trained', 'separate', 'classifier', 'one', 'disorder', 'equally', 'distributed', 'random', 'sample', 'fold', 'cross', 'validation', 'evaluate', 'model', 'applying', 'tdidf', 'feature', 'achieved', 'precision', 'bp', 'bpd', 'model', 'hand', 'applying', 'pattern', 'life', 'feature', 'achieved', 'precision', 'bd', 'bpd', 'model', 'respectively', 'model', 'pretrained', 'prepared', 'restapi', 'service', 'produce', 'statistical', 'output', 'converted', 'insightful', 'visuals']","['train model', 'model require', 'require information', 'information two', 'two different', 'different type', 'type patient', 'patient nonpatients', 'nonpatients therefore', 'therefore employed', 'employed combined', 'combined manual', 'manual effort', 'effort keyword', 'keyword matching', 'matching collection', 'collection approach', 'approach efficiently', 'efficiently collect', 'collect collection', 'collection patient', 'patient manually', 'manually collect', 'collect community', 'community portal', 'portal relevant', 'relevant disorder', 'disorder portal', 'portal follower', 'follower list', 'list select', 'select selfreported', 'selfreported explicitly', 'explicitly state', 'state profile', 'profile description', 'description suffer', 'suffer illness', 'illness ie', 'ie given', 'given checking', 'checking hisher', 'hisher profile', 'profile contains', 'contains keyword', 'keyword related', 'related target', 'target disorder', 'disorder eg', 'eg borderline', 'borderline bpd', 'bpd bipolar', 'bipolar nonpatients', 'nonpatients referred', 'referred random', 'random active', 'active explicitly', 'explicitly stating', 'stating suffering', 'suffering bipolar', 'bipolar disorder', 'disorder hereinafter', 'hereinafter referred', 'referred bd', 'bd borderline', 'borderline personality', 'personality disorder', 'disorder hereinafter', 'hereinafter referred', 'referred bpd', 'bpd obtain', 'obtain randomly', 'randomly sampled', 'sampled id', 'id thereafter', 'thereafter proceeded', 'proceeded download', 'download selected', 'selected id', 'id identified', 'identified manually', 'manually label', 'label one', 'one two', 'two category', 'category patient', 'patient person', 'person suffering', 'suffering disorder', 'disorder notrelated', 'notrelated dont', 'dont consider', 'consider patient', 'patient lastly', 'lastly obtained', 'obtained final', 'final list', 'list patient', 'patient retrieve', 'retrieve step', 'step applied', 'applied collection', 'collection bpd', 'bpd bd', 'bd patient', 'patient datasetsin', 'datasetsin study', 'study collected', 'collected bpd', 'bpd bd', 'bd community', 'community portal', 'portal follower', 'follower portal', 'portal collected', 'collected total', 'total account', 'account account', 'account manually', 'manually picked', 'picked subset', 'subset annotated', 'annotated positive', 'positive example', 'example patient', 'patient notrelated', 'notrelated example', 'example filtering', 'filtering gathered', 'gathered total', 'total bd', 'bd account', 'account bpd', 'bpd account', 'account total', 'total random', 'random sample', 'sample negative', 'negative example', 'example obtained', 'obtained directly', 'directly rest', 'rest api', 'api experimentally', 'experimentally chose', 'chose random', 'random forest', 'forest classifier', 'classifier main', 'main learning', 'learning model', 'model consequently', 'consequently trained', 'trained separate', 'separate classifier', 'classifier one', 'one disorder', 'disorder equally', 'equally distributed', 'distributed random', 'random sample', 'sample fold', 'fold cross', 'cross validation', 'validation evaluate', 'evaluate model', 'model applying', 'applying tdidf', 'tdidf feature', 'feature achieved', 'achieved precision', 'precision bp', 'bp bpd', 'bpd model', 'model hand', 'hand applying', 'applying pattern', 'pattern life', 'life feature', 'feature achieved', 'achieved precision', 'precision bd', 'bd bpd', 'bpd model', 'model respectively', 'respectively model', 'model pretrained', 'pretrained prepared', 'prepared restapi', 'restapi service', 'service produce', 'produce statistical', 'statistical output', 'output converted', 'converted insightful', 'insightful visuals']","['train model require', 'model require information', 'require information two', 'information two different', 'two different type', 'different type patient', 'type patient nonpatients', 'patient nonpatients therefore', 'nonpatients therefore employed', 'therefore employed combined', 'employed combined manual', 'combined manual effort', 'manual effort keyword', 'effort keyword matching', 'keyword matching collection', 'matching collection approach', 'collection approach efficiently', 'approach efficiently collect', 'efficiently collect collection', 'collect collection patient', 'collection patient manually', 'patient manually collect', 'manually collect community', 'collect community portal', 'community portal relevant', 'portal relevant disorder', 'relevant disorder portal', 'disorder portal follower', 'portal follower list', 'follower list select', 'list select selfreported', 'select selfreported explicitly', 'selfreported explicitly state', 'explicitly state profile', 'state profile description', 'profile description suffer', 'description suffer illness', 'suffer illness ie', 'illness ie given', 'ie given checking', 'given checking hisher', 'checking hisher profile', 'hisher profile contains', 'profile contains keyword', 'contains keyword related', 'keyword related target', 'related target disorder', 'target disorder eg', 'disorder eg borderline', 'eg borderline bpd', 'borderline bpd bipolar', 'bpd bipolar nonpatients', 'bipolar nonpatients referred', 'nonpatients referred random', 'referred random active', 'random active explicitly', 'active explicitly stating', 'explicitly stating suffering', 'stating suffering bipolar', 'suffering bipolar disorder', 'bipolar disorder hereinafter', 'disorder hereinafter referred', 'hereinafter referred bd', 'referred bd borderline', 'bd borderline personality', 'borderline personality disorder', 'personality disorder hereinafter', 'disorder hereinafter referred', 'hereinafter referred bpd', 'referred bpd obtain', 'bpd obtain randomly', 'obtain randomly sampled', 'randomly sampled id', 'sampled id thereafter', 'id thereafter proceeded', 'thereafter proceeded download', 'proceeded download selected', 'download selected id', 'selected id identified', 'id identified manually', 'identified manually label', 'manually label one', 'label one two', 'one two category', 'two category patient', 'category patient person', 'patient person suffering', 'person suffering disorder', 'suffering disorder notrelated', 'disorder notrelated dont', 'notrelated dont consider', 'dont consider patient', 'consider patient lastly', 'patient lastly obtained', 'lastly obtained final', 'obtained final list', 'final list patient', 'list patient retrieve', 'patient retrieve step', 'retrieve step applied', 'step applied collection', 'applied collection bpd', 'collection bpd bd', 'bpd bd patient', 'bd patient datasetsin', 'patient datasetsin study', 'datasetsin study collected', 'study collected bpd', 'collected bpd bd', 'bpd bd community', 'bd community portal', 'community portal follower', 'portal follower portal', 'follower portal collected', 'portal collected total', 'collected total account', 'total account account', 'account account manually', 'account manually picked', 'manually picked subset', 'picked subset annotated', 'subset annotated positive', 'annotated positive example', 'positive example patient', 'example patient notrelated', 'patient notrelated example', 'notrelated example filtering', 'example filtering gathered', 'filtering gathered total', 'gathered total bd', 'total bd account', 'bd account bpd', 'account bpd account', 'bpd account total', 'account total random', 'total random sample', 'random sample negative', 'sample negative example', 'negative example obtained', 'example obtained directly', 'obtained directly rest', 'directly rest api', 'rest api experimentally', 'api experimentally chose', 'experimentally chose random', 'chose random forest', 'random forest classifier', 'forest classifier main', 'classifier main learning', 'main learning model', 'learning model consequently', 'model consequently trained', 'consequently trained separate', 'trained separate classifier', 'separate classifier one', 'classifier one disorder', 'one disorder equally', 'disorder equally distributed', 'equally distributed random', 'distributed random sample', 'random sample fold', 'sample fold cross', 'fold cross validation', 'cross validation evaluate', 'validation evaluate model', 'evaluate model applying', 'model applying tdidf', 'applying tdidf feature', 'tdidf feature achieved', 'feature achieved precision', 'achieved precision bp', 'precision bp bpd', 'bp bpd model', 'bpd model hand', 'model hand applying', 'hand applying pattern', 'applying pattern life', 'pattern life feature', 'life feature achieved', 'feature achieved precision', 'achieved precision bd', 'precision bd bpd', 'bd bpd model', 'bpd model respectively', 'model respectively model', 'respectively model pretrained', 'model pretrained prepared', 'pretrained prepared restapi', 'prepared restapi service', 'restapi service produce', 'service produce statistical', 'produce statistical output', 'statistical output converted', 'output converted insightful', 'converted insightful visuals']"
https://www.nature.com/articles/s41598-020-68764-y,0,To train our models we require information from two different types of users: patients and non-patients. Therefore we employed a combined - manual effort and keyword matching - data collection approach to efficiently collect data for these users. For the collection of patients we manually collect the community portals relevant to both mental disorders. 2 From these portals' followers list we select the self-reported users who explicitly state in their profile description that they suffer from a mental illness; i.e. for a given user we are checking if his/her profile contains any keyword related to a target disorder (e.g. “borderline” “bpd” “bipolar”). Non-patients are referred to as random active Twitter users who are not explicitly stating that they are suffering from Bipolar disorder (hereinafter referred to as “BD”) or Borderline Personality Disorder (hereinafter referred to as “BPD”). To obtain these users we randomly sampled Twitter IDs. Thereafter we proceeded to download the tweets from the selected IDs. After the users have been identified we manually label them into one of two categories: 1) Patient: a person who is suffering from a mental disorder 2) Not-related: any user who we don't consider to be a patient. Lastly after having obtained the final list of patients we retrieve their tweets. These steps are applied for the collection of both BPD and BD patient datasets.,to train our model we require information from two different type of user patient and nonpatients therefore we employed a combined manual effort and keyword matching data collection approach to efficiently collect data for these user for the collection of patient we manually collect the community portal relevant to both mental disorder from these portal follower list we select the selfreported user who explicitly state in their profile description that they suffer from a mental illness ie for a given user we are checking if hisher profile contains any keyword related to a target disorder eg borderline bpd bipolar nonpatients are referred to a random active twitter user who are not explicitly stating that they are suffering from bipolar disorder hereinafter referred to a bd or borderline personality disorder hereinafter referred to a bpd to obtain these user we randomly sampled twitter id thereafter we proceeded to download the tweet from the selected id after the user have been identified we manually label them into one of two category patient a person who is suffering from a mental disorder notrelated any user who we dont consider to be a patient lastly after having obtained the final list of patient we retrieve their tweet these step are applied for the collection of both bpd and bd patient datasets,"['train', 'model', 'require', 'information', 'two', 'different', 'type', 'patient', 'nonpatients', 'therefore', 'employed', 'combined', 'manual', 'effort', 'keyword', 'matching', 'collection', 'approach', 'efficiently', 'collect', 'collection', 'patient', 'manually', 'collect', 'community', 'portal', 'relevant', 'disorder', 'portal', 'follower', 'list', 'select', 'selfreported', 'explicitly', 'state', 'profile', 'description', 'suffer', 'illness', 'ie', 'given', 'checking', 'hisher', 'profile', 'contains', 'keyword', 'related', 'target', 'disorder', 'eg', 'borderline', 'bpd', 'bipolar', 'nonpatients', 'referred', 'random', 'active', 'explicitly', 'stating', 'suffering', 'bipolar', 'disorder', 'hereinafter', 'referred', 'bd', 'borderline', 'personality', 'disorder', 'hereinafter', 'referred', 'bpd', 'obtain', 'randomly', 'sampled', 'id', 'thereafter', 'proceeded', 'download', 'selected', 'id', 'identified', 'manually', 'label', 'one', 'two', 'category', 'patient', 'person', 'suffering', 'disorder', 'notrelated', 'dont', 'consider', 'patient', 'lastly', 'obtained', 'final', 'list', 'patient', 'retrieve', 'step', 'applied', 'collection', 'bpd', 'bd', 'patient', 'datasets']","['train model', 'model require', 'require information', 'information two', 'two different', 'different type', 'type patient', 'patient nonpatients', 'nonpatients therefore', 'therefore employed', 'employed combined', 'combined manual', 'manual effort', 'effort keyword', 'keyword matching', 'matching collection', 'collection approach', 'approach efficiently', 'efficiently collect', 'collect collection', 'collection patient', 'patient manually', 'manually collect', 'collect community', 'community portal', 'portal relevant', 'relevant disorder', 'disorder portal', 'portal follower', 'follower list', 'list select', 'select selfreported', 'selfreported explicitly', 'explicitly state', 'state profile', 'profile description', 'description suffer', 'suffer illness', 'illness ie', 'ie given', 'given checking', 'checking hisher', 'hisher profile', 'profile contains', 'contains keyword', 'keyword related', 'related target', 'target disorder', 'disorder eg', 'eg borderline', 'borderline bpd', 'bpd bipolar', 'bipolar nonpatients', 'nonpatients referred', 'referred random', 'random active', 'active explicitly', 'explicitly stating', 'stating suffering', 'suffering bipolar', 'bipolar disorder', 'disorder hereinafter', 'hereinafter referred', 'referred bd', 'bd borderline', 'borderline personality', 'personality disorder', 'disorder hereinafter', 'hereinafter referred', 'referred bpd', 'bpd obtain', 'obtain randomly', 'randomly sampled', 'sampled id', 'id thereafter', 'thereafter proceeded', 'proceeded download', 'download selected', 'selected id', 'id identified', 'identified manually', 'manually label', 'label one', 'one two', 'two category', 'category patient', 'patient person', 'person suffering', 'suffering disorder', 'disorder notrelated', 'notrelated dont', 'dont consider', 'consider patient', 'patient lastly', 'lastly obtained', 'obtained final', 'final list', 'list patient', 'patient retrieve', 'retrieve step', 'step applied', 'applied collection', 'collection bpd', 'bpd bd', 'bd patient', 'patient datasets']","['train model require', 'model require information', 'require information two', 'information two different', 'two different type', 'different type patient', 'type patient nonpatients', 'patient nonpatients therefore', 'nonpatients therefore employed', 'therefore employed combined', 'employed combined manual', 'combined manual effort', 'manual effort keyword', 'effort keyword matching', 'keyword matching collection', 'matching collection approach', 'collection approach efficiently', 'approach efficiently collect', 'efficiently collect collection', 'collect collection patient', 'collection patient manually', 'patient manually collect', 'manually collect community', 'collect community portal', 'community portal relevant', 'portal relevant disorder', 'relevant disorder portal', 'disorder portal follower', 'portal follower list', 'follower list select', 'list select selfreported', 'select selfreported explicitly', 'selfreported explicitly state', 'explicitly state profile', 'state profile description', 'profile description suffer', 'description suffer illness', 'suffer illness ie', 'illness ie given', 'ie given checking', 'given checking hisher', 'checking hisher profile', 'hisher profile contains', 'profile contains keyword', 'contains keyword related', 'keyword related target', 'related target disorder', 'target disorder eg', 'disorder eg borderline', 'eg borderline bpd', 'borderline bpd bipolar', 'bpd bipolar nonpatients', 'bipolar nonpatients referred', 'nonpatients referred random', 'referred random active', 'random active explicitly', 'active explicitly stating', 'explicitly stating suffering', 'stating suffering bipolar', 'suffering bipolar disorder', 'bipolar disorder hereinafter', 'disorder hereinafter referred', 'hereinafter referred bd', 'referred bd borderline', 'bd borderline personality', 'borderline personality disorder', 'personality disorder hereinafter', 'disorder hereinafter referred', 'hereinafter referred bpd', 'referred bpd obtain', 'bpd obtain randomly', 'obtain randomly sampled', 'randomly sampled id', 'sampled id thereafter', 'id thereafter proceeded', 'thereafter proceeded download', 'proceeded download selected', 'download selected id', 'selected id identified', 'id identified manually', 'identified manually label', 'manually label one', 'label one two', 'one two category', 'two category patient', 'category patient person', 'patient person suffering', 'person suffering disorder', 'suffering disorder notrelated', 'disorder notrelated dont', 'notrelated dont consider', 'dont consider patient', 'consider patient lastly', 'patient lastly obtained', 'lastly obtained final', 'obtained final list', 'final list patient', 'list patient retrieve', 'patient retrieve step', 'retrieve step applied', 'step applied collection', 'applied collection bpd', 'collection bpd bd', 'bpd bd patient', 'bd patient datasets']"
https://aclanthology.org/W19-3013.pdf,1,Our cohort construction process entails two key steps: first randomly selecting a large sample of Twitter users; and second annotating those users with key demographic attributes. While such attributes are not provided by the API automated methods can be used to infer such traits from data (Cesare et al. 2017). Following this approach we develop a demographic inference pipeline to automatically infer age gender race/ethnicity and location for each cohort candidate. Age Identifying age based on the content of a user can be challenging and exact age often cannot be determined based on language use alone. Therefore we use discrete categories that provide a more accurate estimate of age: Teenager (below 19) 20s 30s 40s 50s (50 years or older). Gender The gender was inferred using Demographer a supervised model that predicts the (binary) gender of Twitter users with features based on the name field on the user profile (Knowles et al. 2016). Race/Ethnicity The standard formulation of race and ethnicity is not well understood by the general public so categorizing social media users along these two axes may not be reasonable. Therefore we use a single measure of multicultural expression that includes five categories: White (W) Asian (A) Black (B) Hispanic (H) and Other. Location The location was inferred using Carmen an open-source library for geolocating tweets that uses a series of rules to lookup location strings in a location knowledge-base (Dredze et al. 2013). We use the inferred location to select users that live in the United States. The age and race/ethnicity attributes were inferred with custom supervised classifiers based on Amir et al. (2017)’s user-level model. The classifiers were trained and evaluated on a dataset of 5K annotated users attaining performances of 0.28 and 0.41 Average F1 respectively. See the supplemental notes for additional details on these experiments1 .We build on prior work on supervised models for mental health inference over social media data. We focus on two mental health conditions — depression and PTSD — and develop classifiers with the self-reported datasets created for CLPysch 2015 (Mitchell et al. 2015; Coppersmith et al. 2015b). These labeled datasets derive from users that have publicly disclosed on Twitter a diagnosis of depression (327 users) or PTSD (246 users) with an equal number of randomly selected demographically-matched (with respect to age and gender) users as controls. For each user the associated metadata and posting history was also collected — up to the 3000 most recent tweets per limitations of the Twitter API. The participants of the task proposed a host of methods ranging from rule-based systems to various supervised models (Pedersen 2015; PreotiucPietro et al. 2015; Coppersmith et al. 2015b). More recently the neural user-level classifier proposed by Amir et al. (2017) showed not only good performance on this task but also the ability to capture implicit similarities between users affected by the same diseases thus opening the door to more interpretable analyses2 . Hence we adopt their model for this analysis.We constructed a cohort for our analysis by randomly selecting a sample of Twitter users and processing it with the aforementioned demographic inference pipeline. After discarding accounts from users located outside the United States we obtained a cohort of 48K Twitter users with the demographic composition shown in Figure 1. Some demographic groups are over-represented (e.g. young adults) while others are grossly underrepresented (e.g. teenagers) which illustrates the need for methodologies that can take these disparities into account. We then processed the cohort through the mental-health classifiers to estimate the prevalence of depression and PTSD and examine how these illnesses manifest across the population. The analysis revealed that 30.2% of the cohort members are likely to suffer from depression 30.8% from PTSD and 20% from both. We observe a significant overlap between people affected by depression and PTSD which is not surprising given that the comorbidity of these disorders is wellknown with approximately half of people with PTSD also having a diagnosis of major depressive disorder (Flory and Yehuda 2015). How do these conditions affect different parts of the population? To answer this question we looked at the affected users and measured how the demographics of individual sub-populations differ from those of the cohort as a whole. Figures 2 and 3 show the estimates for depression PTSD and both controlled for the cohort demographics. We observe large generational differences — PTSD seems to be more prevalent among older people whereas depression affects predominantly younger people. We also observe that in all cases Women are more susceptible than Men and Blacks and Hispanics are more likely to be affected than Whites. This may represent a bias in the underlying data used to construct the classifiers or a difference in how social media is used by different demographic groups. For example models that were trained with a majority of data from White users maybe oversensitive to specific dialects used by other communities.,our cohort construction process entail two key step first randomly selecting a large sample of twitter user and second annotating those user with key demographic attribute while such attribute are not provided by the api automated method can be used to infer such trait from data cesare et al following this approach we develop a demographic inference pipeline to automatically infer age gender raceethnicity and location for each cohort candidate age identifying age based on the content of a user can be challenging and exact age often cannot be determined based on language use alone therefore we use discrete category that provide a more accurate estimate of age teenager below s s s s year or older gender the gender wa inferred using demographer a supervised model that predicts the binary gender of twitter user with feature based on the name field on the user profile knowles et al raceethnicity the standard formulation of race and ethnicity is not well understood by the general public so categorizing social medium user along these two ax may not be reasonable therefore we use a single measure of multicultural expression that includes five category white w asian a black b hispanic h and other location the location wa inferred using carmen an opensource library for geolocating tweet that us a series of rule to lookup location string in a location knowledgebase dredze et al we use the inferred location to select user that live in the united state the age and raceethnicity attribute were inferred with custom supervised classifier based on amir et al s userlevel model the classifier were trained and evaluated on a dataset of k annotated user attaining performance of and average f respectively see the supplemental note for additional detail on these experiment we build on prior work on supervised model for mental health inference over social medium data we focus on two mental health condition depression and ptsd and develop classifier with the selfreported datasets created for clpysch mitchell et al coppersmith et al b these labeled datasets derive from user that have publicly disclosed on twitter a diagnosis of depression user or ptsd user with an equal number of randomly selected demographicallymatched with respect to age and gender user a control for each user the associated metadata and posting history wa also collected up to the most recent tweet per limitation of the twitter api the participant of the task proposed a host of method ranging from rulebased system to various supervised model pedersen preotiucpietro et al coppersmith et al b more recently the neural userlevel classifier proposed by amir et al showed not only good performance on this task but also the ability to capture implicit similarity between user affected by the same disease thus opening the door to more interpretable analysis hence we adopt their model for this analysiswe constructed a cohort for our analysis by randomly selecting a sample of twitter user and processing it with the aforementioned demographic inference pipeline after discarding account from user located outside the united state we obtained a cohort of k twitter user with the demographic composition shown in figure some demographic group are overrepresented eg young adult while others are grossly underrepresented eg teenager which illustrates the need for methodology that can take these disparity into account we then processed the cohort through the mentalhealth classifier to estimate the prevalence of depression and ptsd and examine how these illness manifest across the population the analysis revealed that of the cohort member are likely to suffer from depression from ptsd and from both we observe a significant overlap between people affected by depression and ptsd which is not surprising given that the comorbidity of these disorder is wellknown with approximately half of people with ptsd also having a diagnosis of major depressive disorder flory and yehuda how do these condition affect different part of the population to answer this question we looked at the affected user and measured how the demographic of individual subpopulation differ from those of the cohort a a whole figure and show the estimate for depression ptsd and both controlled for the cohort demographic we observe large generational difference ptsd seems to be more prevalent among older people whereas depression affect predominantly younger people we also observe that in all case woman are more susceptible than men and black and hispanic are more likely to be affected than white this may represent a bias in the underlying data used to construct the classifier or a difference in how social medium is used by different demographic group for example model that were trained with a majority of data from white user maybe oversensitive to specific dialect used by other community,"['cohort', 'construction', 'process', 'entail', 'two', 'key', 'step', 'first', 'randomly', 'selecting', 'large', 'sample', 'second', 'annotating', 'key', 'demographic', 'attribute', 'attribute', 'provided', 'api', 'automated', 'method', 'infer', 'trait', 'cesare', 'et', 'al', 'following', 'approach', 'develop', 'demographic', 'inference', 'pipeline', 'automatically', 'infer', 'age', 'gender', 'raceethnicity', 'location', 'cohort', 'candidate', 'age', 'identifying', 'age', 'based', 'content', 'challenging', 'exact', 'age', 'often', 'cannot', 'determined', 'based', 'language', 'use', 'alone', 'therefore', 'use', 'discrete', 'category', 'provide', 'accurate', 'estimate', 'age', 'teenager', 'year', 'older', 'gender', 'gender', 'inferred', 'using', 'demographer', 'supervised', 'model', 'predicts', 'binary', 'gender', 'feature', 'based', 'name', 'field', 'profile', 'knowles', 'et', 'al', 'raceethnicity', 'standard', 'formulation', 'race', 'ethnicity', 'well', 'understood', 'general', 'public', 'categorizing', 'social', 'medium', 'along', 'two', 'ax', 'may', 'reasonable', 'therefore', 'use', 'single', 'measure', 'multicultural', 'expression', 'includes', 'five', 'category', 'white', 'w', 'asian', 'black', 'b', 'hispanic', 'h', 'location', 'location', 'inferred', 'using', 'carmen', 'opensource', 'library', 'geolocating', 'us', 'series', 'rule', 'lookup', 'location', 'string', 'location', 'knowledgebase', 'dredze', 'et', 'al', 'use', 'inferred', 'location', 'select', 'live', 'united', 'state', 'age', 'raceethnicity', 'attribute', 'inferred', 'custom', 'supervised', 'classifier', 'based', 'amir', 'et', 'al', 'userlevel', 'model', 'classifier', 'trained', 'evaluated', 'dataset', 'k', 'annotated', 'attaining', 'performance', 'average', 'f', 'respectively', 'see', 'supplemental', 'note', 'additional', 'detail', 'experiment', 'build', 'prior', 'work', 'supervised', 'model', 'inference', 'social', 'medium', 'focus', 'two', 'condition', 'ptsd', 'develop', 'classifier', 'selfreported', 'datasets', 'created', 'clpysch', 'mitchell', 'et', 'al', 'coppersmith', 'et', 'al', 'b', 'labeled', 'datasets', 'derive', 'publicly', 'disclosed', 'diagnosis', 'ptsd', 'equal', 'number', 'randomly', 'selected', 'demographicallymatched', 'respect', 'age', 'gender', 'associated', 'metadata', 'posting', 'history', 'also', 'collected', 'recent', 'per', 'limitation', 'api', 'task', 'proposed', 'host', 'method', 'ranging', 'rulebased', 'system', 'various', 'supervised', 'model', 'pedersen', 'preotiucpietro', 'et', 'al', 'coppersmith', 'et', 'al', 'b', 'recently', 'neural', 'userlevel', 'classifier', 'proposed', 'amir', 'et', 'al', 'showed', 'good', 'performance', 'task', 'also', 'ability', 'capture', 'implicit', 'similarity', 'affected', 'disease', 'thus', 'opening', 'door', 'interpretable', 'analysis', 'hence', 'adopt', 'model', 'analysiswe', 'constructed', 'cohort', 'analysis', 'randomly', 'selecting', 'sample', 'processing', 'aforementioned', 'demographic', 'inference', 'pipeline', 'discarding', 'account', 'located', 'outside', 'united', 'state', 'obtained', 'cohort', 'k', 'demographic', 'composition', 'shown', 'figure', 'demographic', 'group', 'overrepresented', 'eg', 'young', 'adult', 'others', 'grossly', 'underrepresented', 'eg', 'teenager', 'illustrates', 'need', 'methodology', 'take', 'disparity', 'account', 'processed', 'cohort', 'mentalhealth', 'classifier', 'estimate', 'prevalence', 'ptsd', 'examine', 'illness', 'manifest', 'across', 'population', 'analysis', 'revealed', 'cohort', 'member', 'likely', 'suffer', 'ptsd', 'observe', 'significant', 'overlap', 'people', 'affected', 'ptsd', 'surprising', 'given', 'comorbidity', 'disorder', 'wellknown', 'approximately', 'half', 'people', 'ptsd', 'also', 'diagnosis', 'major', 'depressive', 'disorder', 'flory', 'yehuda', 'condition', 'affect', 'different', 'part', 'population', 'answer', 'question', 'looked', 'affected', 'measured', 'demographic', 'individual', 'subpopulation', 'differ', 'cohort', 'whole', 'figure', 'show', 'estimate', 'ptsd', 'controlled', 'cohort', 'demographic', 'observe', 'large', 'generational', 'difference', 'ptsd', 'seems', 'prevalent', 'among', 'older', 'people', 'whereas', 'affect', 'predominantly', 'younger', 'people', 'also', 'observe', 'case', 'woman', 'susceptible', 'men', 'black', 'hispanic', 'likely', 'affected', 'white', 'may', 'represent', 'bias', 'underlying', 'construct', 'classifier', 'difference', 'social', 'medium', 'different', 'demographic', 'group', 'example', 'model', 'trained', 'majority', 'white', 'maybe', 'oversensitive', 'specific', 'dialect', 'community']","['cohort construction', 'construction process', 'process entail', 'entail two', 'two key', 'key step', 'step first', 'first randomly', 'randomly selecting', 'selecting large', 'large sample', 'sample second', 'second annotating', 'annotating key', 'key demographic', 'demographic attribute', 'attribute attribute', 'attribute provided', 'provided api', 'api automated', 'automated method', 'method infer', 'infer trait', 'trait cesare', 'cesare et', 'et al', 'al following', 'following approach', 'approach develop', 'develop demographic', 'demographic inference', 'inference pipeline', 'pipeline automatically', 'automatically infer', 'infer age', 'age gender', 'gender raceethnicity', 'raceethnicity location', 'location cohort', 'cohort candidate', 'candidate age', 'age identifying', 'identifying age', 'age based', 'based content', 'content challenging', 'challenging exact', 'exact age', 'age often', 'often cannot', 'cannot determined', 'determined based', 'based language', 'language use', 'use alone', 'alone therefore', 'therefore use', 'use discrete', 'discrete category', 'category provide', 'provide accurate', 'accurate estimate', 'estimate age', 'age teenager', 'teenager year', 'year older', 'older gender', 'gender gender', 'gender inferred', 'inferred using', 'using demographer', 'demographer supervised', 'supervised model', 'model predicts', 'predicts binary', 'binary gender', 'gender feature', 'feature based', 'based name', 'name field', 'field profile', 'profile knowles', 'knowles et', 'et al', 'al raceethnicity', 'raceethnicity standard', 'standard formulation', 'formulation race', 'race ethnicity', 'ethnicity well', 'well understood', 'understood general', 'general public', 'public categorizing', 'categorizing social', 'social medium', 'medium along', 'along two', 'two ax', 'ax may', 'may reasonable', 'reasonable therefore', 'therefore use', 'use single', 'single measure', 'measure multicultural', 'multicultural expression', 'expression includes', 'includes five', 'five category', 'category white', 'white w', 'w asian', 'asian black', 'black b', 'b hispanic', 'hispanic h', 'h location', 'location location', 'location inferred', 'inferred using', 'using carmen', 'carmen opensource', 'opensource library', 'library geolocating', 'geolocating us', 'us series', 'series rule', 'rule lookup', 'lookup location', 'location string', 'string location', 'location knowledgebase', 'knowledgebase dredze', 'dredze et', 'et al', 'al use', 'use inferred', 'inferred location', 'location select', 'select live', 'live united', 'united state', 'state age', 'age raceethnicity', 'raceethnicity attribute', 'attribute inferred', 'inferred custom', 'custom supervised', 'supervised classifier', 'classifier based', 'based amir', 'amir et', 'et al', 'al userlevel', 'userlevel model', 'model classifier', 'classifier trained', 'trained evaluated', 'evaluated dataset', 'dataset k', 'k annotated', 'annotated attaining', 'attaining performance', 'performance average', 'average f', 'f respectively', 'respectively see', 'see supplemental', 'supplemental note', 'note additional', 'additional detail', 'detail experiment', 'experiment build', 'build prior', 'prior work', 'work supervised', 'supervised model', 'model inference', 'inference social', 'social medium', 'medium focus', 'focus two', 'two condition', 'condition ptsd', 'ptsd develop', 'develop classifier', 'classifier selfreported', 'selfreported datasets', 'datasets created', 'created clpysch', 'clpysch mitchell', 'mitchell et', 'et al', 'al coppersmith', 'coppersmith et', 'et al', 'al b', 'b labeled', 'labeled datasets', 'datasets derive', 'derive publicly', 'publicly disclosed', 'disclosed diagnosis', 'diagnosis ptsd', 'ptsd equal', 'equal number', 'number randomly', 'randomly selected', 'selected demographicallymatched', 'demographicallymatched respect', 'respect age', 'age gender', 'gender associated', 'associated metadata', 'metadata posting', 'posting history', 'history also', 'also collected', 'collected recent', 'recent per', 'per limitation', 'limitation api', 'api task', 'task proposed', 'proposed host', 'host method', 'method ranging', 'ranging rulebased', 'rulebased system', 'system various', 'various supervised', 'supervised model', 'model pedersen', 'pedersen preotiucpietro', 'preotiucpietro et', 'et al', 'al coppersmith', 'coppersmith et', 'et al', 'al b', 'b recently', 'recently neural', 'neural userlevel', 'userlevel classifier', 'classifier proposed', 'proposed amir', 'amir et', 'et al', 'al showed', 'showed good', 'good performance', 'performance task', 'task also', 'also ability', 'ability capture', 'capture implicit', 'implicit similarity', 'similarity affected', 'affected disease', 'disease thus', 'thus opening', 'opening door', 'door interpretable', 'interpretable analysis', 'analysis hence', 'hence adopt', 'adopt model', 'model analysiswe', 'analysiswe constructed', 'constructed cohort', 'cohort analysis', 'analysis randomly', 'randomly selecting', 'selecting sample', 'sample processing', 'processing aforementioned', 'aforementioned demographic', 'demographic inference', 'inference pipeline', 'pipeline discarding', 'discarding account', 'account located', 'located outside', 'outside united', 'united state', 'state obtained', 'obtained cohort', 'cohort k', 'k demographic', 'demographic composition', 'composition shown', 'shown figure', 'figure demographic', 'demographic group', 'group overrepresented', 'overrepresented eg', 'eg young', 'young adult', 'adult others', 'others grossly', 'grossly underrepresented', 'underrepresented eg', 'eg teenager', 'teenager illustrates', 'illustrates need', 'need methodology', 'methodology take', 'take disparity', 'disparity account', 'account processed', 'processed cohort', 'cohort mentalhealth', 'mentalhealth classifier', 'classifier estimate', 'estimate prevalence', 'prevalence ptsd', 'ptsd examine', 'examine illness', 'illness manifest', 'manifest across', 'across population', 'population analysis', 'analysis revealed', 'revealed cohort', 'cohort member', 'member likely', 'likely suffer', 'suffer ptsd', 'ptsd observe', 'observe significant', 'significant overlap', 'overlap people', 'people affected', 'affected ptsd', 'ptsd surprising', 'surprising given', 'given comorbidity', 'comorbidity disorder', 'disorder wellknown', 'wellknown approximately', 'approximately half', 'half people', 'people ptsd', 'ptsd also', 'also diagnosis', 'diagnosis major', 'major depressive', 'depressive disorder', 'disorder flory', 'flory yehuda', 'yehuda condition', 'condition affect', 'affect different', 'different part', 'part population', 'population answer', 'answer question', 'question looked', 'looked affected', 'affected measured', 'measured demographic', 'demographic individual', 'individual subpopulation', 'subpopulation differ', 'differ cohort', 'cohort whole', 'whole figure', 'figure show', 'show estimate', 'estimate ptsd', 'ptsd controlled', 'controlled cohort', 'cohort demographic', 'demographic observe', 'observe large', 'large generational', 'generational difference', 'difference ptsd', 'ptsd seems', 'seems prevalent', 'prevalent among', 'among older', 'older people', 'people whereas', 'whereas affect', 'affect predominantly', 'predominantly younger', 'younger people', 'people also', 'also observe', 'observe case', 'case woman', 'woman susceptible', 'susceptible men', 'men black', 'black hispanic', 'hispanic likely', 'likely affected', 'affected white', 'white may', 'may represent', 'represent bias', 'bias underlying', 'underlying construct', 'construct classifier', 'classifier difference', 'difference social', 'social medium', 'medium different', 'different demographic', 'demographic group', 'group example', 'example model', 'model trained', 'trained majority', 'majority white', 'white maybe', 'maybe oversensitive', 'oversensitive specific', 'specific dialect', 'dialect community']","['cohort construction process', 'construction process entail', 'process entail two', 'entail two key', 'two key step', 'key step first', 'step first randomly', 'first randomly selecting', 'randomly selecting large', 'selecting large sample', 'large sample second', 'sample second annotating', 'second annotating key', 'annotating key demographic', 'key demographic attribute', 'demographic attribute attribute', 'attribute attribute provided', 'attribute provided api', 'provided api automated', 'api automated method', 'automated method infer', 'method infer trait', 'infer trait cesare', 'trait cesare et', 'cesare et al', 'et al following', 'al following approach', 'following approach develop', 'approach develop demographic', 'develop demographic inference', 'demographic inference pipeline', 'inference pipeline automatically', 'pipeline automatically infer', 'automatically infer age', 'infer age gender', 'age gender raceethnicity', 'gender raceethnicity location', 'raceethnicity location cohort', 'location cohort candidate', 'cohort candidate age', 'candidate age identifying', 'age identifying age', 'identifying age based', 'age based content', 'based content challenging', 'content challenging exact', 'challenging exact age', 'exact age often', 'age often cannot', 'often cannot determined', 'cannot determined based', 'determined based language', 'based language use', 'language use alone', 'use alone therefore', 'alone therefore use', 'therefore use discrete', 'use discrete category', 'discrete category provide', 'category provide accurate', 'provide accurate estimate', 'accurate estimate age', 'estimate age teenager', 'age teenager year', 'teenager year older', 'year older gender', 'older gender gender', 'gender gender inferred', 'gender inferred using', 'inferred using demographer', 'using demographer supervised', 'demographer supervised model', 'supervised model predicts', 'model predicts binary', 'predicts binary gender', 'binary gender feature', 'gender feature based', 'feature based name', 'based name field', 'name field profile', 'field profile knowles', 'profile knowles et', 'knowles et al', 'et al raceethnicity', 'al raceethnicity standard', 'raceethnicity standard formulation', 'standard formulation race', 'formulation race ethnicity', 'race ethnicity well', 'ethnicity well understood', 'well understood general', 'understood general public', 'general public categorizing', 'public categorizing social', 'categorizing social medium', 'social medium along', 'medium along two', 'along two ax', 'two ax may', 'ax may reasonable', 'may reasonable therefore', 'reasonable therefore use', 'therefore use single', 'use single measure', 'single measure multicultural', 'measure multicultural expression', 'multicultural expression includes', 'expression includes five', 'includes five category', 'five category white', 'category white w', 'white w asian', 'w asian black', 'asian black b', 'black b hispanic', 'b hispanic h', 'hispanic h location', 'h location location', 'location location inferred', 'location inferred using', 'inferred using carmen', 'using carmen opensource', 'carmen opensource library', 'opensource library geolocating', 'library geolocating us', 'geolocating us series', 'us series rule', 'series rule lookup', 'rule lookup location', 'lookup location string', 'location string location', 'string location knowledgebase', 'location knowledgebase dredze', 'knowledgebase dredze et', 'dredze et al', 'et al use', 'al use inferred', 'use inferred location', 'inferred location select', 'location select live', 'select live united', 'live united state', 'united state age', 'state age raceethnicity', 'age raceethnicity attribute', 'raceethnicity attribute inferred', 'attribute inferred custom', 'inferred custom supervised', 'custom supervised classifier', 'supervised classifier based', 'classifier based amir', 'based amir et', 'amir et al', 'et al userlevel', 'al userlevel model', 'userlevel model classifier', 'model classifier trained', 'classifier trained evaluated', 'trained evaluated dataset', 'evaluated dataset k', 'dataset k annotated', 'k annotated attaining', 'annotated attaining performance', 'attaining performance average', 'performance average f', 'average f respectively', 'f respectively see', 'respectively see supplemental', 'see supplemental note', 'supplemental note additional', 'note additional detail', 'additional detail experiment', 'detail experiment build', 'experiment build prior', 'build prior work', 'prior work supervised', 'work supervised model', 'supervised model inference', 'model inference social', 'inference social medium', 'social medium focus', 'medium focus two', 'focus two condition', 'two condition ptsd', 'condition ptsd develop', 'ptsd develop classifier', 'develop classifier selfreported', 'classifier selfreported datasets', 'selfreported datasets created', 'datasets created clpysch', 'created clpysch mitchell', 'clpysch mitchell et', 'mitchell et al', 'et al coppersmith', 'al coppersmith et', 'coppersmith et al', 'et al b', 'al b labeled', 'b labeled datasets', 'labeled datasets derive', 'datasets derive publicly', 'derive publicly disclosed', 'publicly disclosed diagnosis', 'disclosed diagnosis ptsd', 'diagnosis ptsd equal', 'ptsd equal number', 'equal number randomly', 'number randomly selected', 'randomly selected demographicallymatched', 'selected demographicallymatched respect', 'demographicallymatched respect age', 'respect age gender', 'age gender associated', 'gender associated metadata', 'associated metadata posting', 'metadata posting history', 'posting history also', 'history also collected', 'also collected recent', 'collected recent per', 'recent per limitation', 'per limitation api', 'limitation api task', 'api task proposed', 'task proposed host', 'proposed host method', 'host method ranging', 'method ranging rulebased', 'ranging rulebased system', 'rulebased system various', 'system various supervised', 'various supervised model', 'supervised model pedersen', 'model pedersen preotiucpietro', 'pedersen preotiucpietro et', 'preotiucpietro et al', 'et al coppersmith', 'al coppersmith et', 'coppersmith et al', 'et al b', 'al b recently', 'b recently neural', 'recently neural userlevel', 'neural userlevel classifier', 'userlevel classifier proposed', 'classifier proposed amir', 'proposed amir et', 'amir et al', 'et al showed', 'al showed good', 'showed good performance', 'good performance task', 'performance task also', 'task also ability', 'also ability capture', 'ability capture implicit', 'capture implicit similarity', 'implicit similarity affected', 'similarity affected disease', 'affected disease thus', 'disease thus opening', 'thus opening door', 'opening door interpretable', 'door interpretable analysis', 'interpretable analysis hence', 'analysis hence adopt', 'hence adopt model', 'adopt model analysiswe', 'model analysiswe constructed', 'analysiswe constructed cohort', 'constructed cohort analysis', 'cohort analysis randomly', 'analysis randomly selecting', 'randomly selecting sample', 'selecting sample processing', 'sample processing aforementioned', 'processing aforementioned demographic', 'aforementioned demographic inference', 'demographic inference pipeline', 'inference pipeline discarding', 'pipeline discarding account', 'discarding account located', 'account located outside', 'located outside united', 'outside united state', 'united state obtained', 'state obtained cohort', 'obtained cohort k', 'cohort k demographic', 'k demographic composition', 'demographic composition shown', 'composition shown figure', 'shown figure demographic', 'figure demographic group', 'demographic group overrepresented', 'group overrepresented eg', 'overrepresented eg young', 'eg young adult', 'young adult others', 'adult others grossly', 'others grossly underrepresented', 'grossly underrepresented eg', 'underrepresented eg teenager', 'eg teenager illustrates', 'teenager illustrates need', 'illustrates need methodology', 'need methodology take', 'methodology take disparity', 'take disparity account', 'disparity account processed', 'account processed cohort', 'processed cohort mentalhealth', 'cohort mentalhealth classifier', 'mentalhealth classifier estimate', 'classifier estimate prevalence', 'estimate prevalence ptsd', 'prevalence ptsd examine', 'ptsd examine illness', 'examine illness manifest', 'illness manifest across', 'manifest across population', 'across population analysis', 'population analysis revealed', 'analysis revealed cohort', 'revealed cohort member', 'cohort member likely', 'member likely suffer', 'likely suffer ptsd', 'suffer ptsd observe', 'ptsd observe significant', 'observe significant overlap', 'significant overlap people', 'overlap people affected', 'people affected ptsd', 'affected ptsd surprising', 'ptsd surprising given', 'surprising given comorbidity', 'given comorbidity disorder', 'comorbidity disorder wellknown', 'disorder wellknown approximately', 'wellknown approximately half', 'approximately half people', 'half people ptsd', 'people ptsd also', 'ptsd also diagnosis', 'also diagnosis major', 'diagnosis major depressive', 'major depressive disorder', 'depressive disorder flory', 'disorder flory yehuda', 'flory yehuda condition', 'yehuda condition affect', 'condition affect different', 'affect different part', 'different part population', 'part population answer', 'population answer question', 'answer question looked', 'question looked affected', 'looked affected measured', 'affected measured demographic', 'measured demographic individual', 'demographic individual subpopulation', 'individual subpopulation differ', 'subpopulation differ cohort', 'differ cohort whole', 'cohort whole figure', 'whole figure show', 'figure show estimate', 'show estimate ptsd', 'estimate ptsd controlled', 'ptsd controlled cohort', 'controlled cohort demographic', 'cohort demographic observe', 'demographic observe large', 'observe large generational', 'large generational difference', 'generational difference ptsd', 'difference ptsd seems', 'ptsd seems prevalent', 'seems prevalent among', 'prevalent among older', 'among older people', 'older people whereas', 'people whereas affect', 'whereas affect predominantly', 'affect predominantly younger', 'predominantly younger people', 'younger people also', 'people also observe', 'also observe case', 'observe case woman', 'case woman susceptible', 'woman susceptible men', 'susceptible men black', 'men black hispanic', 'black hispanic likely', 'hispanic likely affected', 'likely affected white', 'affected white may', 'white may represent', 'may represent bias', 'represent bias underlying', 'bias underlying construct', 'underlying construct classifier', 'construct classifier difference', 'classifier difference social', 'difference social medium', 'social medium different', 'medium different demographic', 'different demographic group', 'demographic group example', 'group example model', 'example model trained', 'model trained majority', 'trained majority white', 'majority white maybe', 'white maybe oversensitive', 'maybe oversensitive specific', 'oversensitive specific dialect', 'specific dialect community']"
https://link.springer.com/chapter/10.1007/978-3-319-67186-4_6,1,To evaluate the effectiveness of our topic modelling methodology we selected random subsets of 60 public journals for each topic and 100 public journals with no assigned topic. We manually labeled the sampled journals looking for one of the 14 available topics no topic or “other” topic. Including “other” allowed us to validate whether our list of manually labeled topic names were accurate and complete. We then compared our labels with those assigned by the model. For journals which were assigned two topics by the model we considered the model correct if either one of the assigned topics was equal to the topic we chose manually. Table 2 shows the topic accuracies of our model. Overall our model works well with an average accuracy well above 80%. Journals without topics were much shorter in length. The average journal length of a journal with no topic was 114 characters while one topic was 142 and two topics was 185. Manual inspection confirmed that these journals indeed did not contain any topic more than 70% of the time. Instead they mostly contained sentiment that was already available from mood labels. We conclude this section by remarking that we analyzed activity around significant events such as the 2016 American Election. We did not find statistically significant anomalies in topics mentioned since the topics we derived are mostly related to day-to-day activities.,to evaluate the effectiveness of our topic modelling methodology we selected random subset of public journal for each topic and public journal with no assigned topic we manually labeled the sampled journal looking for one of the available topic no topic or other topic including other allowed u to validate whether our list of manually labeled topic name were accurate and complete we then compared our label with those assigned by the model for journal which were assigned two topic by the model we considered the model correct if either one of the assigned topic wa equal to the topic we chose manually table show the topic accuracy of our model overall our model work well with an average accuracy well above journal without topic were much shorter in length the average journal length of a journal with no topic wa character while one topic wa and two topic wa manual inspection confirmed that these journal indeed did not contain any topic more than of the time instead they mostly contained sentiment that wa already available from mood label we conclude this section by remarking that we analyzed activity around significant event such a the american election we did not find statistically significant anomaly in topic mentioned since the topic we derived are mostly related to daytoday activity,"['evaluate', 'effectiveness', 'topic', 'modelling', 'methodology', 'selected', 'random', 'subset', 'public', 'journal', 'topic', 'public', 'journal', 'assigned', 'topic', 'manually', 'labeled', 'sampled', 'journal', 'looking', 'one', 'available', 'topic', 'topic', 'topic', 'including', 'allowed', 'u', 'validate', 'whether', 'list', 'manually', 'labeled', 'topic', 'name', 'accurate', 'complete', 'compared', 'label', 'assigned', 'model', 'journal', 'assigned', 'two', 'topic', 'model', 'considered', 'model', 'correct', 'either', 'one', 'assigned', 'topic', 'equal', 'topic', 'chose', 'manually', 'table', 'show', 'topic', 'accuracy', 'model', 'overall', 'model', 'work', 'well', 'average', 'accuracy', 'well', 'journal', 'without', 'topic', 'much', 'shorter', 'length', 'average', 'journal', 'length', 'journal', 'topic', 'character', 'one', 'topic', 'two', 'topic', 'manual', 'inspection', 'confirmed', 'journal', 'indeed', 'contain', 'topic', 'time', 'instead', 'mostly', 'contained', 'sentiment', 'already', 'available', 'mood', 'label', 'conclude', 'section', 'remarking', 'analyzed', 'activity', 'around', 'significant', 'event', 'american', 'election', 'find', 'statistically', 'significant', 'anomaly', 'topic', 'mentioned', 'since', 'topic', 'derived', 'mostly', 'related', 'daytoday', 'activity']","['evaluate effectiveness', 'effectiveness topic', 'topic modelling', 'modelling methodology', 'methodology selected', 'selected random', 'random subset', 'subset public', 'public journal', 'journal topic', 'topic public', 'public journal', 'journal assigned', 'assigned topic', 'topic manually', 'manually labeled', 'labeled sampled', 'sampled journal', 'journal looking', 'looking one', 'one available', 'available topic', 'topic topic', 'topic topic', 'topic including', 'including allowed', 'allowed u', 'u validate', 'validate whether', 'whether list', 'list manually', 'manually labeled', 'labeled topic', 'topic name', 'name accurate', 'accurate complete', 'complete compared', 'compared label', 'label assigned', 'assigned model', 'model journal', 'journal assigned', 'assigned two', 'two topic', 'topic model', 'model considered', 'considered model', 'model correct', 'correct either', 'either one', 'one assigned', 'assigned topic', 'topic equal', 'equal topic', 'topic chose', 'chose manually', 'manually table', 'table show', 'show topic', 'topic accuracy', 'accuracy model', 'model overall', 'overall model', 'model work', 'work well', 'well average', 'average accuracy', 'accuracy well', 'well journal', 'journal without', 'without topic', 'topic much', 'much shorter', 'shorter length', 'length average', 'average journal', 'journal length', 'length journal', 'journal topic', 'topic character', 'character one', 'one topic', 'topic two', 'two topic', 'topic manual', 'manual inspection', 'inspection confirmed', 'confirmed journal', 'journal indeed', 'indeed contain', 'contain topic', 'topic time', 'time instead', 'instead mostly', 'mostly contained', 'contained sentiment', 'sentiment already', 'already available', 'available mood', 'mood label', 'label conclude', 'conclude section', 'section remarking', 'remarking analyzed', 'analyzed activity', 'activity around', 'around significant', 'significant event', 'event american', 'american election', 'election find', 'find statistically', 'statistically significant', 'significant anomaly', 'anomaly topic', 'topic mentioned', 'mentioned since', 'since topic', 'topic derived', 'derived mostly', 'mostly related', 'related daytoday', 'daytoday activity']","['evaluate effectiveness topic', 'effectiveness topic modelling', 'topic modelling methodology', 'modelling methodology selected', 'methodology selected random', 'selected random subset', 'random subset public', 'subset public journal', 'public journal topic', 'journal topic public', 'topic public journal', 'public journal assigned', 'journal assigned topic', 'assigned topic manually', 'topic manually labeled', 'manually labeled sampled', 'labeled sampled journal', 'sampled journal looking', 'journal looking one', 'looking one available', 'one available topic', 'available topic topic', 'topic topic topic', 'topic topic including', 'topic including allowed', 'including allowed u', 'allowed u validate', 'u validate whether', 'validate whether list', 'whether list manually', 'list manually labeled', 'manually labeled topic', 'labeled topic name', 'topic name accurate', 'name accurate complete', 'accurate complete compared', 'complete compared label', 'compared label assigned', 'label assigned model', 'assigned model journal', 'model journal assigned', 'journal assigned two', 'assigned two topic', 'two topic model', 'topic model considered', 'model considered model', 'considered model correct', 'model correct either', 'correct either one', 'either one assigned', 'one assigned topic', 'assigned topic equal', 'topic equal topic', 'equal topic chose', 'topic chose manually', 'chose manually table', 'manually table show', 'table show topic', 'show topic accuracy', 'topic accuracy model', 'accuracy model overall', 'model overall model', 'overall model work', 'model work well', 'work well average', 'well average accuracy', 'average accuracy well', 'accuracy well journal', 'well journal without', 'journal without topic', 'without topic much', 'topic much shorter', 'much shorter length', 'shorter length average', 'length average journal', 'average journal length', 'journal length journal', 'length journal topic', 'journal topic character', 'topic character one', 'character one topic', 'one topic two', 'topic two topic', 'two topic manual', 'topic manual inspection', 'manual inspection confirmed', 'inspection confirmed journal', 'confirmed journal indeed', 'journal indeed contain', 'indeed contain topic', 'contain topic time', 'topic time instead', 'time instead mostly', 'instead mostly contained', 'mostly contained sentiment', 'contained sentiment already', 'sentiment already available', 'already available mood', 'available mood label', 'mood label conclude', 'label conclude section', 'conclude section remarking', 'section remarking analyzed', 'remarking analyzed activity', 'analyzed activity around', 'activity around significant', 'around significant event', 'significant event american', 'event american election', 'american election find', 'election find statistically', 'find statistically significant', 'statistically significant anomaly', 'significant anomaly topic', 'anomaly topic mentioned', 'topic mentioned since', 'mentioned since topic', 'since topic derived', 'topic derived mostly', 'derived mostly related', 'mostly related daytoday', 'related daytoday activity']"
https://dl.acm.org/doi/abs/10.1145/2556288.2557214,1,The 197 survey respondents who reported seeking health information using a search engine were asked to recall the most recent instance and to answer questions related to that specific incident. Respondents also described their search objective. These responses were classified using an iterative open coding process. A second rater used this scheme to rate a random sample of 30 responses; inter-rater reliability (Cohen’s ) indicated substantial agreement ( = .72). The same verification strategy is used in the rest of this section. We coded the intent for 183 respondents (the others had unclear intent). Some searches had multiple intents and received multiple categorizations so the percentages sum to more than 100%. The most common motivation for using a search engine was to identify treatment options (53.0%) e.g. “stretches to cure or ease [tight hamstring].” Alternative and holistic treatment was a popular sub-category comprising 13.5% of treatment searches e.g. “alternative treatment [hypothyroidism].” The next most common motivation was diagnosis of a health condition (26.8%) (e.g. “whether or not the symptoms matched my behavior [depression]”) or interpreting the symptoms that they experienced (e.g. “what may be a cause of this and if it may mean something more may be wrong [very heavy menstrual cycle]”). A third motivation was general understanding of a health condition or procedure (20.8%) including understanding what a medical procedure might entail (e.g. “more about the surgery process healing time [umbilical hernia]”) understanding the causes of an illness (e.g. “the caused [sic] of it… [infertility]”) or other general learning about a condition (e.g. “prognosis [congestive heart failure]”). 7.1% of recalled searches were motivated by understanding medications such as understanding side effects (e.g. “to be able to learn the side effects [cholesterol medications]”) comparing and contrasting medications (e.g. “effectiveness [of cancer treatments]”) or seeking information on available medications such as whether non-prescription options are available or learning more about how a medication worked. 6.0% sought lifestyle information for chronic concerns particularly nutrition information for managing diabetes cholesterol or weight loss (“special diet [cholesterol]”). Beyond these broad categories participants also described other intents behind their search activity. 2.2% sought recent medical research findings on conditions or their treatments and 1.1% sought social support such as online support groups for people with their diagnosis. Intent of Twitter Use for Health Information Seeking In a similar way to engine use the 40 respondents who indicated they had sought health information on Twitter were asked to recall the most recent event. They explained their objectives in free-text. Open coding was used to categorize responses; the same categories were used for why people used search engines with additional categories added as needed. Once again substantial agreement was observed with the second coder (30 ratings =.77). Three responses were unclassifiable; percentages are of the remaining 37. As with search engines the most common objective was locating treatment information (56.8%) e.g. “how to help relieve the pain [numbness in the legs]”. 8.1% specifically sought natural or alternative treatments e.g. “natural remedies to headaches.” 16.2% of respondents sought information about healthy lifestyles such as nutrition dieting or fitness (e.g. “different ways to lose weight”) and 13.5% sought to gain a general understanding of a health condition e.g. causes (e.g. “why it happens…” [enlarged prostate]) consequences or general knowledge. 5.4% sought new research about conditions or treatments and 5.4% looked to find others with a similar situation to offer support or advice (e.g. “if anyone else hsd [sic] allergy problems”). Only 2.7% reported seeking diagnostic information on Twitter. Intent of Sharing Health Information on Twitter The 48 respondents who recalled sharing information related to their health on Twitter were asked to consider the most recent incident and to answer a series of questions with that specific occurrence in mind. Participants explained in free-text what their intent was behind sharing health information on Twitter (substantial agreement with second coder =.65). 10 were not coded due to vagueness or missing responses. Of the remaining 38 responses 63.2% reported that they intended to share information about their immediate health status or symptoms (e.g. “I was having a few teeth removed and I may not be online for a few days”). 34.2% wanted to share information or news about a condition (e.g. “treatments that work for me [fibromyalgia and neuropathy]”).We focus on the social media platform Twitter a popular microblogging service used by 18% of U.S. Internet users and whose popularity continues to increase [28]. Twitter is particularly interesting to study since nearly all posts are public; the public nature of tweets provides an interesting counterpoint to the private nature of search engine activity. We gathered a 15-month sample of Twitter’s Firehose stream (which includes all public tweets) between November 1 2011 and March 31 2013 made available to us under contract focusing on English-language tweets. Twitter post count and unique user count were computed for each condition and aggregated over the full time period. Specifically we considered a post to belong to a certain health condition if there was a regular expression match of the condition to the text of the post (this would not permit substring matches within terms). To reduce noise we excluded posts that were retweets or contained hyperlinks since they were likely related to general news and not a user’s personal health. Using this method we obtained 125166549 tweets on the 165 health conditions from 62269225 users in the time period of interest. The median number of posts was 51687 per condition from a median of 40152 users per condition.,the survey respondent who reported seeking health information using a search engine were asked to recall the most recent instance and to answer question related to that specific incident respondent also described their search objective these response were classified using an iterative open coding process a second rater used this scheme to rate a random sample of response interrater reliability cohens indicated substantial agreement the same verification strategy is used in the rest of this section we coded the intent for respondent the others had unclear intent some search had multiple intent and received multiple categorization so the percentage sum to more than the most common motivation for using a search engine wa to identify treatment option eg stretch to cure or ease tight hamstring alternative and holistic treatment wa a popular subcategory comprising of treatment search eg alternative treatment hypothyroidism the next most common motivation wa diagnosis of a health condition eg whether or not the symptom matched my behavior depression or interpreting the symptom that they experienced eg what may be a cause of this and if it may mean something more may be wrong very heavy menstrual cycle a third motivation wa general understanding of a health condition or procedure including understanding what a medical procedure might entail eg more about the surgery process healing time umbilical hernia understanding the cause of an illness eg the caused sic of it infertility or other general learning about a condition eg prognosis congestive heart failure of recalled search were motivated by understanding medication such a understanding side effect eg to be able to learn the side effect cholesterol medication comparing and contrasting medication eg effectiveness of cancer treatment or seeking information on available medication such a whether nonprescription option are available or learning more about how a medication worked sought lifestyle information for chronic concern particularly nutrition information for managing diabetes cholesterol or weight loss special diet cholesterol beyond these broad category participant also described other intent behind their search activity sought recent medical research finding on condition or their treatment and sought social support such a online support group for people with their diagnosis intent of twitter use for health information seeking in a similar way to engine use the respondent who indicated they had sought health information on twitter were asked to recall the most recent event they explained their objective in freetext open coding wa used to categorize response the same category were used for why people used search engine with additional category added a needed once again substantial agreement wa observed with the second coder rating three response were unclassifiable percentage are of the remaining a with search engine the most common objective wa locating treatment information eg how to help relieve the pain numbness in the leg specifically sought natural or alternative treatment eg natural remedy to headache of respondent sought information about healthy lifestyle such a nutrition dieting or fitness eg different way to lose weight and sought to gain a general understanding of a health condition eg cause eg why it happens enlarged prostate consequence or general knowledge sought new research about condition or treatment and looked to find others with a similar situation to offer support or advice eg if anyone else hsd sic allergy problem only reported seeking diagnostic information on twitter intent of sharing health information on twitter the respondent who recalled sharing information related to their health on twitter were asked to consider the most recent incident and to answer a series of question with that specific occurrence in mind participant explained in freetext what their intent wa behind sharing health information on twitter substantial agreement with second coder were not coded due to vagueness or missing response of the remaining response reported that they intended to share information about their immediate health status or symptom eg i wa having a few teeth removed and i may not be online for a few day wanted to share information or news about a condition eg treatment that work for me fibromyalgia and neuropathywe focus on the social medium platform twitter a popular microblogging service used by of u internet user and whose popularity continues to increase twitter is particularly interesting to study since nearly all post are public the public nature of tweet provides an interesting counterpoint to the private nature of search engine activity we gathered a month sample of twitter firehose stream which includes all public tweet between november and march made available to u under contract focusing on englishlanguage tweet twitter post count and unique user count were computed for each condition and aggregated over the full time period specifically we considered a post to belong to a certain health condition if there wa a regular expression match of the condition to the text of the post this would not permit substring match within term to reduce noise we excluded post that were retweets or contained hyperlink since they were likely related to general news and not a user personal health using this method we obtained tweet on the health condition from user in the time period of interest the median number of post wa per condition from a median of user per condition,"['survey', 'respondent', 'reported', 'seeking', 'information', 'using', 'search', 'engine', 'asked', 'recall', 'recent', 'instance', 'answer', 'question', 'related', 'specific', 'incident', 'respondent', 'also', 'described', 'search', 'objective', 'response', 'classified', 'using', 'iterative', 'open', 'coding', 'process', 'second', 'rater', 'scheme', 'rate', 'random', 'sample', 'response', 'interrater', 'reliability', 'cohens', 'indicated', 'substantial', 'agreement', 'verification', 'strategy', 'rest', 'section', 'coded', 'intent', 'respondent', 'others', 'unclear', 'intent', 'search', 'multiple', 'intent', 'received', 'multiple', 'categorization', 'percentage', 'sum', 'common', 'motivation', 'using', 'search', 'engine', 'identify', 'treatment', 'option', 'eg', 'stretch', 'cure', 'ease', 'tight', 'hamstring', 'alternative', 'holistic', 'treatment', 'popular', 'subcategory', 'comprising', 'treatment', 'search', 'eg', 'alternative', 'treatment', 'hypothyroidism', 'next', 'common', 'motivation', 'diagnosis', 'condition', 'eg', 'whether', 'symptom', 'matched', 'behavior', 'interpreting', 'symptom', 'experienced', 'eg', 'may', 'cause', 'may', 'mean', 'something', 'may', 'wrong', 'heavy', 'menstrual', 'cycle', 'third', 'motivation', 'general', 'understanding', 'condition', 'procedure', 'including', 'understanding', 'medical', 'procedure', 'might', 'entail', 'eg', 'surgery', 'process', 'healing', 'time', 'umbilical', 'hernia', 'understanding', 'cause', 'illness', 'eg', 'caused', 'sic', 'infertility', 'general', 'learning', 'condition', 'eg', 'prognosis', 'congestive', 'heart', 'failure', 'recalled', 'search', 'motivated', 'understanding', 'medication', 'understanding', 'side', 'effect', 'eg', 'able', 'learn', 'side', 'effect', 'cholesterol', 'medication', 'comparing', 'contrasting', 'medication', 'eg', 'effectiveness', 'cancer', 'treatment', 'seeking', 'information', 'available', 'medication', 'whether', 'nonprescription', 'option', 'available', 'learning', 'medication', 'worked', 'sought', 'lifestyle', 'information', 'chronic', 'concern', 'particularly', 'nutrition', 'information', 'managing', 'diabetes', 'cholesterol', 'weight', 'loss', 'special', 'diet', 'cholesterol', 'beyond', 'broad', 'category', 'also', 'described', 'intent', 'behind', 'search', 'activity', 'sought', 'recent', 'medical', 'research', 'finding', 'condition', 'treatment', 'sought', 'social', 'support', 'online', 'support', 'group', 'people', 'diagnosis', 'intent', 'use', 'information', 'seeking', 'similar', 'way', 'engine', 'use', 'respondent', 'indicated', 'sought', 'information', 'asked', 'recall', 'recent', 'event', 'explained', 'objective', 'freetext', 'open', 'coding', 'categorize', 'response', 'category', 'people', 'search', 'engine', 'additional', 'category', 'added', 'needed', 'substantial', 'agreement', 'observed', 'second', 'coder', 'rating', 'three', 'response', 'unclassifiable', 'percentage', 'remaining', 'search', 'engine', 'common', 'objective', 'locating', 'treatment', 'information', 'eg', 'help', 'relieve', 'pain', 'numbness', 'leg', 'specifically', 'sought', 'natural', 'alternative', 'treatment', 'eg', 'natural', 'remedy', 'headache', 'respondent', 'sought', 'information', 'healthy', 'lifestyle', 'nutrition', 'dieting', 'fitness', 'eg', 'different', 'way', 'lose', 'weight', 'sought', 'gain', 'general', 'understanding', 'condition', 'eg', 'cause', 'eg', 'happens', 'enlarged', 'prostate', 'consequence', 'general', 'knowledge', 'sought', 'new', 'research', 'condition', 'treatment', 'looked', 'find', 'others', 'similar', 'situation', 'offer', 'support', 'advice', 'eg', 'anyone', 'else', 'hsd', 'sic', 'allergy', 'problem', 'reported', 'seeking', 'diagnostic', 'information', 'intent', 'sharing', 'information', 'respondent', 'recalled', 'sharing', 'information', 'related', 'asked', 'consider', 'recent', 'incident', 'answer', 'series', 'question', 'specific', 'occurrence', 'mind', 'explained', 'freetext', 'intent', 'behind', 'sharing', 'information', 'substantial', 'agreement', 'second', 'coder', 'coded', 'due', 'vagueness', 'missing', 'response', 'remaining', 'response', 'reported', 'intended', 'share', 'information', 'immediate', 'status', 'symptom', 'eg', 'teeth', 'removed', 'may', 'online', 'day', 'wanted', 'share', 'information', 'news', 'condition', 'eg', 'treatment', 'work', 'fibromyalgia', 'neuropathywe', 'focus', 'social', 'medium', 'platform', 'popular', 'microblogging', 'service', 'u', 'internet', 'whose', 'popularity', 'continues', 'increase', 'particularly', 'interesting', 'study', 'since', 'nearly', 'public', 'public', 'nature', 'provides', 'interesting', 'counterpoint', 'private', 'nature', 'search', 'engine', 'activity', 'gathered', 'month', 'sample', 'firehose', 'stream', 'includes', 'public', 'november', 'march', 'made', 'available', 'u', 'contract', 'focusing', 'englishlanguage', 'count', 'unique', 'count', 'computed', 'condition', 'aggregated', 'full', 'time', 'period', 'specifically', 'considered', 'belong', 'certain', 'condition', 'regular', 'expression', 'match', 'condition', 'text', 'would', 'permit', 'substring', 'match', 'within', 'term', 'reduce', 'noise', 'excluded', 'retweets', 'contained', 'hyperlink', 'since', 'likely', 'related', 'general', 'news', 'personal', 'using', 'method', 'obtained', 'condition', 'time', 'period', 'interest', 'median', 'number', 'per', 'condition', 'median', 'per', 'condition']","['survey respondent', 'respondent reported', 'reported seeking', 'seeking information', 'information using', 'using search', 'search engine', 'engine asked', 'asked recall', 'recall recent', 'recent instance', 'instance answer', 'answer question', 'question related', 'related specific', 'specific incident', 'incident respondent', 'respondent also', 'also described', 'described search', 'search objective', 'objective response', 'response classified', 'classified using', 'using iterative', 'iterative open', 'open coding', 'coding process', 'process second', 'second rater', 'rater scheme', 'scheme rate', 'rate random', 'random sample', 'sample response', 'response interrater', 'interrater reliability', 'reliability cohens', 'cohens indicated', 'indicated substantial', 'substantial agreement', 'agreement verification', 'verification strategy', 'strategy rest', 'rest section', 'section coded', 'coded intent', 'intent respondent', 'respondent others', 'others unclear', 'unclear intent', 'intent search', 'search multiple', 'multiple intent', 'intent received', 'received multiple', 'multiple categorization', 'categorization percentage', 'percentage sum', 'sum common', 'common motivation', 'motivation using', 'using search', 'search engine', 'engine identify', 'identify treatment', 'treatment option', 'option eg', 'eg stretch', 'stretch cure', 'cure ease', 'ease tight', 'tight hamstring', 'hamstring alternative', 'alternative holistic', 'holistic treatment', 'treatment popular', 'popular subcategory', 'subcategory comprising', 'comprising treatment', 'treatment search', 'search eg', 'eg alternative', 'alternative treatment', 'treatment hypothyroidism', 'hypothyroidism next', 'next common', 'common motivation', 'motivation diagnosis', 'diagnosis condition', 'condition eg', 'eg whether', 'whether symptom', 'symptom matched', 'matched behavior', 'behavior interpreting', 'interpreting symptom', 'symptom experienced', 'experienced eg', 'eg may', 'may cause', 'cause may', 'may mean', 'mean something', 'something may', 'may wrong', 'wrong heavy', 'heavy menstrual', 'menstrual cycle', 'cycle third', 'third motivation', 'motivation general', 'general understanding', 'understanding condition', 'condition procedure', 'procedure including', 'including understanding', 'understanding medical', 'medical procedure', 'procedure might', 'might entail', 'entail eg', 'eg surgery', 'surgery process', 'process healing', 'healing time', 'time umbilical', 'umbilical hernia', 'hernia understanding', 'understanding cause', 'cause illness', 'illness eg', 'eg caused', 'caused sic', 'sic infertility', 'infertility general', 'general learning', 'learning condition', 'condition eg', 'eg prognosis', 'prognosis congestive', 'congestive heart', 'heart failure', 'failure recalled', 'recalled search', 'search motivated', 'motivated understanding', 'understanding medication', 'medication understanding', 'understanding side', 'side effect', 'effect eg', 'eg able', 'able learn', 'learn side', 'side effect', 'effect cholesterol', 'cholesterol medication', 'medication comparing', 'comparing contrasting', 'contrasting medication', 'medication eg', 'eg effectiveness', 'effectiveness cancer', 'cancer treatment', 'treatment seeking', 'seeking information', 'information available', 'available medication', 'medication whether', 'whether nonprescription', 'nonprescription option', 'option available', 'available learning', 'learning medication', 'medication worked', 'worked sought', 'sought lifestyle', 'lifestyle information', 'information chronic', 'chronic concern', 'concern particularly', 'particularly nutrition', 'nutrition information', 'information managing', 'managing diabetes', 'diabetes cholesterol', 'cholesterol weight', 'weight loss', 'loss special', 'special diet', 'diet cholesterol', 'cholesterol beyond', 'beyond broad', 'broad category', 'category also', 'also described', 'described intent', 'intent behind', 'behind search', 'search activity', 'activity sought', 'sought recent', 'recent medical', 'medical research', 'research finding', 'finding condition', 'condition treatment', 'treatment sought', 'sought social', 'social support', 'support online', 'online support', 'support group', 'group people', 'people diagnosis', 'diagnosis intent', 'intent use', 'use information', 'information seeking', 'seeking similar', 'similar way', 'way engine', 'engine use', 'use respondent', 'respondent indicated', 'indicated sought', 'sought information', 'information asked', 'asked recall', 'recall recent', 'recent event', 'event explained', 'explained objective', 'objective freetext', 'freetext open', 'open coding', 'coding categorize', 'categorize response', 'response category', 'category people', 'people search', 'search engine', 'engine additional', 'additional category', 'category added', 'added needed', 'needed substantial', 'substantial agreement', 'agreement observed', 'observed second', 'second coder', 'coder rating', 'rating three', 'three response', 'response unclassifiable', 'unclassifiable percentage', 'percentage remaining', 'remaining search', 'search engine', 'engine common', 'common objective', 'objective locating', 'locating treatment', 'treatment information', 'information eg', 'eg help', 'help relieve', 'relieve pain', 'pain numbness', 'numbness leg', 'leg specifically', 'specifically sought', 'sought natural', 'natural alternative', 'alternative treatment', 'treatment eg', 'eg natural', 'natural remedy', 'remedy headache', 'headache respondent', 'respondent sought', 'sought information', 'information healthy', 'healthy lifestyle', 'lifestyle nutrition', 'nutrition dieting', 'dieting fitness', 'fitness eg', 'eg different', 'different way', 'way lose', 'lose weight', 'weight sought', 'sought gain', 'gain general', 'general understanding', 'understanding condition', 'condition eg', 'eg cause', 'cause eg', 'eg happens', 'happens enlarged', 'enlarged prostate', 'prostate consequence', 'consequence general', 'general knowledge', 'knowledge sought', 'sought new', 'new research', 'research condition', 'condition treatment', 'treatment looked', 'looked find', 'find others', 'others similar', 'similar situation', 'situation offer', 'offer support', 'support advice', 'advice eg', 'eg anyone', 'anyone else', 'else hsd', 'hsd sic', 'sic allergy', 'allergy problem', 'problem reported', 'reported seeking', 'seeking diagnostic', 'diagnostic information', 'information intent', 'intent sharing', 'sharing information', 'information respondent', 'respondent recalled', 'recalled sharing', 'sharing information', 'information related', 'related asked', 'asked consider', 'consider recent', 'recent incident', 'incident answer', 'answer series', 'series question', 'question specific', 'specific occurrence', 'occurrence mind', 'mind explained', 'explained freetext', 'freetext intent', 'intent behind', 'behind sharing', 'sharing information', 'information substantial', 'substantial agreement', 'agreement second', 'second coder', 'coder coded', 'coded due', 'due vagueness', 'vagueness missing', 'missing response', 'response remaining', 'remaining response', 'response reported', 'reported intended', 'intended share', 'share information', 'information immediate', 'immediate status', 'status symptom', 'symptom eg', 'eg teeth', 'teeth removed', 'removed may', 'may online', 'online day', 'day wanted', 'wanted share', 'share information', 'information news', 'news condition', 'condition eg', 'eg treatment', 'treatment work', 'work fibromyalgia', 'fibromyalgia neuropathywe', 'neuropathywe focus', 'focus social', 'social medium', 'medium platform', 'platform popular', 'popular microblogging', 'microblogging service', 'service u', 'u internet', 'internet whose', 'whose popularity', 'popularity continues', 'continues increase', 'increase particularly', 'particularly interesting', 'interesting study', 'study since', 'since nearly', 'nearly public', 'public public', 'public nature', 'nature provides', 'provides interesting', 'interesting counterpoint', 'counterpoint private', 'private nature', 'nature search', 'search engine', 'engine activity', 'activity gathered', 'gathered month', 'month sample', 'sample firehose', 'firehose stream', 'stream includes', 'includes public', 'public november', 'november march', 'march made', 'made available', 'available u', 'u contract', 'contract focusing', 'focusing englishlanguage', 'englishlanguage count', 'count unique', 'unique count', 'count computed', 'computed condition', 'condition aggregated', 'aggregated full', 'full time', 'time period', 'period specifically', 'specifically considered', 'considered belong', 'belong certain', 'certain condition', 'condition regular', 'regular expression', 'expression match', 'match condition', 'condition text', 'text would', 'would permit', 'permit substring', 'substring match', 'match within', 'within term', 'term reduce', 'reduce noise', 'noise excluded', 'excluded retweets', 'retweets contained', 'contained hyperlink', 'hyperlink since', 'since likely', 'likely related', 'related general', 'general news', 'news personal', 'personal using', 'using method', 'method obtained', 'obtained condition', 'condition time', 'time period', 'period interest', 'interest median', 'median number', 'number per', 'per condition', 'condition median', 'median per', 'per condition']","['survey respondent reported', 'respondent reported seeking', 'reported seeking information', 'seeking information using', 'information using search', 'using search engine', 'search engine asked', 'engine asked recall', 'asked recall recent', 'recall recent instance', 'recent instance answer', 'instance answer question', 'answer question related', 'question related specific', 'related specific incident', 'specific incident respondent', 'incident respondent also', 'respondent also described', 'also described search', 'described search objective', 'search objective response', 'objective response classified', 'response classified using', 'classified using iterative', 'using iterative open', 'iterative open coding', 'open coding process', 'coding process second', 'process second rater', 'second rater scheme', 'rater scheme rate', 'scheme rate random', 'rate random sample', 'random sample response', 'sample response interrater', 'response interrater reliability', 'interrater reliability cohens', 'reliability cohens indicated', 'cohens indicated substantial', 'indicated substantial agreement', 'substantial agreement verification', 'agreement verification strategy', 'verification strategy rest', 'strategy rest section', 'rest section coded', 'section coded intent', 'coded intent respondent', 'intent respondent others', 'respondent others unclear', 'others unclear intent', 'unclear intent search', 'intent search multiple', 'search multiple intent', 'multiple intent received', 'intent received multiple', 'received multiple categorization', 'multiple categorization percentage', 'categorization percentage sum', 'percentage sum common', 'sum common motivation', 'common motivation using', 'motivation using search', 'using search engine', 'search engine identify', 'engine identify treatment', 'identify treatment option', 'treatment option eg', 'option eg stretch', 'eg stretch cure', 'stretch cure ease', 'cure ease tight', 'ease tight hamstring', 'tight hamstring alternative', 'hamstring alternative holistic', 'alternative holistic treatment', 'holistic treatment popular', 'treatment popular subcategory', 'popular subcategory comprising', 'subcategory comprising treatment', 'comprising treatment search', 'treatment search eg', 'search eg alternative', 'eg alternative treatment', 'alternative treatment hypothyroidism', 'treatment hypothyroidism next', 'hypothyroidism next common', 'next common motivation', 'common motivation diagnosis', 'motivation diagnosis condition', 'diagnosis condition eg', 'condition eg whether', 'eg whether symptom', 'whether symptom matched', 'symptom matched behavior', 'matched behavior interpreting', 'behavior interpreting symptom', 'interpreting symptom experienced', 'symptom experienced eg', 'experienced eg may', 'eg may cause', 'may cause may', 'cause may mean', 'may mean something', 'mean something may', 'something may wrong', 'may wrong heavy', 'wrong heavy menstrual', 'heavy menstrual cycle', 'menstrual cycle third', 'cycle third motivation', 'third motivation general', 'motivation general understanding', 'general understanding condition', 'understanding condition procedure', 'condition procedure including', 'procedure including understanding', 'including understanding medical', 'understanding medical procedure', 'medical procedure might', 'procedure might entail', 'might entail eg', 'entail eg surgery', 'eg surgery process', 'surgery process healing', 'process healing time', 'healing time umbilical', 'time umbilical hernia', 'umbilical hernia understanding', 'hernia understanding cause', 'understanding cause illness', 'cause illness eg', 'illness eg caused', 'eg caused sic', 'caused sic infertility', 'sic infertility general', 'infertility general learning', 'general learning condition', 'learning condition eg', 'condition eg prognosis', 'eg prognosis congestive', 'prognosis congestive heart', 'congestive heart failure', 'heart failure recalled', 'failure recalled search', 'recalled search motivated', 'search motivated understanding', 'motivated understanding medication', 'understanding medication understanding', 'medication understanding side', 'understanding side effect', 'side effect eg', 'effect eg able', 'eg able learn', 'able learn side', 'learn side effect', 'side effect cholesterol', 'effect cholesterol medication', 'cholesterol medication comparing', 'medication comparing contrasting', 'comparing contrasting medication', 'contrasting medication eg', 'medication eg effectiveness', 'eg effectiveness cancer', 'effectiveness cancer treatment', 'cancer treatment seeking', 'treatment seeking information', 'seeking information available', 'information available medication', 'available medication whether', 'medication whether nonprescription', 'whether nonprescription option', 'nonprescription option available', 'option available learning', 'available learning medication', 'learning medication worked', 'medication worked sought', 'worked sought lifestyle', 'sought lifestyle information', 'lifestyle information chronic', 'information chronic concern', 'chronic concern particularly', 'concern particularly nutrition', 'particularly nutrition information', 'nutrition information managing', 'information managing diabetes', 'managing diabetes cholesterol', 'diabetes cholesterol weight', 'cholesterol weight loss', 'weight loss special', 'loss special diet', 'special diet cholesterol', 'diet cholesterol beyond', 'cholesterol beyond broad', 'beyond broad category', 'broad category also', 'category also described', 'also described intent', 'described intent behind', 'intent behind search', 'behind search activity', 'search activity sought', 'activity sought recent', 'sought recent medical', 'recent medical research', 'medical research finding', 'research finding condition', 'finding condition treatment', 'condition treatment sought', 'treatment sought social', 'sought social support', 'social support online', 'support online support', 'online support group', 'support group people', 'group people diagnosis', 'people diagnosis intent', 'diagnosis intent use', 'intent use information', 'use information seeking', 'information seeking similar', 'seeking similar way', 'similar way engine', 'way engine use', 'engine use respondent', 'use respondent indicated', 'respondent indicated sought', 'indicated sought information', 'sought information asked', 'information asked recall', 'asked recall recent', 'recall recent event', 'recent event explained', 'event explained objective', 'explained objective freetext', 'objective freetext open', 'freetext open coding', 'open coding categorize', 'coding categorize response', 'categorize response category', 'response category people', 'category people search', 'people search engine', 'search engine additional', 'engine additional category', 'additional category added', 'category added needed', 'added needed substantial', 'needed substantial agreement', 'substantial agreement observed', 'agreement observed second', 'observed second coder', 'second coder rating', 'coder rating three', 'rating three response', 'three response unclassifiable', 'response unclassifiable percentage', 'unclassifiable percentage remaining', 'percentage remaining search', 'remaining search engine', 'search engine common', 'engine common objective', 'common objective locating', 'objective locating treatment', 'locating treatment information', 'treatment information eg', 'information eg help', 'eg help relieve', 'help relieve pain', 'relieve pain numbness', 'pain numbness leg', 'numbness leg specifically', 'leg specifically sought', 'specifically sought natural', 'sought natural alternative', 'natural alternative treatment', 'alternative treatment eg', 'treatment eg natural', 'eg natural remedy', 'natural remedy headache', 'remedy headache respondent', 'headache respondent sought', 'respondent sought information', 'sought information healthy', 'information healthy lifestyle', 'healthy lifestyle nutrition', 'lifestyle nutrition dieting', 'nutrition dieting fitness', 'dieting fitness eg', 'fitness eg different', 'eg different way', 'different way lose', 'way lose weight', 'lose weight sought', 'weight sought gain', 'sought gain general', 'gain general understanding', 'general understanding condition', 'understanding condition eg', 'condition eg cause', 'eg cause eg', 'cause eg happens', 'eg happens enlarged', 'happens enlarged prostate', 'enlarged prostate consequence', 'prostate consequence general', 'consequence general knowledge', 'general knowledge sought', 'knowledge sought new', 'sought new research', 'new research condition', 'research condition treatment', 'condition treatment looked', 'treatment looked find', 'looked find others', 'find others similar', 'others similar situation', 'similar situation offer', 'situation offer support', 'offer support advice', 'support advice eg', 'advice eg anyone', 'eg anyone else', 'anyone else hsd', 'else hsd sic', 'hsd sic allergy', 'sic allergy problem', 'allergy problem reported', 'problem reported seeking', 'reported seeking diagnostic', 'seeking diagnostic information', 'diagnostic information intent', 'information intent sharing', 'intent sharing information', 'sharing information respondent', 'information respondent recalled', 'respondent recalled sharing', 'recalled sharing information', 'sharing information related', 'information related asked', 'related asked consider', 'asked consider recent', 'consider recent incident', 'recent incident answer', 'incident answer series', 'answer series question', 'series question specific', 'question specific occurrence', 'specific occurrence mind', 'occurrence mind explained', 'mind explained freetext', 'explained freetext intent', 'freetext intent behind', 'intent behind sharing', 'behind sharing information', 'sharing information substantial', 'information substantial agreement', 'substantial agreement second', 'agreement second coder', 'second coder coded', 'coder coded due', 'coded due vagueness', 'due vagueness missing', 'vagueness missing response', 'missing response remaining', 'response remaining response', 'remaining response reported', 'response reported intended', 'reported intended share', 'intended share information', 'share information immediate', 'information immediate status', 'immediate status symptom', 'status symptom eg', 'symptom eg teeth', 'eg teeth removed', 'teeth removed may', 'removed may online', 'may online day', 'online day wanted', 'day wanted share', 'wanted share information', 'share information news', 'information news condition', 'news condition eg', 'condition eg treatment', 'eg treatment work', 'treatment work fibromyalgia', 'work fibromyalgia neuropathywe', 'fibromyalgia neuropathywe focus', 'neuropathywe focus social', 'focus social medium', 'social medium platform', 'medium platform popular', 'platform popular microblogging', 'popular microblogging service', 'microblogging service u', 'service u internet', 'u internet whose', 'internet whose popularity', 'whose popularity continues', 'popularity continues increase', 'continues increase particularly', 'increase particularly interesting', 'particularly interesting study', 'interesting study since', 'study since nearly', 'since nearly public', 'nearly public public', 'public public nature', 'public nature provides', 'nature provides interesting', 'provides interesting counterpoint', 'interesting counterpoint private', 'counterpoint private nature', 'private nature search', 'nature search engine', 'search engine activity', 'engine activity gathered', 'activity gathered month', 'gathered month sample', 'month sample firehose', 'sample firehose stream', 'firehose stream includes', 'stream includes public', 'includes public november', 'public november march', 'november march made', 'march made available', 'made available u', 'available u contract', 'u contract focusing', 'contract focusing englishlanguage', 'focusing englishlanguage count', 'englishlanguage count unique', 'count unique count', 'unique count computed', 'count computed condition', 'computed condition aggregated', 'condition aggregated full', 'aggregated full time', 'full time period', 'time period specifically', 'period specifically considered', 'specifically considered belong', 'considered belong certain', 'belong certain condition', 'certain condition regular', 'condition regular expression', 'regular expression match', 'expression match condition', 'match condition text', 'condition text would', 'text would permit', 'would permit substring', 'permit substring match', 'substring match within', 'match within term', 'within term reduce', 'term reduce noise', 'reduce noise excluded', 'noise excluded retweets', 'excluded retweets contained', 'retweets contained hyperlink', 'contained hyperlink since', 'hyperlink since likely', 'since likely related', 'likely related general', 'related general news', 'general news personal', 'news personal using', 'personal using method', 'using method obtained', 'method obtained condition', 'obtained condition time', 'condition time period', 'time period interest', 'period interest median', 'interest median number', 'median number per', 'number per condition', 'per condition median', 'condition median per', 'median per condition']"
https://www.aaai.org/ocs/index.php/ICWSM/ICWSM14/paper/viewPaper/8075,0,reddit is a social news website where registered users submit content in the form of links or text posts. Users also known as “redditors” can then vote each submission “up” or “down” to rank the post and determine its position or prominence on the site’s pages. These two attributes associated with a post are referred to as “upvotes” and “downvotes”. Redditors can also comment on posts and respond back in a conversation tree of comments. Content entries that is the posts are organized by areas of interest or sub-communities called “subreddits” such as politics programming or science. As of 2013 reddit’s official statistics included 56 billion page views 731 million unique visitors 40855032 posts and 404603286 comments (http://blog.reddit.com/2013/ 12/top-posts-of-2013-stats-and-snoo-years.html). We used of reddit’s official API (http://www.reddit.com/ dev /api) to collect posts comments and associated metadata from several mental health subreddits: specifically using a Python wrapper PRAW (https://praw.readthedocs.org/en/ latest/index.html). The subreddits we crawled were: alcoholism anxiety bipolarreddit depression mentalhealth MMFB (Make Me Feel Better) socialanxiety SuicideWatch. All of these subreddits host public content. In order to arrive at a comprehensive list of subreddits to focus on we utilized reddit’s native subreddit search feature (http://www.reddit.com/reddits) and searched for subreddits on “mental health”. Two researchers familiar with reddit employed an initial filtering step on the search results returned so that we focus on high precision subreddits discussing mental health concerns and issues. Thereafter we focused on a snowball approach in which starting with a few seed subreddits (mentalhealth depression) we compiled a second list of “related” or “similar” subreddits that are listed in the profile pages of the seed subreddits. Following a second filtering step we arrived at the list of subreddits listed above. For each of these subreddits we obtained daily crawls of their posts in the New category. Corresponding to each post we collected information on the title of the post the body or textual content id timestamp when the post was made author id and the number of upvotes and downvotes it obtained. Since posts gather comments over a period of time following the time of sharing we crawled all of the comments per post that were shared over a three day period after the post was made. Qualitative examinations of the subreddits of interest revealed that 90% or more of the comments to any post were typically made in a three day window following the time the post is made—hence the choice. The crawl of the subreddits used in this paper We present some descriptive statistics of our crawled data. Our dataset contained 20411 posts with at least one comment and 97661 comments in all with 27102 unique users who made posts comments or both. A set of 7823 users (28.79%) were found to write both at least one post and comment. CDF of the user distribution over posts and comments is given in Figure 1. The figure shows the expected heavy tail trend observed in several social phenomena. Also see Figure 2 for the distribution of comments over time following post share. It illustrates the quick responsivity culture in the communities we study (peak at 3 hours). Some of the additional statistics of our dataset are given in Table 1. Further example titles of a few,reddit is a social news website where registered user submit content in the form of link or text post user also known a redditors can then vote each submission up or down to rank the post and determine it position or prominence on the site page these two attribute associated with a post are referred to a upvotes and downvotes redditors can also comment on post and respond back in a conversation tree of comment content entry that is the post are organized by area of interest or subcommunities called subreddits such a politics programming or science a of reddits official statistic included billion page view million unique visitor post and comment httpblogredditcom toppostsofstatsandsnooyearshtml we used of reddits official api httpwwwredditcom dev api to collect post comment and associated metadata from several mental health subreddits specifically using a python wrapper praw httpsprawreadthedocsorgen latestindexhtml the subreddits we crawled were alcoholism anxiety bipolarreddit depression mentalhealth mmfb make me feel better socialanxiety suicidewatch all of these subreddits host public content in order to arrive at a comprehensive list of subreddits to focus on we utilized reddits native subreddit search feature httpwwwredditcomreddits and searched for subreddits on mental health two researcher familiar with reddit employed an initial filtering step on the search result returned so that we focus on high precision subreddits discussing mental health concern and issue thereafter we focused on a snowball approach in which starting with a few seed subreddits mentalhealth depression we compiled a second list of related or similar subreddits that are listed in the profile page of the seed subreddits following a second filtering step we arrived at the list of subreddits listed above for each of these subreddits we obtained daily crawl of their post in the new category corresponding to each post we collected information on the title of the post the body or textual content id timestamp when the post wa made author id and the number of upvotes and downvotes it obtained since post gather comment over a period of time following the time of sharing we crawled all of the comment per post that were shared over a three day period after the post wa made qualitative examination of the subreddits of interest revealed that or more of the comment to any post were typically made in a three day window following the time the post is madehence the choice the crawl of the subreddits used in this paper we present some descriptive statistic of our crawled data our dataset contained post with at least one comment and comment in all with unique user who made post comment or both a set of user were found to write both at least one post and comment cdf of the user distribution over post and comment is given in figure the figure show the expected heavy tail trend observed in several social phenomenon also see figure for the distribution of comment over time following post share it illustrates the quick responsivity culture in the community we study peak at hour some of the additional statistic of our dataset are given in table further example title of a few,"['reddit', 'social', 'news', 'website', 'registered', 'submit', 'content', 'form', 'link', 'text', 'also', 'known', 'redditors', 'vote', 'submission', 'rank', 'determine', 'position', 'prominence', 'site', 'page', 'two', 'attribute', 'associated', 'referred', 'upvotes', 'downvotes', 'redditors', 'also', 'comment', 'respond', 'back', 'conversation', 'tree', 'comment', 'content', 'entry', 'organized', 'area', 'interest', 'subcommunities', 'called', 'subreddits', 'politics', 'programming', 'science', 'reddits', 'official', 'statistic', 'included', 'billion', 'page', 'view', 'million', 'unique', 'visitor', 'comment', 'httpblogredditcom', 'toppostsofstatsandsnooyearshtml', 'reddits', 'official', 'api', 'httpwwwredditcom', 'dev', 'api', 'collect', 'comment', 'associated', 'metadata', 'several', 'subreddits', 'specifically', 'using', 'python', 'wrapper', 'praw', 'httpsprawreadthedocsorgen', 'latestindexhtml', 'subreddits', 'crawled', 'alcoholism', 'anxiety', 'bipolarreddit', 'mentalhealth', 'mmfb', 'make', 'feel', 'better', 'socialanxiety', 'suicidewatch', 'subreddits', 'host', 'public', 'content', 'order', 'arrive', 'comprehensive', 'list', 'subreddits', 'focus', 'utilized', 'reddits', 'native', 'subreddit', 'search', 'feature', 'httpwwwredditcomreddits', 'searched', 'subreddits', 'two', 'researcher', 'familiar', 'reddit', 'employed', 'initial', 'filtering', 'step', 'search', 'result', 'returned', 'focus', 'high', 'precision', 'subreddits', 'discussing', 'concern', 'issue', 'thereafter', 'focused', 'snowball', 'approach', 'starting', 'seed', 'subreddits', 'mentalhealth', 'compiled', 'second', 'list', 'related', 'similar', 'subreddits', 'listed', 'profile', 'page', 'seed', 'subreddits', 'following', 'second', 'filtering', 'step', 'arrived', 'list', 'subreddits', 'listed', 'subreddits', 'obtained', 'daily', 'crawl', 'new', 'category', 'corresponding', 'collected', 'information', 'title', 'body', 'textual', 'content', 'id', 'timestamp', 'made', 'author', 'id', 'number', 'upvotes', 'downvotes', 'obtained', 'since', 'gather', 'comment', 'period', 'time', 'following', 'time', 'sharing', 'crawled', 'comment', 'per', 'shared', 'three', 'day', 'period', 'made', 'qualitative', 'examination', 'subreddits', 'interest', 'revealed', 'comment', 'typically', 'made', 'three', 'day', 'window', 'following', 'time', 'madehence', 'choice', 'crawl', 'subreddits', 'paper', 'present', 'descriptive', 'statistic', 'crawled', 'dataset', 'contained', 'least', 'one', 'comment', 'comment', 'unique', 'made', 'comment', 'set', 'found', 'write', 'least', 'one', 'comment', 'cdf', 'distribution', 'comment', 'given', 'figure', 'figure', 'show', 'expected', 'heavy', 'tail', 'trend', 'observed', 'several', 'social', 'phenomenon', 'also', 'see', 'figure', 'distribution', 'comment', 'time', 'following', 'share', 'illustrates', 'quick', 'responsivity', 'culture', 'community', 'study', 'peak', 'hour', 'additional', 'statistic', 'dataset', 'given', 'table', 'example', 'title']","['reddit social', 'social news', 'news website', 'website registered', 'registered submit', 'submit content', 'content form', 'form link', 'link text', 'text also', 'also known', 'known redditors', 'redditors vote', 'vote submission', 'submission rank', 'rank determine', 'determine position', 'position prominence', 'prominence site', 'site page', 'page two', 'two attribute', 'attribute associated', 'associated referred', 'referred upvotes', 'upvotes downvotes', 'downvotes redditors', 'redditors also', 'also comment', 'comment respond', 'respond back', 'back conversation', 'conversation tree', 'tree comment', 'comment content', 'content entry', 'entry organized', 'organized area', 'area interest', 'interest subcommunities', 'subcommunities called', 'called subreddits', 'subreddits politics', 'politics programming', 'programming science', 'science reddits', 'reddits official', 'official statistic', 'statistic included', 'included billion', 'billion page', 'page view', 'view million', 'million unique', 'unique visitor', 'visitor comment', 'comment httpblogredditcom', 'httpblogredditcom toppostsofstatsandsnooyearshtml', 'toppostsofstatsandsnooyearshtml reddits', 'reddits official', 'official api', 'api httpwwwredditcom', 'httpwwwredditcom dev', 'dev api', 'api collect', 'collect comment', 'comment associated', 'associated metadata', 'metadata several', 'several subreddits', 'subreddits specifically', 'specifically using', 'using python', 'python wrapper', 'wrapper praw', 'praw httpsprawreadthedocsorgen', 'httpsprawreadthedocsorgen latestindexhtml', 'latestindexhtml subreddits', 'subreddits crawled', 'crawled alcoholism', 'alcoholism anxiety', 'anxiety bipolarreddit', 'bipolarreddit mentalhealth', 'mentalhealth mmfb', 'mmfb make', 'make feel', 'feel better', 'better socialanxiety', 'socialanxiety suicidewatch', 'suicidewatch subreddits', 'subreddits host', 'host public', 'public content', 'content order', 'order arrive', 'arrive comprehensive', 'comprehensive list', 'list subreddits', 'subreddits focus', 'focus utilized', 'utilized reddits', 'reddits native', 'native subreddit', 'subreddit search', 'search feature', 'feature httpwwwredditcomreddits', 'httpwwwredditcomreddits searched', 'searched subreddits', 'subreddits two', 'two researcher', 'researcher familiar', 'familiar reddit', 'reddit employed', 'employed initial', 'initial filtering', 'filtering step', 'step search', 'search result', 'result returned', 'returned focus', 'focus high', 'high precision', 'precision subreddits', 'subreddits discussing', 'discussing concern', 'concern issue', 'issue thereafter', 'thereafter focused', 'focused snowball', 'snowball approach', 'approach starting', 'starting seed', 'seed subreddits', 'subreddits mentalhealth', 'mentalhealth compiled', 'compiled second', 'second list', 'list related', 'related similar', 'similar subreddits', 'subreddits listed', 'listed profile', 'profile page', 'page seed', 'seed subreddits', 'subreddits following', 'following second', 'second filtering', 'filtering step', 'step arrived', 'arrived list', 'list subreddits', 'subreddits listed', 'listed subreddits', 'subreddits obtained', 'obtained daily', 'daily crawl', 'crawl new', 'new category', 'category corresponding', 'corresponding collected', 'collected information', 'information title', 'title body', 'body textual', 'textual content', 'content id', 'id timestamp', 'timestamp made', 'made author', 'author id', 'id number', 'number upvotes', 'upvotes downvotes', 'downvotes obtained', 'obtained since', 'since gather', 'gather comment', 'comment period', 'period time', 'time following', 'following time', 'time sharing', 'sharing crawled', 'crawled comment', 'comment per', 'per shared', 'shared three', 'three day', 'day period', 'period made', 'made qualitative', 'qualitative examination', 'examination subreddits', 'subreddits interest', 'interest revealed', 'revealed comment', 'comment typically', 'typically made', 'made three', 'three day', 'day window', 'window following', 'following time', 'time madehence', 'madehence choice', 'choice crawl', 'crawl subreddits', 'subreddits paper', 'paper present', 'present descriptive', 'descriptive statistic', 'statistic crawled', 'crawled dataset', 'dataset contained', 'contained least', 'least one', 'one comment', 'comment comment', 'comment unique', 'unique made', 'made comment', 'comment set', 'set found', 'found write', 'write least', 'least one', 'one comment', 'comment cdf', 'cdf distribution', 'distribution comment', 'comment given', 'given figure', 'figure figure', 'figure show', 'show expected', 'expected heavy', 'heavy tail', 'tail trend', 'trend observed', 'observed several', 'several social', 'social phenomenon', 'phenomenon also', 'also see', 'see figure', 'figure distribution', 'distribution comment', 'comment time', 'time following', 'following share', 'share illustrates', 'illustrates quick', 'quick responsivity', 'responsivity culture', 'culture community', 'community study', 'study peak', 'peak hour', 'hour additional', 'additional statistic', 'statistic dataset', 'dataset given', 'given table', 'table example', 'example title']","['reddit social news', 'social news website', 'news website registered', 'website registered submit', 'registered submit content', 'submit content form', 'content form link', 'form link text', 'link text also', 'text also known', 'also known redditors', 'known redditors vote', 'redditors vote submission', 'vote submission rank', 'submission rank determine', 'rank determine position', 'determine position prominence', 'position prominence site', 'prominence site page', 'site page two', 'page two attribute', 'two attribute associated', 'attribute associated referred', 'associated referred upvotes', 'referred upvotes downvotes', 'upvotes downvotes redditors', 'downvotes redditors also', 'redditors also comment', 'also comment respond', 'comment respond back', 'respond back conversation', 'back conversation tree', 'conversation tree comment', 'tree comment content', 'comment content entry', 'content entry organized', 'entry organized area', 'organized area interest', 'area interest subcommunities', 'interest subcommunities called', 'subcommunities called subreddits', 'called subreddits politics', 'subreddits politics programming', 'politics programming science', 'programming science reddits', 'science reddits official', 'reddits official statistic', 'official statistic included', 'statistic included billion', 'included billion page', 'billion page view', 'page view million', 'view million unique', 'million unique visitor', 'unique visitor comment', 'visitor comment httpblogredditcom', 'comment httpblogredditcom toppostsofstatsandsnooyearshtml', 'httpblogredditcom toppostsofstatsandsnooyearshtml reddits', 'toppostsofstatsandsnooyearshtml reddits official', 'reddits official api', 'official api httpwwwredditcom', 'api httpwwwredditcom dev', 'httpwwwredditcom dev api', 'dev api collect', 'api collect comment', 'collect comment associated', 'comment associated metadata', 'associated metadata several', 'metadata several subreddits', 'several subreddits specifically', 'subreddits specifically using', 'specifically using python', 'using python wrapper', 'python wrapper praw', 'wrapper praw httpsprawreadthedocsorgen', 'praw httpsprawreadthedocsorgen latestindexhtml', 'httpsprawreadthedocsorgen latestindexhtml subreddits', 'latestindexhtml subreddits crawled', 'subreddits crawled alcoholism', 'crawled alcoholism anxiety', 'alcoholism anxiety bipolarreddit', 'anxiety bipolarreddit mentalhealth', 'bipolarreddit mentalhealth mmfb', 'mentalhealth mmfb make', 'mmfb make feel', 'make feel better', 'feel better socialanxiety', 'better socialanxiety suicidewatch', 'socialanxiety suicidewatch subreddits', 'suicidewatch subreddits host', 'subreddits host public', 'host public content', 'public content order', 'content order arrive', 'order arrive comprehensive', 'arrive comprehensive list', 'comprehensive list subreddits', 'list subreddits focus', 'subreddits focus utilized', 'focus utilized reddits', 'utilized reddits native', 'reddits native subreddit', 'native subreddit search', 'subreddit search feature', 'search feature httpwwwredditcomreddits', 'feature httpwwwredditcomreddits searched', 'httpwwwredditcomreddits searched subreddits', 'searched subreddits two', 'subreddits two researcher', 'two researcher familiar', 'researcher familiar reddit', 'familiar reddit employed', 'reddit employed initial', 'employed initial filtering', 'initial filtering step', 'filtering step search', 'step search result', 'search result returned', 'result returned focus', 'returned focus high', 'focus high precision', 'high precision subreddits', 'precision subreddits discussing', 'subreddits discussing concern', 'discussing concern issue', 'concern issue thereafter', 'issue thereafter focused', 'thereafter focused snowball', 'focused snowball approach', 'snowball approach starting', 'approach starting seed', 'starting seed subreddits', 'seed subreddits mentalhealth', 'subreddits mentalhealth compiled', 'mentalhealth compiled second', 'compiled second list', 'second list related', 'list related similar', 'related similar subreddits', 'similar subreddits listed', 'subreddits listed profile', 'listed profile page', 'profile page seed', 'page seed subreddits', 'seed subreddits following', 'subreddits following second', 'following second filtering', 'second filtering step', 'filtering step arrived', 'step arrived list', 'arrived list subreddits', 'list subreddits listed', 'subreddits listed subreddits', 'listed subreddits obtained', 'subreddits obtained daily', 'obtained daily crawl', 'daily crawl new', 'crawl new category', 'new category corresponding', 'category corresponding collected', 'corresponding collected information', 'collected information title', 'information title body', 'title body textual', 'body textual content', 'textual content id', 'content id timestamp', 'id timestamp made', 'timestamp made author', 'made author id', 'author id number', 'id number upvotes', 'number upvotes downvotes', 'upvotes downvotes obtained', 'downvotes obtained since', 'obtained since gather', 'since gather comment', 'gather comment period', 'comment period time', 'period time following', 'time following time', 'following time sharing', 'time sharing crawled', 'sharing crawled comment', 'crawled comment per', 'comment per shared', 'per shared three', 'shared three day', 'three day period', 'day period made', 'period made qualitative', 'made qualitative examination', 'qualitative examination subreddits', 'examination subreddits interest', 'subreddits interest revealed', 'interest revealed comment', 'revealed comment typically', 'comment typically made', 'typically made three', 'made three day', 'three day window', 'day window following', 'window following time', 'following time madehence', 'time madehence choice', 'madehence choice crawl', 'choice crawl subreddits', 'crawl subreddits paper', 'subreddits paper present', 'paper present descriptive', 'present descriptive statistic', 'descriptive statistic crawled', 'statistic crawled dataset', 'crawled dataset contained', 'dataset contained least', 'contained least one', 'least one comment', 'one comment comment', 'comment comment unique', 'comment unique made', 'unique made comment', 'made comment set', 'comment set found', 'set found write', 'found write least', 'write least one', 'least one comment', 'one comment cdf', 'comment cdf distribution', 'cdf distribution comment', 'distribution comment given', 'comment given figure', 'given figure figure', 'figure figure show', 'figure show expected', 'show expected heavy', 'expected heavy tail', 'heavy tail trend', 'tail trend observed', 'trend observed several', 'observed several social', 'several social phenomenon', 'social phenomenon also', 'phenomenon also see', 'also see figure', 'see figure distribution', 'figure distribution comment', 'distribution comment time', 'comment time following', 'time following share', 'following share illustrates', 'share illustrates quick', 'illustrates quick responsivity', 'quick responsivity culture', 'responsivity culture community', 'culture community study', 'community study peak', 'study peak hour', 'peak hour additional', 'hour additional statistic', 'additional statistic dataset', 'statistic dataset given', 'dataset given table', 'given table example', 'table example title']"
https://dl.acm.org/doi/abs/10.1145/3025453.3025932,0,We utilized Instagram’s official API1 to obtain the dataset used in this paper. Each post in this dataset is public and contains post-related information such as the image caption likes comments hashtags filter and geolocation if tagged. Referring to prior literature [10] we adopted an iterative approach to first identify a set of appropriate distinguishing hashtags around different prominent mental illnesses prevalent in social media. With the seed tags we performed an initial data collection of 1.5 million posts shared on Instagram between Dec 2010 and Nov 2015. Then by leveraging an association rule mining approach we compiled the top k (k = 39 frequency ≥ 5000) co-occurring tags in the 1.5M posts and then appended them to the original seed tag list for further data collection. Table 1 lists a sample set of tags used to crawl the dataset. This final list of 45 tags was thereafter passed on to a psychiatry researcher to be categorized into different disorder types. For tags that described experiences or symptoms crosscutting across different conditions (e.g. “anxiety”) they were counted toward each disorder type. Table 2 gives a list of the ten different disorders identified in our data. We additionally consulted the Diagnostic and Statistical Manual of Mental Health Disorders (DSM-V [5]) that indicates these disorders to be prominent mental health challenges in populations. This categorization of the mental health challenges was conducted to ensure that our data used in the ensuing analysis focused on well-validated and clinically recognized conditions. At the same time it allowed us to focus on a diverse range of disorders expressed on social media rather than specific ones studied in prior work [12 13 27]; thus enabling us to discover generalized patterns in visual disclosures of mental health challenges in social media. Our final crawl included 2757044 posts from 151638 users spanning these disorders.,we utilized instagrams official api to obtain the dataset used in this paper each post in this dataset is public and contains postrelated information such a the image caption like comment hashtags filter and geolocation if tagged referring to prior literature we adopted an iterative approach to first identify a set of appropriate distinguishing hashtags around different prominent mental illness prevalent in social medium with the seed tag we performed an initial data collection of million post shared on instagram between dec and nov then by leveraging an association rule mining approach we compiled the top k k frequency cooccurring tag in the m post and then appended them to the original seed tag list for further data collection table list a sample set of tag used to crawl the dataset this final list of tag wa thereafter passed on to a psychiatry researcher to be categorized into different disorder type for tag that described experience or symptom crosscutting across different condition eg anxiety they were counted toward each disorder type table give a list of the ten different disorder identified in our data we additionally consulted the diagnostic and statistical manual of mental health disorder dsmv that indicates these disorder to be prominent mental health challenge in population this categorization of the mental health challenge wa conducted to ensure that our data used in the ensuing analysis focused on wellvalidated and clinically recognized condition at the same time it allowed u to focus on a diverse range of disorder expressed on social medium rather than specific one studied in prior work thus enabling u to discover generalized pattern in visual disclosure of mental health challenge in social medium our final crawl included post from user spanning these disorder,"['utilized', 'instagrams', 'official', 'api', 'obtain', 'dataset', 'paper', 'dataset', 'public', 'contains', 'postrelated', 'information', 'image', 'caption', 'like', 'comment', 'hashtags', 'filter', 'geolocation', 'tagged', 'referring', 'prior', 'literature', 'adopted', 'iterative', 'approach', 'first', 'identify', 'set', 'appropriate', 'distinguishing', 'hashtags', 'around', 'different', 'prominent', 'illness', 'prevalent', 'social', 'medium', 'seed', 'tag', 'performed', 'initial', 'collection', 'million', 'shared', 'instagram', 'dec', 'nov', 'leveraging', 'association', 'rule', 'mining', 'approach', 'compiled', 'top', 'k', 'k', 'frequency', 'cooccurring', 'tag', 'appended', 'original', 'seed', 'tag', 'list', 'collection', 'table', 'list', 'sample', 'set', 'tag', 'crawl', 'dataset', 'final', 'list', 'tag', 'thereafter', 'passed', 'psychiatry', 'researcher', 'categorized', 'different', 'disorder', 'type', 'tag', 'described', 'experience', 'symptom', 'crosscutting', 'across', 'different', 'condition', 'eg', 'anxiety', 'counted', 'toward', 'disorder', 'type', 'table', 'give', 'list', 'ten', 'different', 'disorder', 'identified', 'additionally', 'consulted', 'diagnostic', 'statistical', 'manual', 'disorder', 'dsmv', 'indicates', 'disorder', 'prominent', 'challenge', 'population', 'categorization', 'challenge', 'conducted', 'ensure', 'ensuing', 'analysis', 'focused', 'wellvalidated', 'clinically', 'recognized', 'condition', 'time', 'allowed', 'u', 'focus', 'diverse', 'range', 'disorder', 'expressed', 'social', 'medium', 'rather', 'specific', 'one', 'studied', 'prior', 'work', 'thus', 'enabling', 'u', 'discover', 'generalized', 'pattern', 'visual', 'disclosure', 'challenge', 'social', 'medium', 'final', 'crawl', 'included', 'spanning', 'disorder']","['utilized instagrams', 'instagrams official', 'official api', 'api obtain', 'obtain dataset', 'dataset paper', 'paper dataset', 'dataset public', 'public contains', 'contains postrelated', 'postrelated information', 'information image', 'image caption', 'caption like', 'like comment', 'comment hashtags', 'hashtags filter', 'filter geolocation', 'geolocation tagged', 'tagged referring', 'referring prior', 'prior literature', 'literature adopted', 'adopted iterative', 'iterative approach', 'approach first', 'first identify', 'identify set', 'set appropriate', 'appropriate distinguishing', 'distinguishing hashtags', 'hashtags around', 'around different', 'different prominent', 'prominent illness', 'illness prevalent', 'prevalent social', 'social medium', 'medium seed', 'seed tag', 'tag performed', 'performed initial', 'initial collection', 'collection million', 'million shared', 'shared instagram', 'instagram dec', 'dec nov', 'nov leveraging', 'leveraging association', 'association rule', 'rule mining', 'mining approach', 'approach compiled', 'compiled top', 'top k', 'k k', 'k frequency', 'frequency cooccurring', 'cooccurring tag', 'tag appended', 'appended original', 'original seed', 'seed tag', 'tag list', 'list collection', 'collection table', 'table list', 'list sample', 'sample set', 'set tag', 'tag crawl', 'crawl dataset', 'dataset final', 'final list', 'list tag', 'tag thereafter', 'thereafter passed', 'passed psychiatry', 'psychiatry researcher', 'researcher categorized', 'categorized different', 'different disorder', 'disorder type', 'type tag', 'tag described', 'described experience', 'experience symptom', 'symptom crosscutting', 'crosscutting across', 'across different', 'different condition', 'condition eg', 'eg anxiety', 'anxiety counted', 'counted toward', 'toward disorder', 'disorder type', 'type table', 'table give', 'give list', 'list ten', 'ten different', 'different disorder', 'disorder identified', 'identified additionally', 'additionally consulted', 'consulted diagnostic', 'diagnostic statistical', 'statistical manual', 'manual disorder', 'disorder dsmv', 'dsmv indicates', 'indicates disorder', 'disorder prominent', 'prominent challenge', 'challenge population', 'population categorization', 'categorization challenge', 'challenge conducted', 'conducted ensure', 'ensure ensuing', 'ensuing analysis', 'analysis focused', 'focused wellvalidated', 'wellvalidated clinically', 'clinically recognized', 'recognized condition', 'condition time', 'time allowed', 'allowed u', 'u focus', 'focus diverse', 'diverse range', 'range disorder', 'disorder expressed', 'expressed social', 'social medium', 'medium rather', 'rather specific', 'specific one', 'one studied', 'studied prior', 'prior work', 'work thus', 'thus enabling', 'enabling u', 'u discover', 'discover generalized', 'generalized pattern', 'pattern visual', 'visual disclosure', 'disclosure challenge', 'challenge social', 'social medium', 'medium final', 'final crawl', 'crawl included', 'included spanning', 'spanning disorder']","['utilized instagrams official', 'instagrams official api', 'official api obtain', 'api obtain dataset', 'obtain dataset paper', 'dataset paper dataset', 'paper dataset public', 'dataset public contains', 'public contains postrelated', 'contains postrelated information', 'postrelated information image', 'information image caption', 'image caption like', 'caption like comment', 'like comment hashtags', 'comment hashtags filter', 'hashtags filter geolocation', 'filter geolocation tagged', 'geolocation tagged referring', 'tagged referring prior', 'referring prior literature', 'prior literature adopted', 'literature adopted iterative', 'adopted iterative approach', 'iterative approach first', 'approach first identify', 'first identify set', 'identify set appropriate', 'set appropriate distinguishing', 'appropriate distinguishing hashtags', 'distinguishing hashtags around', 'hashtags around different', 'around different prominent', 'different prominent illness', 'prominent illness prevalent', 'illness prevalent social', 'prevalent social medium', 'social medium seed', 'medium seed tag', 'seed tag performed', 'tag performed initial', 'performed initial collection', 'initial collection million', 'collection million shared', 'million shared instagram', 'shared instagram dec', 'instagram dec nov', 'dec nov leveraging', 'nov leveraging association', 'leveraging association rule', 'association rule mining', 'rule mining approach', 'mining approach compiled', 'approach compiled top', 'compiled top k', 'top k k', 'k k frequency', 'k frequency cooccurring', 'frequency cooccurring tag', 'cooccurring tag appended', 'tag appended original', 'appended original seed', 'original seed tag', 'seed tag list', 'tag list collection', 'list collection table', 'collection table list', 'table list sample', 'list sample set', 'sample set tag', 'set tag crawl', 'tag crawl dataset', 'crawl dataset final', 'dataset final list', 'final list tag', 'list tag thereafter', 'tag thereafter passed', 'thereafter passed psychiatry', 'passed psychiatry researcher', 'psychiatry researcher categorized', 'researcher categorized different', 'categorized different disorder', 'different disorder type', 'disorder type tag', 'type tag described', 'tag described experience', 'described experience symptom', 'experience symptom crosscutting', 'symptom crosscutting across', 'crosscutting across different', 'across different condition', 'different condition eg', 'condition eg anxiety', 'eg anxiety counted', 'anxiety counted toward', 'counted toward disorder', 'toward disorder type', 'disorder type table', 'type table give', 'table give list', 'give list ten', 'list ten different', 'ten different disorder', 'different disorder identified', 'disorder identified additionally', 'identified additionally consulted', 'additionally consulted diagnostic', 'consulted diagnostic statistical', 'diagnostic statistical manual', 'statistical manual disorder', 'manual disorder dsmv', 'disorder dsmv indicates', 'dsmv indicates disorder', 'indicates disorder prominent', 'disorder prominent challenge', 'prominent challenge population', 'challenge population categorization', 'population categorization challenge', 'categorization challenge conducted', 'challenge conducted ensure', 'conducted ensure ensuing', 'ensure ensuing analysis', 'ensuing analysis focused', 'analysis focused wellvalidated', 'focused wellvalidated clinically', 'wellvalidated clinically recognized', 'clinically recognized condition', 'recognized condition time', 'condition time allowed', 'time allowed u', 'allowed u focus', 'u focus diverse', 'focus diverse range', 'diverse range disorder', 'range disorder expressed', 'disorder expressed social', 'expressed social medium', 'social medium rather', 'medium rather specific', 'rather specific one', 'specific one studied', 'one studied prior', 'studied prior work', 'prior work thus', 'work thus enabling', 'thus enabling u', 'enabling u discover', 'u discover generalized', 'discover generalized pattern', 'generalized pattern visual', 'pattern visual disclosure', 'visual disclosure challenge', 'disclosure challenge social', 'challenge social medium', 'social medium final', 'medium final crawl', 'final crawl included', 'crawl included spanning', 'included spanning disorder']"
https://www.sciencedirect.com/science/article/pii/S0747563215300996,1,Tweets about depression were collected by Simply Measured a company that specializes in social media measurement and analytics (Simply Measured 2014). Simply Measured has access to the Twitter “firehose” (or full volume of tweets) via Gnip a licensed company that can retrieve the full Twitter data stream. All tweets in the English language that contained at least either “depressed” “#depressed” “depression” or “#depression” were collected between April 11 and May 4 2014. We scanned a random sample of the tweets to identify common phrases that included our keywords of interest but were not about mental health. In SAS version 9.3 (SAS Institute Inc. Cary NC) we used the index function which searches a character expression (in this case the text of the tweet) for a specific string of characters to locate and remove such tweets from our sample. We removed tweets that included the following terms regardless of capitalization: “Great Depression” “economic depression” “during the depression” “depression era” “tropical depression” and “depressed real estate”. The popularity and influence of the Tweeters was described using the distribution of followers and Klout Scores. While number of followers is a measure of popularity Klout Score is a measure of influence. Klout Scores range from 0 to 100 with a higher score indicating higher influence. Klout Score is calculated based on an algorithm that considers over 400 signals from eight different online networks. Examples of signals include the amount of retweets a person generates in relation to the amount of tweets shared and the amount of engagement a user drives from unique individuals (e.g. lots of retweets from different individuals as opposed to lots of retweets from one person) (Klout Inc. 2014).Using the SAS surveyselect procedure we selected a simple random sample of 2000 tweets (that were not direct @replies) from the total volume of depression-related tweets. Two members of the research team each with graduate level degrees (i.e. Ph.D. and M.P.H) and more than 10 years of experience in mental health research scanned approximately 300 random tweets in order to determine their most common themes and generate a codebook. We defined themes as topics that occur and reoccur (Ryan & Bernard 2003). Tweets were coded for presence of the following themes: 1) Tweeter discloses feelings of depression; 2) Tweet is a supportive or helpful message about depression; 3) Tweeter discloses feeling school or work-related pressures related to depression; 4) Tweeter engages in substance use to deal with depression; and 5) Tweeter discloses self-harm or suicidal thoughts. Tweets could be assigned as many themes as were pertinent. For tweets where the user indicated that he or she was feeling depressed those that appeared trivial (i.e. not concerning) were identified. These were tweets where the depression terms were used casually or in a humorous manner or referenced depression caused by trivial things such as being depressed after finishing a good book seeing a concert or watching a sad movie. In addition we ascertained the source of the tweet by viewing the Tweeter's profile picture and studying their Twitter handle name. The source was then coded into one of the three following categories: clinician/therapist health-focused handle (e.g. health/government organization handle focused on healthy lifestyle etc.) or regular person or other (handle did not fall into the above categories). Using this codebook the 2000 randomly sampled tweets were coded in teams of two trained student research interns who coded the tweets together discussing each tweet and coming to an agreement on the final assigned codes. A sample of 150 tweets was also coded by a senior team member (Ph.D. clinician) with extensive mental health research experience. Inter-coder reliability for each theme was as follows: 1) Tweeter discloses feelings of depression: percent agreement 85% kappa 0.67; 2) Tweet is a supportive or helpful message about depression: percent agreement 85% kappa 0.70; 3) Tweeter discloses feeling school or work-related pressures related to depression: percent agreement 98% kappa 0.72; 4) Tweeter engages in substance use to deal with depression: percent agreement 100% kappa 1.0; 5) Tweeter discloses self-harm or suicidal thoughts: percent agreement 98% kappa 0.56; 6) trivial disclosures of depression: percent agreement 90% kappa 0.70; 7) source of Tweet: percent agreement 91% kappa 0.51. Because both prevalence of and kappa for diminished ability to think/concentrate were low we chose not to report on this code.,tweet about depression were collected by simply measured a company that specializes in social medium measurement and analytics simply measured simply measured ha access to the twitter firehose or full volume of tweet via gnip a licensed company that can retrieve the full twitter data stream all tweet in the english language that contained at least either depressed depressed depression or depression were collected between april and may we scanned a random sample of the tweet to identify common phrase that included our keywords of interest but were not about mental health in sa version sa institute inc cary nc we used the index function which search a character expression in this case the text of the tweet for a specific string of character to locate and remove such tweet from our sample we removed tweet that included the following term regardless of capitalization great depression economic depression during the depression depression era tropical depression and depressed real estate the popularity and influence of the tweeter wa described using the distribution of follower and klout score while number of follower is a measure of popularity klout score is a measure of influence klout score range from to with a higher score indicating higher influence klout score is calculated based on an algorithm that considers over signal from eight different online network example of signal include the amount of retweets a person generates in relation to the amount of tweet shared and the amount of engagement a user drive from unique individual eg lot of retweets from different individual a opposed to lot of retweets from one person klout inc using the sa surveyselect procedure we selected a simple random sample of tweet that were not direct reply from the total volume of depressionrelated tweet two member of the research team each with graduate level degree ie phd and mph and more than year of experience in mental health research scanned approximately random tweet in order to determine their most common theme and generate a codebook we defined theme a topic that occur and reoccur ryan bernard tweet were coded for presence of the following theme tweeter discloses feeling of depression tweet is a supportive or helpful message about depression tweeter discloses feeling school or workrelated pressure related to depression tweeter engages in substance use to deal with depression and tweeter discloses selfharm or suicidal thought tweet could be assigned a many theme a were pertinent for tweet where the user indicated that he or she wa feeling depressed those that appeared trivial ie not concerning were identified these were tweet where the depression term were used casually or in a humorous manner or referenced depression caused by trivial thing such a being depressed after finishing a good book seeing a concert or watching a sad movie in addition we ascertained the source of the tweet by viewing the tweeter profile picture and studying their twitter handle name the source wa then coded into one of the three following category cliniciantherapist healthfocused handle eg healthgovernment organization handle focused on healthy lifestyle etc or regular person or other handle did not fall into the above category using this codebook the randomly sampled tweet were coded in team of two trained student research intern who coded the tweet together discussing each tweet and coming to an agreement on the final assigned code a sample of tweet wa also coded by a senior team member phd clinician with extensive mental health research experience intercoder reliability for each theme wa a follows tweeter discloses feeling of depression percent agreement kappa tweet is a supportive or helpful message about depression percent agreement kappa tweeter discloses feeling school or workrelated pressure related to depression percent agreement kappa tweeter engages in substance use to deal with depression percent agreement kappa tweeter discloses selfharm or suicidal thought percent agreement kappa trivial disclosure of depression percent agreement kappa source of tweet percent agreement kappa because both prevalence of and kappa for diminished ability to thinkconcentrate were low we chose not to report on this code,"['collected', 'simply', 'measured', 'company', 'specializes', 'social', 'medium', 'measurement', 'analytics', 'simply', 'measured', 'simply', 'measured', 'ha', 'access', 'firehose', 'full', 'volume', 'via', 'gnip', 'licensed', 'company', 'retrieve', 'full', 'stream', 'english', 'language', 'contained', 'least', 'either', 'depressed', 'depressed', 'collected', 'april', 'may', 'scanned', 'random', 'sample', 'identify', 'common', 'phrase', 'included', 'keywords', 'interest', 'sa', 'version', 'sa', 'institute', 'inc', 'cary', 'nc', 'index', 'function', 'search', 'character', 'expression', 'case', 'text', 'specific', 'string', 'character', 'locate', 'remove', 'sample', 'removed', 'included', 'following', 'term', 'regardless', 'capitalization', 'great', 'economic', 'era', 'tropical', 'depressed', 'real', 'estate', 'popularity', 'influence', 'tweeter', 'described', 'using', 'distribution', 'follower', 'klout', 'score', 'number', 'follower', 'measure', 'popularity', 'klout', 'score', 'measure', 'influence', 'klout', 'score', 'range', 'higher', 'score', 'indicating', 'higher', 'influence', 'klout', 'score', 'calculated', 'based', 'algorithm', 'considers', 'signal', 'eight', 'different', 'online', 'network', 'example', 'signal', 'include', 'amount', 'retweets', 'person', 'generates', 'relation', 'amount', 'shared', 'amount', 'engagement', 'drive', 'unique', 'individual', 'eg', 'lot', 'retweets', 'different', 'individual', 'opposed', 'lot', 'retweets', 'one', 'person', 'klout', 'inc', 'using', 'sa', 'surveyselect', 'procedure', 'selected', 'simple', 'random', 'sample', 'direct', 'reply', 'total', 'volume', 'depressionrelated', 'two', 'member', 'research', 'team', 'graduate', 'level', 'degree', 'ie', 'phd', 'mph', 'year', 'experience', 'research', 'scanned', 'approximately', 'random', 'order', 'determine', 'common', 'theme', 'generate', 'codebook', 'defined', 'theme', 'topic', 'occur', 'reoccur', 'ryan', 'bernard', 'coded', 'presence', 'following', 'theme', 'tweeter', 'discloses', 'feeling', 'supportive', 'helpful', 'message', 'tweeter', 'discloses', 'feeling', 'school', 'workrelated', 'pressure', 'related', 'tweeter', 'engages', 'substance', 'use', 'deal', 'tweeter', 'discloses', 'selfharm', 'suicidal', 'thought', 'could', 'assigned', 'many', 'theme', 'pertinent', 'indicated', 'feeling', 'depressed', 'appeared', 'trivial', 'ie', 'concerning', 'identified', 'term', 'casually', 'humorous', 'manner', 'referenced', 'caused', 'trivial', 'thing', 'depressed', 'finishing', 'good', 'book', 'seeing', 'concert', 'watching', 'sad', 'movie', 'addition', 'ascertained', 'source', 'viewing', 'tweeter', 'profile', 'picture', 'studying', 'handle', 'name', 'source', 'coded', 'one', 'three', 'following', 'category', 'cliniciantherapist', 'healthfocused', 'handle', 'eg', 'healthgovernment', 'organization', 'handle', 'focused', 'healthy', 'lifestyle', 'etc', 'regular', 'person', 'handle', 'fall', 'category', 'using', 'codebook', 'randomly', 'sampled', 'coded', 'team', 'two', 'trained', 'student', 'research', 'intern', 'coded', 'together', 'discussing', 'coming', 'agreement', 'final', 'assigned', 'code', 'sample', 'also', 'coded', 'senior', 'team', 'member', 'phd', 'clinician', 'extensive', 'research', 'experience', 'intercoder', 'reliability', 'theme', 'follows', 'tweeter', 'discloses', 'feeling', 'percent', 'agreement', 'kappa', 'supportive', 'helpful', 'message', 'percent', 'agreement', 'kappa', 'tweeter', 'discloses', 'feeling', 'school', 'workrelated', 'pressure', 'related', 'percent', 'agreement', 'kappa', 'tweeter', 'engages', 'substance', 'use', 'deal', 'percent', 'agreement', 'kappa', 'tweeter', 'discloses', 'selfharm', 'suicidal', 'thought', 'percent', 'agreement', 'kappa', 'trivial', 'disclosure', 'percent', 'agreement', 'kappa', 'source', 'percent', 'agreement', 'kappa', 'prevalence', 'kappa', 'diminished', 'ability', 'thinkconcentrate', 'low', 'chose', 'report', 'code']","['collected simply', 'simply measured', 'measured company', 'company specializes', 'specializes social', 'social medium', 'medium measurement', 'measurement analytics', 'analytics simply', 'simply measured', 'measured simply', 'simply measured', 'measured ha', 'ha access', 'access firehose', 'firehose full', 'full volume', 'volume via', 'via gnip', 'gnip licensed', 'licensed company', 'company retrieve', 'retrieve full', 'full stream', 'stream english', 'english language', 'language contained', 'contained least', 'least either', 'either depressed', 'depressed depressed', 'depressed collected', 'collected april', 'april may', 'may scanned', 'scanned random', 'random sample', 'sample identify', 'identify common', 'common phrase', 'phrase included', 'included keywords', 'keywords interest', 'interest sa', 'sa version', 'version sa', 'sa institute', 'institute inc', 'inc cary', 'cary nc', 'nc index', 'index function', 'function search', 'search character', 'character expression', 'expression case', 'case text', 'text specific', 'specific string', 'string character', 'character locate', 'locate remove', 'remove sample', 'sample removed', 'removed included', 'included following', 'following term', 'term regardless', 'regardless capitalization', 'capitalization great', 'great economic', 'economic era', 'era tropical', 'tropical depressed', 'depressed real', 'real estate', 'estate popularity', 'popularity influence', 'influence tweeter', 'tweeter described', 'described using', 'using distribution', 'distribution follower', 'follower klout', 'klout score', 'score number', 'number follower', 'follower measure', 'measure popularity', 'popularity klout', 'klout score', 'score measure', 'measure influence', 'influence klout', 'klout score', 'score range', 'range higher', 'higher score', 'score indicating', 'indicating higher', 'higher influence', 'influence klout', 'klout score', 'score calculated', 'calculated based', 'based algorithm', 'algorithm considers', 'considers signal', 'signal eight', 'eight different', 'different online', 'online network', 'network example', 'example signal', 'signal include', 'include amount', 'amount retweets', 'retweets person', 'person generates', 'generates relation', 'relation amount', 'amount shared', 'shared amount', 'amount engagement', 'engagement drive', 'drive unique', 'unique individual', 'individual eg', 'eg lot', 'lot retweets', 'retweets different', 'different individual', 'individual opposed', 'opposed lot', 'lot retweets', 'retweets one', 'one person', 'person klout', 'klout inc', 'inc using', 'using sa', 'sa surveyselect', 'surveyselect procedure', 'procedure selected', 'selected simple', 'simple random', 'random sample', 'sample direct', 'direct reply', 'reply total', 'total volume', 'volume depressionrelated', 'depressionrelated two', 'two member', 'member research', 'research team', 'team graduate', 'graduate level', 'level degree', 'degree ie', 'ie phd', 'phd mph', 'mph year', 'year experience', 'experience research', 'research scanned', 'scanned approximately', 'approximately random', 'random order', 'order determine', 'determine common', 'common theme', 'theme generate', 'generate codebook', 'codebook defined', 'defined theme', 'theme topic', 'topic occur', 'occur reoccur', 'reoccur ryan', 'ryan bernard', 'bernard coded', 'coded presence', 'presence following', 'following theme', 'theme tweeter', 'tweeter discloses', 'discloses feeling', 'feeling supportive', 'supportive helpful', 'helpful message', 'message tweeter', 'tweeter discloses', 'discloses feeling', 'feeling school', 'school workrelated', 'workrelated pressure', 'pressure related', 'related tweeter', 'tweeter engages', 'engages substance', 'substance use', 'use deal', 'deal tweeter', 'tweeter discloses', 'discloses selfharm', 'selfharm suicidal', 'suicidal thought', 'thought could', 'could assigned', 'assigned many', 'many theme', 'theme pertinent', 'pertinent indicated', 'indicated feeling', 'feeling depressed', 'depressed appeared', 'appeared trivial', 'trivial ie', 'ie concerning', 'concerning identified', 'identified term', 'term casually', 'casually humorous', 'humorous manner', 'manner referenced', 'referenced caused', 'caused trivial', 'trivial thing', 'thing depressed', 'depressed finishing', 'finishing good', 'good book', 'book seeing', 'seeing concert', 'concert watching', 'watching sad', 'sad movie', 'movie addition', 'addition ascertained', 'ascertained source', 'source viewing', 'viewing tweeter', 'tweeter profile', 'profile picture', 'picture studying', 'studying handle', 'handle name', 'name source', 'source coded', 'coded one', 'one three', 'three following', 'following category', 'category cliniciantherapist', 'cliniciantherapist healthfocused', 'healthfocused handle', 'handle eg', 'eg healthgovernment', 'healthgovernment organization', 'organization handle', 'handle focused', 'focused healthy', 'healthy lifestyle', 'lifestyle etc', 'etc regular', 'regular person', 'person handle', 'handle fall', 'fall category', 'category using', 'using codebook', 'codebook randomly', 'randomly sampled', 'sampled coded', 'coded team', 'team two', 'two trained', 'trained student', 'student research', 'research intern', 'intern coded', 'coded together', 'together discussing', 'discussing coming', 'coming agreement', 'agreement final', 'final assigned', 'assigned code', 'code sample', 'sample also', 'also coded', 'coded senior', 'senior team', 'team member', 'member phd', 'phd clinician', 'clinician extensive', 'extensive research', 'research experience', 'experience intercoder', 'intercoder reliability', 'reliability theme', 'theme follows', 'follows tweeter', 'tweeter discloses', 'discloses feeling', 'feeling percent', 'percent agreement', 'agreement kappa', 'kappa supportive', 'supportive helpful', 'helpful message', 'message percent', 'percent agreement', 'agreement kappa', 'kappa tweeter', 'tweeter discloses', 'discloses feeling', 'feeling school', 'school workrelated', 'workrelated pressure', 'pressure related', 'related percent', 'percent agreement', 'agreement kappa', 'kappa tweeter', 'tweeter engages', 'engages substance', 'substance use', 'use deal', 'deal percent', 'percent agreement', 'agreement kappa', 'kappa tweeter', 'tweeter discloses', 'discloses selfharm', 'selfharm suicidal', 'suicidal thought', 'thought percent', 'percent agreement', 'agreement kappa', 'kappa trivial', 'trivial disclosure', 'disclosure percent', 'percent agreement', 'agreement kappa', 'kappa source', 'source percent', 'percent agreement', 'agreement kappa', 'kappa prevalence', 'prevalence kappa', 'kappa diminished', 'diminished ability', 'ability thinkconcentrate', 'thinkconcentrate low', 'low chose', 'chose report', 'report code']","['collected simply measured', 'simply measured company', 'measured company specializes', 'company specializes social', 'specializes social medium', 'social medium measurement', 'medium measurement analytics', 'measurement analytics simply', 'analytics simply measured', 'simply measured simply', 'measured simply measured', 'simply measured ha', 'measured ha access', 'ha access firehose', 'access firehose full', 'firehose full volume', 'full volume via', 'volume via gnip', 'via gnip licensed', 'gnip licensed company', 'licensed company retrieve', 'company retrieve full', 'retrieve full stream', 'full stream english', 'stream english language', 'english language contained', 'language contained least', 'contained least either', 'least either depressed', 'either depressed depressed', 'depressed depressed collected', 'depressed collected april', 'collected april may', 'april may scanned', 'may scanned random', 'scanned random sample', 'random sample identify', 'sample identify common', 'identify common phrase', 'common phrase included', 'phrase included keywords', 'included keywords interest', 'keywords interest sa', 'interest sa version', 'sa version sa', 'version sa institute', 'sa institute inc', 'institute inc cary', 'inc cary nc', 'cary nc index', 'nc index function', 'index function search', 'function search character', 'search character expression', 'character expression case', 'expression case text', 'case text specific', 'text specific string', 'specific string character', 'string character locate', 'character locate remove', 'locate remove sample', 'remove sample removed', 'sample removed included', 'removed included following', 'included following term', 'following term regardless', 'term regardless capitalization', 'regardless capitalization great', 'capitalization great economic', 'great economic era', 'economic era tropical', 'era tropical depressed', 'tropical depressed real', 'depressed real estate', 'real estate popularity', 'estate popularity influence', 'popularity influence tweeter', 'influence tweeter described', 'tweeter described using', 'described using distribution', 'using distribution follower', 'distribution follower klout', 'follower klout score', 'klout score number', 'score number follower', 'number follower measure', 'follower measure popularity', 'measure popularity klout', 'popularity klout score', 'klout score measure', 'score measure influence', 'measure influence klout', 'influence klout score', 'klout score range', 'score range higher', 'range higher score', 'higher score indicating', 'score indicating higher', 'indicating higher influence', 'higher influence klout', 'influence klout score', 'klout score calculated', 'score calculated based', 'calculated based algorithm', 'based algorithm considers', 'algorithm considers signal', 'considers signal eight', 'signal eight different', 'eight different online', 'different online network', 'online network example', 'network example signal', 'example signal include', 'signal include amount', 'include amount retweets', 'amount retweets person', 'retweets person generates', 'person generates relation', 'generates relation amount', 'relation amount shared', 'amount shared amount', 'shared amount engagement', 'amount engagement drive', 'engagement drive unique', 'drive unique individual', 'unique individual eg', 'individual eg lot', 'eg lot retweets', 'lot retweets different', 'retweets different individual', 'different individual opposed', 'individual opposed lot', 'opposed lot retweets', 'lot retweets one', 'retweets one person', 'one person klout', 'person klout inc', 'klout inc using', 'inc using sa', 'using sa surveyselect', 'sa surveyselect procedure', 'surveyselect procedure selected', 'procedure selected simple', 'selected simple random', 'simple random sample', 'random sample direct', 'sample direct reply', 'direct reply total', 'reply total volume', 'total volume depressionrelated', 'volume depressionrelated two', 'depressionrelated two member', 'two member research', 'member research team', 'research team graduate', 'team graduate level', 'graduate level degree', 'level degree ie', 'degree ie phd', 'ie phd mph', 'phd mph year', 'mph year experience', 'year experience research', 'experience research scanned', 'research scanned approximately', 'scanned approximately random', 'approximately random order', 'random order determine', 'order determine common', 'determine common theme', 'common theme generate', 'theme generate codebook', 'generate codebook defined', 'codebook defined theme', 'defined theme topic', 'theme topic occur', 'topic occur reoccur', 'occur reoccur ryan', 'reoccur ryan bernard', 'ryan bernard coded', 'bernard coded presence', 'coded presence following', 'presence following theme', 'following theme tweeter', 'theme tweeter discloses', 'tweeter discloses feeling', 'discloses feeling supportive', 'feeling supportive helpful', 'supportive helpful message', 'helpful message tweeter', 'message tweeter discloses', 'tweeter discloses feeling', 'discloses feeling school', 'feeling school workrelated', 'school workrelated pressure', 'workrelated pressure related', 'pressure related tweeter', 'related tweeter engages', 'tweeter engages substance', 'engages substance use', 'substance use deal', 'use deal tweeter', 'deal tweeter discloses', 'tweeter discloses selfharm', 'discloses selfharm suicidal', 'selfharm suicidal thought', 'suicidal thought could', 'thought could assigned', 'could assigned many', 'assigned many theme', 'many theme pertinent', 'theme pertinent indicated', 'pertinent indicated feeling', 'indicated feeling depressed', 'feeling depressed appeared', 'depressed appeared trivial', 'appeared trivial ie', 'trivial ie concerning', 'ie concerning identified', 'concerning identified term', 'identified term casually', 'term casually humorous', 'casually humorous manner', 'humorous manner referenced', 'manner referenced caused', 'referenced caused trivial', 'caused trivial thing', 'trivial thing depressed', 'thing depressed finishing', 'depressed finishing good', 'finishing good book', 'good book seeing', 'book seeing concert', 'seeing concert watching', 'concert watching sad', 'watching sad movie', 'sad movie addition', 'movie addition ascertained', 'addition ascertained source', 'ascertained source viewing', 'source viewing tweeter', 'viewing tweeter profile', 'tweeter profile picture', 'profile picture studying', 'picture studying handle', 'studying handle name', 'handle name source', 'name source coded', 'source coded one', 'coded one three', 'one three following', 'three following category', 'following category cliniciantherapist', 'category cliniciantherapist healthfocused', 'cliniciantherapist healthfocused handle', 'healthfocused handle eg', 'handle eg healthgovernment', 'eg healthgovernment organization', 'healthgovernment organization handle', 'organization handle focused', 'handle focused healthy', 'focused healthy lifestyle', 'healthy lifestyle etc', 'lifestyle etc regular', 'etc regular person', 'regular person handle', 'person handle fall', 'handle fall category', 'fall category using', 'category using codebook', 'using codebook randomly', 'codebook randomly sampled', 'randomly sampled coded', 'sampled coded team', 'coded team two', 'team two trained', 'two trained student', 'trained student research', 'student research intern', 'research intern coded', 'intern coded together', 'coded together discussing', 'together discussing coming', 'discussing coming agreement', 'coming agreement final', 'agreement final assigned', 'final assigned code', 'assigned code sample', 'code sample also', 'sample also coded', 'also coded senior', 'coded senior team', 'senior team member', 'team member phd', 'member phd clinician', 'phd clinician extensive', 'clinician extensive research', 'extensive research experience', 'research experience intercoder', 'experience intercoder reliability', 'intercoder reliability theme', 'reliability theme follows', 'theme follows tweeter', 'follows tweeter discloses', 'tweeter discloses feeling', 'discloses feeling percent', 'feeling percent agreement', 'percent agreement kappa', 'agreement kappa supportive', 'kappa supportive helpful', 'supportive helpful message', 'helpful message percent', 'message percent agreement', 'percent agreement kappa', 'agreement kappa tweeter', 'kappa tweeter discloses', 'tweeter discloses feeling', 'discloses feeling school', 'feeling school workrelated', 'school workrelated pressure', 'workrelated pressure related', 'pressure related percent', 'related percent agreement', 'percent agreement kappa', 'agreement kappa tweeter', 'kappa tweeter engages', 'tweeter engages substance', 'engages substance use', 'substance use deal', 'use deal percent', 'deal percent agreement', 'percent agreement kappa', 'agreement kappa tweeter', 'kappa tweeter discloses', 'tweeter discloses selfharm', 'discloses selfharm suicidal', 'selfharm suicidal thought', 'suicidal thought percent', 'thought percent agreement', 'percent agreement kappa', 'agreement kappa trivial', 'kappa trivial disclosure', 'trivial disclosure percent', 'disclosure percent agreement', 'percent agreement kappa', 'agreement kappa source', 'kappa source percent', 'source percent agreement', 'percent agreement kappa', 'agreement kappa prevalence', 'kappa prevalence kappa', 'prevalence kappa diminished', 'kappa diminished ability', 'diminished ability thinkconcentrate', 'ability thinkconcentrate low', 'thinkconcentrate low chose', 'low chose report', 'chose report code']"
https://aclanthology.org/W15-1202.pdf,1,We follow the data acquisition and curation process of Coppersmith et al. (2014a) summarizing the major points here: Social media such as Twitter contains frequent public statements by users reporting diagnoses for various medical conditions. Many talk about physical health conditions (e.g. cancer flu) but some also discuss mental illness including schizophrenia. There are a variety of motivations for users to share this information on social media: to offer or seek support to fight the stigma of mental illness or perhaps to offer an explanation for certain behaviors.4 We obtain messages with these self-reported diagnoses using the Twitter API and filtered via (caseinsensitive) regular expression to require “schizo” or a close phonetic approximation to be present; our expression matched “schizophrenia” its subtypes and various approximations: “schizo” “skitzo” “skitso” “schizotypal” “schizoid” etc. All data we collect are public posts made between 2008 and 2015 and exclude any message marked as ‘private’ by the author. All use of the data reported in this paper has been approved by the appropriate Institutional Review Board (IRB). Each self-stated diagnosis included in this study was examined by a human annotator (one of the authors) to verify that it appeared to be a genuine statement of a schizophrenia diagnosis excluding jokes quotes or disingenuous statements. We obtained 174 users with an apparently genuine selfstated diagnosis of a schizophrenia-related condition. Note that we cannot be certain that the Twitter user was actually diagnosed with schizophrenia only that their statement of being diagnosed appears to be genuine. Previous work indicates that interannotator agreement for this task is good: κ = 0.77 (Coppersmith et al. 2014a). For each user we obtained a set of their public Twitter posts via the Twitter API collecting up to 3200 tweets.5 As we wish to focus on user-authored content we exclude from analysis all retweets and any tweets that contain a URL (which often contain text that the user did not author). We lowercase all words and convert any non-standard characters (including emoji) to a systematic ASCII representation via Unidecode.6 For our community controls we used randomlyselected Twitter users who primarily tweet in English. Specifically during a two week period in early 2014 each Twitter user who was included in Twitter’s 1% “spritzer” sample had an equal chance for inclusion in our pool of community controls. We then collected some of their historic tweets and assessed the language(s) they tweeted in according to the Chromium Compact Language Detector.7 Users were excluded from our community controls if their tweets were less than 75% English.8The breadth of language used (to include vocabulary topic areas and syntactic construction) can be measured via perplexity – a measurement based on entropy and roughly interpreted as a measurement of how predictable the language is. We train a trigram language model on one million randomly selected tweets from the 2014 1% feed and then use this model to score the perplexity on all the tweets for each user. If a user’s language wanders broadly (and potentially has the word salad effect sometimes a symptom of schizophrenia) we would expect a high perplexity score for the user. This gives us a single feature value for the perplexity feature for each user.,we follow the data acquisition and curation process of coppersmith et al a summarizing the major point here social medium such a twitter contains frequent public statement by user reporting diagnosis for various medical condition many talk about physical health condition eg cancer flu but some also discus mental illness including schizophrenia there are a variety of motivation for user to share this information on social medium to offer or seek support to fight the stigma of mental illness or perhaps to offer an explanation for certain behavior we obtain message with these selfreported diagnosis using the twitter api and filtered via caseinsensitive regular expression to require schizo or a close phonetic approximation to be present our expression matched schizophrenia it subtypes and various approximation schizo skitzo skitso schizotypal schizoid etc all data we collect are public post made between and and exclude any message marked a private by the author all use of the data reported in this paper ha been approved by the appropriate institutional review board irb each selfstated diagnosis included in this study wa examined by a human annotator one of the author to verify that it appeared to be a genuine statement of a schizophrenia diagnosis excluding joke quote or disingenuous statement we obtained user with an apparently genuine selfstated diagnosis of a schizophreniarelated condition note that we cannot be certain that the twitter user wa actually diagnosed with schizophrenia only that their statement of being diagnosed appears to be genuine previous work indicates that interannotator agreement for this task is good coppersmith et al a for each user we obtained a set of their public twitter post via the twitter api collecting up to tweet a we wish to focus on userauthored content we exclude from analysis all retweets and any tweet that contain a url which often contain text that the user did not author we lowercase all word and convert any nonstandard character including emoji to a systematic ascii representation via unidecode for our community control we used randomlyselected twitter user who primarily tweet in english specifically during a two week period in early each twitter user who wa included in twitter spritzer sample had an equal chance for inclusion in our pool of community control we then collected some of their historic tweet and assessed the language they tweeted in according to the chromium compact language detector user were excluded from our community control if their tweet were le than englishthe breadth of language used to include vocabulary topic area and syntactic construction can be measured via perplexity a measurement based on entropy and roughly interpreted a a measurement of how predictable the language is we train a trigram language model on one million randomly selected tweet from the feed and then use this model to score the perplexity on all the tweet for each user if a user language wanders broadly and potentially ha the word salad effect sometimes a symptom of schizophrenia we would expect a high perplexity score for the user this give u a single feature value for the perplexity feature for each user,"['follow', 'acquisition', 'curation', 'process', 'coppersmith', 'et', 'al', 'summarizing', 'major', 'point', 'social', 'medium', 'contains', 'frequent', 'public', 'statement', 'reporting', 'diagnosis', 'various', 'medical', 'condition', 'many', 'talk', 'physical', 'condition', 'eg', 'cancer', 'flu', 'also', 'discus', 'illness', 'including', 'schizophrenia', 'variety', 'motivation', 'share', 'information', 'social', 'medium', 'offer', 'seek', 'support', 'fight', 'stigma', 'illness', 'perhaps', 'offer', 'explanation', 'certain', 'behavior', 'obtain', 'message', 'selfreported', 'diagnosis', 'using', 'api', 'filtered', 'via', 'caseinsensitive', 'regular', 'expression', 'require', 'schizo', 'close', 'phonetic', 'approximation', 'present', 'expression', 'matched', 'schizophrenia', 'subtypes', 'various', 'approximation', 'schizo', 'skitzo', 'skitso', 'schizotypal', 'schizoid', 'etc', 'collect', 'public', 'made', 'exclude', 'message', 'marked', 'private', 'author', 'use', 'reported', 'paper', 'ha', 'approved', 'appropriate', 'institutional', 'review', 'board', 'irb', 'selfstated', 'diagnosis', 'included', 'study', 'examined', 'human', 'annotator', 'one', 'author', 'verify', 'appeared', 'genuine', 'statement', 'schizophrenia', 'diagnosis', 'excluding', 'joke', 'quote', 'disingenuous', 'statement', 'obtained', 'apparently', 'genuine', 'selfstated', 'diagnosis', 'schizophreniarelated', 'condition', 'note', 'cannot', 'certain', 'actually', 'diagnosed', 'schizophrenia', 'statement', 'diagnosed', 'appears', 'genuine', 'previous', 'work', 'indicates', 'interannotator', 'agreement', 'task', 'good', 'coppersmith', 'et', 'al', 'obtained', 'set', 'public', 'via', 'api', 'collecting', 'wish', 'focus', 'userauthored', 'content', 'exclude', 'analysis', 'retweets', 'contain', 'url', 'often', 'contain', 'text', 'author', 'lowercase', 'convert', 'nonstandard', 'character', 'including', 'emoji', 'systematic', 'ascii', 'representation', 'via', 'unidecode', 'community', 'randomlyselected', 'primarily', 'english', 'specifically', 'two', 'week', 'period', 'early', 'included', 'spritzer', 'sample', 'equal', 'chance', 'inclusion', 'pool', 'community', 'collected', 'historic', 'assessed', 'language', 'tweeted', 'according', 'chromium', 'compact', 'language', 'detector', 'excluded', 'community', 'le', 'englishthe', 'breadth', 'language', 'include', 'vocabulary', 'topic', 'area', 'syntactic', 'construction', 'measured', 'via', 'perplexity', 'measurement', 'based', 'entropy', 'roughly', 'interpreted', 'measurement', 'predictable', 'language', 'train', 'trigram', 'language', 'model', 'one', 'million', 'randomly', 'selected', 'feed', 'use', 'model', 'score', 'perplexity', 'language', 'wanders', 'broadly', 'potentially', 'ha', 'salad', 'effect', 'sometimes', 'symptom', 'schizophrenia', 'would', 'expect', 'high', 'perplexity', 'score', 'give', 'u', 'single', 'feature', 'value', 'perplexity', 'feature']","['follow acquisition', 'acquisition curation', 'curation process', 'process coppersmith', 'coppersmith et', 'et al', 'al summarizing', 'summarizing major', 'major point', 'point social', 'social medium', 'medium contains', 'contains frequent', 'frequent public', 'public statement', 'statement reporting', 'reporting diagnosis', 'diagnosis various', 'various medical', 'medical condition', 'condition many', 'many talk', 'talk physical', 'physical condition', 'condition eg', 'eg cancer', 'cancer flu', 'flu also', 'also discus', 'discus illness', 'illness including', 'including schizophrenia', 'schizophrenia variety', 'variety motivation', 'motivation share', 'share information', 'information social', 'social medium', 'medium offer', 'offer seek', 'seek support', 'support fight', 'fight stigma', 'stigma illness', 'illness perhaps', 'perhaps offer', 'offer explanation', 'explanation certain', 'certain behavior', 'behavior obtain', 'obtain message', 'message selfreported', 'selfreported diagnosis', 'diagnosis using', 'using api', 'api filtered', 'filtered via', 'via caseinsensitive', 'caseinsensitive regular', 'regular expression', 'expression require', 'require schizo', 'schizo close', 'close phonetic', 'phonetic approximation', 'approximation present', 'present expression', 'expression matched', 'matched schizophrenia', 'schizophrenia subtypes', 'subtypes various', 'various approximation', 'approximation schizo', 'schizo skitzo', 'skitzo skitso', 'skitso schizotypal', 'schizotypal schizoid', 'schizoid etc', 'etc collect', 'collect public', 'public made', 'made exclude', 'exclude message', 'message marked', 'marked private', 'private author', 'author use', 'use reported', 'reported paper', 'paper ha', 'ha approved', 'approved appropriate', 'appropriate institutional', 'institutional review', 'review board', 'board irb', 'irb selfstated', 'selfstated diagnosis', 'diagnosis included', 'included study', 'study examined', 'examined human', 'human annotator', 'annotator one', 'one author', 'author verify', 'verify appeared', 'appeared genuine', 'genuine statement', 'statement schizophrenia', 'schizophrenia diagnosis', 'diagnosis excluding', 'excluding joke', 'joke quote', 'quote disingenuous', 'disingenuous statement', 'statement obtained', 'obtained apparently', 'apparently genuine', 'genuine selfstated', 'selfstated diagnosis', 'diagnosis schizophreniarelated', 'schizophreniarelated condition', 'condition note', 'note cannot', 'cannot certain', 'certain actually', 'actually diagnosed', 'diagnosed schizophrenia', 'schizophrenia statement', 'statement diagnosed', 'diagnosed appears', 'appears genuine', 'genuine previous', 'previous work', 'work indicates', 'indicates interannotator', 'interannotator agreement', 'agreement task', 'task good', 'good coppersmith', 'coppersmith et', 'et al', 'al obtained', 'obtained set', 'set public', 'public via', 'via api', 'api collecting', 'collecting wish', 'wish focus', 'focus userauthored', 'userauthored content', 'content exclude', 'exclude analysis', 'analysis retweets', 'retweets contain', 'contain url', 'url often', 'often contain', 'contain text', 'text author', 'author lowercase', 'lowercase convert', 'convert nonstandard', 'nonstandard character', 'character including', 'including emoji', 'emoji systematic', 'systematic ascii', 'ascii representation', 'representation via', 'via unidecode', 'unidecode community', 'community randomlyselected', 'randomlyselected primarily', 'primarily english', 'english specifically', 'specifically two', 'two week', 'week period', 'period early', 'early included', 'included spritzer', 'spritzer sample', 'sample equal', 'equal chance', 'chance inclusion', 'inclusion pool', 'pool community', 'community collected', 'collected historic', 'historic assessed', 'assessed language', 'language tweeted', 'tweeted according', 'according chromium', 'chromium compact', 'compact language', 'language detector', 'detector excluded', 'excluded community', 'community le', 'le englishthe', 'englishthe breadth', 'breadth language', 'language include', 'include vocabulary', 'vocabulary topic', 'topic area', 'area syntactic', 'syntactic construction', 'construction measured', 'measured via', 'via perplexity', 'perplexity measurement', 'measurement based', 'based entropy', 'entropy roughly', 'roughly interpreted', 'interpreted measurement', 'measurement predictable', 'predictable language', 'language train', 'train trigram', 'trigram language', 'language model', 'model one', 'one million', 'million randomly', 'randomly selected', 'selected feed', 'feed use', 'use model', 'model score', 'score perplexity', 'perplexity language', 'language wanders', 'wanders broadly', 'broadly potentially', 'potentially ha', 'ha salad', 'salad effect', 'effect sometimes', 'sometimes symptom', 'symptom schizophrenia', 'schizophrenia would', 'would expect', 'expect high', 'high perplexity', 'perplexity score', 'score give', 'give u', 'u single', 'single feature', 'feature value', 'value perplexity', 'perplexity feature']","['follow acquisition curation', 'acquisition curation process', 'curation process coppersmith', 'process coppersmith et', 'coppersmith et al', 'et al summarizing', 'al summarizing major', 'summarizing major point', 'major point social', 'point social medium', 'social medium contains', 'medium contains frequent', 'contains frequent public', 'frequent public statement', 'public statement reporting', 'statement reporting diagnosis', 'reporting diagnosis various', 'diagnosis various medical', 'various medical condition', 'medical condition many', 'condition many talk', 'many talk physical', 'talk physical condition', 'physical condition eg', 'condition eg cancer', 'eg cancer flu', 'cancer flu also', 'flu also discus', 'also discus illness', 'discus illness including', 'illness including schizophrenia', 'including schizophrenia variety', 'schizophrenia variety motivation', 'variety motivation share', 'motivation share information', 'share information social', 'information social medium', 'social medium offer', 'medium offer seek', 'offer seek support', 'seek support fight', 'support fight stigma', 'fight stigma illness', 'stigma illness perhaps', 'illness perhaps offer', 'perhaps offer explanation', 'offer explanation certain', 'explanation certain behavior', 'certain behavior obtain', 'behavior obtain message', 'obtain message selfreported', 'message selfreported diagnosis', 'selfreported diagnosis using', 'diagnosis using api', 'using api filtered', 'api filtered via', 'filtered via caseinsensitive', 'via caseinsensitive regular', 'caseinsensitive regular expression', 'regular expression require', 'expression require schizo', 'require schizo close', 'schizo close phonetic', 'close phonetic approximation', 'phonetic approximation present', 'approximation present expression', 'present expression matched', 'expression matched schizophrenia', 'matched schizophrenia subtypes', 'schizophrenia subtypes various', 'subtypes various approximation', 'various approximation schizo', 'approximation schizo skitzo', 'schizo skitzo skitso', 'skitzo skitso schizotypal', 'skitso schizotypal schizoid', 'schizotypal schizoid etc', 'schizoid etc collect', 'etc collect public', 'collect public made', 'public made exclude', 'made exclude message', 'exclude message marked', 'message marked private', 'marked private author', 'private author use', 'author use reported', 'use reported paper', 'reported paper ha', 'paper ha approved', 'ha approved appropriate', 'approved appropriate institutional', 'appropriate institutional review', 'institutional review board', 'review board irb', 'board irb selfstated', 'irb selfstated diagnosis', 'selfstated diagnosis included', 'diagnosis included study', 'included study examined', 'study examined human', 'examined human annotator', 'human annotator one', 'annotator one author', 'one author verify', 'author verify appeared', 'verify appeared genuine', 'appeared genuine statement', 'genuine statement schizophrenia', 'statement schizophrenia diagnosis', 'schizophrenia diagnosis excluding', 'diagnosis excluding joke', 'excluding joke quote', 'joke quote disingenuous', 'quote disingenuous statement', 'disingenuous statement obtained', 'statement obtained apparently', 'obtained apparently genuine', 'apparently genuine selfstated', 'genuine selfstated diagnosis', 'selfstated diagnosis schizophreniarelated', 'diagnosis schizophreniarelated condition', 'schizophreniarelated condition note', 'condition note cannot', 'note cannot certain', 'cannot certain actually', 'certain actually diagnosed', 'actually diagnosed schizophrenia', 'diagnosed schizophrenia statement', 'schizophrenia statement diagnosed', 'statement diagnosed appears', 'diagnosed appears genuine', 'appears genuine previous', 'genuine previous work', 'previous work indicates', 'work indicates interannotator', 'indicates interannotator agreement', 'interannotator agreement task', 'agreement task good', 'task good coppersmith', 'good coppersmith et', 'coppersmith et al', 'et al obtained', 'al obtained set', 'obtained set public', 'set public via', 'public via api', 'via api collecting', 'api collecting wish', 'collecting wish focus', 'wish focus userauthored', 'focus userauthored content', 'userauthored content exclude', 'content exclude analysis', 'exclude analysis retweets', 'analysis retweets contain', 'retweets contain url', 'contain url often', 'url often contain', 'often contain text', 'contain text author', 'text author lowercase', 'author lowercase convert', 'lowercase convert nonstandard', 'convert nonstandard character', 'nonstandard character including', 'character including emoji', 'including emoji systematic', 'emoji systematic ascii', 'systematic ascii representation', 'ascii representation via', 'representation via unidecode', 'via unidecode community', 'unidecode community randomlyselected', 'community randomlyselected primarily', 'randomlyselected primarily english', 'primarily english specifically', 'english specifically two', 'specifically two week', 'two week period', 'week period early', 'period early included', 'early included spritzer', 'included spritzer sample', 'spritzer sample equal', 'sample equal chance', 'equal chance inclusion', 'chance inclusion pool', 'inclusion pool community', 'pool community collected', 'community collected historic', 'collected historic assessed', 'historic assessed language', 'assessed language tweeted', 'language tweeted according', 'tweeted according chromium', 'according chromium compact', 'chromium compact language', 'compact language detector', 'language detector excluded', 'detector excluded community', 'excluded community le', 'community le englishthe', 'le englishthe breadth', 'englishthe breadth language', 'breadth language include', 'language include vocabulary', 'include vocabulary topic', 'vocabulary topic area', 'topic area syntactic', 'area syntactic construction', 'syntactic construction measured', 'construction measured via', 'measured via perplexity', 'via perplexity measurement', 'perplexity measurement based', 'measurement based entropy', 'based entropy roughly', 'entropy roughly interpreted', 'roughly interpreted measurement', 'interpreted measurement predictable', 'measurement predictable language', 'predictable language train', 'language train trigram', 'train trigram language', 'trigram language model', 'language model one', 'model one million', 'one million randomly', 'million randomly selected', 'randomly selected feed', 'selected feed use', 'feed use model', 'use model score', 'model score perplexity', 'score perplexity language', 'perplexity language wanders', 'language wanders broadly', 'wanders broadly potentially', 'broadly potentially ha', 'potentially ha salad', 'ha salad effect', 'salad effect sometimes', 'effect sometimes symptom', 'sometimes symptom schizophrenia', 'symptom schizophrenia would', 'schizophrenia would expect', 'would expect high', 'expect high perplexity', 'high perplexity score', 'perplexity score give', 'score give u', 'give u single', 'u single feature', 'single feature value', 'feature value perplexity', 'value perplexity feature']"
https://dl.acm.org/doi/abs/10.1145/2700171.2791026,0,Our goal is to measure the change in both the quantity and quality of posts to SW following a celebrity suicide. First we will measure the volume of posts on SW preceding and succeeding a celebrity suicide to obtain a measure of increased interest in the topic of suicide. Next we will use a series of content analysis techniques to examine the nature of these posts: how the topic of posts changed in the wake of the suicide.We begin by constructing a baseline as to the expected variability in posts by measuring pairs of subsequent two week periods. Deviations from these expected trends following a celebrity suicide would provide evidence for the Werther effect. Our goal is therefore to identify per celebrity a set of k consecutive two-week time period pairs in the entire timeframe of our data. We refer to the first item of the pair (i.e. the first two-week window) as the “preceding” window and the immediately following two-week window as the “succeeding” window. Collectively these baseline pairs yield an empirical distribution of the expected variation when there is not a celebrity suicide. Specifically each of the k two-week window pairs (1) have no reported celebrity suicide and (2) take periods that start on the same as the day of week. This accounts for day-ofweek related variations on SW. For the purposes of this paper we choose k as 20. 4.1.2 Developing a Control Next we develop a control to establish that changes in volume of posts in SW succeeding a celebrity suicide compared to that preceding it is attributed to the topic of suicide in particular and such changes are not part of a broader shift in interest in mental health topics. For this purpose we identified a set of “control group” subreddits which are on topics related to mental health but are unlikely to be specifically about suicide or suicidal ideation. These mental health subreddits (henceforth referred to as MH subreddits) were compiled based on our prior work in [11]; refer to the paper for details on how these subreddits are identified and crawled. Table 3 lists the control subreddits crawled in the same timeframe as SW. We obtained 32509 posts from 23807 unique users. Like SW all of these subreddits are public.,our goal is to measure the change in both the quantity and quality of post to sw following a celebrity suicide first we will measure the volume of post on sw preceding and succeeding a celebrity suicide to obtain a measure of increased interest in the topic of suicide next we will use a series of content analysis technique to examine the nature of these post how the topic of post changed in the wake of the suicidewe begin by constructing a baseline a to the expected variability in post by measuring pair of subsequent two week period deviation from these expected trend following a celebrity suicide would provide evidence for the werther effect our goal is therefore to identify per celebrity a set of k consecutive twoweek time period pair in the entire timeframe of our data we refer to the first item of the pair ie the first twoweek window a the preceding window and the immediately following twoweek window a the succeeding window collectively these baseline pair yield an empirical distribution of the expected variation when there is not a celebrity suicide specifically each of the k twoweek window pair have no reported celebrity suicide and take period that start on the same a the day of week this account for dayofweek related variation on sw for the purpose of this paper we choose k a developing a control next we develop a control to establish that change in volume of post in sw succeeding a celebrity suicide compared to that preceding it is attributed to the topic of suicide in particular and such change are not part of a broader shift in interest in mental health topic for this purpose we identified a set of control group subreddits which are on topic related to mental health but are unlikely to be specifically about suicide or suicidal ideation these mental health subreddits henceforth referred to a mh subreddits were compiled based on our prior work in refer to the paper for detail on how these subreddits are identified and crawled table list the control subreddits crawled in the same timeframe a sw we obtained post from unique user like sw all of these subreddits are public,"['goal', 'measure', 'change', 'quantity', 'quality', 'sw', 'following', 'celebrity', 'suicide', 'first', 'measure', 'volume', 'sw', 'preceding', 'succeeding', 'celebrity', 'suicide', 'obtain', 'measure', 'increased', 'interest', 'topic', 'suicide', 'next', 'use', 'series', 'content', 'analysis', 'technique', 'examine', 'nature', 'topic', 'changed', 'wake', 'suicidewe', 'begin', 'constructing', 'baseline', 'expected', 'variability', 'measuring', 'pair', 'subsequent', 'two', 'week', 'period', 'deviation', 'expected', 'trend', 'following', 'celebrity', 'suicide', 'would', 'provide', 'evidence', 'werther', 'effect', 'goal', 'therefore', 'identify', 'per', 'celebrity', 'set', 'k', 'consecutive', 'twoweek', 'time', 'period', 'pair', 'entire', 'timeframe', 'refer', 'first', 'item', 'pair', 'ie', 'first', 'twoweek', 'window', 'preceding', 'window', 'immediately', 'following', 'twoweek', 'window', 'succeeding', 'window', 'collectively', 'baseline', 'pair', 'yield', 'empirical', 'distribution', 'expected', 'variation', 'celebrity', 'suicide', 'specifically', 'k', 'twoweek', 'window', 'pair', 'reported', 'celebrity', 'suicide', 'take', 'period', 'start', 'day', 'week', 'account', 'dayofweek', 'related', 'variation', 'sw', 'purpose', 'paper', 'choose', 'k', 'developing', 'next', 'develop', 'establish', 'change', 'volume', 'sw', 'succeeding', 'celebrity', 'suicide', 'compared', 'preceding', 'attributed', 'topic', 'suicide', 'particular', 'change', 'part', 'broader', 'shift', 'interest', 'topic', 'purpose', 'identified', 'set', 'group', 'subreddits', 'topic', 'related', 'unlikely', 'specifically', 'suicide', 'suicidal', 'ideation', 'subreddits', 'henceforth', 'referred', 'mh', 'subreddits', 'compiled', 'based', 'prior', 'work', 'refer', 'paper', 'detail', 'subreddits', 'identified', 'crawled', 'table', 'list', 'subreddits', 'crawled', 'timeframe', 'sw', 'obtained', 'unique', 'like', 'sw', 'subreddits', 'public']","['goal measure', 'measure change', 'change quantity', 'quantity quality', 'quality sw', 'sw following', 'following celebrity', 'celebrity suicide', 'suicide first', 'first measure', 'measure volume', 'volume sw', 'sw preceding', 'preceding succeeding', 'succeeding celebrity', 'celebrity suicide', 'suicide obtain', 'obtain measure', 'measure increased', 'increased interest', 'interest topic', 'topic suicide', 'suicide next', 'next use', 'use series', 'series content', 'content analysis', 'analysis technique', 'technique examine', 'examine nature', 'nature topic', 'topic changed', 'changed wake', 'wake suicidewe', 'suicidewe begin', 'begin constructing', 'constructing baseline', 'baseline expected', 'expected variability', 'variability measuring', 'measuring pair', 'pair subsequent', 'subsequent two', 'two week', 'week period', 'period deviation', 'deviation expected', 'expected trend', 'trend following', 'following celebrity', 'celebrity suicide', 'suicide would', 'would provide', 'provide evidence', 'evidence werther', 'werther effect', 'effect goal', 'goal therefore', 'therefore identify', 'identify per', 'per celebrity', 'celebrity set', 'set k', 'k consecutive', 'consecutive twoweek', 'twoweek time', 'time period', 'period pair', 'pair entire', 'entire timeframe', 'timeframe refer', 'refer first', 'first item', 'item pair', 'pair ie', 'ie first', 'first twoweek', 'twoweek window', 'window preceding', 'preceding window', 'window immediately', 'immediately following', 'following twoweek', 'twoweek window', 'window succeeding', 'succeeding window', 'window collectively', 'collectively baseline', 'baseline pair', 'pair yield', 'yield empirical', 'empirical distribution', 'distribution expected', 'expected variation', 'variation celebrity', 'celebrity suicide', 'suicide specifically', 'specifically k', 'k twoweek', 'twoweek window', 'window pair', 'pair reported', 'reported celebrity', 'celebrity suicide', 'suicide take', 'take period', 'period start', 'start day', 'day week', 'week account', 'account dayofweek', 'dayofweek related', 'related variation', 'variation sw', 'sw purpose', 'purpose paper', 'paper choose', 'choose k', 'k developing', 'developing next', 'next develop', 'develop establish', 'establish change', 'change volume', 'volume sw', 'sw succeeding', 'succeeding celebrity', 'celebrity suicide', 'suicide compared', 'compared preceding', 'preceding attributed', 'attributed topic', 'topic suicide', 'suicide particular', 'particular change', 'change part', 'part broader', 'broader shift', 'shift interest', 'interest topic', 'topic purpose', 'purpose identified', 'identified set', 'set group', 'group subreddits', 'subreddits topic', 'topic related', 'related unlikely', 'unlikely specifically', 'specifically suicide', 'suicide suicidal', 'suicidal ideation', 'ideation subreddits', 'subreddits henceforth', 'henceforth referred', 'referred mh', 'mh subreddits', 'subreddits compiled', 'compiled based', 'based prior', 'prior work', 'work refer', 'refer paper', 'paper detail', 'detail subreddits', 'subreddits identified', 'identified crawled', 'crawled table', 'table list', 'list subreddits', 'subreddits crawled', 'crawled timeframe', 'timeframe sw', 'sw obtained', 'obtained unique', 'unique like', 'like sw', 'sw subreddits', 'subreddits public']","['goal measure change', 'measure change quantity', 'change quantity quality', 'quantity quality sw', 'quality sw following', 'sw following celebrity', 'following celebrity suicide', 'celebrity suicide first', 'suicide first measure', 'first measure volume', 'measure volume sw', 'volume sw preceding', 'sw preceding succeeding', 'preceding succeeding celebrity', 'succeeding celebrity suicide', 'celebrity suicide obtain', 'suicide obtain measure', 'obtain measure increased', 'measure increased interest', 'increased interest topic', 'interest topic suicide', 'topic suicide next', 'suicide next use', 'next use series', 'use series content', 'series content analysis', 'content analysis technique', 'analysis technique examine', 'technique examine nature', 'examine nature topic', 'nature topic changed', 'topic changed wake', 'changed wake suicidewe', 'wake suicidewe begin', 'suicidewe begin constructing', 'begin constructing baseline', 'constructing baseline expected', 'baseline expected variability', 'expected variability measuring', 'variability measuring pair', 'measuring pair subsequent', 'pair subsequent two', 'subsequent two week', 'two week period', 'week period deviation', 'period deviation expected', 'deviation expected trend', 'expected trend following', 'trend following celebrity', 'following celebrity suicide', 'celebrity suicide would', 'suicide would provide', 'would provide evidence', 'provide evidence werther', 'evidence werther effect', 'werther effect goal', 'effect goal therefore', 'goal therefore identify', 'therefore identify per', 'identify per celebrity', 'per celebrity set', 'celebrity set k', 'set k consecutive', 'k consecutive twoweek', 'consecutive twoweek time', 'twoweek time period', 'time period pair', 'period pair entire', 'pair entire timeframe', 'entire timeframe refer', 'timeframe refer first', 'refer first item', 'first item pair', 'item pair ie', 'pair ie first', 'ie first twoweek', 'first twoweek window', 'twoweek window preceding', 'window preceding window', 'preceding window immediately', 'window immediately following', 'immediately following twoweek', 'following twoweek window', 'twoweek window succeeding', 'window succeeding window', 'succeeding window collectively', 'window collectively baseline', 'collectively baseline pair', 'baseline pair yield', 'pair yield empirical', 'yield empirical distribution', 'empirical distribution expected', 'distribution expected variation', 'expected variation celebrity', 'variation celebrity suicide', 'celebrity suicide specifically', 'suicide specifically k', 'specifically k twoweek', 'k twoweek window', 'twoweek window pair', 'window pair reported', 'pair reported celebrity', 'reported celebrity suicide', 'celebrity suicide take', 'suicide take period', 'take period start', 'period start day', 'start day week', 'day week account', 'week account dayofweek', 'account dayofweek related', 'dayofweek related variation', 'related variation sw', 'variation sw purpose', 'sw purpose paper', 'purpose paper choose', 'paper choose k', 'choose k developing', 'k developing next', 'developing next develop', 'next develop establish', 'develop establish change', 'establish change volume', 'change volume sw', 'volume sw succeeding', 'sw succeeding celebrity', 'succeeding celebrity suicide', 'celebrity suicide compared', 'suicide compared preceding', 'compared preceding attributed', 'preceding attributed topic', 'attributed topic suicide', 'topic suicide particular', 'suicide particular change', 'particular change part', 'change part broader', 'part broader shift', 'broader shift interest', 'shift interest topic', 'interest topic purpose', 'topic purpose identified', 'purpose identified set', 'identified set group', 'set group subreddits', 'group subreddits topic', 'subreddits topic related', 'topic related unlikely', 'related unlikely specifically', 'unlikely specifically suicide', 'specifically suicide suicidal', 'suicide suicidal ideation', 'suicidal ideation subreddits', 'ideation subreddits henceforth', 'subreddits henceforth referred', 'henceforth referred mh', 'referred mh subreddits', 'mh subreddits compiled', 'subreddits compiled based', 'compiled based prior', 'based prior work', 'prior work refer', 'work refer paper', 'refer paper detail', 'paper detail subreddits', 'detail subreddits identified', 'subreddits identified crawled', 'identified crawled table', 'crawled table list', 'table list subreddits', 'list subreddits crawled', 'subreddits crawled timeframe', 'crawled timeframe sw', 'timeframe sw obtained', 'sw obtained unique', 'obtained unique like', 'unique like sw', 'like sw subreddits', 'sw subreddits public']"
https://aclanthology.org/W17-3110.pdf,1,We briefly explain the data collection method here but we refer the interested reader with further questions on the methodology to Coppersmith et al. (2016) for the suicide attempt data and Coppersmith et al. (2014a) for all other conditions. The data for these analyses are Twitter posts collected via two methods. Most of the data come from users who have publicly discussed their mental health conditions. These users are frequently referred to as “self-stated diagnosis” users as they state publicly something like “I was diagnosed with schizophrenia” or “I’m so thankful to have survived my suicide attempt last year”. The data for users with a suicide attempt was supplemented by data from OurDataHelps.org a data donation site where people provide access to their public posts and fill out a short questionnaire about their mental health history. Data are then deidentified and made available to researchers addressing questions of interest to the mental health community. Donors provide consent for their data to be used in mental health research upon signup. Of the users who attempted suicide 146 came from OurDataHelps.org. Specifically we examine generalized anxiety disorder eating disorders panic attacks schizophrenia and attempted suicides. These conditions were selected based on the theory that there are important timing aspects to their symptoms – ebbing and flowing of symptoms as treatment is effective (especially schizophrenia) onset and exacerbation of symptoms by external events and stress and punctuated events in time of psychological symptoms (suicide attempts panic attacks and binging/purging behavior with eating disorders). We use the Twitter streaming API to collect a sample of users who used a series of mental health words or phrases in their tweet text (e.g. ‘schizophrenia‘ or ‘suicide attempt‘). Each tweet that uses one of these phrases is examined via regular expression to indicate that the user is talking about themselves. Finally those tweets that pass the regular expression are examined by a human to confirm (to the best of our ability) that their selfstatement of diagnosis appears to be genuine. This results in a dataset with users that have a self-stated diagnosis of generalized anxiety disorder (n = 2408) an eating disorder (749) panic attacks (263) schizophrenia (350) or someone who would go on to attempt suicide (423). Some of these users do not exhibit the sort of posting behavior required to create micropatterns (i.e. they rarely post multiple times within a 3 hour time window). We exclude these users from our analysis which is 5-9% of users for most conditions with the exception of those with a suicide attempt where a little over half the users do not exhibit this posting behavior. The resultant dataset used for analyses is: generalized anxiety disorder (n = 2271) eating disorders (687) panic attacks (247) schizophrenia (318) suicide attempts (157). In order to allow comparisons of each condition to control users we gather a random sample of 10000 Twitter users for whom at least 75% of their posts are identified by Twitter as English. All the users with a self-stated diagnoses and all members of this control population have their age and gender estimated according to Sap et al. (2014). For each user with a self-stated diagnosis we find a matched control through the following procedure: create a pool of users where the estimated gender matches and the estimated age is within the same 10-year bracket (the suggested accuracy of the age estimator). From that pool of age- and gender- matched users we select the user whose tweets start and end over the most similar timeframe. We will refer to these age- gender- and time-matched controls simply as “matched controls” throughout the rest of this paper. All tweets were publicly posted by their author (i.e. no users marked at “protected” or “private” were included). On average users had 2949 tweets. The distribution of estimated age and genders for users with each self-stated condition can be seen in Figure 1. For most conditions the population skews female though for schizophrenia the genders are roughly balanced. The average age tends to be in the early-to-mid 20s.,we briefly explain the data collection method here but we refer the interested reader with further question on the methodology to coppersmith et al for the suicide attempt data and coppersmith et al a for all other condition the data for these analysis are twitter post collected via two method most of the data come from user who have publicly discussed their mental health condition these user are frequently referred to a selfstated diagnosis user a they state publicly something like i wa diagnosed with schizophrenia or im so thankful to have survived my suicide attempt last year the data for user with a suicide attempt wa supplemented by data from ourdatahelpsorg a data donation site where people provide access to their public post and fill out a short questionnaire about their mental health history data are then deidentified and made available to researcher addressing question of interest to the mental health community donor provide consent for their data to be used in mental health research upon signup of the user who attempted suicide came from ourdatahelpsorg specifically we examine generalized anxiety disorder eating disorder panic attack schizophrenia and attempted suicide these condition were selected based on the theory that there are important timing aspect to their symptom ebbing and flowing of symptom a treatment is effective especially schizophrenia onset and exacerbation of symptom by external event and stress and punctuated event in time of psychological symptom suicide attempt panic attack and bingingpurging behavior with eating disorder we use the twitter streaming api to collect a sample of user who used a series of mental health word or phrase in their tweet text eg schizophrenia or suicide attempt each tweet that us one of these phrase is examined via regular expression to indicate that the user is talking about themselves finally those tweet that pas the regular expression are examined by a human to confirm to the best of our ability that their selfstatement of diagnosis appears to be genuine this result in a dataset with user that have a selfstated diagnosis of generalized anxiety disorder n an eating disorder panic attack schizophrenia or someone who would go on to attempt suicide some of these user do not exhibit the sort of posting behavior required to create micropatterns ie they rarely post multiple time within a hour time window we exclude these user from our analysis which is of user for most condition with the exception of those with a suicide attempt where a little over half the user do not exhibit this posting behavior the resultant dataset used for analysis is generalized anxiety disorder n eating disorder panic attack schizophrenia suicide attempt in order to allow comparison of each condition to control user we gather a random sample of twitter user for whom at least of their post are identified by twitter a english all the user with a selfstated diagnosis and all member of this control population have their age and gender estimated according to sap et al for each user with a selfstated diagnosis we find a matched control through the following procedure create a pool of user where the estimated gender match and the estimated age is within the same year bracket the suggested accuracy of the age estimator from that pool of age and gender matched user we select the user whose tweet start and end over the most similar timeframe we will refer to these age gender and timematched control simply a matched control throughout the rest of this paper all tweet were publicly posted by their author ie no user marked at protected or private were included on average user had tweet the distribution of estimated age and gender for user with each selfstated condition can be seen in figure for most condition the population skews female though for schizophrenia the gender are roughly balanced the average age tends to be in the earlytomid s,"['briefly', 'explain', 'collection', 'method', 'refer', 'interested', 'reader', 'question', 'methodology', 'coppersmith', 'et', 'al', 'suicide', 'attempt', 'coppersmith', 'et', 'al', 'condition', 'analysis', 'collected', 'via', 'two', 'method', 'come', 'publicly', 'discussed', 'condition', 'frequently', 'referred', 'selfstated', 'diagnosis', 'state', 'publicly', 'something', 'like', 'diagnosed', 'schizophrenia', 'im', 'thankful', 'survived', 'suicide', 'attempt', 'last', 'year', 'suicide', 'attempt', 'supplemented', 'ourdatahelpsorg', 'donation', 'site', 'people', 'provide', 'access', 'public', 'fill', 'short', 'questionnaire', 'history', 'deidentified', 'made', 'available', 'researcher', 'addressing', 'question', 'interest', 'community', 'donor', 'provide', 'consent', 'research', 'upon', 'signup', 'attempted', 'suicide', 'came', 'ourdatahelpsorg', 'specifically', 'examine', 'generalized', 'anxiety', 'disorder', 'eating', 'disorder', 'panic', 'attack', 'schizophrenia', 'attempted', 'suicide', 'condition', 'selected', 'based', 'theory', 'important', 'timing', 'aspect', 'symptom', 'ebbing', 'flowing', 'symptom', 'treatment', 'effective', 'especially', 'schizophrenia', 'onset', 'exacerbation', 'symptom', 'external', 'event', 'stress', 'punctuated', 'event', 'time', 'psychological', 'symptom', 'suicide', 'attempt', 'panic', 'attack', 'bingingpurging', 'behavior', 'eating', 'disorder', 'use', 'streaming', 'api', 'collect', 'sample', 'series', 'phrase', 'text', 'eg', 'schizophrenia', 'suicide', 'attempt', 'us', 'one', 'phrase', 'examined', 'via', 'regular', 'expression', 'indicate', 'talking', 'finally', 'pas', 'regular', 'expression', 'examined', 'human', 'confirm', 'best', 'ability', 'selfstatement', 'diagnosis', 'appears', 'genuine', 'result', 'dataset', 'selfstated', 'diagnosis', 'generalized', 'anxiety', 'disorder', 'n', 'eating', 'disorder', 'panic', 'attack', 'schizophrenia', 'someone', 'would', 'go', 'attempt', 'suicide', 'exhibit', 'sort', 'posting', 'behavior', 'required', 'create', 'micropatterns', 'ie', 'rarely', 'multiple', 'time', 'within', 'hour', 'time', 'window', 'exclude', 'analysis', 'condition', 'exception', 'suicide', 'attempt', 'little', 'half', 'exhibit', 'posting', 'behavior', 'resultant', 'dataset', 'analysis', 'generalized', 'anxiety', 'disorder', 'n', 'eating', 'disorder', 'panic', 'attack', 'schizophrenia', 'suicide', 'attempt', 'order', 'allow', 'comparison', 'condition', 'gather', 'random', 'sample', 'least', 'identified', 'english', 'selfstated', 'diagnosis', 'member', 'population', 'age', 'gender', 'estimated', 'according', 'sap', 'et', 'al', 'selfstated', 'diagnosis', 'find', 'matched', 'following', 'procedure', 'create', 'pool', 'estimated', 'gender', 'match', 'estimated', 'age', 'within', 'year', 'bracket', 'suggested', 'accuracy', 'age', 'estimator', 'pool', 'age', 'gender', 'matched', 'select', 'whose', 'start', 'end', 'similar', 'timeframe', 'refer', 'age', 'gender', 'timematched', 'simply', 'matched', 'throughout', 'rest', 'paper', 'publicly', 'posted', 'author', 'ie', 'marked', 'protected', 'private', 'included', 'average', 'distribution', 'estimated', 'age', 'gender', 'selfstated', 'condition', 'seen', 'figure', 'condition', 'population', 'skews', 'female', 'though', 'schizophrenia', 'gender', 'roughly', 'balanced', 'average', 'age', 'tends', 'earlytomid']","['briefly explain', 'explain collection', 'collection method', 'method refer', 'refer interested', 'interested reader', 'reader question', 'question methodology', 'methodology coppersmith', 'coppersmith et', 'et al', 'al suicide', 'suicide attempt', 'attempt coppersmith', 'coppersmith et', 'et al', 'al condition', 'condition analysis', 'analysis collected', 'collected via', 'via two', 'two method', 'method come', 'come publicly', 'publicly discussed', 'discussed condition', 'condition frequently', 'frequently referred', 'referred selfstated', 'selfstated diagnosis', 'diagnosis state', 'state publicly', 'publicly something', 'something like', 'like diagnosed', 'diagnosed schizophrenia', 'schizophrenia im', 'im thankful', 'thankful survived', 'survived suicide', 'suicide attempt', 'attempt last', 'last year', 'year suicide', 'suicide attempt', 'attempt supplemented', 'supplemented ourdatahelpsorg', 'ourdatahelpsorg donation', 'donation site', 'site people', 'people provide', 'provide access', 'access public', 'public fill', 'fill short', 'short questionnaire', 'questionnaire history', 'history deidentified', 'deidentified made', 'made available', 'available researcher', 'researcher addressing', 'addressing question', 'question interest', 'interest community', 'community donor', 'donor provide', 'provide consent', 'consent research', 'research upon', 'upon signup', 'signup attempted', 'attempted suicide', 'suicide came', 'came ourdatahelpsorg', 'ourdatahelpsorg specifically', 'specifically examine', 'examine generalized', 'generalized anxiety', 'anxiety disorder', 'disorder eating', 'eating disorder', 'disorder panic', 'panic attack', 'attack schizophrenia', 'schizophrenia attempted', 'attempted suicide', 'suicide condition', 'condition selected', 'selected based', 'based theory', 'theory important', 'important timing', 'timing aspect', 'aspect symptom', 'symptom ebbing', 'ebbing flowing', 'flowing symptom', 'symptom treatment', 'treatment effective', 'effective especially', 'especially schizophrenia', 'schizophrenia onset', 'onset exacerbation', 'exacerbation symptom', 'symptom external', 'external event', 'event stress', 'stress punctuated', 'punctuated event', 'event time', 'time psychological', 'psychological symptom', 'symptom suicide', 'suicide attempt', 'attempt panic', 'panic attack', 'attack bingingpurging', 'bingingpurging behavior', 'behavior eating', 'eating disorder', 'disorder use', 'use streaming', 'streaming api', 'api collect', 'collect sample', 'sample series', 'series phrase', 'phrase text', 'text eg', 'eg schizophrenia', 'schizophrenia suicide', 'suicide attempt', 'attempt us', 'us one', 'one phrase', 'phrase examined', 'examined via', 'via regular', 'regular expression', 'expression indicate', 'indicate talking', 'talking finally', 'finally pas', 'pas regular', 'regular expression', 'expression examined', 'examined human', 'human confirm', 'confirm best', 'best ability', 'ability selfstatement', 'selfstatement diagnosis', 'diagnosis appears', 'appears genuine', 'genuine result', 'result dataset', 'dataset selfstated', 'selfstated diagnosis', 'diagnosis generalized', 'generalized anxiety', 'anxiety disorder', 'disorder n', 'n eating', 'eating disorder', 'disorder panic', 'panic attack', 'attack schizophrenia', 'schizophrenia someone', 'someone would', 'would go', 'go attempt', 'attempt suicide', 'suicide exhibit', 'exhibit sort', 'sort posting', 'posting behavior', 'behavior required', 'required create', 'create micropatterns', 'micropatterns ie', 'ie rarely', 'rarely multiple', 'multiple time', 'time within', 'within hour', 'hour time', 'time window', 'window exclude', 'exclude analysis', 'analysis condition', 'condition exception', 'exception suicide', 'suicide attempt', 'attempt little', 'little half', 'half exhibit', 'exhibit posting', 'posting behavior', 'behavior resultant', 'resultant dataset', 'dataset analysis', 'analysis generalized', 'generalized anxiety', 'anxiety disorder', 'disorder n', 'n eating', 'eating disorder', 'disorder panic', 'panic attack', 'attack schizophrenia', 'schizophrenia suicide', 'suicide attempt', 'attempt order', 'order allow', 'allow comparison', 'comparison condition', 'condition gather', 'gather random', 'random sample', 'sample least', 'least identified', 'identified english', 'english selfstated', 'selfstated diagnosis', 'diagnosis member', 'member population', 'population age', 'age gender', 'gender estimated', 'estimated according', 'according sap', 'sap et', 'et al', 'al selfstated', 'selfstated diagnosis', 'diagnosis find', 'find matched', 'matched following', 'following procedure', 'procedure create', 'create pool', 'pool estimated', 'estimated gender', 'gender match', 'match estimated', 'estimated age', 'age within', 'within year', 'year bracket', 'bracket suggested', 'suggested accuracy', 'accuracy age', 'age estimator', 'estimator pool', 'pool age', 'age gender', 'gender matched', 'matched select', 'select whose', 'whose start', 'start end', 'end similar', 'similar timeframe', 'timeframe refer', 'refer age', 'age gender', 'gender timematched', 'timematched simply', 'simply matched', 'matched throughout', 'throughout rest', 'rest paper', 'paper publicly', 'publicly posted', 'posted author', 'author ie', 'ie marked', 'marked protected', 'protected private', 'private included', 'included average', 'average distribution', 'distribution estimated', 'estimated age', 'age gender', 'gender selfstated', 'selfstated condition', 'condition seen', 'seen figure', 'figure condition', 'condition population', 'population skews', 'skews female', 'female though', 'though schizophrenia', 'schizophrenia gender', 'gender roughly', 'roughly balanced', 'balanced average', 'average age', 'age tends', 'tends earlytomid']","['briefly explain collection', 'explain collection method', 'collection method refer', 'method refer interested', 'refer interested reader', 'interested reader question', 'reader question methodology', 'question methodology coppersmith', 'methodology coppersmith et', 'coppersmith et al', 'et al suicide', 'al suicide attempt', 'suicide attempt coppersmith', 'attempt coppersmith et', 'coppersmith et al', 'et al condition', 'al condition analysis', 'condition analysis collected', 'analysis collected via', 'collected via two', 'via two method', 'two method come', 'method come publicly', 'come publicly discussed', 'publicly discussed condition', 'discussed condition frequently', 'condition frequently referred', 'frequently referred selfstated', 'referred selfstated diagnosis', 'selfstated diagnosis state', 'diagnosis state publicly', 'state publicly something', 'publicly something like', 'something like diagnosed', 'like diagnosed schizophrenia', 'diagnosed schizophrenia im', 'schizophrenia im thankful', 'im thankful survived', 'thankful survived suicide', 'survived suicide attempt', 'suicide attempt last', 'attempt last year', 'last year suicide', 'year suicide attempt', 'suicide attempt supplemented', 'attempt supplemented ourdatahelpsorg', 'supplemented ourdatahelpsorg donation', 'ourdatahelpsorg donation site', 'donation site people', 'site people provide', 'people provide access', 'provide access public', 'access public fill', 'public fill short', 'fill short questionnaire', 'short questionnaire history', 'questionnaire history deidentified', 'history deidentified made', 'deidentified made available', 'made available researcher', 'available researcher addressing', 'researcher addressing question', 'addressing question interest', 'question interest community', 'interest community donor', 'community donor provide', 'donor provide consent', 'provide consent research', 'consent research upon', 'research upon signup', 'upon signup attempted', 'signup attempted suicide', 'attempted suicide came', 'suicide came ourdatahelpsorg', 'came ourdatahelpsorg specifically', 'ourdatahelpsorg specifically examine', 'specifically examine generalized', 'examine generalized anxiety', 'generalized anxiety disorder', 'anxiety disorder eating', 'disorder eating disorder', 'eating disorder panic', 'disorder panic attack', 'panic attack schizophrenia', 'attack schizophrenia attempted', 'schizophrenia attempted suicide', 'attempted suicide condition', 'suicide condition selected', 'condition selected based', 'selected based theory', 'based theory important', 'theory important timing', 'important timing aspect', 'timing aspect symptom', 'aspect symptom ebbing', 'symptom ebbing flowing', 'ebbing flowing symptom', 'flowing symptom treatment', 'symptom treatment effective', 'treatment effective especially', 'effective especially schizophrenia', 'especially schizophrenia onset', 'schizophrenia onset exacerbation', 'onset exacerbation symptom', 'exacerbation symptom external', 'symptom external event', 'external event stress', 'event stress punctuated', 'stress punctuated event', 'punctuated event time', 'event time psychological', 'time psychological symptom', 'psychological symptom suicide', 'symptom suicide attempt', 'suicide attempt panic', 'attempt panic attack', 'panic attack bingingpurging', 'attack bingingpurging behavior', 'bingingpurging behavior eating', 'behavior eating disorder', 'eating disorder use', 'disorder use streaming', 'use streaming api', 'streaming api collect', 'api collect sample', 'collect sample series', 'sample series phrase', 'series phrase text', 'phrase text eg', 'text eg schizophrenia', 'eg schizophrenia suicide', 'schizophrenia suicide attempt', 'suicide attempt us', 'attempt us one', 'us one phrase', 'one phrase examined', 'phrase examined via', 'examined via regular', 'via regular expression', 'regular expression indicate', 'expression indicate talking', 'indicate talking finally', 'talking finally pas', 'finally pas regular', 'pas regular expression', 'regular expression examined', 'expression examined human', 'examined human confirm', 'human confirm best', 'confirm best ability', 'best ability selfstatement', 'ability selfstatement diagnosis', 'selfstatement diagnosis appears', 'diagnosis appears genuine', 'appears genuine result', 'genuine result dataset', 'result dataset selfstated', 'dataset selfstated diagnosis', 'selfstated diagnosis generalized', 'diagnosis generalized anxiety', 'generalized anxiety disorder', 'anxiety disorder n', 'disorder n eating', 'n eating disorder', 'eating disorder panic', 'disorder panic attack', 'panic attack schizophrenia', 'attack schizophrenia someone', 'schizophrenia someone would', 'someone would go', 'would go attempt', 'go attempt suicide', 'attempt suicide exhibit', 'suicide exhibit sort', 'exhibit sort posting', 'sort posting behavior', 'posting behavior required', 'behavior required create', 'required create micropatterns', 'create micropatterns ie', 'micropatterns ie rarely', 'ie rarely multiple', 'rarely multiple time', 'multiple time within', 'time within hour', 'within hour time', 'hour time window', 'time window exclude', 'window exclude analysis', 'exclude analysis condition', 'analysis condition exception', 'condition exception suicide', 'exception suicide attempt', 'suicide attempt little', 'attempt little half', 'little half exhibit', 'half exhibit posting', 'exhibit posting behavior', 'posting behavior resultant', 'behavior resultant dataset', 'resultant dataset analysis', 'dataset analysis generalized', 'analysis generalized anxiety', 'generalized anxiety disorder', 'anxiety disorder n', 'disorder n eating', 'n eating disorder', 'eating disorder panic', 'disorder panic attack', 'panic attack schizophrenia', 'attack schizophrenia suicide', 'schizophrenia suicide attempt', 'suicide attempt order', 'attempt order allow', 'order allow comparison', 'allow comparison condition', 'comparison condition gather', 'condition gather random', 'gather random sample', 'random sample least', 'sample least identified', 'least identified english', 'identified english selfstated', 'english selfstated diagnosis', 'selfstated diagnosis member', 'diagnosis member population', 'member population age', 'population age gender', 'age gender estimated', 'gender estimated according', 'estimated according sap', 'according sap et', 'sap et al', 'et al selfstated', 'al selfstated diagnosis', 'selfstated diagnosis find', 'diagnosis find matched', 'find matched following', 'matched following procedure', 'following procedure create', 'procedure create pool', 'create pool estimated', 'pool estimated gender', 'estimated gender match', 'gender match estimated', 'match estimated age', 'estimated age within', 'age within year', 'within year bracket', 'year bracket suggested', 'bracket suggested accuracy', 'suggested accuracy age', 'accuracy age estimator', 'age estimator pool', 'estimator pool age', 'pool age gender', 'age gender matched', 'gender matched select', 'matched select whose', 'select whose start', 'whose start end', 'start end similar', 'end similar timeframe', 'similar timeframe refer', 'timeframe refer age', 'refer age gender', 'age gender timematched', 'gender timematched simply', 'timematched simply matched', 'simply matched throughout', 'matched throughout rest', 'throughout rest paper', 'rest paper publicly', 'paper publicly posted', 'publicly posted author', 'posted author ie', 'author ie marked', 'ie marked protected', 'marked protected private', 'protected private included', 'private included average', 'included average distribution', 'average distribution estimated', 'distribution estimated age', 'estimated age gender', 'age gender selfstated', 'gender selfstated condition', 'selfstated condition seen', 'condition seen figure', 'seen figure condition', 'figure condition population', 'condition population skews', 'population skews female', 'skews female though', 'female though schizophrenia', 'though schizophrenia gender', 'schizophrenia gender roughly', 'gender roughly balanced', 'roughly balanced average', 'balanced average age', 'average age tends', 'age tends earlytomid']"
https://dl.acm.org/doi/abs/10.1145/2998181.2998220,1,Our study uses publicly shared mental illness self-disclosure data collected from the social media Twitter. We started by obtaining a large sample of English language candidate selfdisclosure posts from the full archive of public Twitter data around a variety of mental health concerns. Specifically we filtered the Twitter posts shared in March 2015 containing any of the keyphrases included in Table 1. These keyphrases were collated by a combination of reference to prior work [11 12] and consultation with a trained psychiatrist practitioner. Through these keyphrases we sought to identify who publicly state that they have been diagnosed with or suffering from some form of mental illness. As noted by Coppersmith et al. users may make such a statement to seek support from others in their Twitter social network to fight the stigma of mental illness or perhaps as an explanation of some of their behavior [11]. We obtained 1319064 posts from 534829 unique users at the end of this initial data collection phase. Parallelly we obtained a candidate control data sample from Twitter’s Firehose stream so as to allow robust statistical comparisons between Twitter users who choose to self-disclose their mental illness and those who do not. This dataset included a random sample of 1513279 posts from 673898 unique users made on Twitter during March 2015 ensuring that none of these posts matched any of the keyphrases given in Table 1. Thereafter for both of the candidate mental health disclosure sample and the candidate control sample of posts we utilized Twitter’s official API3 to obtain the last 3200 posts for each of the unique users in both datasets. For the control dataset if any of the users had any post in their crawled posts matching one of the keyphrases above we disregard them from our analysis. Further employing the Google Compact Language Detector4  we disregarded any users if at least 75% of their posts were not written in English. Our final candidate disclosure sample contained 51038914 posts from 470337 users (µ = 108.5) while the control sample contained 66214850 posts from 480685 users (µ = 137.7).We note that the populations of the four countries are widely different along with their overall reported internet penetration rates6 . Hence we devise a subsampling strategy to filter users belonging to one of the four countries from the set of users in the candidate disclosure and the control datasets with inferrable country information. First for population based subsampling we use the inverse of the population ranks of the countries4 as the respective rates of sampling. Then we use the internet penetration percentages of the countries5 to randomly sample that fraction of users from the population subsampled sets. In this manner across both the datasets we obtained 211132 Twitter users from the US 61816 users from the UK 10808 from IN and 5769 from ZA.Next we qualitatively verified whether posts from these users indeed were self-disclosures of mental health challenges. For the purpose we consulted a licensed psychologist and also included two researchers who were familiar with mental health content shared on social media. Over a random sample of 100 posts complied from the timeline of 100 randomly selected MID users we obtained independent binary annotations on whether a post was likely to be related to mental health. The Fleiss’ κ for interrater agreement was found to be high .87 along with an accuracy of 96% in distinguishing users who engage in genuine disclosures from those who do not. This establishes adequacy of our approach. Table 2 gives some paraphrased mental health disclosure posts of Twitter users who were identified to be genuine mental health disclosers by our approach. In Figure 2 we show the pipeline of steps involved in our approach of arriving at this final dataset.,our study us publicly shared mental illness selfdisclosure data collected from the social medium twitter we started by obtaining a large sample of english language candidate selfdisclosure post from the full archive of public twitter data around a variety of mental health concern specifically we filtered the twitter post shared in march containing any of the keyphrases included in table these keyphrases were collated by a combination of reference to prior work and consultation with a trained psychiatrist practitioner through these keyphrases we sought to identify who publicly state that they have been diagnosed with or suffering from some form of mental illness a noted by coppersmith et al user may make such a statement to seek support from others in their twitter social network to fight the stigma of mental illness or perhaps a an explanation of some of their behavior we obtained post from unique user at the end of this initial data collection phase parallelly we obtained a candidate control data sample from twitter firehose stream so a to allow robust statistical comparison between twitter user who choose to selfdisclose their mental illness and those who do not this dataset included a random sample of post from unique user made on twitter during march ensuring that none of these post matched any of the keyphrases given in table thereafter for both of the candidate mental health disclosure sample and the candidate control sample of post we utilized twitter official api to obtain the last post for each of the unique user in both datasets for the control dataset if any of the user had any post in their crawled post matching one of the keyphrases above we disregard them from our analysis further employing the google compact language detector we disregarded any user if at least of their post were not written in english our final candidate disclosure sample contained post from user while the control sample contained post from user we note that the population of the four country are widely different along with their overall reported internet penetration rate hence we devise a subsampling strategy to filter user belonging to one of the four country from the set of user in the candidate disclosure and the control datasets with inferrable country information first for population based subsampling we use the inverse of the population rank of the country a the respective rate of sampling then we use the internet penetration percentage of the country to randomly sample that fraction of user from the population subsampled set in this manner across both the datasets we obtained twitter user from the u user from the uk from in and from zanext we qualitatively verified whether post from these user indeed were selfdisclosures of mental health challenge for the purpose we consulted a licensed psychologist and also included two researcher who were familiar with mental health content shared on social medium over a random sample of post complied from the timeline of randomly selected mid user we obtained independent binary annotation on whether a post wa likely to be related to mental health the fleiss for interrater agreement wa found to be high along with an accuracy of in distinguishing user who engage in genuine disclosure from those who do not this establishes adequacy of our approach table give some paraphrased mental health disclosure post of twitter user who were identified to be genuine mental health disclosers by our approach in figure we show the pipeline of step involved in our approach of arriving at this final dataset,"['study', 'us', 'publicly', 'shared', 'illness', 'selfdisclosure', 'collected', 'social', 'medium', 'started', 'obtaining', 'large', 'sample', 'english', 'language', 'candidate', 'selfdisclosure', 'full', 'archive', 'public', 'around', 'variety', 'concern', 'specifically', 'filtered', 'shared', 'march', 'containing', 'keyphrases', 'included', 'table', 'keyphrases', 'collated', 'combination', 'reference', 'prior', 'work', 'consultation', 'trained', 'psychiatrist', 'practitioner', 'keyphrases', 'sought', 'identify', 'publicly', 'state', 'diagnosed', 'suffering', 'form', 'illness', 'noted', 'coppersmith', 'et', 'al', 'may', 'make', 'statement', 'seek', 'support', 'others', 'social', 'network', 'fight', 'stigma', 'illness', 'perhaps', 'explanation', 'behavior', 'obtained', 'unique', 'end', 'initial', 'collection', 'phase', 'parallelly', 'obtained', 'candidate', 'sample', 'firehose', 'stream', 'allow', 'robust', 'statistical', 'comparison', 'choose', 'selfdisclose', 'illness', 'dataset', 'included', 'random', 'sample', 'unique', 'made', 'march', 'ensuring', 'none', 'matched', 'keyphrases', 'given', 'table', 'thereafter', 'candidate', 'disclosure', 'sample', 'candidate', 'sample', 'utilized', 'official', 'api', 'obtain', 'last', 'unique', 'datasets', 'dataset', 'crawled', 'matching', 'one', 'keyphrases', 'disregard', 'analysis', 'employing', 'google', 'compact', 'language', 'detector', 'disregarded', 'least', 'written', 'english', 'final', 'candidate', 'disclosure', 'sample', 'contained', 'sample', 'contained', 'note', 'population', 'four', 'country', 'widely', 'different', 'along', 'overall', 'reported', 'internet', 'penetration', 'rate', 'hence', 'devise', 'subsampling', 'strategy', 'filter', 'belonging', 'one', 'four', 'country', 'set', 'candidate', 'disclosure', 'datasets', 'inferrable', 'country', 'information', 'first', 'population', 'based', 'subsampling', 'use', 'inverse', 'population', 'rank', 'country', 'respective', 'rate', 'sampling', 'use', 'internet', 'penetration', 'percentage', 'country', 'randomly', 'sample', 'fraction', 'population', 'subsampled', 'set', 'manner', 'across', 'datasets', 'obtained', 'u', 'uk', 'zanext', 'qualitatively', 'verified', 'whether', 'indeed', 'selfdisclosures', 'challenge', 'purpose', 'consulted', 'licensed', 'psychologist', 'also', 'included', 'two', 'researcher', 'familiar', 'content', 'shared', 'social', 'medium', 'random', 'sample', 'complied', 'timeline', 'randomly', 'selected', 'mid', 'obtained', 'independent', 'binary', 'annotation', 'whether', 'likely', 'related', 'fleiss', 'interrater', 'agreement', 'found', 'high', 'along', 'accuracy', 'distinguishing', 'engage', 'genuine', 'disclosure', 'establishes', 'adequacy', 'approach', 'table', 'give', 'paraphrased', 'disclosure', 'identified', 'genuine', 'disclosers', 'approach', 'figure', 'show', 'pipeline', 'step', 'involved', 'approach', 'arriving', 'final', 'dataset']","['study us', 'us publicly', 'publicly shared', 'shared illness', 'illness selfdisclosure', 'selfdisclosure collected', 'collected social', 'social medium', 'medium started', 'started obtaining', 'obtaining large', 'large sample', 'sample english', 'english language', 'language candidate', 'candidate selfdisclosure', 'selfdisclosure full', 'full archive', 'archive public', 'public around', 'around variety', 'variety concern', 'concern specifically', 'specifically filtered', 'filtered shared', 'shared march', 'march containing', 'containing keyphrases', 'keyphrases included', 'included table', 'table keyphrases', 'keyphrases collated', 'collated combination', 'combination reference', 'reference prior', 'prior work', 'work consultation', 'consultation trained', 'trained psychiatrist', 'psychiatrist practitioner', 'practitioner keyphrases', 'keyphrases sought', 'sought identify', 'identify publicly', 'publicly state', 'state diagnosed', 'diagnosed suffering', 'suffering form', 'form illness', 'illness noted', 'noted coppersmith', 'coppersmith et', 'et al', 'al may', 'may make', 'make statement', 'statement seek', 'seek support', 'support others', 'others social', 'social network', 'network fight', 'fight stigma', 'stigma illness', 'illness perhaps', 'perhaps explanation', 'explanation behavior', 'behavior obtained', 'obtained unique', 'unique end', 'end initial', 'initial collection', 'collection phase', 'phase parallelly', 'parallelly obtained', 'obtained candidate', 'candidate sample', 'sample firehose', 'firehose stream', 'stream allow', 'allow robust', 'robust statistical', 'statistical comparison', 'comparison choose', 'choose selfdisclose', 'selfdisclose illness', 'illness dataset', 'dataset included', 'included random', 'random sample', 'sample unique', 'unique made', 'made march', 'march ensuring', 'ensuring none', 'none matched', 'matched keyphrases', 'keyphrases given', 'given table', 'table thereafter', 'thereafter candidate', 'candidate disclosure', 'disclosure sample', 'sample candidate', 'candidate sample', 'sample utilized', 'utilized official', 'official api', 'api obtain', 'obtain last', 'last unique', 'unique datasets', 'datasets dataset', 'dataset crawled', 'crawled matching', 'matching one', 'one keyphrases', 'keyphrases disregard', 'disregard analysis', 'analysis employing', 'employing google', 'google compact', 'compact language', 'language detector', 'detector disregarded', 'disregarded least', 'least written', 'written english', 'english final', 'final candidate', 'candidate disclosure', 'disclosure sample', 'sample contained', 'contained sample', 'sample contained', 'contained note', 'note population', 'population four', 'four country', 'country widely', 'widely different', 'different along', 'along overall', 'overall reported', 'reported internet', 'internet penetration', 'penetration rate', 'rate hence', 'hence devise', 'devise subsampling', 'subsampling strategy', 'strategy filter', 'filter belonging', 'belonging one', 'one four', 'four country', 'country set', 'set candidate', 'candidate disclosure', 'disclosure datasets', 'datasets inferrable', 'inferrable country', 'country information', 'information first', 'first population', 'population based', 'based subsampling', 'subsampling use', 'use inverse', 'inverse population', 'population rank', 'rank country', 'country respective', 'respective rate', 'rate sampling', 'sampling use', 'use internet', 'internet penetration', 'penetration percentage', 'percentage country', 'country randomly', 'randomly sample', 'sample fraction', 'fraction population', 'population subsampled', 'subsampled set', 'set manner', 'manner across', 'across datasets', 'datasets obtained', 'obtained u', 'u uk', 'uk zanext', 'zanext qualitatively', 'qualitatively verified', 'verified whether', 'whether indeed', 'indeed selfdisclosures', 'selfdisclosures challenge', 'challenge purpose', 'purpose consulted', 'consulted licensed', 'licensed psychologist', 'psychologist also', 'also included', 'included two', 'two researcher', 'researcher familiar', 'familiar content', 'content shared', 'shared social', 'social medium', 'medium random', 'random sample', 'sample complied', 'complied timeline', 'timeline randomly', 'randomly selected', 'selected mid', 'mid obtained', 'obtained independent', 'independent binary', 'binary annotation', 'annotation whether', 'whether likely', 'likely related', 'related fleiss', 'fleiss interrater', 'interrater agreement', 'agreement found', 'found high', 'high along', 'along accuracy', 'accuracy distinguishing', 'distinguishing engage', 'engage genuine', 'genuine disclosure', 'disclosure establishes', 'establishes adequacy', 'adequacy approach', 'approach table', 'table give', 'give paraphrased', 'paraphrased disclosure', 'disclosure identified', 'identified genuine', 'genuine disclosers', 'disclosers approach', 'approach figure', 'figure show', 'show pipeline', 'pipeline step', 'step involved', 'involved approach', 'approach arriving', 'arriving final', 'final dataset']","['study us publicly', 'us publicly shared', 'publicly shared illness', 'shared illness selfdisclosure', 'illness selfdisclosure collected', 'selfdisclosure collected social', 'collected social medium', 'social medium started', 'medium started obtaining', 'started obtaining large', 'obtaining large sample', 'large sample english', 'sample english language', 'english language candidate', 'language candidate selfdisclosure', 'candidate selfdisclosure full', 'selfdisclosure full archive', 'full archive public', 'archive public around', 'public around variety', 'around variety concern', 'variety concern specifically', 'concern specifically filtered', 'specifically filtered shared', 'filtered shared march', 'shared march containing', 'march containing keyphrases', 'containing keyphrases included', 'keyphrases included table', 'included table keyphrases', 'table keyphrases collated', 'keyphrases collated combination', 'collated combination reference', 'combination reference prior', 'reference prior work', 'prior work consultation', 'work consultation trained', 'consultation trained psychiatrist', 'trained psychiatrist practitioner', 'psychiatrist practitioner keyphrases', 'practitioner keyphrases sought', 'keyphrases sought identify', 'sought identify publicly', 'identify publicly state', 'publicly state diagnosed', 'state diagnosed suffering', 'diagnosed suffering form', 'suffering form illness', 'form illness noted', 'illness noted coppersmith', 'noted coppersmith et', 'coppersmith et al', 'et al may', 'al may make', 'may make statement', 'make statement seek', 'statement seek support', 'seek support others', 'support others social', 'others social network', 'social network fight', 'network fight stigma', 'fight stigma illness', 'stigma illness perhaps', 'illness perhaps explanation', 'perhaps explanation behavior', 'explanation behavior obtained', 'behavior obtained unique', 'obtained unique end', 'unique end initial', 'end initial collection', 'initial collection phase', 'collection phase parallelly', 'phase parallelly obtained', 'parallelly obtained candidate', 'obtained candidate sample', 'candidate sample firehose', 'sample firehose stream', 'firehose stream allow', 'stream allow robust', 'allow robust statistical', 'robust statistical comparison', 'statistical comparison choose', 'comparison choose selfdisclose', 'choose selfdisclose illness', 'selfdisclose illness dataset', 'illness dataset included', 'dataset included random', 'included random sample', 'random sample unique', 'sample unique made', 'unique made march', 'made march ensuring', 'march ensuring none', 'ensuring none matched', 'none matched keyphrases', 'matched keyphrases given', 'keyphrases given table', 'given table thereafter', 'table thereafter candidate', 'thereafter candidate disclosure', 'candidate disclosure sample', 'disclosure sample candidate', 'sample candidate sample', 'candidate sample utilized', 'sample utilized official', 'utilized official api', 'official api obtain', 'api obtain last', 'obtain last unique', 'last unique datasets', 'unique datasets dataset', 'datasets dataset crawled', 'dataset crawled matching', 'crawled matching one', 'matching one keyphrases', 'one keyphrases disregard', 'keyphrases disregard analysis', 'disregard analysis employing', 'analysis employing google', 'employing google compact', 'google compact language', 'compact language detector', 'language detector disregarded', 'detector disregarded least', 'disregarded least written', 'least written english', 'written english final', 'english final candidate', 'final candidate disclosure', 'candidate disclosure sample', 'disclosure sample contained', 'sample contained sample', 'contained sample contained', 'sample contained note', 'contained note population', 'note population four', 'population four country', 'four country widely', 'country widely different', 'widely different along', 'different along overall', 'along overall reported', 'overall reported internet', 'reported internet penetration', 'internet penetration rate', 'penetration rate hence', 'rate hence devise', 'hence devise subsampling', 'devise subsampling strategy', 'subsampling strategy filter', 'strategy filter belonging', 'filter belonging one', 'belonging one four', 'one four country', 'four country set', 'country set candidate', 'set candidate disclosure', 'candidate disclosure datasets', 'disclosure datasets inferrable', 'datasets inferrable country', 'inferrable country information', 'country information first', 'information first population', 'first population based', 'population based subsampling', 'based subsampling use', 'subsampling use inverse', 'use inverse population', 'inverse population rank', 'population rank country', 'rank country respective', 'country respective rate', 'respective rate sampling', 'rate sampling use', 'sampling use internet', 'use internet penetration', 'internet penetration percentage', 'penetration percentage country', 'percentage country randomly', 'country randomly sample', 'randomly sample fraction', 'sample fraction population', 'fraction population subsampled', 'population subsampled set', 'subsampled set manner', 'set manner across', 'manner across datasets', 'across datasets obtained', 'datasets obtained u', 'obtained u uk', 'u uk zanext', 'uk zanext qualitatively', 'zanext qualitatively verified', 'qualitatively verified whether', 'verified whether indeed', 'whether indeed selfdisclosures', 'indeed selfdisclosures challenge', 'selfdisclosures challenge purpose', 'challenge purpose consulted', 'purpose consulted licensed', 'consulted licensed psychologist', 'licensed psychologist also', 'psychologist also included', 'also included two', 'included two researcher', 'two researcher familiar', 'researcher familiar content', 'familiar content shared', 'content shared social', 'shared social medium', 'social medium random', 'medium random sample', 'random sample complied', 'sample complied timeline', 'complied timeline randomly', 'timeline randomly selected', 'randomly selected mid', 'selected mid obtained', 'mid obtained independent', 'obtained independent binary', 'independent binary annotation', 'binary annotation whether', 'annotation whether likely', 'whether likely related', 'likely related fleiss', 'related fleiss interrater', 'fleiss interrater agreement', 'interrater agreement found', 'agreement found high', 'found high along', 'high along accuracy', 'along accuracy distinguishing', 'accuracy distinguishing engage', 'distinguishing engage genuine', 'engage genuine disclosure', 'genuine disclosure establishes', 'disclosure establishes adequacy', 'establishes adequacy approach', 'adequacy approach table', 'approach table give', 'table give paraphrased', 'give paraphrased disclosure', 'paraphrased disclosure identified', 'disclosure identified genuine', 'identified genuine disclosers', 'genuine disclosers approach', 'disclosers approach figure', 'approach figure show', 'figure show pipeline', 'show pipeline step', 'pipeline step involved', 'step involved approach', 'involved approach arriving', 'approach arriving final', 'arriving final dataset']"
https://www.jmir.org/2019/6/e14199/,1,The selection of the tweets and their users was based on the filtered real-time streaming support provided by the Twitter API. In the first step we selected the users who showed potential signs of depression on Twitter on the basis of the 20 most frequent words in Spanish expressed by patients suffering from depression in clinical settings. These words were jointly identified and selected by a psychologist and a family physician with clinical experience and were based on the definition and general features of depression according to the Diagnostic and Statistical Manual of Mental Disorders [42]. The list of words used and their English translations are shown in Textbox 1. During June 2018 1470000 tweets including 1 or more occurrences of the words listed in Textbox 1 were collected. From this collection of tweets and to select the users who publicly stated in the textual description associated to their profile that they suffered from depression all the profile descriptions including 1 or more occurrences of the word “depr” and all the possible derivations related to the word depression in Spanish such as “depre” “depresión” “depresivo” “depresiva” “deprimido” and “deprimida” were considered. From the 720 users who included 1 or more of these words in their description profile 90 users who stated they suffered from depression or were receiving treatment for depression were selected for the analysis. This selection was performed by a psychologist verifying that the statements were related to real expressions of depression excluding quotes jokes or fake ones. For each of these depressed Twitter users we collected all the most recent tweets from their timeline up to a maximum of about 3200 tweets. Thus a total of 189669 tweets were collected a figure that was reduced to 140946 after discarding the retweets. These 140946 tweets constituted the depressive users dataset. Examples of sentences appearing in the user profiles that were used for selecting the depressive users are: “Paciente psiquiátrico con depresión crónica” (Psychiatric patient with chronic depression; example of a profile sentence that indicates depression). “Colecciono errores traducidos a tweets depresivos y a uno que otro impulso de amor” (I gather errors translated into depressing tweets and into one or another love impulse; example of a profile sentence that does not indicate depression). Once the users with profile sentences indicating depression had been retrieved their Twitter timelines were collected. Only those users having in their timeline at least 10 tweets that suggested signs of depression were retained for further analyses. For each user the selection of these tweets was performed by manually inspecting the tweets of the user’s complete timeline in reverse temporal order starting from the most recent one to the oldest tweet of the timeline retrieved by means of the Twitter API . Finally a total number of 1000 tweets issued by the 90 depressive users suggesting signs of depression were detected and used for the analysis. This set of tweets provided us with the depressive tweets dataset which was used to analyze linguistic features of tweets showing signs of depression. It has to be mentioned that these 1000 tweets were not to be included in the depressive users dataset (see Figure 1). At the same time more than 97500000 tweets were also collected in June 2018: such tweets were gathered by listening to the public Twitter stream during this time span by only considering tweets with Spanish textual contents (as detected by Twitter language identification support). Given that Twitter requires more restrictive filters than just the language of the tweets we used a list of the most frequently used Spanish words (stopwords) to retrieve all tweets that included 1 or more of these words. The vast majority of Spanish tweets should match this criterion. A sample of 450 users who did not mention in their profile the word depression and its derivations were selected randomly from the 97500000 tweets. The complete timelines of these users were compiled (1141021 tweets) which were reduced to 712589 once retweets were removed. These 712589 tweets constituted the control dataset. To identify the language of a tweet we relied on the language automatically identified by Twitter for each tweet selecting tweets in Spanish. It has to be noted that these data can contain some tweets from unidentified depressive users.This study was developed in 2 steps. In the first step the selection of users and the compilation of tweets were performed. A total of 3 datasets of tweets were created a depressive users dataset (made up of the timeline of 90 users who explicitly mentioned that they suffer from depression) a depressive tweets dataset (a manual selection of tweets from the previous users which included expressions indicative of depression) and a control dataset (made up of the timeline of 450 randomly selected users). In the second step the comparison and analysis of the 3 datasets of tweets were carried out.This study was designed and developed in 2 steps with the aim of analyzing the linguistic patterns and behavioral features of Twitter users suffering from depression in comparison with the general population of Twitter users. The study was focused on tweets written in Spanish. In the first step the selection of users and the compilation of tweets were performed. Given the design and purpose of the study we decided to use the Twitter Application Programming Interface (API) [41]. Using this API 3 datasets of tweets were created: The depressive users dataset was made up of the timeline of 90 users who publicly mentioned on their Twitter profile that they suffer from depression. The control dataset was made up of the timeline of 450 randomly selected Twitter users. The depressive tweets dataset was constituted by a manual selection of tweets from the depressive users dataset which specifically included expressions indicative of depression. In the second step comparison and analysis of the 3 datasets of tweets (control depressive users and depressive tweets datasets) were carried out to spot their distinguishing features. In the rest of this section we will describe the methodology in detail. The flow diagram of the study is depicted in Figure 1.,the selection of the tweet and their user wa based on the filtered realtime streaming support provided by the twitter api in the first step we selected the user who showed potential sign of depression on twitter on the basis of the most frequent word in spanish expressed by patient suffering from depression in clinical setting these word were jointly identified and selected by a psychologist and a family physician with clinical experience and were based on the definition and general feature of depression according to the diagnostic and statistical manual of mental disorder the list of word used and their english translation are shown in textbox during june tweet including or more occurrence of the word listed in textbox were collected from this collection of tweet and to select the user who publicly stated in the textual description associated to their profile that they suffered from depression all the profile description including or more occurrence of the word depr and all the possible derivation related to the word depression in spanish such a depre depresin depresivo depresiva deprimido and deprimida were considered from the user who included or more of these word in their description profile user who stated they suffered from depression or were receiving treatment for depression were selected for the analysis this selection wa performed by a psychologist verifying that the statement were related to real expression of depression excluding quote joke or fake one for each of these depressed twitter user we collected all the most recent tweet from their timeline up to a maximum of about tweet thus a total of tweet were collected a figure that wa reduced to after discarding the retweets these tweet constituted the depressive user dataset example of sentence appearing in the user profile that were used for selecting the depressive user are paciente psiquitrico con depresin crnica psychiatric patient with chronic depression example of a profile sentence that indicates depression colecciono errores traducidos a tweet depresivos y a uno que otro impulso de amor i gather error translated into depressing tweet and into one or another love impulse example of a profile sentence that doe not indicate depression once the user with profile sentence indicating depression had been retrieved their twitter timeline were collected only those user having in their timeline at least tweet that suggested sign of depression were retained for further analysis for each user the selection of these tweet wa performed by manually inspecting the tweet of the user complete timeline in reverse temporal order starting from the most recent one to the oldest tweet of the timeline retrieved by mean of the twitter api finally a total number of tweet issued by the depressive user suggesting sign of depression were detected and used for the analysis this set of tweet provided u with the depressive tweet dataset which wa used to analyze linguistic feature of tweet showing sign of depression it ha to be mentioned that these tweet were not to be included in the depressive user dataset see figure at the same time more than tweet were also collected in june such tweet were gathered by listening to the public twitter stream during this time span by only considering tweet with spanish textual content a detected by twitter language identification support given that twitter requires more restrictive filter than just the language of the tweet we used a list of the most frequently used spanish word stopwords to retrieve all tweet that included or more of these word the vast majority of spanish tweet should match this criterion a sample of user who did not mention in their profile the word depression and it derivation were selected randomly from the tweet the complete timeline of these user were compiled tweet which were reduced to once retweets were removed these tweet constituted the control dataset to identify the language of a tweet we relied on the language automatically identified by twitter for each tweet selecting tweet in spanish it ha to be noted that these data can contain some tweet from unidentified depressive usersthis study wa developed in step in the first step the selection of user and the compilation of tweet were performed a total of datasets of tweet were created a depressive user dataset made up of the timeline of user who explicitly mentioned that they suffer from depression a depressive tweet dataset a manual selection of tweet from the previous user which included expression indicative of depression and a control dataset made up of the timeline of randomly selected user in the second step the comparison and analysis of the datasets of tweet were carried outthis study wa designed and developed in step with the aim of analyzing the linguistic pattern and behavioral feature of twitter user suffering from depression in comparison with the general population of twitter user the study wa focused on tweet written in spanish in the first step the selection of user and the compilation of tweet were performed given the design and purpose of the study we decided to use the twitter application programming interface api using this api datasets of tweet were created the depressive user dataset wa made up of the timeline of user who publicly mentioned on their twitter profile that they suffer from depression the control dataset wa made up of the timeline of randomly selected twitter user the depressive tweet dataset wa constituted by a manual selection of tweet from the depressive user dataset which specifically included expression indicative of depression in the second step comparison and analysis of the datasets of tweet control depressive user and depressive tweet datasets were carried out to spot their distinguishing feature in the rest of this section we will describe the methodology in detail the flow diagram of the study is depicted in figure,"['selection', 'based', 'filtered', 'realtime', 'streaming', 'support', 'provided', 'api', 'first', 'step', 'selected', 'showed', 'potential', 'sign', 'basis', 'frequent', 'spanish', 'expressed', 'patient', 'suffering', 'clinical', 'setting', 'jointly', 'identified', 'selected', 'psychologist', 'family', 'physician', 'clinical', 'experience', 'based', 'definition', 'general', 'feature', 'according', 'diagnostic', 'statistical', 'manual', 'disorder', 'list', 'english', 'translation', 'shown', 'textbox', 'june', 'including', 'occurrence', 'listed', 'textbox', 'collected', 'collection', 'select', 'publicly', 'stated', 'textual', 'description', 'associated', 'profile', 'suffered', 'profile', 'description', 'including', 'occurrence', 'depr', 'possible', 'derivation', 'related', 'spanish', 'depre', 'depresin', 'depresivo', 'depresiva', 'deprimido', 'deprimida', 'considered', 'included', 'description', 'profile', 'stated', 'suffered', 'receiving', 'treatment', 'selected', 'analysis', 'selection', 'performed', 'psychologist', 'verifying', 'statement', 'related', 'real', 'expression', 'excluding', 'quote', 'joke', 'fake', 'one', 'depressed', 'collected', 'recent', 'timeline', 'maximum', 'thus', 'total', 'collected', 'figure', 'reduced', 'discarding', 'retweets', 'constituted', 'depressive', 'dataset', 'example', 'sentence', 'appearing', 'profile', 'selecting', 'depressive', 'paciente', 'psiquitrico', 'con', 'depresin', 'crnica', 'psychiatric', 'patient', 'chronic', 'example', 'profile', 'sentence', 'indicates', 'colecciono', 'errores', 'traducidos', 'depresivos', 'uno', 'que', 'otro', 'impulso', 'de', 'amor', 'gather', 'error', 'translated', 'depressing', 'one', 'another', 'love', 'impulse', 'example', 'profile', 'sentence', 'doe', 'indicate', 'profile', 'sentence', 'indicating', 'retrieved', 'timeline', 'collected', 'timeline', 'least', 'suggested', 'sign', 'retained', 'analysis', 'selection', 'performed', 'manually', 'inspecting', 'complete', 'timeline', 'reverse', 'temporal', 'order', 'starting', 'recent', 'one', 'oldest', 'timeline', 'retrieved', 'mean', 'api', 'finally', 'total', 'number', 'issued', 'depressive', 'suggesting', 'sign', 'detected', 'analysis', 'set', 'provided', 'u', 'depressive', 'dataset', 'analyze', 'linguistic', 'feature', 'showing', 'sign', 'ha', 'mentioned', 'included', 'depressive', 'dataset', 'see', 'figure', 'time', 'also', 'collected', 'june', 'gathered', 'listening', 'public', 'stream', 'time', 'span', 'considering', 'spanish', 'textual', 'content', 'detected', 'language', 'identification', 'support', 'given', 'requires', 'restrictive', 'filter', 'language', 'list', 'frequently', 'spanish', 'stopwords', 'retrieve', 'included', 'vast', 'majority', 'spanish', 'match', 'criterion', 'sample', 'mention', 'profile', 'derivation', 'selected', 'randomly', 'complete', 'timeline', 'compiled', 'reduced', 'retweets', 'removed', 'constituted', 'dataset', 'identify', 'language', 'relied', 'language', 'automatically', 'identified', 'selecting', 'spanish', 'ha', 'noted', 'contain', 'unidentified', 'depressive', 'usersthis', 'study', 'developed', 'step', 'first', 'step', 'selection', 'compilation', 'performed', 'total', 'datasets', 'created', 'depressive', 'dataset', 'made', 'timeline', 'explicitly', 'mentioned', 'suffer', 'depressive', 'dataset', 'manual', 'selection', 'previous', 'included', 'expression', 'indicative', 'dataset', 'made', 'timeline', 'randomly', 'selected', 'second', 'step', 'comparison', 'analysis', 'datasets', 'carried', 'outthis', 'study', 'designed', 'developed', 'step', 'aim', 'analyzing', 'linguistic', 'pattern', 'behavioral', 'feature', 'suffering', 'comparison', 'general', 'population', 'study', 'focused', 'written', 'spanish', 'first', 'step', 'selection', 'compilation', 'performed', 'given', 'design', 'purpose', 'study', 'decided', 'use', 'application', 'programming', 'interface', 'api', 'using', 'api', 'datasets', 'created', 'depressive', 'dataset', 'made', 'timeline', 'publicly', 'mentioned', 'profile', 'suffer', 'dataset', 'made', 'timeline', 'randomly', 'selected', 'depressive', 'dataset', 'constituted', 'manual', 'selection', 'depressive', 'dataset', 'specifically', 'included', 'expression', 'indicative', 'second', 'step', 'comparison', 'analysis', 'datasets', 'depressive', 'depressive', 'datasets', 'carried', 'spot', 'distinguishing', 'feature', 'rest', 'section', 'describe', 'methodology', 'detail', 'flow', 'diagram', 'study', 'depicted', 'figure']","['selection based', 'based filtered', 'filtered realtime', 'realtime streaming', 'streaming support', 'support provided', 'provided api', 'api first', 'first step', 'step selected', 'selected showed', 'showed potential', 'potential sign', 'sign basis', 'basis frequent', 'frequent spanish', 'spanish expressed', 'expressed patient', 'patient suffering', 'suffering clinical', 'clinical setting', 'setting jointly', 'jointly identified', 'identified selected', 'selected psychologist', 'psychologist family', 'family physician', 'physician clinical', 'clinical experience', 'experience based', 'based definition', 'definition general', 'general feature', 'feature according', 'according diagnostic', 'diagnostic statistical', 'statistical manual', 'manual disorder', 'disorder list', 'list english', 'english translation', 'translation shown', 'shown textbox', 'textbox june', 'june including', 'including occurrence', 'occurrence listed', 'listed textbox', 'textbox collected', 'collected collection', 'collection select', 'select publicly', 'publicly stated', 'stated textual', 'textual description', 'description associated', 'associated profile', 'profile suffered', 'suffered profile', 'profile description', 'description including', 'including occurrence', 'occurrence depr', 'depr possible', 'possible derivation', 'derivation related', 'related spanish', 'spanish depre', 'depre depresin', 'depresin depresivo', 'depresivo depresiva', 'depresiva deprimido', 'deprimido deprimida', 'deprimida considered', 'considered included', 'included description', 'description profile', 'profile stated', 'stated suffered', 'suffered receiving', 'receiving treatment', 'treatment selected', 'selected analysis', 'analysis selection', 'selection performed', 'performed psychologist', 'psychologist verifying', 'verifying statement', 'statement related', 'related real', 'real expression', 'expression excluding', 'excluding quote', 'quote joke', 'joke fake', 'fake one', 'one depressed', 'depressed collected', 'collected recent', 'recent timeline', 'timeline maximum', 'maximum thus', 'thus total', 'total collected', 'collected figure', 'figure reduced', 'reduced discarding', 'discarding retweets', 'retweets constituted', 'constituted depressive', 'depressive dataset', 'dataset example', 'example sentence', 'sentence appearing', 'appearing profile', 'profile selecting', 'selecting depressive', 'depressive paciente', 'paciente psiquitrico', 'psiquitrico con', 'con depresin', 'depresin crnica', 'crnica psychiatric', 'psychiatric patient', 'patient chronic', 'chronic example', 'example profile', 'profile sentence', 'sentence indicates', 'indicates colecciono', 'colecciono errores', 'errores traducidos', 'traducidos depresivos', 'depresivos uno', 'uno que', 'que otro', 'otro impulso', 'impulso de', 'de amor', 'amor gather', 'gather error', 'error translated', 'translated depressing', 'depressing one', 'one another', 'another love', 'love impulse', 'impulse example', 'example profile', 'profile sentence', 'sentence doe', 'doe indicate', 'indicate profile', 'profile sentence', 'sentence indicating', 'indicating retrieved', 'retrieved timeline', 'timeline collected', 'collected timeline', 'timeline least', 'least suggested', 'suggested sign', 'sign retained', 'retained analysis', 'analysis selection', 'selection performed', 'performed manually', 'manually inspecting', 'inspecting complete', 'complete timeline', 'timeline reverse', 'reverse temporal', 'temporal order', 'order starting', 'starting recent', 'recent one', 'one oldest', 'oldest timeline', 'timeline retrieved', 'retrieved mean', 'mean api', 'api finally', 'finally total', 'total number', 'number issued', 'issued depressive', 'depressive suggesting', 'suggesting sign', 'sign detected', 'detected analysis', 'analysis set', 'set provided', 'provided u', 'u depressive', 'depressive dataset', 'dataset analyze', 'analyze linguistic', 'linguistic feature', 'feature showing', 'showing sign', 'sign ha', 'ha mentioned', 'mentioned included', 'included depressive', 'depressive dataset', 'dataset see', 'see figure', 'figure time', 'time also', 'also collected', 'collected june', 'june gathered', 'gathered listening', 'listening public', 'public stream', 'stream time', 'time span', 'span considering', 'considering spanish', 'spanish textual', 'textual content', 'content detected', 'detected language', 'language identification', 'identification support', 'support given', 'given requires', 'requires restrictive', 'restrictive filter', 'filter language', 'language list', 'list frequently', 'frequently spanish', 'spanish stopwords', 'stopwords retrieve', 'retrieve included', 'included vast', 'vast majority', 'majority spanish', 'spanish match', 'match criterion', 'criterion sample', 'sample mention', 'mention profile', 'profile derivation', 'derivation selected', 'selected randomly', 'randomly complete', 'complete timeline', 'timeline compiled', 'compiled reduced', 'reduced retweets', 'retweets removed', 'removed constituted', 'constituted dataset', 'dataset identify', 'identify language', 'language relied', 'relied language', 'language automatically', 'automatically identified', 'identified selecting', 'selecting spanish', 'spanish ha', 'ha noted', 'noted contain', 'contain unidentified', 'unidentified depressive', 'depressive usersthis', 'usersthis study', 'study developed', 'developed step', 'step first', 'first step', 'step selection', 'selection compilation', 'compilation performed', 'performed total', 'total datasets', 'datasets created', 'created depressive', 'depressive dataset', 'dataset made', 'made timeline', 'timeline explicitly', 'explicitly mentioned', 'mentioned suffer', 'suffer depressive', 'depressive dataset', 'dataset manual', 'manual selection', 'selection previous', 'previous included', 'included expression', 'expression indicative', 'indicative dataset', 'dataset made', 'made timeline', 'timeline randomly', 'randomly selected', 'selected second', 'second step', 'step comparison', 'comparison analysis', 'analysis datasets', 'datasets carried', 'carried outthis', 'outthis study', 'study designed', 'designed developed', 'developed step', 'step aim', 'aim analyzing', 'analyzing linguistic', 'linguistic pattern', 'pattern behavioral', 'behavioral feature', 'feature suffering', 'suffering comparison', 'comparison general', 'general population', 'population study', 'study focused', 'focused written', 'written spanish', 'spanish first', 'first step', 'step selection', 'selection compilation', 'compilation performed', 'performed given', 'given design', 'design purpose', 'purpose study', 'study decided', 'decided use', 'use application', 'application programming', 'programming interface', 'interface api', 'api using', 'using api', 'api datasets', 'datasets created', 'created depressive', 'depressive dataset', 'dataset made', 'made timeline', 'timeline publicly', 'publicly mentioned', 'mentioned profile', 'profile suffer', 'suffer dataset', 'dataset made', 'made timeline', 'timeline randomly', 'randomly selected', 'selected depressive', 'depressive dataset', 'dataset constituted', 'constituted manual', 'manual selection', 'selection depressive', 'depressive dataset', 'dataset specifically', 'specifically included', 'included expression', 'expression indicative', 'indicative second', 'second step', 'step comparison', 'comparison analysis', 'analysis datasets', 'datasets depressive', 'depressive depressive', 'depressive datasets', 'datasets carried', 'carried spot', 'spot distinguishing', 'distinguishing feature', 'feature rest', 'rest section', 'section describe', 'describe methodology', 'methodology detail', 'detail flow', 'flow diagram', 'diagram study', 'study depicted', 'depicted figure']","['selection based filtered', 'based filtered realtime', 'filtered realtime streaming', 'realtime streaming support', 'streaming support provided', 'support provided api', 'provided api first', 'api first step', 'first step selected', 'step selected showed', 'selected showed potential', 'showed potential sign', 'potential sign basis', 'sign basis frequent', 'basis frequent spanish', 'frequent spanish expressed', 'spanish expressed patient', 'expressed patient suffering', 'patient suffering clinical', 'suffering clinical setting', 'clinical setting jointly', 'setting jointly identified', 'jointly identified selected', 'identified selected psychologist', 'selected psychologist family', 'psychologist family physician', 'family physician clinical', 'physician clinical experience', 'clinical experience based', 'experience based definition', 'based definition general', 'definition general feature', 'general feature according', 'feature according diagnostic', 'according diagnostic statistical', 'diagnostic statistical manual', 'statistical manual disorder', 'manual disorder list', 'disorder list english', 'list english translation', 'english translation shown', 'translation shown textbox', 'shown textbox june', 'textbox june including', 'june including occurrence', 'including occurrence listed', 'occurrence listed textbox', 'listed textbox collected', 'textbox collected collection', 'collected collection select', 'collection select publicly', 'select publicly stated', 'publicly stated textual', 'stated textual description', 'textual description associated', 'description associated profile', 'associated profile suffered', 'profile suffered profile', 'suffered profile description', 'profile description including', 'description including occurrence', 'including occurrence depr', 'occurrence depr possible', 'depr possible derivation', 'possible derivation related', 'derivation related spanish', 'related spanish depre', 'spanish depre depresin', 'depre depresin depresivo', 'depresin depresivo depresiva', 'depresivo depresiva deprimido', 'depresiva deprimido deprimida', 'deprimido deprimida considered', 'deprimida considered included', 'considered included description', 'included description profile', 'description profile stated', 'profile stated suffered', 'stated suffered receiving', 'suffered receiving treatment', 'receiving treatment selected', 'treatment selected analysis', 'selected analysis selection', 'analysis selection performed', 'selection performed psychologist', 'performed psychologist verifying', 'psychologist verifying statement', 'verifying statement related', 'statement related real', 'related real expression', 'real expression excluding', 'expression excluding quote', 'excluding quote joke', 'quote joke fake', 'joke fake one', 'fake one depressed', 'one depressed collected', 'depressed collected recent', 'collected recent timeline', 'recent timeline maximum', 'timeline maximum thus', 'maximum thus total', 'thus total collected', 'total collected figure', 'collected figure reduced', 'figure reduced discarding', 'reduced discarding retweets', 'discarding retweets constituted', 'retweets constituted depressive', 'constituted depressive dataset', 'depressive dataset example', 'dataset example sentence', 'example sentence appearing', 'sentence appearing profile', 'appearing profile selecting', 'profile selecting depressive', 'selecting depressive paciente', 'depressive paciente psiquitrico', 'paciente psiquitrico con', 'psiquitrico con depresin', 'con depresin crnica', 'depresin crnica psychiatric', 'crnica psychiatric patient', 'psychiatric patient chronic', 'patient chronic example', 'chronic example profile', 'example profile sentence', 'profile sentence indicates', 'sentence indicates colecciono', 'indicates colecciono errores', 'colecciono errores traducidos', 'errores traducidos depresivos', 'traducidos depresivos uno', 'depresivos uno que', 'uno que otro', 'que otro impulso', 'otro impulso de', 'impulso de amor', 'de amor gather', 'amor gather error', 'gather error translated', 'error translated depressing', 'translated depressing one', 'depressing one another', 'one another love', 'another love impulse', 'love impulse example', 'impulse example profile', 'example profile sentence', 'profile sentence doe', 'sentence doe indicate', 'doe indicate profile', 'indicate profile sentence', 'profile sentence indicating', 'sentence indicating retrieved', 'indicating retrieved timeline', 'retrieved timeline collected', 'timeline collected timeline', 'collected timeline least', 'timeline least suggested', 'least suggested sign', 'suggested sign retained', 'sign retained analysis', 'retained analysis selection', 'analysis selection performed', 'selection performed manually', 'performed manually inspecting', 'manually inspecting complete', 'inspecting complete timeline', 'complete timeline reverse', 'timeline reverse temporal', 'reverse temporal order', 'temporal order starting', 'order starting recent', 'starting recent one', 'recent one oldest', 'one oldest timeline', 'oldest timeline retrieved', 'timeline retrieved mean', 'retrieved mean api', 'mean api finally', 'api finally total', 'finally total number', 'total number issued', 'number issued depressive', 'issued depressive suggesting', 'depressive suggesting sign', 'suggesting sign detected', 'sign detected analysis', 'detected analysis set', 'analysis set provided', 'set provided u', 'provided u depressive', 'u depressive dataset', 'depressive dataset analyze', 'dataset analyze linguistic', 'analyze linguistic feature', 'linguistic feature showing', 'feature showing sign', 'showing sign ha', 'sign ha mentioned', 'ha mentioned included', 'mentioned included depressive', 'included depressive dataset', 'depressive dataset see', 'dataset see figure', 'see figure time', 'figure time also', 'time also collected', 'also collected june', 'collected june gathered', 'june gathered listening', 'gathered listening public', 'listening public stream', 'public stream time', 'stream time span', 'time span considering', 'span considering spanish', 'considering spanish textual', 'spanish textual content', 'textual content detected', 'content detected language', 'detected language identification', 'language identification support', 'identification support given', 'support given requires', 'given requires restrictive', 'requires restrictive filter', 'restrictive filter language', 'filter language list', 'language list frequently', 'list frequently spanish', 'frequently spanish stopwords', 'spanish stopwords retrieve', 'stopwords retrieve included', 'retrieve included vast', 'included vast majority', 'vast majority spanish', 'majority spanish match', 'spanish match criterion', 'match criterion sample', 'criterion sample mention', 'sample mention profile', 'mention profile derivation', 'profile derivation selected', 'derivation selected randomly', 'selected randomly complete', 'randomly complete timeline', 'complete timeline compiled', 'timeline compiled reduced', 'compiled reduced retweets', 'reduced retweets removed', 'retweets removed constituted', 'removed constituted dataset', 'constituted dataset identify', 'dataset identify language', 'identify language relied', 'language relied language', 'relied language automatically', 'language automatically identified', 'automatically identified selecting', 'identified selecting spanish', 'selecting spanish ha', 'spanish ha noted', 'ha noted contain', 'noted contain unidentified', 'contain unidentified depressive', 'unidentified depressive usersthis', 'depressive usersthis study', 'usersthis study developed', 'study developed step', 'developed step first', 'step first step', 'first step selection', 'step selection compilation', 'selection compilation performed', 'compilation performed total', 'performed total datasets', 'total datasets created', 'datasets created depressive', 'created depressive dataset', 'depressive dataset made', 'dataset made timeline', 'made timeline explicitly', 'timeline explicitly mentioned', 'explicitly mentioned suffer', 'mentioned suffer depressive', 'suffer depressive dataset', 'depressive dataset manual', 'dataset manual selection', 'manual selection previous', 'selection previous included', 'previous included expression', 'included expression indicative', 'expression indicative dataset', 'indicative dataset made', 'dataset made timeline', 'made timeline randomly', 'timeline randomly selected', 'randomly selected second', 'selected second step', 'second step comparison', 'step comparison analysis', 'comparison analysis datasets', 'analysis datasets carried', 'datasets carried outthis', 'carried outthis study', 'outthis study designed', 'study designed developed', 'designed developed step', 'developed step aim', 'step aim analyzing', 'aim analyzing linguistic', 'analyzing linguistic pattern', 'linguistic pattern behavioral', 'pattern behavioral feature', 'behavioral feature suffering', 'feature suffering comparison', 'suffering comparison general', 'comparison general population', 'general population study', 'population study focused', 'study focused written', 'focused written spanish', 'written spanish first', 'spanish first step', 'first step selection', 'step selection compilation', 'selection compilation performed', 'compilation performed given', 'performed given design', 'given design purpose', 'design purpose study', 'purpose study decided', 'study decided use', 'decided use application', 'use application programming', 'application programming interface', 'programming interface api', 'interface api using', 'api using api', 'using api datasets', 'api datasets created', 'datasets created depressive', 'created depressive dataset', 'depressive dataset made', 'dataset made timeline', 'made timeline publicly', 'timeline publicly mentioned', 'publicly mentioned profile', 'mentioned profile suffer', 'profile suffer dataset', 'suffer dataset made', 'dataset made timeline', 'made timeline randomly', 'timeline randomly selected', 'randomly selected depressive', 'selected depressive dataset', 'depressive dataset constituted', 'dataset constituted manual', 'constituted manual selection', 'manual selection depressive', 'selection depressive dataset', 'depressive dataset specifically', 'dataset specifically included', 'specifically included expression', 'included expression indicative', 'expression indicative second', 'indicative second step', 'second step comparison', 'step comparison analysis', 'comparison analysis datasets', 'analysis datasets depressive', 'datasets depressive depressive', 'depressive depressive datasets', 'depressive datasets carried', 'datasets carried spot', 'carried spot distinguishing', 'spot distinguishing feature', 'distinguishing feature rest', 'feature rest section', 'rest section describe', 'section describe methodology', 'describe methodology detail', 'methodology detail flow', 'detail flow diagram', 'flow diagram study', 'diagram study depicted', 'study depicted figure']"
https://aclanthology.org/W18-0608.pdf,1,Data was collected from 7 Cups of Tea an anonymous online chat-based peer support community for emotional distress1 . Users agree at signup that their data may be used for the purposes of research. All the data used for the current study was anonymous and securely stored. This research was performed in line with the ethical and privacy protocols outlined in detail in (Benton et al. 2017). Data from 7 Cups takes the form of written dialogue between users of the service and volunteers who are trained as “active listeners”. A fragment of an exchange between the user of the service (U) and the volunteer (V) might go as follows: For the analyses reported in this paper we used only text generated by users of the service not the volunteers providing peer support. Users who reported depression as their primary concern at sign up were eligible for inclusion in analyses. Our original sample was comprised of 23048 conversations involving 1937 unique users. Users were excluded from the sample if they did not indicate their culture or if they selected ‘Other’. This resulted in the exclusion of 199 and 130 users respectively. The original sample also included users identifying as Native American or American Indian. This group was excluded from analyses since the majority of the data among these users was not English. This resulted in the removal of 15 users leaving a total sample size of 1593.,data wa collected from cup of tea an anonymous online chatbased peer support community for emotional distress user agree at signup that their data may be used for the purpose of research all the data used for the current study wa anonymous and securely stored this research wa performed in line with the ethical and privacy protocol outlined in detail in benton et al data from cup take the form of written dialogue between user of the service and volunteer who are trained a active listener a fragment of an exchange between the user of the service u and the volunteer v might go a follows for the analysis reported in this paper we used only text generated by user of the service not the volunteer providing peer support user who reported depression a their primary concern at sign up were eligible for inclusion in analysis our original sample wa comprised of conversation involving unique user user were excluded from the sample if they did not indicate their culture or if they selected other this resulted in the exclusion of and user respectively the original sample also included user identifying a native american or american indian this group wa excluded from analysis since the majority of the data among these user wa not english this resulted in the removal of user leaving a total sample size of,"['collected', 'cup', 'tea', 'anonymous', 'online', 'chatbased', 'peer', 'support', 'community', 'emotional', 'distress', 'agree', 'signup', 'may', 'purpose', 'research', 'current', 'study', 'anonymous', 'securely', 'stored', 'research', 'performed', 'line', 'ethical', 'privacy', 'protocol', 'outlined', 'detail', 'benton', 'et', 'al', 'cup', 'take', 'form', 'written', 'dialogue', 'service', 'volunteer', 'trained', 'active', 'listener', 'fragment', 'exchange', 'service', 'u', 'volunteer', 'v', 'might', 'go', 'follows', 'analysis', 'reported', 'paper', 'text', 'generated', 'service', 'volunteer', 'providing', 'peer', 'support', 'reported', 'primary', 'concern', 'sign', 'eligible', 'inclusion', 'analysis', 'original', 'sample', 'comprised', 'conversation', 'involving', 'unique', 'excluded', 'sample', 'indicate', 'culture', 'selected', 'resulted', 'exclusion', 'respectively', 'original', 'sample', 'also', 'included', 'identifying', 'native', 'american', 'american', 'indian', 'group', 'excluded', 'analysis', 'since', 'majority', 'among', 'english', 'resulted', 'removal', 'leaving', 'total', 'sample', 'size']","['collected cup', 'cup tea', 'tea anonymous', 'anonymous online', 'online chatbased', 'chatbased peer', 'peer support', 'support community', 'community emotional', 'emotional distress', 'distress agree', 'agree signup', 'signup may', 'may purpose', 'purpose research', 'research current', 'current study', 'study anonymous', 'anonymous securely', 'securely stored', 'stored research', 'research performed', 'performed line', 'line ethical', 'ethical privacy', 'privacy protocol', 'protocol outlined', 'outlined detail', 'detail benton', 'benton et', 'et al', 'al cup', 'cup take', 'take form', 'form written', 'written dialogue', 'dialogue service', 'service volunteer', 'volunteer trained', 'trained active', 'active listener', 'listener fragment', 'fragment exchange', 'exchange service', 'service u', 'u volunteer', 'volunteer v', 'v might', 'might go', 'go follows', 'follows analysis', 'analysis reported', 'reported paper', 'paper text', 'text generated', 'generated service', 'service volunteer', 'volunteer providing', 'providing peer', 'peer support', 'support reported', 'reported primary', 'primary concern', 'concern sign', 'sign eligible', 'eligible inclusion', 'inclusion analysis', 'analysis original', 'original sample', 'sample comprised', 'comprised conversation', 'conversation involving', 'involving unique', 'unique excluded', 'excluded sample', 'sample indicate', 'indicate culture', 'culture selected', 'selected resulted', 'resulted exclusion', 'exclusion respectively', 'respectively original', 'original sample', 'sample also', 'also included', 'included identifying', 'identifying native', 'native american', 'american american', 'american indian', 'indian group', 'group excluded', 'excluded analysis', 'analysis since', 'since majority', 'majority among', 'among english', 'english resulted', 'resulted removal', 'removal leaving', 'leaving total', 'total sample', 'sample size']","['collected cup tea', 'cup tea anonymous', 'tea anonymous online', 'anonymous online chatbased', 'online chatbased peer', 'chatbased peer support', 'peer support community', 'support community emotional', 'community emotional distress', 'emotional distress agree', 'distress agree signup', 'agree signup may', 'signup may purpose', 'may purpose research', 'purpose research current', 'research current study', 'current study anonymous', 'study anonymous securely', 'anonymous securely stored', 'securely stored research', 'stored research performed', 'research performed line', 'performed line ethical', 'line ethical privacy', 'ethical privacy protocol', 'privacy protocol outlined', 'protocol outlined detail', 'outlined detail benton', 'detail benton et', 'benton et al', 'et al cup', 'al cup take', 'cup take form', 'take form written', 'form written dialogue', 'written dialogue service', 'dialogue service volunteer', 'service volunteer trained', 'volunteer trained active', 'trained active listener', 'active listener fragment', 'listener fragment exchange', 'fragment exchange service', 'exchange service u', 'service u volunteer', 'u volunteer v', 'volunteer v might', 'v might go', 'might go follows', 'go follows analysis', 'follows analysis reported', 'analysis reported paper', 'reported paper text', 'paper text generated', 'text generated service', 'generated service volunteer', 'service volunteer providing', 'volunteer providing peer', 'providing peer support', 'peer support reported', 'support reported primary', 'reported primary concern', 'primary concern sign', 'concern sign eligible', 'sign eligible inclusion', 'eligible inclusion analysis', 'inclusion analysis original', 'analysis original sample', 'original sample comprised', 'sample comprised conversation', 'comprised conversation involving', 'conversation involving unique', 'involving unique excluded', 'unique excluded sample', 'excluded sample indicate', 'sample indicate culture', 'indicate culture selected', 'culture selected resulted', 'selected resulted exclusion', 'resulted exclusion respectively', 'exclusion respectively original', 'respectively original sample', 'original sample also', 'sample also included', 'also included identifying', 'included identifying native', 'identifying native american', 'native american american', 'american american indian', 'american indian group', 'indian group excluded', 'group excluded analysis', 'excluded analysis since', 'analysis since majority', 'since majority among', 'majority among english', 'among english resulted', 'english resulted removal', 'resulted removal leaving', 'removal leaving total', 'leaving total sample', 'total sample size']"
https://dl.acm.org/doi/pdf/10.1145/3359169,1,"Selection Criteria and Data Scope. To understand the impact of cultural differences on how individuals use online mental health platforms we begin our analysis by creating a dataset of users from different national communities on Talklife a support platform with over half a million users [91]. For this analysis due to the fact that most research in CSCW on mental health online has been done either agnostic of cultural context [12 34] or in a Western context [60 67 88] we choose to focus on users from non-Western countries following Zhang et al. [103]. As researchers located in the Global South and with lived experience interacting with the health system and diverse explanatory models [52] of mental illness we believe that moving the focus of CSCW and CSCWadjacent mental health research away from the West is crucial to better meet the needs of people often underserved by the medical system [70]. To create these subgroups of users we choose the three non-Western countries with the highest user populations on Talklife or India Malaysia and the Philippines. Guided by the rich amount of literature on the unique nuances to mental health expression for each country [35 62 77 80] we examine the national identity linguistic and behavior-based differences of use between each user subgroup. In particular this research notes that as a result of cultural norms around the sharing of distress and alternative conceptualizations of mental illness in India Malaysia and the Philippines symptoms are often expressed in somatic and religious terms as opposed to traditionally clinical or psychiatric terms. We choose to analyze each subgroup at the national level for both theoretical and practical reasons. On a theoretical level in past work in the medical anthropology of mental health national identity has commonly been used for a approximate level of analysis for cultural identity [31 33 52]. Additionally on a more practical level each user’s country was determined using their IP address by Talklife and shared with us in an user-anonymized dataset. Inferring a more precise location could potentially compromise user anonymity as discussed in past work [47] and did not seem to have any more significant value for our analysis of cultural differences than analysis at the national level. We analyze data from 10532 Indian users 3370 Malaysian users and 3370 Filipino users as shown in Table 2. Collectively we refer to these countries as the minority sample. As a comparison set we construct a random sample of all threads on Talklife and refer to it as the majority sample. Due to the relative prevalence of users from Western English-speaking countries in Talklife most of the threads in the majority sample include posts from countries such as the USA UK and Canada. Indians are the largest non-Western minority subgroup on Talklife. Data was sampled from May 2012 to June 2018. Following this cross-national analysis to see if our broader results on Talklife generalize to a differently structured online mental health community we picked the largest Western country (the United States) and the largest non-Western country (India) represented on 7Cups a similar support platform with more than 15000 users actively using the platform each week [7]. Using 7Cups data we repeat our analysis testing for the same cultural differences we found in our Talklife sample. For this analysis we were provided a sample of data on activity from 6055 Indian users and 18581 American users as shown in Table 2. Unlike our sample of Talklife users this dataset is not a random sample. There is an upsampling of Indian users to ensure that we have data from a sufficient number of Indians in the dataset. Like on Talklife Indians are the largest non-Western minority subgroup on 7Cups. We focus on Indian users due to a lack of sufficient data on users from Malaysia or the Philippines. Data was sampled from March 2014 - August 2018. 3.1.2 Defining Cultural Identity and Use of Clinical Language. In this work we examine the relationship between cultural identity and use of online mental health support forums. To do so we leverage Tomlinson’s definition of cultural identity as “self and communal definitions based around specific usually politically inflected differentiations: gender sexuality class religion race and ethnicity nationality"" [94] particularly looking at the aspect that of modern cultural identity that runs along national lines as delineated by Hall et al. [41]. As a diverse and amorphous form of identity cultural identity can often intersect and interact with other forms of identity including religious or ethnic identity. However in the absence of direct information about religious or ethnic identity based on the data available we use national identity as a proxy for cultural identity. Additionally following Schlesinger et al’s [83] call for more intersectional analyses and methods within HCI we also include analyses of adjacent and intersecting identities when relevant including religious identity. To analyze clinical language we use a broader definition of clinical language than just specific medical diagnoses. Following methods used in past work to analyze antidepressant related language [30] we create a dataset of clinical mental health language including unigrams bigrams and trigrams from a list of mental disorders as defined by the International Classification of Diseases (ICD-10) and Diagnostic and Statistical Manual of Mental Disorders (DSM-5) [100]. We also included all unigrams from the MacMillan Dictionary list of words used to describe illnesses and diseases both specifically for mental illness and general illness [1–3]. As a result we include unigrams like “night"" (from night terrors) or sleep (from “sleep disorder"") as these are often correlated with specific symptoms of mental illness or distress such as sleep issues or being awake at night [30]. This included any clinically common abbreviations for mental disorders such as OCD for “obsessive compulsive disorder"" or BPD for “borderline personality disorder."" Shorthand for disorders commonly used by online communities such as “pro-ana” (as used in pro-eating disorder communities) [22] were not included due to the difficulty in finding an exhaustive list of these terms across disorders. We choose to use terms from and associated with DSM and ICD categorized disorders as a result of the common usage of these frameworks globally [99]. Throughout our analysis of these varied factors we use µ to represent means and σ to represent standard deviations. 3.1.3 Constraints Limitations and Tradeoffs. Cultural identity can exist at many different and intersecting levels including subcultures and subcommunities within the larger umbrella of a cultural identity. As a result for the purpose of this analysis we had to adopt some constraints in order to do a meaningful and specific analysis. One large limiting constraint that we chose for this study is to use national identity at the state level as a proxy for cultural identity. Though a major and formative part of modern cultural identity as argued by both Hall [41] and Tomlinson [94] each country we analyze is incredibly diverse with many individual cultural identities that both intersect and diverge from a greater national identity [54 64 89]. A more rich analysis of these other forms of cultural identity is beyond the scope of this work but could lead to richer conclusions about the nature of cultural identity in online mental health support communities particularly with regard to cultural differences between users with the same national identity. Additionally to stay consistent between analyses as a result of a lack of data on users from Malaysia and the Philippines we only analyze users in India on 7Cups and extend these findings to the experience of being part of a minority group on an online mental health forum. We draw validity for these exploratory findings from similar consistent patterns we observe between Indian Malaysian and Filipino users but a deeper analysis with a larger dataset is likely necessary to determine when and for which minority communities these conclusions do not hold true. Additionally while we construct clinical language through use of the commonly used DSM and ICD both frameworks of illness categorization have significant limitations particularly in the countries we have selected. For example there are both mental health disorders that are culturebound [74] as well as mental health language that is used in different ways within the specific countries we analyze such as depression often being an umbrella term for all mental illnesses [53]. Additionally it is clear that online support communities often develop their own cultural norms and language around mental health [21 72] and a deeper understanding of how this plays out on Talklife and 7Cups is neither the focus nor within the scope of this work. In this work we intentionally use standard clinical and medical terms for mental health disorders in our analysis of clinical language. As detailed in past anthropological research [52] it is theorized that the use of medical and clinical language is representative of a medicalized explanatory model of illness and we frame use of this language across cultures as a approximate signifier of a greater awareness of the presence of a mental disorder as opposed to conceptualizing distress as “stress"" “tension"" or “depression"" [25 53 98]. For our analysis we strictly analyzed posts that were in the Latin alphabet with almost all posts on both Talklife and 7Cups being in English. However as both Malay [8] and Tagalog [82] are most commonly written in the Latin script and since it is common for users from India speakers to use romanized versions of Indian languages online [79] it is possible that a small minority of posts in our analysis were text in a different language. However as confirmed by only seeing English words used in our analysis of the top n-grams among each user subgroup it is clear that English is the predominant language on both platforms. Though beyond the immediate scope of this work a greater analysis of non-English code-switching on these platforms could lead to a deeper understanding of the impact of interactions on expression between users with the same national identity but different language preferences.",selection criterion and data scope to understand the impact of cultural difference on how individual use online mental health platform we begin our analysis by creating a dataset of user from different national community on talklife a support platform with over half a million user for this analysis due to the fact that most research in cscw on mental health online ha been done either agnostic of cultural context or in a western context we choose to focus on user from nonwestern country following zhang et al a researcher located in the global south and with lived experience interacting with the health system and diverse explanatory model of mental illness we believe that moving the focus of cscw and cscwadjacent mental health research away from the west is crucial to better meet the need of people often underserved by the medical system to create these subgroup of user we choose the three nonwestern country with the highest user population on talklife or india malaysia and the philippine guided by the rich amount of literature on the unique nuance to mental health expression for each country we examine the national identity linguistic and behaviorbased difference of use between each user subgroup in particular this research note that a a result of cultural norm around the sharing of distress and alternative conceptualization of mental illness in india malaysia and the philippine symptom are often expressed in somatic and religious term a opposed to traditionally clinical or psychiatric term we choose to analyze each subgroup at the national level for both theoretical and practical reason on a theoretical level in past work in the medical anthropology of mental health national identity ha commonly been used for a approximate level of analysis for cultural identity additionally on a more practical level each user country wa determined using their ip address by talklife and shared with u in an useranonymized dataset inferring a more precise location could potentially compromise user anonymity a discussed in past work and did not seem to have any more significant value for our analysis of cultural difference than analysis at the national level we analyze data from indian user malaysian user and filipino user a shown in table collectively we refer to these country a the minority sample a a comparison set we construct a random sample of all thread on talklife and refer to it a the majority sample due to the relative prevalence of user from western englishspeaking country in talklife most of the thread in the majority sample include post from country such a the usa uk and canada indian are the largest nonwestern minority subgroup on talklife data wa sampled from may to june following this crossnational analysis to see if our broader result on talklife generalize to a differently structured online mental health community we picked the largest western country the united state and the largest nonwestern country india represented on cup a similar support platform with more than user actively using the platform each week using cup data we repeat our analysis testing for the same cultural difference we found in our talklife sample for this analysis we were provided a sample of data on activity from indian user and american user a shown in table unlike our sample of talklife user this dataset is not a random sample there is an upsampling of indian user to ensure that we have data from a sufficient number of indian in the dataset like on talklife indian are the largest nonwestern minority subgroup on cup we focus on indian user due to a lack of sufficient data on user from malaysia or the philippine data wa sampled from march august defining cultural identity and use of clinical language in this work we examine the relationship between cultural identity and use of online mental health support forum to do so we leverage tomlinsons definition of cultural identity a self and communal definition based around specific usually politically inflected differentiation gender sexuality class religion race and ethnicity nationality particularly looking at the aspect that of modern cultural identity that run along national line a delineated by hall et al a a diverse and amorphous form of identity cultural identity can often intersect and interact with other form of identity including religious or ethnic identity however in the absence of direct information about religious or ethnic identity based on the data available we use national identity a a proxy for cultural identity additionally following schlesinger et al call for more intersectional analysis and method within hci we also include analysis of adjacent and intersecting identity when relevant including religious identity to analyze clinical language we use a broader definition of clinical language than just specific medical diagnosis following method used in past work to analyze antidepressant related language we create a dataset of clinical mental health language including unigrams bigram and trigram from a list of mental disorder a defined by the international classification of disease icd and diagnostic and statistical manual of mental disorder dsm we also included all unigrams from the macmillan dictionary list of word used to describe illness and disease both specifically for mental illness and general illness a a result we include unigrams like night from night terror or sleep from sleep disorder a these are often correlated with specific symptom of mental illness or distress such a sleep issue or being awake at night this included any clinically common abbreviation for mental disorder such a ocd for obsessive compulsive disorder or bpd for borderline personality disorder shorthand for disorder commonly used by online community such a proana a used in proeating disorder community were not included due to the difficulty in finding an exhaustive list of these term across disorder we choose to use term from and associated with dsm and icd categorized disorder a a result of the common usage of these framework globally throughout our analysis of these varied factor we use to represent mean and to represent standard deviation constraint limitation and tradeoff cultural identity can exist at many different and intersecting level including subculture and subcommunities within the larger umbrella of a cultural identity a a result for the purpose of this analysis we had to adopt some constraint in order to do a meaningful and specific analysis one large limiting constraint that we chose for this study is to use national identity at the state level a a proxy for cultural identity though a major and formative part of modern cultural identity a argued by both hall and tomlinson each country we analyze is incredibly diverse with many individual cultural identity that both intersect and diverge from a greater national identity a more rich analysis of these other form of cultural identity is beyond the scope of this work but could lead to richer conclusion about the nature of cultural identity in online mental health support community particularly with regard to cultural difference between user with the same national identity additionally to stay consistent between analysis a a result of a lack of data on user from malaysia and the philippine we only analyze user in india on cup and extend these finding to the experience of being part of a minority group on an online mental health forum we draw validity for these exploratory finding from similar consistent pattern we observe between indian malaysian and filipino user but a deeper analysis with a larger dataset is likely necessary to determine when and for which minority community these conclusion do not hold true additionally while we construct clinical language through use of the commonly used dsm and icd both framework of illness categorization have significant limitation particularly in the country we have selected for example there are both mental health disorder that are culturebound a well a mental health language that is used in different way within the specific country we analyze such a depression often being an umbrella term for all mental illness additionally it is clear that online support community often develop their own cultural norm and language around mental health and a deeper understanding of how this play out on talklife and cup is neither the focus nor within the scope of this work in this work we intentionally use standard clinical and medical term for mental health disorder in our analysis of clinical language a detailed in past anthropological research it is theorized that the use of medical and clinical language is representative of a medicalized explanatory model of illness and we frame use of this language across culture a a approximate signifier of a greater awareness of the presence of a mental disorder a opposed to conceptualizing distress a stress tension or depression for our analysis we strictly analyzed post that were in the latin alphabet with almost all post on both talklife and cup being in english however a both malay and tagalog are most commonly written in the latin script and since it is common for user from india speaker to use romanized version of indian language online it is possible that a small minority of post in our analysis were text in a different language however a confirmed by only seeing english word used in our analysis of the top ngrams among each user subgroup it is clear that english is the predominant language on both platform though beyond the immediate scope of this work a greater analysis of nonenglish codeswitching on these platform could lead to a deeper understanding of the impact of interaction on expression between user with the same national identity but different language preference,"['selection', 'criterion', 'scope', 'understand', 'impact', 'cultural', 'difference', 'individual', 'use', 'online', 'platform', 'begin', 'analysis', 'creating', 'dataset', 'different', 'national', 'community', 'talklife', 'support', 'platform', 'half', 'million', 'analysis', 'due', 'fact', 'research', 'cscw', 'online', 'ha', 'done', 'either', 'agnostic', 'cultural', 'context', 'western', 'context', 'choose', 'focus', 'nonwestern', 'country', 'following', 'zhang', 'et', 'al', 'researcher', 'located', 'global', 'south', 'lived', 'experience', 'interacting', 'system', 'diverse', 'explanatory', 'model', 'illness', 'believe', 'moving', 'focus', 'cscw', 'cscwadjacent', 'research', 'away', 'west', 'crucial', 'better', 'meet', 'need', 'people', 'often', 'underserved', 'medical', 'system', 'create', 'subgroup', 'choose', 'three', 'nonwestern', 'country', 'highest', 'population', 'talklife', 'india', 'malaysia', 'philippine', 'guided', 'rich', 'amount', 'literature', 'unique', 'nuance', 'expression', 'country', 'examine', 'national', 'identity', 'linguistic', 'behaviorbased', 'difference', 'use', 'subgroup', 'particular', 'research', 'note', 'result', 'cultural', 'norm', 'around', 'sharing', 'distress', 'alternative', 'conceptualization', 'illness', 'india', 'malaysia', 'philippine', 'symptom', 'often', 'expressed', 'somatic', 'religious', 'term', 'opposed', 'traditionally', 'clinical', 'psychiatric', 'term', 'choose', 'analyze', 'subgroup', 'national', 'level', 'theoretical', 'practical', 'reason', 'theoretical', 'level', 'past', 'work', 'medical', 'anthropology', 'national', 'identity', 'ha', 'commonly', 'approximate', 'level', 'analysis', 'cultural', 'identity', 'additionally', 'practical', 'level', 'country', 'determined', 'using', 'ip', 'address', 'talklife', 'shared', 'u', 'useranonymized', 'dataset', 'inferring', 'precise', 'location', 'could', 'potentially', 'compromise', 'anonymity', 'discussed', 'past', 'work', 'seem', 'significant', 'value', 'analysis', 'cultural', 'difference', 'analysis', 'national', 'level', 'analyze', 'indian', 'malaysian', 'filipino', 'shown', 'table', 'collectively', 'refer', 'country', 'minority', 'sample', 'comparison', 'set', 'construct', 'random', 'sample', 'thread', 'talklife', 'refer', 'majority', 'sample', 'due', 'relative', 'prevalence', 'western', 'englishspeaking', 'country', 'talklife', 'thread', 'majority', 'sample', 'include', 'country', 'usa', 'uk', 'canada', 'indian', 'largest', 'nonwestern', 'minority', 'subgroup', 'talklife', 'sampled', 'may', 'june', 'following', 'crossnational', 'analysis', 'see', 'broader', 'result', 'talklife', 'generalize', 'differently', 'structured', 'online', 'community', 'picked', 'largest', 'western', 'country', 'united', 'state', 'largest', 'nonwestern', 'country', 'india', 'represented', 'cup', 'similar', 'support', 'platform', 'actively', 'using', 'platform', 'week', 'using', 'cup', 'repeat', 'analysis', 'testing', 'cultural', 'difference', 'found', 'talklife', 'sample', 'analysis', 'provided', 'sample', 'activity', 'indian', 'american', 'shown', 'table', 'unlike', 'sample', 'talklife', 'dataset', 'random', 'sample', 'upsampling', 'indian', 'ensure', 'sufficient', 'number', 'indian', 'dataset', 'like', 'talklife', 'indian', 'largest', 'nonwestern', 'minority', 'subgroup', 'cup', 'focus', 'indian', 'due', 'lack', 'sufficient', 'malaysia', 'philippine', 'sampled', 'march', 'august', 'defining', 'cultural', 'identity', 'use', 'clinical', 'language', 'work', 'examine', 'relationship', 'cultural', 'identity', 'use', 'online', 'support', 'forum', 'leverage', 'tomlinsons', 'definition', 'cultural', 'identity', 'self', 'communal', 'definition', 'based', 'around', 'specific', 'usually', 'politically', 'inflected', 'differentiation', 'gender', 'sexuality', 'class', 'religion', 'race', 'ethnicity', 'nationality', 'particularly', 'looking', 'aspect', 'modern', 'cultural', 'identity', 'run', 'along', 'national', 'line', 'delineated', 'hall', 'et', 'al', 'diverse', 'amorphous', 'form', 'identity', 'cultural', 'identity', 'often', 'intersect', 'interact', 'form', 'identity', 'including', 'religious', 'ethnic', 'identity', 'however', 'absence', 'direct', 'information', 'religious', 'ethnic', 'identity', 'based', 'available', 'use', 'national', 'identity', 'proxy', 'cultural', 'identity', 'additionally', 'following', 'schlesinger', 'et', 'al', 'call', 'intersectional', 'analysis', 'method', 'within', 'hci', 'also', 'include', 'analysis', 'adjacent', 'intersecting', 'identity', 'relevant', 'including', 'religious', 'identity', 'analyze', 'clinical', 'language', 'use', 'broader', 'definition', 'clinical', 'language', 'specific', 'medical', 'diagnosis', 'following', 'method', 'past', 'work', 'analyze', 'antidepressant', 'related', 'language', 'create', 'dataset', 'clinical', 'language', 'including', 'unigrams', 'bigram', 'trigram', 'list', 'disorder', 'defined', 'international', 'classification', 'disease', 'icd', 'diagnostic', 'statistical', 'manual', 'disorder', 'dsm', 'also', 'included', 'unigrams', 'macmillan', 'dictionary', 'list', 'describe', 'illness', 'disease', 'specifically', 'illness', 'general', 'illness', 'result', 'include', 'unigrams', 'like', 'night', 'night', 'terror', 'sleep', 'sleep', 'disorder', 'often', 'correlated', 'specific', 'symptom', 'illness', 'distress', 'sleep', 'issue', 'awake', 'night', 'included', 'clinically', 'common', 'abbreviation', 'disorder', 'ocd', 'obsessive', 'compulsive', 'disorder', 'bpd', 'borderline', 'personality', 'disorder', 'shorthand', 'disorder', 'commonly', 'online', 'community', 'proana', 'proeating', 'disorder', 'community', 'included', 'due', 'difficulty', 'finding', 'exhaustive', 'list', 'term', 'across', 'disorder', 'choose', 'use', 'term', 'associated', 'dsm', 'icd', 'categorized', 'disorder', 'result', 'common', 'usage', 'framework', 'globally', 'throughout', 'analysis', 'varied', 'factor', 'use', 'represent', 'mean', 'represent', 'standard', 'deviation', 'constraint', 'limitation', 'tradeoff', 'cultural', 'identity', 'exist', 'many', 'different', 'intersecting', 'level', 'including', 'subculture', 'subcommunities', 'within', 'larger', 'umbrella', 'cultural', 'identity', 'result', 'purpose', 'analysis', 'adopt', 'constraint', 'order', 'meaningful', 'specific', 'analysis', 'one', 'large', 'limiting', 'constraint', 'chose', 'study', 'use', 'national', 'identity', 'state', 'level', 'proxy', 'cultural', 'identity', 'though', 'major', 'formative', 'part', 'modern', 'cultural', 'identity', 'argued', 'hall', 'tomlinson', 'country', 'analyze', 'incredibly', 'diverse', 'many', 'individual', 'cultural', 'identity', 'intersect', 'diverge', 'greater', 'national', 'identity', 'rich', 'analysis', 'form', 'cultural', 'identity', 'beyond', 'scope', 'work', 'could', 'lead', 'richer', 'conclusion', 'nature', 'cultural', 'identity', 'online', 'support', 'community', 'particularly', 'regard', 'cultural', 'difference', 'national', 'identity', 'additionally', 'stay', 'consistent', 'analysis', 'result', 'lack', 'malaysia', 'philippine', 'analyze', 'india', 'cup', 'extend', 'finding', 'experience', 'part', 'minority', 'group', 'online', 'forum', 'draw', 'validity', 'exploratory', 'finding', 'similar', 'consistent', 'pattern', 'observe', 'indian', 'malaysian', 'filipino', 'deeper', 'analysis', 'larger', 'dataset', 'likely', 'necessary', 'determine', 'minority', 'community', 'conclusion', 'hold', 'true', 'additionally', 'construct', 'clinical', 'language', 'use', 'commonly', 'dsm', 'icd', 'framework', 'illness', 'categorization', 'significant', 'limitation', 'particularly', 'country', 'selected', 'example', 'disorder', 'culturebound', 'well', 'language', 'different', 'way', 'within', 'specific', 'country', 'analyze', 'often', 'umbrella', 'term', 'illness', 'additionally', 'clear', 'online', 'support', 'community', 'often', 'develop', 'cultural', 'norm', 'language', 'around', 'deeper', 'understanding', 'play', 'talklife', 'cup', 'neither', 'focus', 'within', 'scope', 'work', 'work', 'intentionally', 'use', 'standard', 'clinical', 'medical', 'term', 'disorder', 'analysis', 'clinical', 'language', 'detailed', 'past', 'anthropological', 'research', 'theorized', 'use', 'medical', 'clinical', 'language', 'representative', 'medicalized', 'explanatory', 'model', 'illness', 'frame', 'use', 'language', 'across', 'culture', 'approximate', 'signifier', 'greater', 'awareness', 'presence', 'disorder', 'opposed', 'conceptualizing', 'distress', 'stress', 'tension', 'analysis', 'strictly', 'analyzed', 'latin', 'alphabet', 'almost', 'talklife', 'cup', 'english', 'however', 'malay', 'tagalog', 'commonly', 'written', 'latin', 'script', 'since', 'common', 'india', 'speaker', 'use', 'romanized', 'version', 'indian', 'language', 'online', 'possible', 'small', 'minority', 'analysis', 'text', 'different', 'language', 'however', 'confirmed', 'seeing', 'english', 'analysis', 'top', 'ngrams', 'among', 'subgroup', 'clear', 'english', 'predominant', 'language', 'platform', 'though', 'beyond', 'immediate', 'scope', 'work', 'greater', 'analysis', 'nonenglish', 'codeswitching', 'platform', 'could', 'lead', 'deeper', 'understanding', 'impact', 'interaction', 'expression', 'national', 'identity', 'different', 'language', 'preference']","['selection criterion', 'criterion scope', 'scope understand', 'understand impact', 'impact cultural', 'cultural difference', 'difference individual', 'individual use', 'use online', 'online platform', 'platform begin', 'begin analysis', 'analysis creating', 'creating dataset', 'dataset different', 'different national', 'national community', 'community talklife', 'talklife support', 'support platform', 'platform half', 'half million', 'million analysis', 'analysis due', 'due fact', 'fact research', 'research cscw', 'cscw online', 'online ha', 'ha done', 'done either', 'either agnostic', 'agnostic cultural', 'cultural context', 'context western', 'western context', 'context choose', 'choose focus', 'focus nonwestern', 'nonwestern country', 'country following', 'following zhang', 'zhang et', 'et al', 'al researcher', 'researcher located', 'located global', 'global south', 'south lived', 'lived experience', 'experience interacting', 'interacting system', 'system diverse', 'diverse explanatory', 'explanatory model', 'model illness', 'illness believe', 'believe moving', 'moving focus', 'focus cscw', 'cscw cscwadjacent', 'cscwadjacent research', 'research away', 'away west', 'west crucial', 'crucial better', 'better meet', 'meet need', 'need people', 'people often', 'often underserved', 'underserved medical', 'medical system', 'system create', 'create subgroup', 'subgroup choose', 'choose three', 'three nonwestern', 'nonwestern country', 'country highest', 'highest population', 'population talklife', 'talklife india', 'india malaysia', 'malaysia philippine', 'philippine guided', 'guided rich', 'rich amount', 'amount literature', 'literature unique', 'unique nuance', 'nuance expression', 'expression country', 'country examine', 'examine national', 'national identity', 'identity linguistic', 'linguistic behaviorbased', 'behaviorbased difference', 'difference use', 'use subgroup', 'subgroup particular', 'particular research', 'research note', 'note result', 'result cultural', 'cultural norm', 'norm around', 'around sharing', 'sharing distress', 'distress alternative', 'alternative conceptualization', 'conceptualization illness', 'illness india', 'india malaysia', 'malaysia philippine', 'philippine symptom', 'symptom often', 'often expressed', 'expressed somatic', 'somatic religious', 'religious term', 'term opposed', 'opposed traditionally', 'traditionally clinical', 'clinical psychiatric', 'psychiatric term', 'term choose', 'choose analyze', 'analyze subgroup', 'subgroup national', 'national level', 'level theoretical', 'theoretical practical', 'practical reason', 'reason theoretical', 'theoretical level', 'level past', 'past work', 'work medical', 'medical anthropology', 'anthropology national', 'national identity', 'identity ha', 'ha commonly', 'commonly approximate', 'approximate level', 'level analysis', 'analysis cultural', 'cultural identity', 'identity additionally', 'additionally practical', 'practical level', 'level country', 'country determined', 'determined using', 'using ip', 'ip address', 'address talklife', 'talklife shared', 'shared u', 'u useranonymized', 'useranonymized dataset', 'dataset inferring', 'inferring precise', 'precise location', 'location could', 'could potentially', 'potentially compromise', 'compromise anonymity', 'anonymity discussed', 'discussed past', 'past work', 'work seem', 'seem significant', 'significant value', 'value analysis', 'analysis cultural', 'cultural difference', 'difference analysis', 'analysis national', 'national level', 'level analyze', 'analyze indian', 'indian malaysian', 'malaysian filipino', 'filipino shown', 'shown table', 'table collectively', 'collectively refer', 'refer country', 'country minority', 'minority sample', 'sample comparison', 'comparison set', 'set construct', 'construct random', 'random sample', 'sample thread', 'thread talklife', 'talklife refer', 'refer majority', 'majority sample', 'sample due', 'due relative', 'relative prevalence', 'prevalence western', 'western englishspeaking', 'englishspeaking country', 'country talklife', 'talklife thread', 'thread majority', 'majority sample', 'sample include', 'include country', 'country usa', 'usa uk', 'uk canada', 'canada indian', 'indian largest', 'largest nonwestern', 'nonwestern minority', 'minority subgroup', 'subgroup talklife', 'talklife sampled', 'sampled may', 'may june', 'june following', 'following crossnational', 'crossnational analysis', 'analysis see', 'see broader', 'broader result', 'result talklife', 'talklife generalize', 'generalize differently', 'differently structured', 'structured online', 'online community', 'community picked', 'picked largest', 'largest western', 'western country', 'country united', 'united state', 'state largest', 'largest nonwestern', 'nonwestern country', 'country india', 'india represented', 'represented cup', 'cup similar', 'similar support', 'support platform', 'platform actively', 'actively using', 'using platform', 'platform week', 'week using', 'using cup', 'cup repeat', 'repeat analysis', 'analysis testing', 'testing cultural', 'cultural difference', 'difference found', 'found talklife', 'talklife sample', 'sample analysis', 'analysis provided', 'provided sample', 'sample activity', 'activity indian', 'indian american', 'american shown', 'shown table', 'table unlike', 'unlike sample', 'sample talklife', 'talklife dataset', 'dataset random', 'random sample', 'sample upsampling', 'upsampling indian', 'indian ensure', 'ensure sufficient', 'sufficient number', 'number indian', 'indian dataset', 'dataset like', 'like talklife', 'talklife indian', 'indian largest', 'largest nonwestern', 'nonwestern minority', 'minority subgroup', 'subgroup cup', 'cup focus', 'focus indian', 'indian due', 'due lack', 'lack sufficient', 'sufficient malaysia', 'malaysia philippine', 'philippine sampled', 'sampled march', 'march august', 'august defining', 'defining cultural', 'cultural identity', 'identity use', 'use clinical', 'clinical language', 'language work', 'work examine', 'examine relationship', 'relationship cultural', 'cultural identity', 'identity use', 'use online', 'online support', 'support forum', 'forum leverage', 'leverage tomlinsons', 'tomlinsons definition', 'definition cultural', 'cultural identity', 'identity self', 'self communal', 'communal definition', 'definition based', 'based around', 'around specific', 'specific usually', 'usually politically', 'politically inflected', 'inflected differentiation', 'differentiation gender', 'gender sexuality', 'sexuality class', 'class religion', 'religion race', 'race ethnicity', 'ethnicity nationality', 'nationality particularly', 'particularly looking', 'looking aspect', 'aspect modern', 'modern cultural', 'cultural identity', 'identity run', 'run along', 'along national', 'national line', 'line delineated', 'delineated hall', 'hall et', 'et al', 'al diverse', 'diverse amorphous', 'amorphous form', 'form identity', 'identity cultural', 'cultural identity', 'identity often', 'often intersect', 'intersect interact', 'interact form', 'form identity', 'identity including', 'including religious', 'religious ethnic', 'ethnic identity', 'identity however', 'however absence', 'absence direct', 'direct information', 'information religious', 'religious ethnic', 'ethnic identity', 'identity based', 'based available', 'available use', 'use national', 'national identity', 'identity proxy', 'proxy cultural', 'cultural identity', 'identity additionally', 'additionally following', 'following schlesinger', 'schlesinger et', 'et al', 'al call', 'call intersectional', 'intersectional analysis', 'analysis method', 'method within', 'within hci', 'hci also', 'also include', 'include analysis', 'analysis adjacent', 'adjacent intersecting', 'intersecting identity', 'identity relevant', 'relevant including', 'including religious', 'religious identity', 'identity analyze', 'analyze clinical', 'clinical language', 'language use', 'use broader', 'broader definition', 'definition clinical', 'clinical language', 'language specific', 'specific medical', 'medical diagnosis', 'diagnosis following', 'following method', 'method past', 'past work', 'work analyze', 'analyze antidepressant', 'antidepressant related', 'related language', 'language create', 'create dataset', 'dataset clinical', 'clinical language', 'language including', 'including unigrams', 'unigrams bigram', 'bigram trigram', 'trigram list', 'list disorder', 'disorder defined', 'defined international', 'international classification', 'classification disease', 'disease icd', 'icd diagnostic', 'diagnostic statistical', 'statistical manual', 'manual disorder', 'disorder dsm', 'dsm also', 'also included', 'included unigrams', 'unigrams macmillan', 'macmillan dictionary', 'dictionary list', 'list describe', 'describe illness', 'illness disease', 'disease specifically', 'specifically illness', 'illness general', 'general illness', 'illness result', 'result include', 'include unigrams', 'unigrams like', 'like night', 'night night', 'night terror', 'terror sleep', 'sleep sleep', 'sleep disorder', 'disorder often', 'often correlated', 'correlated specific', 'specific symptom', 'symptom illness', 'illness distress', 'distress sleep', 'sleep issue', 'issue awake', 'awake night', 'night included', 'included clinically', 'clinically common', 'common abbreviation', 'abbreviation disorder', 'disorder ocd', 'ocd obsessive', 'obsessive compulsive', 'compulsive disorder', 'disorder bpd', 'bpd borderline', 'borderline personality', 'personality disorder', 'disorder shorthand', 'shorthand disorder', 'disorder commonly', 'commonly online', 'online community', 'community proana', 'proana proeating', 'proeating disorder', 'disorder community', 'community included', 'included due', 'due difficulty', 'difficulty finding', 'finding exhaustive', 'exhaustive list', 'list term', 'term across', 'across disorder', 'disorder choose', 'choose use', 'use term', 'term associated', 'associated dsm', 'dsm icd', 'icd categorized', 'categorized disorder', 'disorder result', 'result common', 'common usage', 'usage framework', 'framework globally', 'globally throughout', 'throughout analysis', 'analysis varied', 'varied factor', 'factor use', 'use represent', 'represent mean', 'mean represent', 'represent standard', 'standard deviation', 'deviation constraint', 'constraint limitation', 'limitation tradeoff', 'tradeoff cultural', 'cultural identity', 'identity exist', 'exist many', 'many different', 'different intersecting', 'intersecting level', 'level including', 'including subculture', 'subculture subcommunities', 'subcommunities within', 'within larger', 'larger umbrella', 'umbrella cultural', 'cultural identity', 'identity result', 'result purpose', 'purpose analysis', 'analysis adopt', 'adopt constraint', 'constraint order', 'order meaningful', 'meaningful specific', 'specific analysis', 'analysis one', 'one large', 'large limiting', 'limiting constraint', 'constraint chose', 'chose study', 'study use', 'use national', 'national identity', 'identity state', 'state level', 'level proxy', 'proxy cultural', 'cultural identity', 'identity though', 'though major', 'major formative', 'formative part', 'part modern', 'modern cultural', 'cultural identity', 'identity argued', 'argued hall', 'hall tomlinson', 'tomlinson country', 'country analyze', 'analyze incredibly', 'incredibly diverse', 'diverse many', 'many individual', 'individual cultural', 'cultural identity', 'identity intersect', 'intersect diverge', 'diverge greater', 'greater national', 'national identity', 'identity rich', 'rich analysis', 'analysis form', 'form cultural', 'cultural identity', 'identity beyond', 'beyond scope', 'scope work', 'work could', 'could lead', 'lead richer', 'richer conclusion', 'conclusion nature', 'nature cultural', 'cultural identity', 'identity online', 'online support', 'support community', 'community particularly', 'particularly regard', 'regard cultural', 'cultural difference', 'difference national', 'national identity', 'identity additionally', 'additionally stay', 'stay consistent', 'consistent analysis', 'analysis result', 'result lack', 'lack malaysia', 'malaysia philippine', 'philippine analyze', 'analyze india', 'india cup', 'cup extend', 'extend finding', 'finding experience', 'experience part', 'part minority', 'minority group', 'group online', 'online forum', 'forum draw', 'draw validity', 'validity exploratory', 'exploratory finding', 'finding similar', 'similar consistent', 'consistent pattern', 'pattern observe', 'observe indian', 'indian malaysian', 'malaysian filipino', 'filipino deeper', 'deeper analysis', 'analysis larger', 'larger dataset', 'dataset likely', 'likely necessary', 'necessary determine', 'determine minority', 'minority community', 'community conclusion', 'conclusion hold', 'hold true', 'true additionally', 'additionally construct', 'construct clinical', 'clinical language', 'language use', 'use commonly', 'commonly dsm', 'dsm icd', 'icd framework', 'framework illness', 'illness categorization', 'categorization significant', 'significant limitation', 'limitation particularly', 'particularly country', 'country selected', 'selected example', 'example disorder', 'disorder culturebound', 'culturebound well', 'well language', 'language different', 'different way', 'way within', 'within specific', 'specific country', 'country analyze', 'analyze often', 'often umbrella', 'umbrella term', 'term illness', 'illness additionally', 'additionally clear', 'clear online', 'online support', 'support community', 'community often', 'often develop', 'develop cultural', 'cultural norm', 'norm language', 'language around', 'around deeper', 'deeper understanding', 'understanding play', 'play talklife', 'talklife cup', 'cup neither', 'neither focus', 'focus within', 'within scope', 'scope work', 'work work', 'work intentionally', 'intentionally use', 'use standard', 'standard clinical', 'clinical medical', 'medical term', 'term disorder', 'disorder analysis', 'analysis clinical', 'clinical language', 'language detailed', 'detailed past', 'past anthropological', 'anthropological research', 'research theorized', 'theorized use', 'use medical', 'medical clinical', 'clinical language', 'language representative', 'representative medicalized', 'medicalized explanatory', 'explanatory model', 'model illness', 'illness frame', 'frame use', 'use language', 'language across', 'across culture', 'culture approximate', 'approximate signifier', 'signifier greater', 'greater awareness', 'awareness presence', 'presence disorder', 'disorder opposed', 'opposed conceptualizing', 'conceptualizing distress', 'distress stress', 'stress tension', 'tension analysis', 'analysis strictly', 'strictly analyzed', 'analyzed latin', 'latin alphabet', 'alphabet almost', 'almost talklife', 'talklife cup', 'cup english', 'english however', 'however malay', 'malay tagalog', 'tagalog commonly', 'commonly written', 'written latin', 'latin script', 'script since', 'since common', 'common india', 'india speaker', 'speaker use', 'use romanized', 'romanized version', 'version indian', 'indian language', 'language online', 'online possible', 'possible small', 'small minority', 'minority analysis', 'analysis text', 'text different', 'different language', 'language however', 'however confirmed', 'confirmed seeing', 'seeing english', 'english analysis', 'analysis top', 'top ngrams', 'ngrams among', 'among subgroup', 'subgroup clear', 'clear english', 'english predominant', 'predominant language', 'language platform', 'platform though', 'though beyond', 'beyond immediate', 'immediate scope', 'scope work', 'work greater', 'greater analysis', 'analysis nonenglish', 'nonenglish codeswitching', 'codeswitching platform', 'platform could', 'could lead', 'lead deeper', 'deeper understanding', 'understanding impact', 'impact interaction', 'interaction expression', 'expression national', 'national identity', 'identity different', 'different language', 'language preference']","['selection criterion scope', 'criterion scope understand', 'scope understand impact', 'understand impact cultural', 'impact cultural difference', 'cultural difference individual', 'difference individual use', 'individual use online', 'use online platform', 'online platform begin', 'platform begin analysis', 'begin analysis creating', 'analysis creating dataset', 'creating dataset different', 'dataset different national', 'different national community', 'national community talklife', 'community talklife support', 'talklife support platform', 'support platform half', 'platform half million', 'half million analysis', 'million analysis due', 'analysis due fact', 'due fact research', 'fact research cscw', 'research cscw online', 'cscw online ha', 'online ha done', 'ha done either', 'done either agnostic', 'either agnostic cultural', 'agnostic cultural context', 'cultural context western', 'context western context', 'western context choose', 'context choose focus', 'choose focus nonwestern', 'focus nonwestern country', 'nonwestern country following', 'country following zhang', 'following zhang et', 'zhang et al', 'et al researcher', 'al researcher located', 'researcher located global', 'located global south', 'global south lived', 'south lived experience', 'lived experience interacting', 'experience interacting system', 'interacting system diverse', 'system diverse explanatory', 'diverse explanatory model', 'explanatory model illness', 'model illness believe', 'illness believe moving', 'believe moving focus', 'moving focus cscw', 'focus cscw cscwadjacent', 'cscw cscwadjacent research', 'cscwadjacent research away', 'research away west', 'away west crucial', 'west crucial better', 'crucial better meet', 'better meet need', 'meet need people', 'need people often', 'people often underserved', 'often underserved medical', 'underserved medical system', 'medical system create', 'system create subgroup', 'create subgroup choose', 'subgroup choose three', 'choose three nonwestern', 'three nonwestern country', 'nonwestern country highest', 'country highest population', 'highest population talklife', 'population talklife india', 'talklife india malaysia', 'india malaysia philippine', 'malaysia philippine guided', 'philippine guided rich', 'guided rich amount', 'rich amount literature', 'amount literature unique', 'literature unique nuance', 'unique nuance expression', 'nuance expression country', 'expression country examine', 'country examine national', 'examine national identity', 'national identity linguistic', 'identity linguistic behaviorbased', 'linguistic behaviorbased difference', 'behaviorbased difference use', 'difference use subgroup', 'use subgroup particular', 'subgroup particular research', 'particular research note', 'research note result', 'note result cultural', 'result cultural norm', 'cultural norm around', 'norm around sharing', 'around sharing distress', 'sharing distress alternative', 'distress alternative conceptualization', 'alternative conceptualization illness', 'conceptualization illness india', 'illness india malaysia', 'india malaysia philippine', 'malaysia philippine symptom', 'philippine symptom often', 'symptom often expressed', 'often expressed somatic', 'expressed somatic religious', 'somatic religious term', 'religious term opposed', 'term opposed traditionally', 'opposed traditionally clinical', 'traditionally clinical psychiatric', 'clinical psychiatric term', 'psychiatric term choose', 'term choose analyze', 'choose analyze subgroup', 'analyze subgroup national', 'subgroup national level', 'national level theoretical', 'level theoretical practical', 'theoretical practical reason', 'practical reason theoretical', 'reason theoretical level', 'theoretical level past', 'level past work', 'past work medical', 'work medical anthropology', 'medical anthropology national', 'anthropology national identity', 'national identity ha', 'identity ha commonly', 'ha commonly approximate', 'commonly approximate level', 'approximate level analysis', 'level analysis cultural', 'analysis cultural identity', 'cultural identity additionally', 'identity additionally practical', 'additionally practical level', 'practical level country', 'level country determined', 'country determined using', 'determined using ip', 'using ip address', 'ip address talklife', 'address talklife shared', 'talklife shared u', 'shared u useranonymized', 'u useranonymized dataset', 'useranonymized dataset inferring', 'dataset inferring precise', 'inferring precise location', 'precise location could', 'location could potentially', 'could potentially compromise', 'potentially compromise anonymity', 'compromise anonymity discussed', 'anonymity discussed past', 'discussed past work', 'past work seem', 'work seem significant', 'seem significant value', 'significant value analysis', 'value analysis cultural', 'analysis cultural difference', 'cultural difference analysis', 'difference analysis national', 'analysis national level', 'national level analyze', 'level analyze indian', 'analyze indian malaysian', 'indian malaysian filipino', 'malaysian filipino shown', 'filipino shown table', 'shown table collectively', 'table collectively refer', 'collectively refer country', 'refer country minority', 'country minority sample', 'minority sample comparison', 'sample comparison set', 'comparison set construct', 'set construct random', 'construct random sample', 'random sample thread', 'sample thread talklife', 'thread talklife refer', 'talklife refer majority', 'refer majority sample', 'majority sample due', 'sample due relative', 'due relative prevalence', 'relative prevalence western', 'prevalence western englishspeaking', 'western englishspeaking country', 'englishspeaking country talklife', 'country talklife thread', 'talklife thread majority', 'thread majority sample', 'majority sample include', 'sample include country', 'include country usa', 'country usa uk', 'usa uk canada', 'uk canada indian', 'canada indian largest', 'indian largest nonwestern', 'largest nonwestern minority', 'nonwestern minority subgroup', 'minority subgroup talklife', 'subgroup talklife sampled', 'talklife sampled may', 'sampled may june', 'may june following', 'june following crossnational', 'following crossnational analysis', 'crossnational analysis see', 'analysis see broader', 'see broader result', 'broader result talklife', 'result talklife generalize', 'talklife generalize differently', 'generalize differently structured', 'differently structured online', 'structured online community', 'online community picked', 'community picked largest', 'picked largest western', 'largest western country', 'western country united', 'country united state', 'united state largest', 'state largest nonwestern', 'largest nonwestern country', 'nonwestern country india', 'country india represented', 'india represented cup', 'represented cup similar', 'cup similar support', 'similar support platform', 'support platform actively', 'platform actively using', 'actively using platform', 'using platform week', 'platform week using', 'week using cup', 'using cup repeat', 'cup repeat analysis', 'repeat analysis testing', 'analysis testing cultural', 'testing cultural difference', 'cultural difference found', 'difference found talklife', 'found talklife sample', 'talklife sample analysis', 'sample analysis provided', 'analysis provided sample', 'provided sample activity', 'sample activity indian', 'activity indian american', 'indian american shown', 'american shown table', 'shown table unlike', 'table unlike sample', 'unlike sample talklife', 'sample talklife dataset', 'talklife dataset random', 'dataset random sample', 'random sample upsampling', 'sample upsampling indian', 'upsampling indian ensure', 'indian ensure sufficient', 'ensure sufficient number', 'sufficient number indian', 'number indian dataset', 'indian dataset like', 'dataset like talklife', 'like talklife indian', 'talklife indian largest', 'indian largest nonwestern', 'largest nonwestern minority', 'nonwestern minority subgroup', 'minority subgroup cup', 'subgroup cup focus', 'cup focus indian', 'focus indian due', 'indian due lack', 'due lack sufficient', 'lack sufficient malaysia', 'sufficient malaysia philippine', 'malaysia philippine sampled', 'philippine sampled march', 'sampled march august', 'march august defining', 'august defining cultural', 'defining cultural identity', 'cultural identity use', 'identity use clinical', 'use clinical language', 'clinical language work', 'language work examine', 'work examine relationship', 'examine relationship cultural', 'relationship cultural identity', 'cultural identity use', 'identity use online', 'use online support', 'online support forum', 'support forum leverage', 'forum leverage tomlinsons', 'leverage tomlinsons definition', 'tomlinsons definition cultural', 'definition cultural identity', 'cultural identity self', 'identity self communal', 'self communal definition', 'communal definition based', 'definition based around', 'based around specific', 'around specific usually', 'specific usually politically', 'usually politically inflected', 'politically inflected differentiation', 'inflected differentiation gender', 'differentiation gender sexuality', 'gender sexuality class', 'sexuality class religion', 'class religion race', 'religion race ethnicity', 'race ethnicity nationality', 'ethnicity nationality particularly', 'nationality particularly looking', 'particularly looking aspect', 'looking aspect modern', 'aspect modern cultural', 'modern cultural identity', 'cultural identity run', 'identity run along', 'run along national', 'along national line', 'national line delineated', 'line delineated hall', 'delineated hall et', 'hall et al', 'et al diverse', 'al diverse amorphous', 'diverse amorphous form', 'amorphous form identity', 'form identity cultural', 'identity cultural identity', 'cultural identity often', 'identity often intersect', 'often intersect interact', 'intersect interact form', 'interact form identity', 'form identity including', 'identity including religious', 'including religious ethnic', 'religious ethnic identity', 'ethnic identity however', 'identity however absence', 'however absence direct', 'absence direct information', 'direct information religious', 'information religious ethnic', 'religious ethnic identity', 'ethnic identity based', 'identity based available', 'based available use', 'available use national', 'use national identity', 'national identity proxy', 'identity proxy cultural', 'proxy cultural identity', 'cultural identity additionally', 'identity additionally following', 'additionally following schlesinger', 'following schlesinger et', 'schlesinger et al', 'et al call', 'al call intersectional', 'call intersectional analysis', 'intersectional analysis method', 'analysis method within', 'method within hci', 'within hci also', 'hci also include', 'also include analysis', 'include analysis adjacent', 'analysis adjacent intersecting', 'adjacent intersecting identity', 'intersecting identity relevant', 'identity relevant including', 'relevant including religious', 'including religious identity', 'religious identity analyze', 'identity analyze clinical', 'analyze clinical language', 'clinical language use', 'language use broader', 'use broader definition', 'broader definition clinical', 'definition clinical language', 'clinical language specific', 'language specific medical', 'specific medical diagnosis', 'medical diagnosis following', 'diagnosis following method', 'following method past', 'method past work', 'past work analyze', 'work analyze antidepressant', 'analyze antidepressant related', 'antidepressant related language', 'related language create', 'language create dataset', 'create dataset clinical', 'dataset clinical language', 'clinical language including', 'language including unigrams', 'including unigrams bigram', 'unigrams bigram trigram', 'bigram trigram list', 'trigram list disorder', 'list disorder defined', 'disorder defined international', 'defined international classification', 'international classification disease', 'classification disease icd', 'disease icd diagnostic', 'icd diagnostic statistical', 'diagnostic statistical manual', 'statistical manual disorder', 'manual disorder dsm', 'disorder dsm also', 'dsm also included', 'also included unigrams', 'included unigrams macmillan', 'unigrams macmillan dictionary', 'macmillan dictionary list', 'dictionary list describe', 'list describe illness', 'describe illness disease', 'illness disease specifically', 'disease specifically illness', 'specifically illness general', 'illness general illness', 'general illness result', 'illness result include', 'result include unigrams', 'include unigrams like', 'unigrams like night', 'like night night', 'night night terror', 'night terror sleep', 'terror sleep sleep', 'sleep sleep disorder', 'sleep disorder often', 'disorder often correlated', 'often correlated specific', 'correlated specific symptom', 'specific symptom illness', 'symptom illness distress', 'illness distress sleep', 'distress sleep issue', 'sleep issue awake', 'issue awake night', 'awake night included', 'night included clinically', 'included clinically common', 'clinically common abbreviation', 'common abbreviation disorder', 'abbreviation disorder ocd', 'disorder ocd obsessive', 'ocd obsessive compulsive', 'obsessive compulsive disorder', 'compulsive disorder bpd', 'disorder bpd borderline', 'bpd borderline personality', 'borderline personality disorder', 'personality disorder shorthand', 'disorder shorthand disorder', 'shorthand disorder commonly', 'disorder commonly online', 'commonly online community', 'online community proana', 'community proana proeating', 'proana proeating disorder', 'proeating disorder community', 'disorder community included', 'community included due', 'included due difficulty', 'due difficulty finding', 'difficulty finding exhaustive', 'finding exhaustive list', 'exhaustive list term', 'list term across', 'term across disorder', 'across disorder choose', 'disorder choose use', 'choose use term', 'use term associated', 'term associated dsm', 'associated dsm icd', 'dsm icd categorized', 'icd categorized disorder', 'categorized disorder result', 'disorder result common', 'result common usage', 'common usage framework', 'usage framework globally', 'framework globally throughout', 'globally throughout analysis', 'throughout analysis varied', 'analysis varied factor', 'varied factor use', 'factor use represent', 'use represent mean', 'represent mean represent', 'mean represent standard', 'represent standard deviation', 'standard deviation constraint', 'deviation constraint limitation', 'constraint limitation tradeoff', 'limitation tradeoff cultural', 'tradeoff cultural identity', 'cultural identity exist', 'identity exist many', 'exist many different', 'many different intersecting', 'different intersecting level', 'intersecting level including', 'level including subculture', 'including subculture subcommunities', 'subculture subcommunities within', 'subcommunities within larger', 'within larger umbrella', 'larger umbrella cultural', 'umbrella cultural identity', 'cultural identity result', 'identity result purpose', 'result purpose analysis', 'purpose analysis adopt', 'analysis adopt constraint', 'adopt constraint order', 'constraint order meaningful', 'order meaningful specific', 'meaningful specific analysis', 'specific analysis one', 'analysis one large', 'one large limiting', 'large limiting constraint', 'limiting constraint chose', 'constraint chose study', 'chose study use', 'study use national', 'use national identity', 'national identity state', 'identity state level', 'state level proxy', 'level proxy cultural', 'proxy cultural identity', 'cultural identity though', 'identity though major', 'though major formative', 'major formative part', 'formative part modern', 'part modern cultural', 'modern cultural identity', 'cultural identity argued', 'identity argued hall', 'argued hall tomlinson', 'hall tomlinson country', 'tomlinson country analyze', 'country analyze incredibly', 'analyze incredibly diverse', 'incredibly diverse many', 'diverse many individual', 'many individual cultural', 'individual cultural identity', 'cultural identity intersect', 'identity intersect diverge', 'intersect diverge greater', 'diverge greater national', 'greater national identity', 'national identity rich', 'identity rich analysis', 'rich analysis form', 'analysis form cultural', 'form cultural identity', 'cultural identity beyond', 'identity beyond scope', 'beyond scope work', 'scope work could', 'work could lead', 'could lead richer', 'lead richer conclusion', 'richer conclusion nature', 'conclusion nature cultural', 'nature cultural identity', 'cultural identity online', 'identity online support', 'online support community', 'support community particularly', 'community particularly regard', 'particularly regard cultural', 'regard cultural difference', 'cultural difference national', 'difference national identity', 'national identity additionally', 'identity additionally stay', 'additionally stay consistent', 'stay consistent analysis', 'consistent analysis result', 'analysis result lack', 'result lack malaysia', 'lack malaysia philippine', 'malaysia philippine analyze', 'philippine analyze india', 'analyze india cup', 'india cup extend', 'cup extend finding', 'extend finding experience', 'finding experience part', 'experience part minority', 'part minority group', 'minority group online', 'group online forum', 'online forum draw', 'forum draw validity', 'draw validity exploratory', 'validity exploratory finding', 'exploratory finding similar', 'finding similar consistent', 'similar consistent pattern', 'consistent pattern observe', 'pattern observe indian', 'observe indian malaysian', 'indian malaysian filipino', 'malaysian filipino deeper', 'filipino deeper analysis', 'deeper analysis larger', 'analysis larger dataset', 'larger dataset likely', 'dataset likely necessary', 'likely necessary determine', 'necessary determine minority', 'determine minority community', 'minority community conclusion', 'community conclusion hold', 'conclusion hold true', 'hold true additionally', 'true additionally construct', 'additionally construct clinical', 'construct clinical language', 'clinical language use', 'language use commonly', 'use commonly dsm', 'commonly dsm icd', 'dsm icd framework', 'icd framework illness', 'framework illness categorization', 'illness categorization significant', 'categorization significant limitation', 'significant limitation particularly', 'limitation particularly country', 'particularly country selected', 'country selected example', 'selected example disorder', 'example disorder culturebound', 'disorder culturebound well', 'culturebound well language', 'well language different', 'language different way', 'different way within', 'way within specific', 'within specific country', 'specific country analyze', 'country analyze often', 'analyze often umbrella', 'often umbrella term', 'umbrella term illness', 'term illness additionally', 'illness additionally clear', 'additionally clear online', 'clear online support', 'online support community', 'support community often', 'community often develop', 'often develop cultural', 'develop cultural norm', 'cultural norm language', 'norm language around', 'language around deeper', 'around deeper understanding', 'deeper understanding play', 'understanding play talklife', 'play talklife cup', 'talklife cup neither', 'cup neither focus', 'neither focus within', 'focus within scope', 'within scope work', 'scope work work', 'work work intentionally', 'work intentionally use', 'intentionally use standard', 'use standard clinical', 'standard clinical medical', 'clinical medical term', 'medical term disorder', 'term disorder analysis', 'disorder analysis clinical', 'analysis clinical language', 'clinical language detailed', 'language detailed past', 'detailed past anthropological', 'past anthropological research', 'anthropological research theorized', 'research theorized use', 'theorized use medical', 'use medical clinical', 'medical clinical language', 'clinical language representative', 'language representative medicalized', 'representative medicalized explanatory', 'medicalized explanatory model', 'explanatory model illness', 'model illness frame', 'illness frame use', 'frame use language', 'use language across', 'language across culture', 'across culture approximate', 'culture approximate signifier', 'approximate signifier greater', 'signifier greater awareness', 'greater awareness presence', 'awareness presence disorder', 'presence disorder opposed', 'disorder opposed conceptualizing', 'opposed conceptualizing distress', 'conceptualizing distress stress', 'distress stress tension', 'stress tension analysis', 'tension analysis strictly', 'analysis strictly analyzed', 'strictly analyzed latin', 'analyzed latin alphabet', 'latin alphabet almost', 'alphabet almost talklife', 'almost talklife cup', 'talklife cup english', 'cup english however', 'english however malay', 'however malay tagalog', 'malay tagalog commonly', 'tagalog commonly written', 'commonly written latin', 'written latin script', 'latin script since', 'script since common', 'since common india', 'common india speaker', 'india speaker use', 'speaker use romanized', 'use romanized version', 'romanized version indian', 'version indian language', 'indian language online', 'language online possible', 'online possible small', 'possible small minority', 'small minority analysis', 'minority analysis text', 'analysis text different', 'text different language', 'different language however', 'language however confirmed', 'however confirmed seeing', 'confirmed seeing english', 'seeing english analysis', 'english analysis top', 'analysis top ngrams', 'top ngrams among', 'ngrams among subgroup', 'among subgroup clear', 'subgroup clear english', 'clear english predominant', 'english predominant language', 'predominant language platform', 'language platform though', 'platform though beyond', 'though beyond immediate', 'beyond immediate scope', 'immediate scope work', 'scope work greater', 'work greater analysis', 'greater analysis nonenglish', 'analysis nonenglish codeswitching', 'nonenglish codeswitching platform', 'codeswitching platform could', 'platform could lead', 'could lead deeper', 'lead deeper understanding', 'deeper understanding impact', 'understanding impact interaction', 'impact interaction expression', 'interaction expression national', 'expression national identity', 'national identity different', 'identity different language', 'different language preference']"
https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-018-2197-z,1,In this section we first present the data gathered and used in our analysis. Researchers interested in the code and the data are invited to contact the authors. Reddit is a website which enables users to aggregate rate and discuss news entertainment politics and many other topics. According to Alexa it is the 8th most popular website in the world. It was estimated by the Pew research center that 6% of online adults use Reddit [26]. The site is organized into a collection of “subreddits” each focused on a particular topic and administered by a collection of moderators. The subreddit r/SuicideWatch is a forum in which online users are encouraged to post their thoughts regarding suicide. At the time of our data collection it had over 58000 subscribers. Sometimes users express a preoccupation with the thought of suicide. Other times users discuss immediate plans to take their own life. These posts often contain a description of their mental state including depression reaction to stress their feelings of being alone and having a low self-esteem. While most online sources of data are notoriously noisy this particular subreddit is remarkably clean. Given the serious nature of the subreddit individuals are less likely to post harassing comments or off-topic remarks. When users post such comments the moderators of the subreddit quickly remove them. We collected all posts from its inception in 2008 to 2016. Each post is often commented on by other individuals. In this work we focused on the original post as it most often represents the suicidal ideation of a user and comments often represent emotional support from other users. We cleaned this data. First we removed empty posts in which the content had been deleted. Second we removed links and replaced them with the word “link”. Third we concatenated the text of the post to the title as many users begin their post in the title and continue in the body of the post. Finally we removed punctuation and other special characters. After cleaning this data we had 131728 posts with 27978246 words of which 84607 words were unique posted by 63252 unique users.,in this section we first present the data gathered and used in our analysis researcher interested in the code and the data are invited to contact the author reddit is a website which enables user to aggregate rate and discus news entertainment politics and many other topic according to alexa it is the th most popular website in the world it wa estimated by the pew research center that of online adult use reddit the site is organized into a collection of subreddits each focused on a particular topic and administered by a collection of moderator the subreddit rsuicidewatch is a forum in which online user are encouraged to post their thought regarding suicide at the time of our data collection it had over subscriber sometimes user express a preoccupation with the thought of suicide other time user discus immediate plan to take their own life these post often contain a description of their mental state including depression reaction to stress their feeling of being alone and having a low selfesteem while most online source of data are notoriously noisy this particular subreddit is remarkably clean given the serious nature of the subreddit individual are le likely to post harassing comment or offtopic remark when user post such comment the moderator of the subreddit quickly remove them we collected all post from it inception in to each post is often commented on by other individual in this work we focused on the original post a it most often represents the suicidal ideation of a user and comment often represent emotional support from other user we cleaned this data first we removed empty post in which the content had been deleted second we removed link and replaced them with the word link third we concatenated the text of the post to the title a many user begin their post in the title and continue in the body of the post finally we removed punctuation and other special character after cleaning this data we had post with word of which word were unique posted by unique user,"['section', 'first', 'present', 'gathered', 'analysis', 'researcher', 'interested', 'code', 'invited', 'contact', 'author', 'reddit', 'website', 'enables', 'aggregate', 'rate', 'discus', 'news', 'entertainment', 'politics', 'many', 'topic', 'according', 'alexa', 'th', 'popular', 'website', 'world', 'estimated', 'pew', 'research', 'center', 'online', 'adult', 'use', 'reddit', 'site', 'organized', 'collection', 'subreddits', 'focused', 'particular', 'topic', 'administered', 'collection', 'moderator', 'subreddit', 'rsuicidewatch', 'forum', 'online', 'encouraged', 'thought', 'regarding', 'suicide', 'time', 'collection', 'subscriber', 'sometimes', 'express', 'preoccupation', 'thought', 'suicide', 'time', 'discus', 'immediate', 'plan', 'take', 'life', 'often', 'contain', 'description', 'state', 'including', 'reaction', 'stress', 'feeling', 'alone', 'low', 'selfesteem', 'online', 'source', 'notoriously', 'noisy', 'particular', 'subreddit', 'remarkably', 'clean', 'given', 'serious', 'nature', 'subreddit', 'individual', 'le', 'likely', 'harassing', 'comment', 'offtopic', 'remark', 'comment', 'moderator', 'subreddit', 'quickly', 'remove', 'collected', 'inception', 'often', 'commented', 'individual', 'work', 'focused', 'original', 'often', 'represents', 'suicidal', 'ideation', 'comment', 'often', 'represent', 'emotional', 'support', 'cleaned', 'first', 'removed', 'empty', 'content', 'deleted', 'second', 'removed', 'link', 'replaced', 'link', 'third', 'concatenated', 'text', 'title', 'many', 'begin', 'title', 'continue', 'body', 'finally', 'removed', 'punctuation', 'special', 'character', 'cleaning', 'unique', 'posted', 'unique']","['section first', 'first present', 'present gathered', 'gathered analysis', 'analysis researcher', 'researcher interested', 'interested code', 'code invited', 'invited contact', 'contact author', 'author reddit', 'reddit website', 'website enables', 'enables aggregate', 'aggregate rate', 'rate discus', 'discus news', 'news entertainment', 'entertainment politics', 'politics many', 'many topic', 'topic according', 'according alexa', 'alexa th', 'th popular', 'popular website', 'website world', 'world estimated', 'estimated pew', 'pew research', 'research center', 'center online', 'online adult', 'adult use', 'use reddit', 'reddit site', 'site organized', 'organized collection', 'collection subreddits', 'subreddits focused', 'focused particular', 'particular topic', 'topic administered', 'administered collection', 'collection moderator', 'moderator subreddit', 'subreddit rsuicidewatch', 'rsuicidewatch forum', 'forum online', 'online encouraged', 'encouraged thought', 'thought regarding', 'regarding suicide', 'suicide time', 'time collection', 'collection subscriber', 'subscriber sometimes', 'sometimes express', 'express preoccupation', 'preoccupation thought', 'thought suicide', 'suicide time', 'time discus', 'discus immediate', 'immediate plan', 'plan take', 'take life', 'life often', 'often contain', 'contain description', 'description state', 'state including', 'including reaction', 'reaction stress', 'stress feeling', 'feeling alone', 'alone low', 'low selfesteem', 'selfesteem online', 'online source', 'source notoriously', 'notoriously noisy', 'noisy particular', 'particular subreddit', 'subreddit remarkably', 'remarkably clean', 'clean given', 'given serious', 'serious nature', 'nature subreddit', 'subreddit individual', 'individual le', 'le likely', 'likely harassing', 'harassing comment', 'comment offtopic', 'offtopic remark', 'remark comment', 'comment moderator', 'moderator subreddit', 'subreddit quickly', 'quickly remove', 'remove collected', 'collected inception', 'inception often', 'often commented', 'commented individual', 'individual work', 'work focused', 'focused original', 'original often', 'often represents', 'represents suicidal', 'suicidal ideation', 'ideation comment', 'comment often', 'often represent', 'represent emotional', 'emotional support', 'support cleaned', 'cleaned first', 'first removed', 'removed empty', 'empty content', 'content deleted', 'deleted second', 'second removed', 'removed link', 'link replaced', 'replaced link', 'link third', 'third concatenated', 'concatenated text', 'text title', 'title many', 'many begin', 'begin title', 'title continue', 'continue body', 'body finally', 'finally removed', 'removed punctuation', 'punctuation special', 'special character', 'character cleaning', 'cleaning unique', 'unique posted', 'posted unique']","['section first present', 'first present gathered', 'present gathered analysis', 'gathered analysis researcher', 'analysis researcher interested', 'researcher interested code', 'interested code invited', 'code invited contact', 'invited contact author', 'contact author reddit', 'author reddit website', 'reddit website enables', 'website enables aggregate', 'enables aggregate rate', 'aggregate rate discus', 'rate discus news', 'discus news entertainment', 'news entertainment politics', 'entertainment politics many', 'politics many topic', 'many topic according', 'topic according alexa', 'according alexa th', 'alexa th popular', 'th popular website', 'popular website world', 'website world estimated', 'world estimated pew', 'estimated pew research', 'pew research center', 'research center online', 'center online adult', 'online adult use', 'adult use reddit', 'use reddit site', 'reddit site organized', 'site organized collection', 'organized collection subreddits', 'collection subreddits focused', 'subreddits focused particular', 'focused particular topic', 'particular topic administered', 'topic administered collection', 'administered collection moderator', 'collection moderator subreddit', 'moderator subreddit rsuicidewatch', 'subreddit rsuicidewatch forum', 'rsuicidewatch forum online', 'forum online encouraged', 'online encouraged thought', 'encouraged thought regarding', 'thought regarding suicide', 'regarding suicide time', 'suicide time collection', 'time collection subscriber', 'collection subscriber sometimes', 'subscriber sometimes express', 'sometimes express preoccupation', 'express preoccupation thought', 'preoccupation thought suicide', 'thought suicide time', 'suicide time discus', 'time discus immediate', 'discus immediate plan', 'immediate plan take', 'plan take life', 'take life often', 'life often contain', 'often contain description', 'contain description state', 'description state including', 'state including reaction', 'including reaction stress', 'reaction stress feeling', 'stress feeling alone', 'feeling alone low', 'alone low selfesteem', 'low selfesteem online', 'selfesteem online source', 'online source notoriously', 'source notoriously noisy', 'notoriously noisy particular', 'noisy particular subreddit', 'particular subreddit remarkably', 'subreddit remarkably clean', 'remarkably clean given', 'clean given serious', 'given serious nature', 'serious nature subreddit', 'nature subreddit individual', 'subreddit individual le', 'individual le likely', 'le likely harassing', 'likely harassing comment', 'harassing comment offtopic', 'comment offtopic remark', 'offtopic remark comment', 'remark comment moderator', 'comment moderator subreddit', 'moderator subreddit quickly', 'subreddit quickly remove', 'quickly remove collected', 'remove collected inception', 'collected inception often', 'inception often commented', 'often commented individual', 'commented individual work', 'individual work focused', 'work focused original', 'focused original often', 'original often represents', 'often represents suicidal', 'represents suicidal ideation', 'suicidal ideation comment', 'ideation comment often', 'comment often represent', 'often represent emotional', 'represent emotional support', 'emotional support cleaned', 'support cleaned first', 'cleaned first removed', 'first removed empty', 'removed empty content', 'empty content deleted', 'content deleted second', 'deleted second removed', 'second removed link', 'removed link replaced', 'link replaced link', 'replaced link third', 'link third concatenated', 'third concatenated text', 'concatenated text title', 'text title many', 'title many begin', 'many begin title', 'begin title continue', 'title continue body', 'continue body finally', 'body finally removed', 'finally removed punctuation', 'removed punctuation special', 'punctuation special character', 'special character cleaning', 'character cleaning unique', 'cleaning unique posted', 'unique posted unique']"
https://ieeexplore.ieee.org/abstract/document/8609647,1,RMN is a recursive neural network designed to model relationships between pairs of entities from text [13]. Each relationship is represented at a given point in time as a vector of weights over K descriptors. Entities that form a relationship do not need to be of the same class: for example in this work we model the relationships between a user and the community in which she interacts. Each post or comment corresponds to a different instant. Words are represented as embeddings of dimension P that is each word w of a vocabulary V is a vector in RP. Users and communities are represented by embeddings of dimension U and C respectively. As in previous works we generated embeddings using GloVe [15]. The descriptors obtained from RMN are vectors in RP allowing us to find the closest words to each descriptor. The post's (or comment's) representation is denoted by vpost∈RP. This vector is the average of the word embeddings contained in the post. The representations of users and communities are denoted by vuser and vcomm. For each post or comment RMN takes as input a vector v∈RP+U+C obtained by concatenating vpostvuser and vcomm. These vectors are combined through the weights of the neural network to obtain a representation dt∈RK of the relationship between the user and the community at that particular time. RMN uses a smoothing parameter α∈(01) to avoid abrupt changes in the representation of the same relation in consecutive instants dt and dt−1. The descriptor array R∈RK×P is used for attempting to reconstruct the post vpost by making rt=R⊤dt. RMN parameters (weights and matrix of descriptors) are trained in order to maximize an objective function that aims to approximate rt and vpost while retaining some distance between rt and other randomly sampled posts. See [13] for more details on RMN. The input data for RMN was preprocessed as follows. First we removed all posts and comments marked as [deleted} or [removed] standard stop-words (using the NLTK library) punctuation and accents. Second for each subreddit we removed posts and comments from users who performed less than 50 activities (posts or comments) following the methodology presented in [16]. Finally we selected the words that appear at least once in each of the four subreddits analyzed seeking to find similarities in the way people express themselves when discussing mental health disorders. The final subset of data analyzed by RMN is composed of 18020 unique words 25101 posts and 401428 comments.,rmn is a recursive neural network designed to model relationship between pair of entity from text each relationship is represented at a given point in time a a vector of weight over k descriptor entity that form a relationship do not need to be of the same class for example in this work we model the relationship between a user and the community in which she interacts each post or comment corresponds to a different instant word are represented a embeddings of dimension p that is each word w of a vocabulary v is a vector in rp user and community are represented by embeddings of dimension u and c respectively a in previous work we generated embeddings using glove the descriptor obtained from rmn are vector in rp allowing u to find the closest word to each descriptor the post or comment representation is denoted by vpostrp this vector is the average of the word embeddings contained in the post the representation of user and community are denoted by vuser and vcomm for each post or comment rmn take a input a vector vrpuc obtained by concatenating vpostvuser and vcomm these vector are combined through the weight of the neural network to obtain a representation dtrk of the relationship between the user and the community at that particular time rmn us a smoothing parameter to avoid abrupt change in the representation of the same relation in consecutive instant dt and dt the descriptor array rrkp is used for attempting to reconstruct the post vpost by making rtrdt rmn parameter weight and matrix of descriptor are trained in order to maximize an objective function that aim to approximate rt and vpost while retaining some distance between rt and other randomly sampled post see for more detail on rmn the input data for rmn wa preprocessed a follows first we removed all post and comment marked a deleted or removed standard stopwords using the nltk library punctuation and accent second for each subreddit we removed post and comment from user who performed le than activity post or comment following the methodology presented in finally we selected the word that appear at least once in each of the four subreddits analyzed seeking to find similarity in the way people express themselves when discussing mental health disorder the final subset of data analyzed by rmn is composed of unique word post and comment,"['rmn', 'recursive', 'neural', 'network', 'designed', 'model', 'relationship', 'pair', 'entity', 'text', 'relationship', 'represented', 'given', 'point', 'time', 'vector', 'weight', 'k', 'descriptor', 'entity', 'form', 'relationship', 'need', 'class', 'example', 'work', 'model', 'relationship', 'community', 'interacts', 'comment', 'corresponds', 'different', 'instant', 'represented', 'embeddings', 'dimension', 'p', 'w', 'vocabulary', 'v', 'vector', 'rp', 'community', 'represented', 'embeddings', 'dimension', 'u', 'c', 'respectively', 'previous', 'work', 'generated', 'embeddings', 'using', 'glove', 'descriptor', 'obtained', 'rmn', 'vector', 'rp', 'allowing', 'u', 'find', 'closest', 'descriptor', 'comment', 'representation', 'denoted', 'vpostrp', 'vector', 'average', 'embeddings', 'contained', 'representation', 'community', 'denoted', 'vuser', 'vcomm', 'comment', 'rmn', 'take', 'input', 'vector', 'vrpuc', 'obtained', 'concatenating', 'vpostvuser', 'vcomm', 'vector', 'combined', 'weight', 'neural', 'network', 'obtain', 'representation', 'dtrk', 'relationship', 'community', 'particular', 'time', 'rmn', 'us', 'smoothing', 'parameter', 'avoid', 'abrupt', 'change', 'representation', 'relation', 'consecutive', 'instant', 'dt', 'dt', 'descriptor', 'array', 'rrkp', 'attempting', 'reconstruct', 'vpost', 'making', 'rtrdt', 'rmn', 'parameter', 'weight', 'matrix', 'descriptor', 'trained', 'order', 'maximize', 'objective', 'function', 'aim', 'approximate', 'rt', 'vpost', 'retaining', 'distance', 'rt', 'randomly', 'sampled', 'see', 'detail', 'rmn', 'input', 'rmn', 'preprocessed', 'follows', 'first', 'removed', 'comment', 'marked', 'deleted', 'removed', 'standard', 'stopwords', 'using', 'nltk', 'library', 'punctuation', 'accent', 'second', 'subreddit', 'removed', 'comment', 'performed', 'le', 'activity', 'comment', 'following', 'methodology', 'presented', 'finally', 'selected', 'appear', 'least', 'four', 'subreddits', 'analyzed', 'seeking', 'find', 'similarity', 'way', 'people', 'express', 'discussing', 'disorder', 'final', 'subset', 'analyzed', 'rmn', 'composed', 'unique', 'comment']","['rmn recursive', 'recursive neural', 'neural network', 'network designed', 'designed model', 'model relationship', 'relationship pair', 'pair entity', 'entity text', 'text relationship', 'relationship represented', 'represented given', 'given point', 'point time', 'time vector', 'vector weight', 'weight k', 'k descriptor', 'descriptor entity', 'entity form', 'form relationship', 'relationship need', 'need class', 'class example', 'example work', 'work model', 'model relationship', 'relationship community', 'community interacts', 'interacts comment', 'comment corresponds', 'corresponds different', 'different instant', 'instant represented', 'represented embeddings', 'embeddings dimension', 'dimension p', 'p w', 'w vocabulary', 'vocabulary v', 'v vector', 'vector rp', 'rp community', 'community represented', 'represented embeddings', 'embeddings dimension', 'dimension u', 'u c', 'c respectively', 'respectively previous', 'previous work', 'work generated', 'generated embeddings', 'embeddings using', 'using glove', 'glove descriptor', 'descriptor obtained', 'obtained rmn', 'rmn vector', 'vector rp', 'rp allowing', 'allowing u', 'u find', 'find closest', 'closest descriptor', 'descriptor comment', 'comment representation', 'representation denoted', 'denoted vpostrp', 'vpostrp vector', 'vector average', 'average embeddings', 'embeddings contained', 'contained representation', 'representation community', 'community denoted', 'denoted vuser', 'vuser vcomm', 'vcomm comment', 'comment rmn', 'rmn take', 'take input', 'input vector', 'vector vrpuc', 'vrpuc obtained', 'obtained concatenating', 'concatenating vpostvuser', 'vpostvuser vcomm', 'vcomm vector', 'vector combined', 'combined weight', 'weight neural', 'neural network', 'network obtain', 'obtain representation', 'representation dtrk', 'dtrk relationship', 'relationship community', 'community particular', 'particular time', 'time rmn', 'rmn us', 'us smoothing', 'smoothing parameter', 'parameter avoid', 'avoid abrupt', 'abrupt change', 'change representation', 'representation relation', 'relation consecutive', 'consecutive instant', 'instant dt', 'dt dt', 'dt descriptor', 'descriptor array', 'array rrkp', 'rrkp attempting', 'attempting reconstruct', 'reconstruct vpost', 'vpost making', 'making rtrdt', 'rtrdt rmn', 'rmn parameter', 'parameter weight', 'weight matrix', 'matrix descriptor', 'descriptor trained', 'trained order', 'order maximize', 'maximize objective', 'objective function', 'function aim', 'aim approximate', 'approximate rt', 'rt vpost', 'vpost retaining', 'retaining distance', 'distance rt', 'rt randomly', 'randomly sampled', 'sampled see', 'see detail', 'detail rmn', 'rmn input', 'input rmn', 'rmn preprocessed', 'preprocessed follows', 'follows first', 'first removed', 'removed comment', 'comment marked', 'marked deleted', 'deleted removed', 'removed standard', 'standard stopwords', 'stopwords using', 'using nltk', 'nltk library', 'library punctuation', 'punctuation accent', 'accent second', 'second subreddit', 'subreddit removed', 'removed comment', 'comment performed', 'performed le', 'le activity', 'activity comment', 'comment following', 'following methodology', 'methodology presented', 'presented finally', 'finally selected', 'selected appear', 'appear least', 'least four', 'four subreddits', 'subreddits analyzed', 'analyzed seeking', 'seeking find', 'find similarity', 'similarity way', 'way people', 'people express', 'express discussing', 'discussing disorder', 'disorder final', 'final subset', 'subset analyzed', 'analyzed rmn', 'rmn composed', 'composed unique', 'unique comment']","['rmn recursive neural', 'recursive neural network', 'neural network designed', 'network designed model', 'designed model relationship', 'model relationship pair', 'relationship pair entity', 'pair entity text', 'entity text relationship', 'text relationship represented', 'relationship represented given', 'represented given point', 'given point time', 'point time vector', 'time vector weight', 'vector weight k', 'weight k descriptor', 'k descriptor entity', 'descriptor entity form', 'entity form relationship', 'form relationship need', 'relationship need class', 'need class example', 'class example work', 'example work model', 'work model relationship', 'model relationship community', 'relationship community interacts', 'community interacts comment', 'interacts comment corresponds', 'comment corresponds different', 'corresponds different instant', 'different instant represented', 'instant represented embeddings', 'represented embeddings dimension', 'embeddings dimension p', 'dimension p w', 'p w vocabulary', 'w vocabulary v', 'vocabulary v vector', 'v vector rp', 'vector rp community', 'rp community represented', 'community represented embeddings', 'represented embeddings dimension', 'embeddings dimension u', 'dimension u c', 'u c respectively', 'c respectively previous', 'respectively previous work', 'previous work generated', 'work generated embeddings', 'generated embeddings using', 'embeddings using glove', 'using glove descriptor', 'glove descriptor obtained', 'descriptor obtained rmn', 'obtained rmn vector', 'rmn vector rp', 'vector rp allowing', 'rp allowing u', 'allowing u find', 'u find closest', 'find closest descriptor', 'closest descriptor comment', 'descriptor comment representation', 'comment representation denoted', 'representation denoted vpostrp', 'denoted vpostrp vector', 'vpostrp vector average', 'vector average embeddings', 'average embeddings contained', 'embeddings contained representation', 'contained representation community', 'representation community denoted', 'community denoted vuser', 'denoted vuser vcomm', 'vuser vcomm comment', 'vcomm comment rmn', 'comment rmn take', 'rmn take input', 'take input vector', 'input vector vrpuc', 'vector vrpuc obtained', 'vrpuc obtained concatenating', 'obtained concatenating vpostvuser', 'concatenating vpostvuser vcomm', 'vpostvuser vcomm vector', 'vcomm vector combined', 'vector combined weight', 'combined weight neural', 'weight neural network', 'neural network obtain', 'network obtain representation', 'obtain representation dtrk', 'representation dtrk relationship', 'dtrk relationship community', 'relationship community particular', 'community particular time', 'particular time rmn', 'time rmn us', 'rmn us smoothing', 'us smoothing parameter', 'smoothing parameter avoid', 'parameter avoid abrupt', 'avoid abrupt change', 'abrupt change representation', 'change representation relation', 'representation relation consecutive', 'relation consecutive instant', 'consecutive instant dt', 'instant dt dt', 'dt dt descriptor', 'dt descriptor array', 'descriptor array rrkp', 'array rrkp attempting', 'rrkp attempting reconstruct', 'attempting reconstruct vpost', 'reconstruct vpost making', 'vpost making rtrdt', 'making rtrdt rmn', 'rtrdt rmn parameter', 'rmn parameter weight', 'parameter weight matrix', 'weight matrix descriptor', 'matrix descriptor trained', 'descriptor trained order', 'trained order maximize', 'order maximize objective', 'maximize objective function', 'objective function aim', 'function aim approximate', 'aim approximate rt', 'approximate rt vpost', 'rt vpost retaining', 'vpost retaining distance', 'retaining distance rt', 'distance rt randomly', 'rt randomly sampled', 'randomly sampled see', 'sampled see detail', 'see detail rmn', 'detail rmn input', 'rmn input rmn', 'input rmn preprocessed', 'rmn preprocessed follows', 'preprocessed follows first', 'follows first removed', 'first removed comment', 'removed comment marked', 'comment marked deleted', 'marked deleted removed', 'deleted removed standard', 'removed standard stopwords', 'standard stopwords using', 'stopwords using nltk', 'using nltk library', 'nltk library punctuation', 'library punctuation accent', 'punctuation accent second', 'accent second subreddit', 'second subreddit removed', 'subreddit removed comment', 'removed comment performed', 'comment performed le', 'performed le activity', 'le activity comment', 'activity comment following', 'comment following methodology', 'following methodology presented', 'methodology presented finally', 'presented finally selected', 'finally selected appear', 'selected appear least', 'appear least four', 'least four subreddits', 'four subreddits analyzed', 'subreddits analyzed seeking', 'analyzed seeking find', 'seeking find similarity', 'find similarity way', 'similarity way people', 'way people express', 'people express discussing', 'express discussing disorder', 'discussing disorder final', 'disorder final subset', 'final subset analyzed', 'subset analyzed rmn', 'analyzed rmn composed', 'rmn composed unique', 'composed unique comment']"
