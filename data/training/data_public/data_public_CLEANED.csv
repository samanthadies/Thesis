Link to paper,Score,Text,Cleaned,unigrams,bigrams,trigrams
https://link.springer.com/content/pdf/10.1140/epjds/s13688-017-0110-z.pdf,0,Data collection was crowdsourced using Amazon’s Mechanical Turk (MTurk) crowdwork platform. Separate surveys were created for depressed and healthy individuals. In the depressed survey participants were invited to complete a survey that involved passing a series of inclusion criteria responding to a standardized clinical depression survey answering questions related to demographics and history of depression and sharing social media history. We used the CES-D (Center for Epidemiologic Studies Depression Scale) questionnaire to screen participant depression levels []. CES-D assessment quality has been demonstrated as on-par with other depression inventories including the Beck Depression Inventory and the Kellner Symptom Questionnaire [ ]. Healthy participants were screened to ensure no history of depression and active Instagram use. See Additional file  for actual survey text. Qualified participants were asked to share their Instagram usernames and history. An app embedded in the survey allowed participants to securely log into their Instagram accounts and agree to share their data.b Upon securing consent we made a one-time collection of participants’ entire Instagram posting history. In total we collected  photographs from  Instagram users  of whom had a history of depression. We asked a different set of MTurk crowdworkers to rate the Instagram photographs collected. This new task asked participants to rate a random selection of  photos from the data we collected. Raters were asked to judge how interesting likable happy and sad each photo seemed on a continuous - scale. Each photo was rated by at least three different raters and ratings were averaged across raters. Raters were not informed that photos were from Instagram nor were they given any information about the study participants who provided the photos including mental health status. Each ratings category showed good inter-rater agreement. Only a subset of participant Instagram photos were rated (N = ). We limited ratings data to a subset because this task was time-consuming for crowdworkers and so proved a costly form of data collection. For the depressed sample ratings were only made for photos posted within a year in either direction of the date of first depression diagnosis. Within this subset for each user the nearest  posts prior to the diagnosis date were rated. For the control population the most recent  photos from each user’s date of participation in this study were rated.,data collection wa crowdsourced using amazon mechanical turk mturk crowdwork platform separate survey were created for depressed and healthy individual in the depressed survey participant were invited to complete a survey that involved passing a series of inclusion criterion responding to a standardized clinical depression survey answering question related to demographic and history of depression and sharing social medium history we used the cesd center for epidemiologic study depression scale questionnaire to screen participant depression level cesd assessment quality ha been demonstrated a onpar with other depression inventory including the beck depression inventory and the kellner symptom questionnaire healthy participant were screened to ensure no history of depression and active instagram use see additional file for actual survey text qualified participant were asked to share their instagram usernames and history an app embedded in the survey allowed participant to securely log into their instagram account and agree to share their datab upon securing consent we made a onetime collection of participant entire instagram posting history in total we collected photograph from instagram user of whom had a history of depression we asked a different set of mturk crowdworkers to rate the instagram photograph collected this new task asked participant to rate a random selection of photo from the data we collected raters were asked to judge how interesting likable happy and sad each photo seemed on a continuous scale each photo wa rated by at least three different raters and rating were averaged across raters raters were not informed that photo were from instagram nor were they given any information about the study participant who provided the photo including mental health status each rating category showed good interrater agreement only a subset of participant instagram photo were rated n we limited rating data to a subset because this task wa timeconsuming for crowdworkers and so proved a costly form of data collection for the depressed sample rating were only made for photo posted within a year in either direction of the date of first depression diagnosis within this subset for each user the nearest post prior to the diagnosis date were rated for the control population the most recent photo from each user date of participation in this study were rated,"['collection', 'crowdsourced', 'using', 'amazon', 'mechanical', 'turk', 'mturk', 'crowdwork', 'platform', 'separate', 'survey', 'created', 'depressed', 'healthy', 'individual', 'depressed', 'survey', 'participant', 'invited', 'complete', 'survey', 'involved', 'passing', 'series', 'inclusion', 'criterion', 'responding', 'standardized', 'clinical', 'survey', 'answering', 'question', 'related', 'demographic', 'history', 'sharing', 'social', 'medium', 'history', 'cesd', 'center', 'epidemiologic', 'study', 'scale', 'questionnaire', 'screen', 'participant', 'level', 'cesd', 'assessment', 'quality', 'ha', 'demonstrated', 'onpar', 'inventory', 'including', 'beck', 'inventory', 'kellner', 'symptom', 'questionnaire', 'healthy', 'participant', 'screened', 'ensure', 'history', 'active', 'instagram', 'use', 'see', 'additional', 'file', 'actual', 'survey', 'text', 'qualified', 'participant', 'asked', 'share', 'instagram', 'usernames', 'history', 'app', 'embedded', 'survey', 'allowed', 'participant', 'securely', 'log', 'instagram', 'account', 'agree', 'share', 'datab', 'upon', 'securing', 'consent', 'made', 'onetime', 'collection', 'participant', 'entire', 'instagram', 'posting', 'history', 'total', 'collected', 'photograph', 'instagram', 'history', 'asked', 'different', 'set', 'mturk', 'crowdworkers', 'rate', 'instagram', 'photograph', 'collected', 'new', 'task', 'asked', 'participant', 'rate', 'random', 'selection', 'photo', 'collected', 'raters', 'asked', 'judge', 'interesting', 'likable', 'happy', 'sad', 'photo', 'seemed', 'continuous', 'scale', 'photo', 'rated', 'least', 'three', 'different', 'raters', 'rating', 'averaged', 'across', 'raters', 'raters', 'informed', 'photo', 'instagram', 'given', 'information', 'study', 'participant', 'provided', 'photo', 'including', 'status', 'rating', 'category', 'showed', 'good', 'interrater', 'agreement', 'subset', 'participant', 'instagram', 'photo', 'rated', 'n', 'limited', 'rating', 'subset', 'task', 'timeconsuming', 'crowdworkers', 'proved', 'costly', 'form', 'collection', 'depressed', 'sample', 'rating', 'made', 'photo', 'posted', 'within', 'year', 'either', 'direction', 'date', 'first', 'diagnosis', 'within', 'subset', 'nearest', 'prior', 'diagnosis', 'date', 'rated', 'control', 'population', 'recent', 'photo', 'date', 'participation', 'study', 'rated']","['collection crowdsourced', 'crowdsourced using', 'using amazon', 'amazon mechanical', 'mechanical turk', 'turk mturk', 'mturk crowdwork', 'crowdwork platform', 'platform separate', 'separate survey', 'survey created', 'created depressed', 'depressed healthy', 'healthy individual', 'individual depressed', 'depressed survey', 'survey participant', 'participant invited', 'invited complete', 'complete survey', 'survey involved', 'involved passing', 'passing series', 'series inclusion', 'inclusion criterion', 'criterion responding', 'responding standardized', 'standardized clinical', 'clinical survey', 'survey answering', 'answering question', 'question related', 'related demographic', 'demographic history', 'history sharing', 'sharing social', 'social medium', 'medium history', 'history cesd', 'cesd center', 'center epidemiologic', 'epidemiologic study', 'study scale', 'scale questionnaire', 'questionnaire screen', 'screen participant', 'participant level', 'level cesd', 'cesd assessment', 'assessment quality', 'quality ha', 'ha demonstrated', 'demonstrated onpar', 'onpar inventory', 'inventory including', 'including beck', 'beck inventory', 'inventory kellner', 'kellner symptom', 'symptom questionnaire', 'questionnaire healthy', 'healthy participant', 'participant screened', 'screened ensure', 'ensure history', 'history active', 'active instagram', 'instagram use', 'use see', 'see additional', 'additional file', 'file actual', 'actual survey', 'survey text', 'text qualified', 'qualified participant', 'participant asked', 'asked share', 'share instagram', 'instagram usernames', 'usernames history', 'history app', 'app embedded', 'embedded survey', 'survey allowed', 'allowed participant', 'participant securely', 'securely log', 'log instagram', 'instagram account', 'account agree', 'agree share', 'share datab', 'datab upon', 'upon securing', 'securing consent', 'consent made', 'made onetime', 'onetime collection', 'collection participant', 'participant entire', 'entire instagram', 'instagram posting', 'posting history', 'history total', 'total collected', 'collected photograph', 'photograph instagram', 'instagram history', 'history asked', 'asked different', 'different set', 'set mturk', 'mturk crowdworkers', 'crowdworkers rate', 'rate instagram', 'instagram photograph', 'photograph collected', 'collected new', 'new task', 'task asked', 'asked participant', 'participant rate', 'rate random', 'random selection', 'selection photo', 'photo collected', 'collected raters', 'raters asked', 'asked judge', 'judge interesting', 'interesting likable', 'likable happy', 'happy sad', 'sad photo', 'photo seemed', 'seemed continuous', 'continuous scale', 'scale photo', 'photo rated', 'rated least', 'least three', 'three different', 'different raters', 'raters rating', 'rating averaged', 'averaged across', 'across raters', 'raters raters', 'raters informed', 'informed photo', 'photo instagram', 'instagram given', 'given information', 'information study', 'study participant', 'participant provided', 'provided photo', 'photo including', 'including status', 'status rating', 'rating category', 'category showed', 'showed good', 'good interrater', 'interrater agreement', 'agreement subset', 'subset participant', 'participant instagram', 'instagram photo', 'photo rated', 'rated n', 'n limited', 'limited rating', 'rating subset', 'subset task', 'task timeconsuming', 'timeconsuming crowdworkers', 'crowdworkers proved', 'proved costly', 'costly form', 'form collection', 'collection depressed', 'depressed sample', 'sample rating', 'rating made', 'made photo', 'photo posted', 'posted within', 'within year', 'year either', 'either direction', 'direction date', 'date first', 'first diagnosis', 'diagnosis within', 'within subset', 'subset nearest', 'nearest prior', 'prior diagnosis', 'diagnosis date', 'date rated', 'rated control', 'control population', 'population recent', 'recent photo', 'photo date', 'date participation', 'participation study', 'study rated']","['collection crowdsourced using', 'crowdsourced using amazon', 'using amazon mechanical', 'amazon mechanical turk', 'mechanical turk mturk', 'turk mturk crowdwork', 'mturk crowdwork platform', 'crowdwork platform separate', 'platform separate survey', 'separate survey created', 'survey created depressed', 'created depressed healthy', 'depressed healthy individual', 'healthy individual depressed', 'individual depressed survey', 'depressed survey participant', 'survey participant invited', 'participant invited complete', 'invited complete survey', 'complete survey involved', 'survey involved passing', 'involved passing series', 'passing series inclusion', 'series inclusion criterion', 'inclusion criterion responding', 'criterion responding standardized', 'responding standardized clinical', 'standardized clinical survey', 'clinical survey answering', 'survey answering question', 'answering question related', 'question related demographic', 'related demographic history', 'demographic history sharing', 'history sharing social', 'sharing social medium', 'social medium history', 'medium history cesd', 'history cesd center', 'cesd center epidemiologic', 'center epidemiologic study', 'epidemiologic study scale', 'study scale questionnaire', 'scale questionnaire screen', 'questionnaire screen participant', 'screen participant level', 'participant level cesd', 'level cesd assessment', 'cesd assessment quality', 'assessment quality ha', 'quality ha demonstrated', 'ha demonstrated onpar', 'demonstrated onpar inventory', 'onpar inventory including', 'inventory including beck', 'including beck inventory', 'beck inventory kellner', 'inventory kellner symptom', 'kellner symptom questionnaire', 'symptom questionnaire healthy', 'questionnaire healthy participant', 'healthy participant screened', 'participant screened ensure', 'screened ensure history', 'ensure history active', 'history active instagram', 'active instagram use', 'instagram use see', 'use see additional', 'see additional file', 'additional file actual', 'file actual survey', 'actual survey text', 'survey text qualified', 'text qualified participant', 'qualified participant asked', 'participant asked share', 'asked share instagram', 'share instagram usernames', 'instagram usernames history', 'usernames history app', 'history app embedded', 'app embedded survey', 'embedded survey allowed', 'survey allowed participant', 'allowed participant securely', 'participant securely log', 'securely log instagram', 'log instagram account', 'instagram account agree', 'account agree share', 'agree share datab', 'share datab upon', 'datab upon securing', 'upon securing consent', 'securing consent made', 'consent made onetime', 'made onetime collection', 'onetime collection participant', 'collection participant entire', 'participant entire instagram', 'entire instagram posting', 'instagram posting history', 'posting history total', 'history total collected', 'total collected photograph', 'collected photograph instagram', 'photograph instagram history', 'instagram history asked', 'history asked different', 'asked different set', 'different set mturk', 'set mturk crowdworkers', 'mturk crowdworkers rate', 'crowdworkers rate instagram', 'rate instagram photograph', 'instagram photograph collected', 'photograph collected new', 'collected new task', 'new task asked', 'task asked participant', 'asked participant rate', 'participant rate random', 'rate random selection', 'random selection photo', 'selection photo collected', 'photo collected raters', 'collected raters asked', 'raters asked judge', 'asked judge interesting', 'judge interesting likable', 'interesting likable happy', 'likable happy sad', 'happy sad photo', 'sad photo seemed', 'photo seemed continuous', 'seemed continuous scale', 'continuous scale photo', 'scale photo rated', 'photo rated least', 'rated least three', 'least three different', 'three different raters', 'different raters rating', 'raters rating averaged', 'rating averaged across', 'averaged across raters', 'across raters raters', 'raters raters informed', 'raters informed photo', 'informed photo instagram', 'photo instagram given', 'instagram given information', 'given information study', 'information study participant', 'study participant provided', 'participant provided photo', 'provided photo including', 'photo including status', 'including status rating', 'status rating category', 'rating category showed', 'category showed good', 'showed good interrater', 'good interrater agreement', 'interrater agreement subset', 'agreement subset participant', 'subset participant instagram', 'participant instagram photo', 'instagram photo rated', 'photo rated n', 'rated n limited', 'n limited rating', 'limited rating subset', 'rating subset task', 'subset task timeconsuming', 'task timeconsuming crowdworkers', 'timeconsuming crowdworkers proved', 'crowdworkers proved costly', 'proved costly form', 'costly form collection', 'form collection depressed', 'collection depressed sample', 'depressed sample rating', 'sample rating made', 'rating made photo', 'made photo posted', 'photo posted within', 'posted within year', 'within year either', 'year either direction', 'either direction date', 'direction date first', 'date first diagnosis', 'first diagnosis within', 'diagnosis within subset', 'within subset nearest', 'subset nearest prior', 'nearest prior diagnosis', 'prior diagnosis date', 'diagnosis date rated', 'date rated control', 'rated control population', 'control population recent', 'population recent photo', 'recent photo date', 'photo date participation', 'date participation study', 'participation study rated']"
https://dl.acm.org/doi/abs/10.1145/2858036.2858207 ,1,We use public data from Reddit. Personally identifiable information was removed and content was de-identified and paraphrased before being reported in the paper for exemplary purposes. This work has been approved by the appropriate Institutional Review Board (IRB). Our work does not make any diagnostic claims related to mental illness or suicide.,we use public data from reddit personally identifiable information wa removed and content wa deidentified and paraphrased before being reported in the paper for exemplary purpose this work ha been approved by the appropriate institutional review board irb our work doe not make any diagnostic claim related to mental illness or suicide,"['use', 'public', 'reddit', 'personally', 'identifiable', 'information', 'removed', 'content', 'deidentified', 'paraphrased', 'reported', 'paper', 'exemplary', 'purpose', 'work', 'ha', 'approved', 'appropriate', 'institutional', 'review', 'board', 'irb', 'work', 'doe', 'make', 'diagnostic', 'claim', 'related', 'illness', 'suicide']","['use public', 'public reddit', 'reddit personally', 'personally identifiable', 'identifiable information', 'information removed', 'removed content', 'content deidentified', 'deidentified paraphrased', 'paraphrased reported', 'reported paper', 'paper exemplary', 'exemplary purpose', 'purpose work', 'work ha', 'ha approved', 'approved appropriate', 'appropriate institutional', 'institutional review', 'review board', 'board irb', 'irb work', 'work doe', 'doe make', 'make diagnostic', 'diagnostic claim', 'claim related', 'related illness', 'illness suicide']","['use public reddit', 'public reddit personally', 'reddit personally identifiable', 'personally identifiable information', 'identifiable information removed', 'information removed content', 'removed content deidentified', 'content deidentified paraphrased', 'deidentified paraphrased reported', 'paraphrased reported paper', 'reported paper exemplary', 'paper exemplary purpose', 'exemplary purpose work', 'purpose work ha', 'work ha approved', 'ha approved appropriate', 'approved appropriate institutional', 'appropriate institutional review', 'institutional review board', 'review board irb', 'board irb work', 'irb work doe', 'work doe make', 'doe make diagnostic', 'make diagnostic claim', 'diagnostic claim related', 'claim related illness', 'related illness suicide']"
https://dl.acm.org/doi/abs/10.1145/2702613.2732733,1,We used Reddit's official API to collect posts comments on posts and associated metadata from several mental health focused subreddits. We build on the data collection methodology we used in [4]. In order to arrive at a comprehensive list of subreddits to focus on we utilized Reddit's native subreddit search feature (http://www.reddit.com/reddits). We searched for subreddits on “mental health”. Two researchers familiar with Reddit employed an initial filtering step on the search results returned so that we “seed” on high precision subreddits discussing mental health concerns. Thereafter we focused on a snowball approach to compile a second list of “related” or “similar” subreddits that are mentioned in the profile pages of the seed subreddits. Sample of subreddits (31 in all) we crawled are given in Table 1. Note all of these subreddits host public content. For the purposes of self-disclosure detection we also identified subreddits (sample listed in Table 2) as our control group (total of 12 subreddits) – meaning they are unrelated to mental health topics. For sanity check we randomly sampled a set of 200 posts from the control subreddits and two researchers familiar with Reddit manually checked their content for presence of any mental health content. We found that 97% of subreddit content in our sample were not about any mental health concern (Cohen’s Kappa for inter-rater agreement was .84). In all our dataset had 32509 posts from 23807 users in the mental health subreddits and 15383 posts from 13216 users in the control forums. For each of the unique users in the mental health forums we further collected all of their Reddit post/comment histories (last 1000 posts/comments per Reddit API limits) if their number of posts and comments in our dataset was five or more – this gave us 7248 users and 4.1M posts/comments,we used reddits official api to collect post comment on post and associated metadata from several mental health focused subreddits we build on the data collection methodology we used in in order to arrive at a comprehensive list of subreddits to focus on we utilized reddits native subreddit search feature httpwwwredditcomreddits we searched for subreddits on mental health two researcher familiar with reddit employed an initial filtering step on the search result returned so that we seed on high precision subreddits discussing mental health concern thereafter we focused on a snowball approach to compile a second list of related or similar subreddits that are mentioned in the profile page of the seed subreddits sample of subreddits in all we crawled are given in table note all of these subreddits host public content for the purpose of selfdisclosure detection we also identified subreddits sample listed in table a our control group total of subreddits meaning they are unrelated to mental health topic for sanity check we randomly sampled a set of post from the control subreddits and two researcher familiar with reddit manually checked their content for presence of any mental health content we found that of subreddit content in our sample were not about any mental health concern cohens kappa for interrater agreement wa in all our dataset had post from user in the mental health subreddits and post from user in the control forum for each of the unique user in the mental health forum we further collected all of their reddit postcomment history last postscomments per reddit api limit if their number of post and comment in our dataset wa five or more this gave u user and m postscomments,"['reddits', 'official', 'api', 'collect', 'comment', 'associated', 'metadata', 'several', 'focused', 'subreddits', 'build', 'collection', 'methodology', 'order', 'arrive', 'comprehensive', 'list', 'subreddits', 'focus', 'utilized', 'reddits', 'native', 'subreddit', 'search', 'feature', 'httpwwwredditcomreddits', 'searched', 'subreddits', 'two', 'researcher', 'familiar', 'reddit', 'employed', 'initial', 'filtering', 'step', 'search', 'result', 'returned', 'seed', 'high', 'precision', 'subreddits', 'discussing', 'concern', 'thereafter', 'focused', 'snowball', 'approach', 'compile', 'second', 'list', 'related', 'similar', 'subreddits', 'mentioned', 'profile', 'page', 'seed', 'subreddits', 'sample', 'subreddits', 'crawled', 'given', 'table', 'note', 'subreddits', 'host', 'public', 'content', 'purpose', 'detection', 'also', 'identified', 'subreddits', 'sample', 'listed', 'table', 'control', 'group', 'total', 'subreddits', 'meaning', 'unrelated', 'topic', 'sanity', 'check', 'randomly', 'sampled', 'set', 'control', 'subreddits', 'two', 'researcher', 'familiar', 'reddit', 'manually', 'checked', 'content', 'presence', 'content', 'found', 'subreddit', 'content', 'sample', 'concern', 'cohens', 'kappa', 'interrater', 'agreement', 'dataset', 'subreddits', 'control', 'forum', 'unique', 'forum', 'collected', 'reddit', 'postcomment', 'history', 'last', 'postscomments', 'per', 'reddit', 'api', 'limit', 'number', 'comment', 'dataset', 'five', 'gave', 'u', 'postscomments']","['reddits official', 'official api', 'api collect', 'collect comment', 'comment associated', 'associated metadata', 'metadata several', 'several focused', 'focused subreddits', 'subreddits build', 'build collection', 'collection methodology', 'methodology order', 'order arrive', 'arrive comprehensive', 'comprehensive list', 'list subreddits', 'subreddits focus', 'focus utilized', 'utilized reddits', 'reddits native', 'native subreddit', 'subreddit search', 'search feature', 'feature httpwwwredditcomreddits', 'httpwwwredditcomreddits searched', 'searched subreddits', 'subreddits two', 'two researcher', 'researcher familiar', 'familiar reddit', 'reddit employed', 'employed initial', 'initial filtering', 'filtering step', 'step search', 'search result', 'result returned', 'returned seed', 'seed high', 'high precision', 'precision subreddits', 'subreddits discussing', 'discussing concern', 'concern thereafter', 'thereafter focused', 'focused snowball', 'snowball approach', 'approach compile', 'compile second', 'second list', 'list related', 'related similar', 'similar subreddits', 'subreddits mentioned', 'mentioned profile', 'profile page', 'page seed', 'seed subreddits', 'subreddits sample', 'sample subreddits', 'subreddits crawled', 'crawled given', 'given table', 'table note', 'note subreddits', 'subreddits host', 'host public', 'public content', 'content purpose', 'purpose detection', 'detection also', 'also identified', 'identified subreddits', 'subreddits sample', 'sample listed', 'listed table', 'table control', 'control group', 'group total', 'total subreddits', 'subreddits meaning', 'meaning unrelated', 'unrelated topic', 'topic sanity', 'sanity check', 'check randomly', 'randomly sampled', 'sampled set', 'set control', 'control subreddits', 'subreddits two', 'two researcher', 'researcher familiar', 'familiar reddit', 'reddit manually', 'manually checked', 'checked content', 'content presence', 'presence content', 'content found', 'found subreddit', 'subreddit content', 'content sample', 'sample concern', 'concern cohens', 'cohens kappa', 'kappa interrater', 'interrater agreement', 'agreement dataset', 'dataset subreddits', 'subreddits control', 'control forum', 'forum unique', 'unique forum', 'forum collected', 'collected reddit', 'reddit postcomment', 'postcomment history', 'history last', 'last postscomments', 'postscomments per', 'per reddit', 'reddit api', 'api limit', 'limit number', 'number comment', 'comment dataset', 'dataset five', 'five gave', 'gave u', 'u postscomments']","['reddits official api', 'official api collect', 'api collect comment', 'collect comment associated', 'comment associated metadata', 'associated metadata several', 'metadata several focused', 'several focused subreddits', 'focused subreddits build', 'subreddits build collection', 'build collection methodology', 'collection methodology order', 'methodology order arrive', 'order arrive comprehensive', 'arrive comprehensive list', 'comprehensive list subreddits', 'list subreddits focus', 'subreddits focus utilized', 'focus utilized reddits', 'utilized reddits native', 'reddits native subreddit', 'native subreddit search', 'subreddit search feature', 'search feature httpwwwredditcomreddits', 'feature httpwwwredditcomreddits searched', 'httpwwwredditcomreddits searched subreddits', 'searched subreddits two', 'subreddits two researcher', 'two researcher familiar', 'researcher familiar reddit', 'familiar reddit employed', 'reddit employed initial', 'employed initial filtering', 'initial filtering step', 'filtering step search', 'step search result', 'search result returned', 'result returned seed', 'returned seed high', 'seed high precision', 'high precision subreddits', 'precision subreddits discussing', 'subreddits discussing concern', 'discussing concern thereafter', 'concern thereafter focused', 'thereafter focused snowball', 'focused snowball approach', 'snowball approach compile', 'approach compile second', 'compile second list', 'second list related', 'list related similar', 'related similar subreddits', 'similar subreddits mentioned', 'subreddits mentioned profile', 'mentioned profile page', 'profile page seed', 'page seed subreddits', 'seed subreddits sample', 'subreddits sample subreddits', 'sample subreddits crawled', 'subreddits crawled given', 'crawled given table', 'given table note', 'table note subreddits', 'note subreddits host', 'subreddits host public', 'host public content', 'public content purpose', 'content purpose detection', 'purpose detection also', 'detection also identified', 'also identified subreddits', 'identified subreddits sample', 'subreddits sample listed', 'sample listed table', 'listed table control', 'table control group', 'control group total', 'group total subreddits', 'total subreddits meaning', 'subreddits meaning unrelated', 'meaning unrelated topic', 'unrelated topic sanity', 'topic sanity check', 'sanity check randomly', 'check randomly sampled', 'randomly sampled set', 'sampled set control', 'set control subreddits', 'control subreddits two', 'subreddits two researcher', 'two researcher familiar', 'researcher familiar reddit', 'familiar reddit manually', 'reddit manually checked', 'manually checked content', 'checked content presence', 'content presence content', 'presence content found', 'content found subreddit', 'found subreddit content', 'subreddit content sample', 'content sample concern', 'sample concern cohens', 'concern cohens kappa', 'cohens kappa interrater', 'kappa interrater agreement', 'interrater agreement dataset', 'agreement dataset subreddits', 'dataset subreddits control', 'subreddits control forum', 'control forum unique', 'forum unique forum', 'unique forum collected', 'forum collected reddit', 'collected reddit postcomment', 'reddit postcomment history', 'postcomment history last', 'history last postscomments', 'last postscomments per', 'postscomments per reddit', 'per reddit api', 'reddit api limit', 'api limit number', 'limit number comment', 'number comment dataset', 'comment dataset five', 'dataset five gave', 'five gave u', 'gave u postscomments']"
https://dl.acm.org/doi/abs/10.1145/2702123.2702280,0,In this study we gathered information on depression levels of Twitter users and their activity histories. To do this we published a website to administer a questionnaire and disseminated information about the website over Twitter1. In contrast to De Choudhury et al. [14] who collected data from Englishspeaking users through crowdsourcing this study collected data from Japanese-speaking volunteers. This approach was used to investigate the extent to which depression risk can be estimated for a population different from the population considered by the prior research [14]. Figure 1 shows a screenshot of our website. The website collected the responses to a questionnaire to evaluate the degree of depression of the Twitter users who participated (hereinafter the participants) and to collect the histories of participants activities on Twitter. The activity histories of participants were collected through the Twitter application programming interface (API)2 and the questionnaires to determine degree of depression were completed by participants through their web browsers. Before data collection visitors to the website were presented with a written explanation of the aims of the experiment the information that would be collected and how that information would be handled. Those who consented to become participants after receiving the explanation logged into their individual Twitter accounts through the OAuth authorization process. Next participants were surveyed on gender age occupation and history of depression following which they answered a questionnaire designed to evaluate degree of depression. A message called the “kokoro score” (“kokoro” is a Japanese word meaning “heart”) determined on the basis of answers to the questionnaire and information in the collected tweets was displayed to participants after completion of the questionnaire (Fig. 2). Experiment participants were able to tweet the message displayed which made it possible to promote the website over Twitter by word-of-mouth in a type of snowball sampling. The CES-D questionnaire was used to evaluate the degree of depression [30]. In the CES-D test participants answered 20 questions on a Likert-type 4-point scale. Each answer was assigned a score of 0-3 points with the sum of the points from all answers used as the score to estimate likelihood of depression. Several standards exist by which to determine the appropriate cutoff score for identifying depression. In this research we regarded a score of 22 points or higher as indicating active depression and a score of 21 points or lower as indicating no active depression; these are the same values as used in [14] and give a cutoff score of 22. In addition answers to BDI [2] a depression scale used with characteristics similar to CESD were collected to ensure the reliability of data. For each participant scores were calculated on both scales with poor correlation regarded as indicating unreliable answers. The time taken to answer the questionnaires was also recorded and those completed in too brief a time were excluded. After each participant answered the questionnaire the activity history of that participant on Twitter was collected from Twitter by using the API. At most 3200 tweets were collected for each participant and the number of users following the participant and being followed by the participant were recorded. Tweets published after the questionnaire was taken were discarded. The website was opened to the public on 4 December 2013 at which time the authors publicized it on their Twitter accounts. Between 4 December 2013 and 8 February 2014 219 people participated in the experiment. After eliminating participants who did not tweet and participants who answered the questionnaire in fewer than 30 seconds (as previously mentioned to ensure the reliability of the questionnaire answers) 214 sets of answers remained. Only the first set of answers was used for participants who completed the questionnaire more than once. As a result data about 209 experiment participants (male: 121; female: 88) aged 16 to 55 (mean: 28.8 years; standard deviation: 8.2 years) were analyzed. The correlations between CES-D score and BDI score for these participants were high 0.87 and there were no participants with uncorrelated scores so the data for all 209 participants were used; excluded datasets are not discussed any further. Figure 3 shows the histogram of CES-D scores of 209 participants. Among the participants 81 (resp. 128) were estimated to have (resp. not have) active depression for an incidence of approximately 39%. This incidence is similar to that found by De Choudhury et al. [14] who identified depression in approximately 36% of participants. Table 1 gives statistics on the activity histories of participants.,in this study we gathered information on depression level of twitter user and their activity history to do this we published a website to administer a questionnaire and disseminated information about the website over twitter in contrast to de choudhury et al who collected data from englishspeaking user through crowdsourcing this study collected data from japanesespeaking volunteer this approach wa used to investigate the extent to which depression risk can be estimated for a population different from the population considered by the prior research figure show a screenshot of our website the website collected the response to a questionnaire to evaluate the degree of depression of the twitter user who participated hereinafter the participant and to collect the history of participant activity on twitter the activity history of participant were collected through the twitter application programming interface api and the questionnaire to determine degree of depression were completed by participant through their web browser before data collection visitor to the website were presented with a written explanation of the aim of the experiment the information that would be collected and how that information would be handled those who consented to become participant after receiving the explanation logged into their individual twitter account through the oauth authorization process next participant were surveyed on gender age occupation and history of depression following which they answered a questionnaire designed to evaluate degree of depression a message called the kokoro score kokoro is a japanese word meaning heart determined on the basis of answer to the questionnaire and information in the collected tweet wa displayed to participant after completion of the questionnaire fig experiment participant were able to tweet the message displayed which made it possible to promote the website over twitter by wordofmouth in a type of snowball sampling the cesd questionnaire wa used to evaluate the degree of depression in the cesd test participant answered question on a likerttype point scale each answer wa assigned a score of point with the sum of the point from all answer used a the score to estimate likelihood of depression several standard exist by which to determine the appropriate cutoff score for identifying depression in this research we regarded a score of point or higher a indicating active depression and a score of point or lower a indicating no active depression these are the same value a used in and give a cutoff score of in addition answer to bdi a depression scale used with characteristic similar to cesd were collected to ensure the reliability of data for each participant score were calculated on both scale with poor correlation regarded a indicating unreliable answer the time taken to answer the questionnaire wa also recorded and those completed in too brief a time were excluded after each participant answered the questionnaire the activity history of that participant on twitter wa collected from twitter by using the api at most tweet were collected for each participant and the number of user following the participant and being followed by the participant were recorded tweet published after the questionnaire wa taken were discarded the website wa opened to the public on december at which time the author publicized it on their twitter account between december and february people participated in the experiment after eliminating participant who did not tweet and participant who answered the questionnaire in fewer than second a previously mentioned to ensure the reliability of the questionnaire answer set of answer remained only the first set of answer wa used for participant who completed the questionnaire more than once a a result data about experiment participant male female aged to mean year standard deviation year were analyzed the correlation between cesd score and bdi score for these participant were high and there were no participant with uncorrelated score so the data for all participant were used excluded datasets are not discussed any further figure show the histogram of cesd score of participant among the participant resp were estimated to have resp not have active depression for an incidence of approximately this incidence is similar to that found by de choudhury et al who identified depression in approximately of participant table give statistic on the activity history of participant,"['study', 'gathered', 'information', 'level', 'activity', 'history', 'published', 'website', 'administer', 'questionnaire', 'disseminated', 'information', 'website', 'contrast', 'de', 'choudhury', 'et', 'al', 'collected', 'englishspeaking', 'crowdsourcing', 'study', 'collected', 'japanesespeaking', 'volunteer', 'approach', 'investigate', 'extent', 'risk', 'estimated', 'population', 'different', 'population', 'considered', 'prior', 'research', 'figure', 'show', 'screenshot', 'website', 'website', 'collected', 'response', 'questionnaire', 'evaluate', 'degree', 'participated', 'hereinafter', 'participant', 'collect', 'history', 'participant', 'activity', 'activity', 'history', 'participant', 'collected', 'application', 'programming', 'interface', 'api', 'questionnaire', 'determine', 'degree', 'completed', 'participant', 'web', 'browser', 'collection', 'visitor', 'website', 'presented', 'written', 'explanation', 'aim', 'experiment', 'information', 'would', 'collected', 'information', 'would', 'handled', 'consented', 'become', 'participant', 'receiving', 'explanation', 'logged', 'individual', 'account', 'oauth', 'authorization', 'process', 'next', 'participant', 'surveyed', 'gender', 'age', 'occupation', 'history', 'following', 'answered', 'questionnaire', 'designed', 'evaluate', 'degree', 'message', 'called', 'kokoro', 'score', 'kokoro', 'japanese', 'word', 'meaning', 'heart', 'determined', 'basis', 'answer', 'questionnaire', 'information', 'collected', 'displayed', 'participant', 'completion', 'questionnaire', 'fig', 'experiment', 'participant', 'able', 'message', 'displayed', 'made', 'possible', 'promote', 'website', 'wordofmouth', 'type', 'snowball', 'sampling', 'cesd', 'questionnaire', 'evaluate', 'degree', 'cesd', 'test', 'participant', 'answered', 'question', 'likerttype', 'point', 'scale', 'answer', 'assigned', 'score', 'point', 'sum', 'point', 'answer', 'score', 'estimate', 'likelihood', 'several', 'standard', 'exist', 'determine', 'appropriate', 'cutoff', 'score', 'identifying', 'research', 'regarded', 'score', 'point', 'higher', 'indicating', 'active', 'score', 'point', 'lower', 'indicating', 'active', 'value', 'give', 'cutoff', 'score', 'addition', 'answer', 'bdi', 'scale', 'characteristic', 'similar', 'cesd', 'collected', 'ensure', 'reliability', 'participant', 'score', 'calculated', 'scale', 'poor', 'correlation', 'regarded', 'indicating', 'unreliable', 'answer', 'time', 'taken', 'answer', 'questionnaire', 'also', 'recorded', 'completed', 'brief', 'time', 'excluded', 'participant', 'answered', 'questionnaire', 'activity', 'history', 'participant', 'collected', 'using', 'api', 'collected', 'participant', 'number', 'following', 'participant', 'followed', 'participant', 'recorded', 'published', 'questionnaire', 'taken', 'discarded', 'website', 'opened', 'public', 'december', 'time', 'author', 'publicized', 'account', 'december', 'february', 'people', 'participated', 'experiment', 'eliminating', 'participant', 'participant', 'answered', 'questionnaire', 'fewer', 'second', 'previously', 'mentioned', 'ensure', 'reliability', 'questionnaire', 'answer', 'set', 'answer', 'remained', 'first', 'set', 'answer', 'participant', 'completed', 'questionnaire', 'result', 'experiment', 'participant', 'male', 'female', 'aged', 'mean', 'year', 'standard', 'deviation', 'year', 'analyzed', 'correlation', 'cesd', 'score', 'bdi', 'score', 'participant', 'high', 'participant', 'uncorrelated', 'score', 'participant', 'excluded', 'datasets', 'discussed', 'figure', 'show', 'histogram', 'cesd', 'score', 'participant', 'among', 'participant', 'resp', 'estimated', 'resp', 'active', 'incidence', 'approximately', 'incidence', 'similar', 'found', 'de', 'choudhury', 'et', 'al', 'identified', 'approximately', 'participant', 'table', 'give', 'statistic', 'activity', 'history', 'participant']","['study gathered', 'gathered information', 'information level', 'level activity', 'activity history', 'history published', 'published website', 'website administer', 'administer questionnaire', 'questionnaire disseminated', 'disseminated information', 'information website', 'website contrast', 'contrast de', 'de choudhury', 'choudhury et', 'et al', 'al collected', 'collected englishspeaking', 'englishspeaking crowdsourcing', 'crowdsourcing study', 'study collected', 'collected japanesespeaking', 'japanesespeaking volunteer', 'volunteer approach', 'approach investigate', 'investigate extent', 'extent risk', 'risk estimated', 'estimated population', 'population different', 'different population', 'population considered', 'considered prior', 'prior research', 'research figure', 'figure show', 'show screenshot', 'screenshot website', 'website website', 'website collected', 'collected response', 'response questionnaire', 'questionnaire evaluate', 'evaluate degree', 'degree participated', 'participated hereinafter', 'hereinafter participant', 'participant collect', 'collect history', 'history participant', 'participant activity', 'activity activity', 'activity history', 'history participant', 'participant collected', 'collected application', 'application programming', 'programming interface', 'interface api', 'api questionnaire', 'questionnaire determine', 'determine degree', 'degree completed', 'completed participant', 'participant web', 'web browser', 'browser collection', 'collection visitor', 'visitor website', 'website presented', 'presented written', 'written explanation', 'explanation aim', 'aim experiment', 'experiment information', 'information would', 'would collected', 'collected information', 'information would', 'would handled', 'handled consented', 'consented become', 'become participant', 'participant receiving', 'receiving explanation', 'explanation logged', 'logged individual', 'individual account', 'account oauth', 'oauth authorization', 'authorization process', 'process next', 'next participant', 'participant surveyed', 'surveyed gender', 'gender age', 'age occupation', 'occupation history', 'history following', 'following answered', 'answered questionnaire', 'questionnaire designed', 'designed evaluate', 'evaluate degree', 'degree message', 'message called', 'called kokoro', 'kokoro score', 'score kokoro', 'kokoro japanese', 'japanese word', 'word meaning', 'meaning heart', 'heart determined', 'determined basis', 'basis answer', 'answer questionnaire', 'questionnaire information', 'information collected', 'collected displayed', 'displayed participant', 'participant completion', 'completion questionnaire', 'questionnaire fig', 'fig experiment', 'experiment participant', 'participant able', 'able message', 'message displayed', 'displayed made', 'made possible', 'possible promote', 'promote website', 'website wordofmouth', 'wordofmouth type', 'type snowball', 'snowball sampling', 'sampling cesd', 'cesd questionnaire', 'questionnaire evaluate', 'evaluate degree', 'degree cesd', 'cesd test', 'test participant', 'participant answered', 'answered question', 'question likerttype', 'likerttype point', 'point scale', 'scale answer', 'answer assigned', 'assigned score', 'score point', 'point sum', 'sum point', 'point answer', 'answer score', 'score estimate', 'estimate likelihood', 'likelihood several', 'several standard', 'standard exist', 'exist determine', 'determine appropriate', 'appropriate cutoff', 'cutoff score', 'score identifying', 'identifying research', 'research regarded', 'regarded score', 'score point', 'point higher', 'higher indicating', 'indicating active', 'active score', 'score point', 'point lower', 'lower indicating', 'indicating active', 'active value', 'value give', 'give cutoff', 'cutoff score', 'score addition', 'addition answer', 'answer bdi', 'bdi scale', 'scale characteristic', 'characteristic similar', 'similar cesd', 'cesd collected', 'collected ensure', 'ensure reliability', 'reliability participant', 'participant score', 'score calculated', 'calculated scale', 'scale poor', 'poor correlation', 'correlation regarded', 'regarded indicating', 'indicating unreliable', 'unreliable answer', 'answer time', 'time taken', 'taken answer', 'answer questionnaire', 'questionnaire also', 'also recorded', 'recorded completed', 'completed brief', 'brief time', 'time excluded', 'excluded participant', 'participant answered', 'answered questionnaire', 'questionnaire activity', 'activity history', 'history participant', 'participant collected', 'collected using', 'using api', 'api collected', 'collected participant', 'participant number', 'number following', 'following participant', 'participant followed', 'followed participant', 'participant recorded', 'recorded published', 'published questionnaire', 'questionnaire taken', 'taken discarded', 'discarded website', 'website opened', 'opened public', 'public december', 'december time', 'time author', 'author publicized', 'publicized account', 'account december', 'december february', 'february people', 'people participated', 'participated experiment', 'experiment eliminating', 'eliminating participant', 'participant participant', 'participant answered', 'answered questionnaire', 'questionnaire fewer', 'fewer second', 'second previously', 'previously mentioned', 'mentioned ensure', 'ensure reliability', 'reliability questionnaire', 'questionnaire answer', 'answer set', 'set answer', 'answer remained', 'remained first', 'first set', 'set answer', 'answer participant', 'participant completed', 'completed questionnaire', 'questionnaire result', 'result experiment', 'experiment participant', 'participant male', 'male female', 'female aged', 'aged mean', 'mean year', 'year standard', 'standard deviation', 'deviation year', 'year analyzed', 'analyzed correlation', 'correlation cesd', 'cesd score', 'score bdi', 'bdi score', 'score participant', 'participant high', 'high participant', 'participant uncorrelated', 'uncorrelated score', 'score participant', 'participant excluded', 'excluded datasets', 'datasets discussed', 'discussed figure', 'figure show', 'show histogram', 'histogram cesd', 'cesd score', 'score participant', 'participant among', 'among participant', 'participant resp', 'resp estimated', 'estimated resp', 'resp active', 'active incidence', 'incidence approximately', 'approximately incidence', 'incidence similar', 'similar found', 'found de', 'de choudhury', 'choudhury et', 'et al', 'al identified', 'identified approximately', 'approximately participant', 'participant table', 'table give', 'give statistic', 'statistic activity', 'activity history', 'history participant']","['study gathered information', 'gathered information level', 'information level activity', 'level activity history', 'activity history published', 'history published website', 'published website administer', 'website administer questionnaire', 'administer questionnaire disseminated', 'questionnaire disseminated information', 'disseminated information website', 'information website contrast', 'website contrast de', 'contrast de choudhury', 'de choudhury et', 'choudhury et al', 'et al collected', 'al collected englishspeaking', 'collected englishspeaking crowdsourcing', 'englishspeaking crowdsourcing study', 'crowdsourcing study collected', 'study collected japanesespeaking', 'collected japanesespeaking volunteer', 'japanesespeaking volunteer approach', 'volunteer approach investigate', 'approach investigate extent', 'investigate extent risk', 'extent risk estimated', 'risk estimated population', 'estimated population different', 'population different population', 'different population considered', 'population considered prior', 'considered prior research', 'prior research figure', 'research figure show', 'figure show screenshot', 'show screenshot website', 'screenshot website website', 'website website collected', 'website collected response', 'collected response questionnaire', 'response questionnaire evaluate', 'questionnaire evaluate degree', 'evaluate degree participated', 'degree participated hereinafter', 'participated hereinafter participant', 'hereinafter participant collect', 'participant collect history', 'collect history participant', 'history participant activity', 'participant activity activity', 'activity activity history', 'activity history participant', 'history participant collected', 'participant collected application', 'collected application programming', 'application programming interface', 'programming interface api', 'interface api questionnaire', 'api questionnaire determine', 'questionnaire determine degree', 'determine degree completed', 'degree completed participant', 'completed participant web', 'participant web browser', 'web browser collection', 'browser collection visitor', 'collection visitor website', 'visitor website presented', 'website presented written', 'presented written explanation', 'written explanation aim', 'explanation aim experiment', 'aim experiment information', 'experiment information would', 'information would collected', 'would collected information', 'collected information would', 'information would handled', 'would handled consented', 'handled consented become', 'consented become participant', 'become participant receiving', 'participant receiving explanation', 'receiving explanation logged', 'explanation logged individual', 'logged individual account', 'individual account oauth', 'account oauth authorization', 'oauth authorization process', 'authorization process next', 'process next participant', 'next participant surveyed', 'participant surveyed gender', 'surveyed gender age', 'gender age occupation', 'age occupation history', 'occupation history following', 'history following answered', 'following answered questionnaire', 'answered questionnaire designed', 'questionnaire designed evaluate', 'designed evaluate degree', 'evaluate degree message', 'degree message called', 'message called kokoro', 'called kokoro score', 'kokoro score kokoro', 'score kokoro japanese', 'kokoro japanese word', 'japanese word meaning', 'word meaning heart', 'meaning heart determined', 'heart determined basis', 'determined basis answer', 'basis answer questionnaire', 'answer questionnaire information', 'questionnaire information collected', 'information collected displayed', 'collected displayed participant', 'displayed participant completion', 'participant completion questionnaire', 'completion questionnaire fig', 'questionnaire fig experiment', 'fig experiment participant', 'experiment participant able', 'participant able message', 'able message displayed', 'message displayed made', 'displayed made possible', 'made possible promote', 'possible promote website', 'promote website wordofmouth', 'website wordofmouth type', 'wordofmouth type snowball', 'type snowball sampling', 'snowball sampling cesd', 'sampling cesd questionnaire', 'cesd questionnaire evaluate', 'questionnaire evaluate degree', 'evaluate degree cesd', 'degree cesd test', 'cesd test participant', 'test participant answered', 'participant answered question', 'answered question likerttype', 'question likerttype point', 'likerttype point scale', 'point scale answer', 'scale answer assigned', 'answer assigned score', 'assigned score point', 'score point sum', 'point sum point', 'sum point answer', 'point answer score', 'answer score estimate', 'score estimate likelihood', 'estimate likelihood several', 'likelihood several standard', 'several standard exist', 'standard exist determine', 'exist determine appropriate', 'determine appropriate cutoff', 'appropriate cutoff score', 'cutoff score identifying', 'score identifying research', 'identifying research regarded', 'research regarded score', 'regarded score point', 'score point higher', 'point higher indicating', 'higher indicating active', 'indicating active score', 'active score point', 'score point lower', 'point lower indicating', 'lower indicating active', 'indicating active value', 'active value give', 'value give cutoff', 'give cutoff score', 'cutoff score addition', 'score addition answer', 'addition answer bdi', 'answer bdi scale', 'bdi scale characteristic', 'scale characteristic similar', 'characteristic similar cesd', 'similar cesd collected', 'cesd collected ensure', 'collected ensure reliability', 'ensure reliability participant', 'reliability participant score', 'participant score calculated', 'score calculated scale', 'calculated scale poor', 'scale poor correlation', 'poor correlation regarded', 'correlation regarded indicating', 'regarded indicating unreliable', 'indicating unreliable answer', 'unreliable answer time', 'answer time taken', 'time taken answer', 'taken answer questionnaire', 'answer questionnaire also', 'questionnaire also recorded', 'also recorded completed', 'recorded completed brief', 'completed brief time', 'brief time excluded', 'time excluded participant', 'excluded participant answered', 'participant answered questionnaire', 'answered questionnaire activity', 'questionnaire activity history', 'activity history participant', 'history participant collected', 'participant collected using', 'collected using api', 'using api collected', 'api collected participant', 'collected participant number', 'participant number following', 'number following participant', 'following participant followed', 'participant followed participant', 'followed participant recorded', 'participant recorded published', 'recorded published questionnaire', 'published questionnaire taken', 'questionnaire taken discarded', 'taken discarded website', 'discarded website opened', 'website opened public', 'opened public december', 'public december time', 'december time author', 'time author publicized', 'author publicized account', 'publicized account december', 'account december february', 'december february people', 'february people participated', 'people participated experiment', 'participated experiment eliminating', 'experiment eliminating participant', 'eliminating participant participant', 'participant participant answered', 'participant answered questionnaire', 'answered questionnaire fewer', 'questionnaire fewer second', 'fewer second previously', 'second previously mentioned', 'previously mentioned ensure', 'mentioned ensure reliability', 'ensure reliability questionnaire', 'reliability questionnaire answer', 'questionnaire answer set', 'answer set answer', 'set answer remained', 'answer remained first', 'remained first set', 'first set answer', 'set answer participant', 'answer participant completed', 'participant completed questionnaire', 'completed questionnaire result', 'questionnaire result experiment', 'result experiment participant', 'experiment participant male', 'participant male female', 'male female aged', 'female aged mean', 'aged mean year', 'mean year standard', 'year standard deviation', 'standard deviation year', 'deviation year analyzed', 'year analyzed correlation', 'analyzed correlation cesd', 'correlation cesd score', 'cesd score bdi', 'score bdi score', 'bdi score participant', 'score participant high', 'participant high participant', 'high participant uncorrelated', 'participant uncorrelated score', 'uncorrelated score participant', 'score participant excluded', 'participant excluded datasets', 'excluded datasets discussed', 'datasets discussed figure', 'discussed figure show', 'figure show histogram', 'show histogram cesd', 'histogram cesd score', 'cesd score participant', 'score participant among', 'participant among participant', 'among participant resp', 'participant resp estimated', 'resp estimated resp', 'estimated resp active', 'resp active incidence', 'active incidence approximately', 'incidence approximately incidence', 'approximately incidence similar', 'incidence similar found', 'similar found de', 'found de choudhury', 'de choudhury et', 'choudhury et al', 'et al identified', 'al identified approximately', 'identified approximately participant', 'approximately participant table', 'participant table give', 'table give statistic', 'give statistic activity', 'statistic activity history', 'activity history participant']"
https://www.nature.com/articles/s41598-017-12961-9,0,Data was collected from 7 Cups of Tea an anonymous online chat-based peer support community for emotional distress1 . Users agree at signup that their data may be used for the purposes of research. All the data used for the current study was anonymous and securely stored. This research was performed in line with the ethical and privacy protocols outlined in detail in (Benton et al. 2017). Data from 7 Cups takes the form of written dialogue between users of the service and volunteers who are trained as “active listeners”. A fragment of an exchange between the user of the service (U) and the volunteer (V) might go as follows: For the analyses reported in this paper we used only text generated by users of the service not the volunteers providing peer support. Users who reported depression as their primary concern at sign up were eligible for inclusion in analyses. Our original sample was comprised of 23048 conversations involving 1937 unique users. Users were excluded from the sample if they did not indicate their culture or if they selected ‘Other’. This resulted in the exclusion of 199 and 130 users respectively. The original sample also included users identifying as Native American or American Indian. This group was excluded from analyses since the majority of the data among these users was not English. This resulted in the removal of 15 users leaving a total sample size of 1593.,data wa collected from cup of tea an anonymous online chatbased peer support community for emotional distress user agree at signup that their data may be used for the purpose of research all the data used for the current study wa anonymous and securely stored this research wa performed in line with the ethical and privacy protocol outlined in detail in benton et al data from cup take the form of written dialogue between user of the service and volunteer who are trained a active listener a fragment of an exchange between the user of the service u and the volunteer v might go a follows for the analysis reported in this paper we used only text generated by user of the service not the volunteer providing peer support user who reported depression a their primary concern at sign up were eligible for inclusion in analysis our original sample wa comprised of conversation involving unique user user were excluded from the sample if they did not indicate their culture or if they selected other this resulted in the exclusion of and user respectively the original sample also included user identifying a native american or american indian this group wa excluded from analysis since the majority of the data among these user wa not english this resulted in the removal of user leaving a total sample size of,"['collected', 'cup', 'tea', 'anonymous', 'online', 'chatbased', 'peer', 'support', 'community', 'emotional', 'distress', 'agree', 'signup', 'may', 'purpose', 'research', 'current', 'study', 'anonymous', 'securely', 'stored', 'research', 'performed', 'line', 'ethical', 'privacy', 'protocol', 'outlined', 'detail', 'benton', 'et', 'al', 'cup', 'take', 'form', 'written', 'dialogue', 'service', 'volunteer', 'trained', 'active', 'listener', 'fragment', 'exchange', 'service', 'u', 'volunteer', 'v', 'might', 'go', 'follows', 'reported', 'paper', 'text', 'generated', 'service', 'volunteer', 'providing', 'peer', 'support', 'reported', 'primary', 'concern', 'sign', 'eligible', 'inclusion', 'original', 'sample', 'comprised', 'conversation', 'involving', 'unique', 'excluded', 'sample', 'indicate', 'culture', 'selected', 'resulted', 'exclusion', 'respectively', 'original', 'sample', 'also', 'included', 'identifying', 'native', 'american', 'american', 'indian', 'group', 'excluded', 'since', 'majority', 'among', 'english', 'resulted', 'removal', 'leaving', 'total', 'sample', 'size']","['collected cup', 'cup tea', 'tea anonymous', 'anonymous online', 'online chatbased', 'chatbased peer', 'peer support', 'support community', 'community emotional', 'emotional distress', 'distress agree', 'agree signup', 'signup may', 'may purpose', 'purpose research', 'research current', 'current study', 'study anonymous', 'anonymous securely', 'securely stored', 'stored research', 'research performed', 'performed line', 'line ethical', 'ethical privacy', 'privacy protocol', 'protocol outlined', 'outlined detail', 'detail benton', 'benton et', 'et al', 'al cup', 'cup take', 'take form', 'form written', 'written dialogue', 'dialogue service', 'service volunteer', 'volunteer trained', 'trained active', 'active listener', 'listener fragment', 'fragment exchange', 'exchange service', 'service u', 'u volunteer', 'volunteer v', 'v might', 'might go', 'go follows', 'follows reported', 'reported paper', 'paper text', 'text generated', 'generated service', 'service volunteer', 'volunteer providing', 'providing peer', 'peer support', 'support reported', 'reported primary', 'primary concern', 'concern sign', 'sign eligible', 'eligible inclusion', 'inclusion original', 'original sample', 'sample comprised', 'comprised conversation', 'conversation involving', 'involving unique', 'unique excluded', 'excluded sample', 'sample indicate', 'indicate culture', 'culture selected', 'selected resulted', 'resulted exclusion', 'exclusion respectively', 'respectively original', 'original sample', 'sample also', 'also included', 'included identifying', 'identifying native', 'native american', 'american american', 'american indian', 'indian group', 'group excluded', 'excluded since', 'since majority', 'majority among', 'among english', 'english resulted', 'resulted removal', 'removal leaving', 'leaving total', 'total sample', 'sample size']","['collected cup tea', 'cup tea anonymous', 'tea anonymous online', 'anonymous online chatbased', 'online chatbased peer', 'chatbased peer support', 'peer support community', 'support community emotional', 'community emotional distress', 'emotional distress agree', 'distress agree signup', 'agree signup may', 'signup may purpose', 'may purpose research', 'purpose research current', 'research current study', 'current study anonymous', 'study anonymous securely', 'anonymous securely stored', 'securely stored research', 'stored research performed', 'research performed line', 'performed line ethical', 'line ethical privacy', 'ethical privacy protocol', 'privacy protocol outlined', 'protocol outlined detail', 'outlined detail benton', 'detail benton et', 'benton et al', 'et al cup', 'al cup take', 'cup take form', 'take form written', 'form written dialogue', 'written dialogue service', 'dialogue service volunteer', 'service volunteer trained', 'volunteer trained active', 'trained active listener', 'active listener fragment', 'listener fragment exchange', 'fragment exchange service', 'exchange service u', 'service u volunteer', 'u volunteer v', 'volunteer v might', 'v might go', 'might go follows', 'go follows reported', 'follows reported paper', 'reported paper text', 'paper text generated', 'text generated service', 'generated service volunteer', 'service volunteer providing', 'volunteer providing peer', 'providing peer support', 'peer support reported', 'support reported primary', 'reported primary concern', 'primary concern sign', 'concern sign eligible', 'sign eligible inclusion', 'eligible inclusion original', 'inclusion original sample', 'original sample comprised', 'sample comprised conversation', 'comprised conversation involving', 'conversation involving unique', 'involving unique excluded', 'unique excluded sample', 'excluded sample indicate', 'sample indicate culture', 'indicate culture selected', 'culture selected resulted', 'selected resulted exclusion', 'resulted exclusion respectively', 'exclusion respectively original', 'respectively original sample', 'original sample also', 'sample also included', 'also included identifying', 'included identifying native', 'identifying native american', 'native american american', 'american american indian', 'american indian group', 'indian group excluded', 'group excluded since', 'excluded since majority', 'since majority among', 'majority among english', 'among english resulted', 'english resulted removal', 'resulted removal leaving', 'removal leaving total', 'leaving total sample', 'total sample size']"
https://aclanthology.org/W14-3214.pdf,0,We used a dataset of 28749 nonclinical users who opted into a Facebook application (“MyPersonality”; Kosinski and Stillwell 2012) between June 2009 and March 2011 completed a 100-item personality questionnaire (an International Personality Item Pool (IPIP) proxy to the NEO-PI-R (Goldberg 1999) and shared access to their status updates containing at least 500 words. Users wrote on average of 4236 words (69917624 total word instances) and a subset of 16507 users provided gender and age in which 57.0% were female and the mean age was 24.8. The dataset was divided into training and testing samples. In particular the testing sample consisted of a random set of 1000 users who wrote at least 1000 words and completed the personality measure while the training set contained the 27749 remaining users.,we used a dataset of nonclinical user who opted into a facebook application mypersonality kosinski and stillwell between june and march completed a item personality questionnaire an international personality item pool ipip proxy to the neopir goldberg and shared access to their status update containing at least word user wrote on average of word total word instance and a subset of user provided gender and age in which were female and the mean age wa the dataset wa divided into training and testing sample in particular the testing sample consisted of a random set of user who wrote at least word and completed the personality measure while the training set contained the remaining user,"['dataset', 'nonclinical', 'opted', 'facebook', 'application', 'mypersonality', 'kosinski', 'stillwell', 'june', 'march', 'completed', 'item', 'personality', 'questionnaire', 'international', 'personality', 'item', 'pool', 'ipip', 'proxy', 'neopir', 'goldberg', 'shared', 'access', 'status', 'update', 'containing', 'least', 'word', 'wrote', 'average', 'word', 'total', 'word', 'instance', 'subset', 'provided', 'gender', 'age', 'female', 'mean', 'age', 'dataset', 'divided', 'training', 'testing', 'sample', 'particular', 'testing', 'sample', 'consisted', 'random', 'set', 'wrote', 'least', 'word', 'completed', 'personality', 'measure', 'training', 'set', 'contained', 'remaining']","['dataset nonclinical', 'nonclinical opted', 'opted facebook', 'facebook application', 'application mypersonality', 'mypersonality kosinski', 'kosinski stillwell', 'stillwell june', 'june march', 'march completed', 'completed item', 'item personality', 'personality questionnaire', 'questionnaire international', 'international personality', 'personality item', 'item pool', 'pool ipip', 'ipip proxy', 'proxy neopir', 'neopir goldberg', 'goldberg shared', 'shared access', 'access status', 'status update', 'update containing', 'containing least', 'least word', 'word wrote', 'wrote average', 'average word', 'word total', 'total word', 'word instance', 'instance subset', 'subset provided', 'provided gender', 'gender age', 'age female', 'female mean', 'mean age', 'age dataset', 'dataset divided', 'divided training', 'training testing', 'testing sample', 'sample particular', 'particular testing', 'testing sample', 'sample consisted', 'consisted random', 'random set', 'set wrote', 'wrote least', 'least word', 'word completed', 'completed personality', 'personality measure', 'measure training', 'training set', 'set contained', 'contained remaining']","['dataset nonclinical opted', 'nonclinical opted facebook', 'opted facebook application', 'facebook application mypersonality', 'application mypersonality kosinski', 'mypersonality kosinski stillwell', 'kosinski stillwell june', 'stillwell june march', 'june march completed', 'march completed item', 'completed item personality', 'item personality questionnaire', 'personality questionnaire international', 'questionnaire international personality', 'international personality item', 'personality item pool', 'item pool ipip', 'pool ipip proxy', 'ipip proxy neopir', 'proxy neopir goldberg', 'neopir goldberg shared', 'goldberg shared access', 'shared access status', 'access status update', 'status update containing', 'update containing least', 'containing least word', 'least word wrote', 'word wrote average', 'wrote average word', 'average word total', 'word total word', 'total word instance', 'word instance subset', 'instance subset provided', 'subset provided gender', 'provided gender age', 'gender age female', 'age female mean', 'female mean age', 'mean age dataset', 'age dataset divided', 'dataset divided training', 'divided training testing', 'training testing sample', 'testing sample particular', 'sample particular testing', 'particular testing sample', 'testing sample consisted', 'sample consisted random', 'consisted random set', 'random set wrote', 'set wrote least', 'wrote least word', 'least word completed', 'word completed personality', 'completed personality measure', 'personality measure training', 'measure training set', 'training set contained', 'set contained remaining']"
https://ieeexplore.ieee.org/abstract/document/6784326,0,a) CLINICAL Communities: Communities who are interested in ‘depression’ and with at least 200 posts are extracted from LiveJournal. This is identified through the ‘Search communities by interest’2 provided by LiveJournal and results in 24 communities with 38401 posts. The CLINICAL communities are grouped based on name and description of the individual community: depression bipolar self-harm attachment/separation and suicide (See Table 1 for statistics). The earliest community creation date was in 2001 thus our data set spans over 10 years. b) CONTROL communities: We constructed a CONTROL data set using five popular categories of communities in the LiveJournal Directory.3 We select communities who have at least 200 posts resulting in 23 communities with 229563 posts. This set is called CONTROL and the statistics of these 23 communities and their description are shown in Table 2.,a clinical community community who are interested in depression and with at least post are extracted from livejournal this is identified through the search community by interest provided by livejournal and result in community with post the clinical community are grouped based on name and description of the individual community depression bipolar selfharm attachmentseparation and suicide see table for statistic the earliest community creation date wa in thus our data set span over year b control community we constructed a control data set using five popular category of community in the livejournal directory we select community who have at least post resulting in community with post this set is called control and the statistic of these community and their description are shown in table,"['clinical', 'community', 'community', 'interested', 'least', 'extracted', 'livejournal', 'identified', 'search', 'community', 'interest', 'provided', 'livejournal', 'result', 'community', 'clinical', 'community', 'grouped', 'based', 'name', 'description', 'individual', 'community', 'bipolar', 'selfharm', 'attachmentseparation', 'suicide', 'see', 'table', 'statistic', 'earliest', 'community', 'creation', 'date', 'thus', 'set', 'span', 'year', 'b', 'control', 'community', 'constructed', 'control', 'set', 'using', 'five', 'popular', 'category', 'community', 'livejournal', 'directory', 'select', 'community', 'least', 'resulting', 'community', 'set', 'called', 'control', 'statistic', 'community', 'description', 'shown', 'table']","['clinical community', 'community community', 'community interested', 'interested least', 'least extracted', 'extracted livejournal', 'livejournal identified', 'identified search', 'search community', 'community interest', 'interest provided', 'provided livejournal', 'livejournal result', 'result community', 'community clinical', 'clinical community', 'community grouped', 'grouped based', 'based name', 'name description', 'description individual', 'individual community', 'community bipolar', 'bipolar selfharm', 'selfharm attachmentseparation', 'attachmentseparation suicide', 'suicide see', 'see table', 'table statistic', 'statistic earliest', 'earliest community', 'community creation', 'creation date', 'date thus', 'thus set', 'set span', 'span year', 'year b', 'b control', 'control community', 'community constructed', 'constructed control', 'control set', 'set using', 'using five', 'five popular', 'popular category', 'category community', 'community livejournal', 'livejournal directory', 'directory select', 'select community', 'community least', 'least resulting', 'resulting community', 'community set', 'set called', 'called control', 'control statistic', 'statistic community', 'community description', 'description shown', 'shown table']","['clinical community community', 'community community interested', 'community interested least', 'interested least extracted', 'least extracted livejournal', 'extracted livejournal identified', 'livejournal identified search', 'identified search community', 'search community interest', 'community interest provided', 'interest provided livejournal', 'provided livejournal result', 'livejournal result community', 'result community clinical', 'community clinical community', 'clinical community grouped', 'community grouped based', 'grouped based name', 'based name description', 'name description individual', 'description individual community', 'individual community bipolar', 'community bipolar selfharm', 'bipolar selfharm attachmentseparation', 'selfharm attachmentseparation suicide', 'attachmentseparation suicide see', 'suicide see table', 'see table statistic', 'table statistic earliest', 'statistic earliest community', 'earliest community creation', 'community creation date', 'creation date thus', 'date thus set', 'thus set span', 'set span year', 'span year b', 'year b control', 'b control community', 'control community constructed', 'community constructed control', 'constructed control set', 'control set using', 'set using five', 'using five popular', 'five popular category', 'popular category community', 'category community livejournal', 'community livejournal directory', 'livejournal directory select', 'directory select community', 'select community least', 'community least resulting', 'least resulting community', 'resulting community set', 'community set called', 'set called control', 'called control statistic', 'control statistic community', 'statistic community description', 'community description shown', 'description shown table']"
https://www.jmir.org/2017/7/e243/,1,A Web-based survey of Weibo users was conducted to assess the respondents’ suicide risk and emotional distress (ie depression anxiety and stress). The invitation letter to participate in this survey was widely sent out to general Weibo users by various promotion activities. For a Weibo user to be eligible for the study she or he had to be 18 years or older (by self-report). A 30 Renminbi incentive for each complete survey was provided to boost the respond rate. With the respondents’ consent their Weibo posts that were posted in the public domain during the 12 months before the survey were downloaded by calling Weibo API. The survey fulfilled the Checklist for Reporting Results of Internet E-Surveys (CHERRIES) checklist and details of the procedure have been reported in previous publications [2232]. In addition when multiple survey feedback were submitted from the same Internet protocol addresses only the first submission was used to avoid duplicate participation. In contrast to a previous study [32] this study excluded those who posted nothing throughout the 12 months but not those who posted fewer than 100 posts. Eventually data provided by 974 respondents remained for further analyses. The study has obtained ethical approvals from the Human Research Ethical Review Committee at the University of Hong Kong and the Institute Review Board of the Institute of Psychology at the Chinese Academy of Sciences. The survey measured respondents’ suicide probability score depression anxiety stress and Weibo suicide communication (WSC) as the outcome variables. In addition the respondents’ Weibo posts language features were extracted as independent variables or features for machine learning. The details of how those data were obtained are elaborated in the following subsections.,a webbased survey of weibo user wa conducted to ass the respondent suicide risk and emotional distress ie depression anxiety and stress the invitation letter to participate in this survey wa widely sent out to general weibo user by various promotion activity for a weibo user to be eligible for the study she or he had to be year or older by selfreport a renminbi incentive for each complete survey wa provided to boost the respond rate with the respondent consent their weibo post that were posted in the public domain during the month before the survey were downloaded by calling weibo api the survey fulfilled the checklist for reporting result of internet esurveys cherry checklist and detail of the procedure have been reported in previous publication in addition when multiple survey feedback were submitted from the same internet protocol address only the first submission wa used to avoid duplicate participation in contrast to a previous study this study excluded those who posted nothing throughout the month but not those who posted fewer than post eventually data provided by respondent remained for further analysis the study ha obtained ethical approval from the human research ethical review committee at the university of hong kong and the institute review board of the institute of psychology at the chinese academy of science the survey measured respondent suicide probability score depression anxiety stress and weibo suicide communication wsc a the outcome variable in addition the respondent weibo post language feature were extracted a independent variable or feature for machine learning the detail of how those data were obtained are elaborated in the following subsection,"['webbased', 'survey', 'weibo', 'conducted', 'ass', 'respondent', 'suicide', 'risk', 'emotional', 'distress', 'ie', 'anxiety', 'stress', 'invitation', 'letter', 'participate', 'survey', 'widely', 'sent', 'general', 'weibo', 'various', 'promotion', 'activity', 'weibo', 'eligible', 'study', 'year', 'older', 'selfreport', 'renminbi', 'incentive', 'complete', 'survey', 'provided', 'boost', 'respond', 'rate', 'respondent', 'consent', 'weibo', 'posted', 'public', 'domain', 'month', 'survey', 'downloaded', 'calling', 'weibo', 'api', 'survey', 'fulfilled', 'checklist', 'reporting', 'result', 'internet', 'esurveys', 'cherry', 'checklist', 'detail', 'procedure', 'reported', 'previous', 'publication', 'addition', 'multiple', 'survey', 'feedback', 'submitted', 'internet', 'protocol', 'address', 'first', 'submission', 'avoid', 'duplicate', 'participation', 'contrast', 'previous', 'study', 'study', 'excluded', 'posted', 'nothing', 'throughout', 'month', 'posted', 'fewer', 'eventually', 'provided', 'respondent', 'remained', 'study', 'ha', 'obtained', 'ethical', 'approval', 'human', 'research', 'ethical', 'review', 'committee', 'university', 'hong', 'kong', 'institute', 'review', 'board', 'institute', 'psychology', 'chinese', 'academy', 'science', 'survey', 'measured', 'respondent', 'suicide', 'probability', 'score', 'anxiety', 'stress', 'weibo', 'suicide', 'communication', 'wsc', 'outcome', 'variable', 'addition', 'respondent', 'weibo', 'language', 'feature', 'extracted', 'independent', 'variable', 'feature', 'machine', 'learning', 'detail', 'obtained', 'elaborated', 'following', 'subsection']","['webbased survey', 'survey weibo', 'weibo conducted', 'conducted ass', 'ass respondent', 'respondent suicide', 'suicide risk', 'risk emotional', 'emotional distress', 'distress ie', 'ie anxiety', 'anxiety stress', 'stress invitation', 'invitation letter', 'letter participate', 'participate survey', 'survey widely', 'widely sent', 'sent general', 'general weibo', 'weibo various', 'various promotion', 'promotion activity', 'activity weibo', 'weibo eligible', 'eligible study', 'study year', 'year older', 'older selfreport', 'selfreport renminbi', 'renminbi incentive', 'incentive complete', 'complete survey', 'survey provided', 'provided boost', 'boost respond', 'respond rate', 'rate respondent', 'respondent consent', 'consent weibo', 'weibo posted', 'posted public', 'public domain', 'domain month', 'month survey', 'survey downloaded', 'downloaded calling', 'calling weibo', 'weibo api', 'api survey', 'survey fulfilled', 'fulfilled checklist', 'checklist reporting', 'reporting result', 'result internet', 'internet esurveys', 'esurveys cherry', 'cherry checklist', 'checklist detail', 'detail procedure', 'procedure reported', 'reported previous', 'previous publication', 'publication addition', 'addition multiple', 'multiple survey', 'survey feedback', 'feedback submitted', 'submitted internet', 'internet protocol', 'protocol address', 'address first', 'first submission', 'submission avoid', 'avoid duplicate', 'duplicate participation', 'participation contrast', 'contrast previous', 'previous study', 'study study', 'study excluded', 'excluded posted', 'posted nothing', 'nothing throughout', 'throughout month', 'month posted', 'posted fewer', 'fewer eventually', 'eventually provided', 'provided respondent', 'respondent remained', 'remained study', 'study ha', 'ha obtained', 'obtained ethical', 'ethical approval', 'approval human', 'human research', 'research ethical', 'ethical review', 'review committee', 'committee university', 'university hong', 'hong kong', 'kong institute', 'institute review', 'review board', 'board institute', 'institute psychology', 'psychology chinese', 'chinese academy', 'academy science', 'science survey', 'survey measured', 'measured respondent', 'respondent suicide', 'suicide probability', 'probability score', 'score anxiety', 'anxiety stress', 'stress weibo', 'weibo suicide', 'suicide communication', 'communication wsc', 'wsc outcome', 'outcome variable', 'variable addition', 'addition respondent', 'respondent weibo', 'weibo language', 'language feature', 'feature extracted', 'extracted independent', 'independent variable', 'variable feature', 'feature machine', 'machine learning', 'learning detail', 'detail obtained', 'obtained elaborated', 'elaborated following', 'following subsection']","['webbased survey weibo', 'survey weibo conducted', 'weibo conducted ass', 'conducted ass respondent', 'ass respondent suicide', 'respondent suicide risk', 'suicide risk emotional', 'risk emotional distress', 'emotional distress ie', 'distress ie anxiety', 'ie anxiety stress', 'anxiety stress invitation', 'stress invitation letter', 'invitation letter participate', 'letter participate survey', 'participate survey widely', 'survey widely sent', 'widely sent general', 'sent general weibo', 'general weibo various', 'weibo various promotion', 'various promotion activity', 'promotion activity weibo', 'activity weibo eligible', 'weibo eligible study', 'eligible study year', 'study year older', 'year older selfreport', 'older selfreport renminbi', 'selfreport renminbi incentive', 'renminbi incentive complete', 'incentive complete survey', 'complete survey provided', 'survey provided boost', 'provided boost respond', 'boost respond rate', 'respond rate respondent', 'rate respondent consent', 'respondent consent weibo', 'consent weibo posted', 'weibo posted public', 'posted public domain', 'public domain month', 'domain month survey', 'month survey downloaded', 'survey downloaded calling', 'downloaded calling weibo', 'calling weibo api', 'weibo api survey', 'api survey fulfilled', 'survey fulfilled checklist', 'fulfilled checklist reporting', 'checklist reporting result', 'reporting result internet', 'result internet esurveys', 'internet esurveys cherry', 'esurveys cherry checklist', 'cherry checklist detail', 'checklist detail procedure', 'detail procedure reported', 'procedure reported previous', 'reported previous publication', 'previous publication addition', 'publication addition multiple', 'addition multiple survey', 'multiple survey feedback', 'survey feedback submitted', 'feedback submitted internet', 'submitted internet protocol', 'internet protocol address', 'protocol address first', 'address first submission', 'first submission avoid', 'submission avoid duplicate', 'avoid duplicate participation', 'duplicate participation contrast', 'participation contrast previous', 'contrast previous study', 'previous study study', 'study study excluded', 'study excluded posted', 'excluded posted nothing', 'posted nothing throughout', 'nothing throughout month', 'throughout month posted', 'month posted fewer', 'posted fewer eventually', 'fewer eventually provided', 'eventually provided respondent', 'provided respondent remained', 'respondent remained study', 'remained study ha', 'study ha obtained', 'ha obtained ethical', 'obtained ethical approval', 'ethical approval human', 'approval human research', 'human research ethical', 'research ethical review', 'ethical review committee', 'review committee university', 'committee university hong', 'university hong kong', 'hong kong institute', 'kong institute review', 'institute review board', 'review board institute', 'board institute psychology', 'institute psychology chinese', 'psychology chinese academy', 'chinese academy science', 'academy science survey', 'science survey measured', 'survey measured respondent', 'measured respondent suicide', 'respondent suicide probability', 'suicide probability score', 'probability score anxiety', 'score anxiety stress', 'anxiety stress weibo', 'stress weibo suicide', 'weibo suicide communication', 'suicide communication wsc', 'communication wsc outcome', 'wsc outcome variable', 'outcome variable addition', 'variable addition respondent', 'addition respondent weibo', 'respondent weibo language', 'weibo language feature', 'language feature extracted', 'feature extracted independent', 'extracted independent variable', 'independent variable feature', 'variable feature machine', 'feature machine learning', 'machine learning detail', 'learning detail obtained', 'detail obtained elaborated', 'obtained elaborated following', 'elaborated following subsection']"
https://dl.acm.org/doi/abs/10.1145/3025453.3025909,1,We first obtained a list of 150 ranked major universities in the United States by crawling the US News and World Report website [48]. This list is constructed based on the Carnegie classification employed extensively by higher education researchers and using a set of 16 indicators of academic excellence defined by US News. The list includes a variety of universities spread across the US in different settings (e.g. urban rural) and with a wide range of student enrollment sizes. Figure 1(a) shows their geographic distribution. As a part of this crawl we also obtained university metadata: gender distribution of students average tuition and fees and academic calendar (semester/quarter). To obtain further information about the nature of the student body we crawled the Wikipedia pages of all of the 150 universities. From these pages we extracted the size of student enrollment type (public/private) and setting (rural/suburban/urban/city) at every institution. These definitions come from a formal categorization scheme used by the US Department of Education. The student body enrollment sizes ranged from 2255 to 97494 with 98 public and 52 private universities. 50 universities were reported to be urban 47 city 39 suburban and 13 rural. Finally we obtained information on racial diversity of the universities from a website known as Priceonomics [58]. The website calculates the Herfindahl-Hirschman Index (HHI) by combining the race/ethnicity distribution of student bodies at different universities with data given from the Department of Education. HHI ranges from 1 (the least diverse: a population of all one type) to 1/N (the most diverse) where N is the number of different racial categories being analyzed. Social Media Data of Universities Next we obtained social media data of the above universities. Specifically we focused on the social media Reddit. Why Reddit? Reddit is known to be a widely used online forum and social media site among the college student demographic [23]. Due to its forum structure it is extensively used for both content sharing as well as for obtaining feedback and information from communities of interest. Reddit harbors a variety of communities known as “subreddits” including many dedicated to specific university campuses. This allows a large sample of posts shared by students of a university to be collected in one place. Our preliminary manual inspection of university subreddits (e.g. r/gatech or r/KState) revealed that these subreddits are appropriated by students to discuss college topics (Table 1). Focusing on these public Reddit communities also does not require explicit data collection efforts to be coordinated at each of the 150 university sites. Although more students are likely to use Facebook due to its largely privately shared content it is challenging to obtain access to a large dataset of a university’s students. Next while Twitter is also widely adopted without explicit self-reported information it is challenging to identify college student accounts. Finally prior work [2 18] notes that semianonymity of Reddit enables candid self disclosure around stigmatized topics like mental health. Initial Data Acquisition. We leveraged the archive of all of Reddit data made available on Google’s BigQuery [11]. BigQuery is a cloud based managed data warehouse that allows third parties to access large publicly available dataset through simple SQL-type queries. Our queries grabbed all posts ranging between June 2011 and February 2016 available in the Reddit data archive. This included 424984 posts from 153378 unique users across all of the 146 universities with a mean of 2910.8 posts ( = 4329.6) and 1050 unique users ( = 1407) per subreddit. Filling the Gaps in Subreddit Data. The second step of our data collection process focused on identifying subreddits with insufficient data and supplementing them through additional alternative data collection. Through Reddit’s official API (https://www.reddit.com/dev/api/) we obtained the most recent number of subscribers in the 146 university subreddits (as of July 2016). Then to investigate if and to what extent some subreddits may have had unusually low data as given in step 1 we determined the median unique user to subscriber ratio in each subreddit. This allows us to capture the subreddits where the subscriber count is high however the data obtained is not sufficiently representative. For subreddits with unique user to subscriber ratio under median (.42) (73 in all) we performed a one-time data collection using the Reddit API. This gave us a set of (at most) 1000 most recent posts for each subreddit with a total of 39824 posts added to the data obtained in step 1 following de-duplication. We note that this procedure did not skew the yearly distributions of data across the subreddits: The skew (yearly rate of change) before and after data filling were 4.86 and 5.05 respectively which were found to be statistically equivalent based on a two-sample equivalence test (p = .013 p = .025) a test that uses two one-sided t-tests on the before-after yearly rates of change from both sides of a chosen difference interval [1 1].,we first obtained a list of ranked major university in the united state by crawling the u news and world report website this list is constructed based on the carnegie classification employed extensively by higher education researcher and using a set of indicator of academic excellence defined by u news the list includes a variety of university spread across the u in different setting eg urban rural and with a wide range of student enrollment size figure a show their geographic distribution a a part of this crawl we also obtained university metadata gender distribution of student average tuition and fee and academic calendar semesterquarter to obtain further information about the nature of the student body we crawled the wikipedia page of all of the university from these page we extracted the size of student enrollment type publicprivate and setting ruralsuburbanurbancity at every institution these definition come from a formal categorization scheme used by the u department of education the student body enrollment size ranged from to with public and private university university were reported to be urban city suburban and rural finally we obtained information on racial diversity of the university from a website known a priceonomics the website calculates the herfindahlhirschman index hhi by combining the raceethnicity distribution of student body at different university with data given from the department of education hhi range from the least diverse a population of all one type to n the most diverse where n is the number of different racial category being analyzed social medium data of university next we obtained social medium data of the above university specifically we focused on the social medium reddit why reddit reddit is known to be a widely used online forum and social medium site among the college student demographic due to it forum structure it is extensively used for both content sharing a well a for obtaining feedback and information from community of interest reddit harbor a variety of community known a subreddits including many dedicated to specific university campus this allows a large sample of post shared by student of a university to be collected in one place our preliminary manual inspection of university subreddits eg rgatech or rkstate revealed that these subreddits are appropriated by student to discus college topic table focusing on these public reddit community also doe not require explicit data collection effort to be coordinated at each of the university site although more student are likely to use facebook due to it largely privately shared content it is challenging to obtain access to a large dataset of a university student next while twitter is also widely adopted without explicit selfreported information it is challenging to identify college student account finally prior work note that semianonymity of reddit enables candid self disclosure around stigmatized topic like mental health initial data acquisition we leveraged the archive of all of reddit data made available on google bigquery bigquery is a cloud based managed data warehouse that allows third party to access large publicly available dataset through simple sqltype query our query grabbed all post ranging between june and february available in the reddit data archive this included post from unique user across all of the university with a mean of post and unique user per subreddit filling the gap in subreddit data the second step of our data collection process focused on identifying subreddits with insufficient data and supplementing them through additional alternative data collection through reddits official api httpswwwredditcomdevapi we obtained the most recent number of subscriber in the university subreddits a of july then to investigate if and to what extent some subreddits may have had unusually low data a given in step we determined the median unique user to subscriber ratio in each subreddit this allows u to capture the subreddits where the subscriber count is high however the data obtained is not sufficiently representative for subreddits with unique user to subscriber ratio under median in all we performed a onetime data collection using the reddit api this gave u a set of at most most recent post for each subreddit with a total of post added to the data obtained in step following deduplication we note that this procedure did not skew the yearly distribution of data across the subreddits the skew yearly rate of change before and after data filling were and respectively which were found to be statistically equivalent based on a twosample equivalence test p p a test that us two onesided ttests on the beforeafter yearly rate of change from both side of a chosen difference interval,"['first', 'obtained', 'list', 'ranked', 'major', 'university', 'united', 'state', 'crawling', 'u', 'news', 'world', 'report', 'website', 'list', 'constructed', 'based', 'carnegie', 'classification', 'employed', 'extensively', 'higher', 'education', 'researcher', 'using', 'set', 'indicator', 'academic', 'excellence', 'defined', 'u', 'news', 'list', 'includes', 'variety', 'university', 'spread', 'across', 'u', 'different', 'setting', 'eg', 'urban', 'rural', 'wide', 'range', 'student', 'enrollment', 'size', 'figure', 'show', 'geographic', 'distribution', 'part', 'crawl', 'also', 'obtained', 'university', 'metadata', 'gender', 'distribution', 'student', 'average', 'tuition', 'fee', 'academic', 'calendar', 'semesterquarter', 'obtain', 'information', 'nature', 'student', 'body', 'crawled', 'wikipedia', 'page', 'university', 'page', 'extracted', 'size', 'student', 'enrollment', 'type', 'publicprivate', 'setting', 'ruralsuburbanurbancity', 'every', 'institution', 'definition', 'come', 'formal', 'categorization', 'scheme', 'u', 'department', 'education', 'student', 'body', 'enrollment', 'size', 'ranged', 'public', 'private', 'university', 'university', 'reported', 'urban', 'city', 'suburban', 'rural', 'finally', 'obtained', 'information', 'racial', 'diversity', 'university', 'website', 'known', 'priceonomics', 'website', 'calculates', 'herfindahlhirschman', 'index', 'hhi', 'combining', 'raceethnicity', 'distribution', 'student', 'body', 'different', 'university', 'given', 'department', 'education', 'hhi', 'range', 'least', 'diverse', 'population', 'one', 'type', 'n', 'diverse', 'n', 'number', 'different', 'racial', 'category', 'analyzed', 'social', 'medium', 'university', 'next', 'obtained', 'social', 'medium', 'university', 'specifically', 'focused', 'social', 'medium', 'reddit', 'reddit', 'reddit', 'known', 'widely', 'online', 'forum', 'social', 'medium', 'site', 'among', 'college', 'student', 'demographic', 'due', 'forum', 'structure', 'extensively', 'content', 'sharing', 'well', 'obtaining', 'feedback', 'information', 'community', 'interest', 'reddit', 'harbor', 'variety', 'community', 'known', 'subreddits', 'including', 'many', 'dedicated', 'specific', 'university', 'campus', 'allows', 'large', 'sample', 'shared', 'student', 'university', 'collected', 'one', 'place', 'preliminary', 'manual', 'inspection', 'university', 'subreddits', 'eg', 'rgatech', 'rkstate', 'revealed', 'subreddits', 'appropriated', 'student', 'discus', 'college', 'topic', 'table', 'focusing', 'public', 'reddit', 'community', 'also', 'doe', 'require', 'explicit', 'collection', 'effort', 'coordinated', 'university', 'site', 'although', 'student', 'likely', 'use', 'facebook', 'due', 'largely', 'privately', 'shared', 'content', 'challenging', 'obtain', 'access', 'large', 'dataset', 'university', 'student', 'next', 'also', 'widely', 'adopted', 'without', 'explicit', 'selfreported', 'information', 'challenging', 'identify', 'college', 'student', 'account', 'finally', 'prior', 'work', 'note', 'semianonymity', 'reddit', 'enables', 'candid', 'self', 'disclosure', 'around', 'stigmatized', 'topic', 'like', 'initial', 'acquisition', 'leveraged', 'archive', 'reddit', 'made', 'available', 'google', 'bigquery', 'bigquery', 'cloud', 'based', 'managed', 'warehouse', 'allows', 'third', 'party', 'access', 'large', 'publicly', 'available', 'dataset', 'simple', 'sqltype', 'query', 'query', 'grabbed', 'ranging', 'june', 'february', 'available', 'reddit', 'archive', 'included', 'unique', 'across', 'university', 'mean', 'unique', 'per', 'subreddit', 'filling', 'gap', 'subreddit', 'second', 'step', 'collection', 'process', 'focused', 'identifying', 'subreddits', 'insufficient', 'supplementing', 'additional', 'alternative', 'collection', 'reddits', 'official', 'api', 'httpswwwredditcomdevapi', 'obtained', 'recent', 'number', 'subscriber', 'university', 'subreddits', 'july', 'investigate', 'extent', 'subreddits', 'may', 'unusually', 'low', 'given', 'step', 'determined', 'median', 'unique', 'subscriber', 'ratio', 'subreddit', 'allows', 'u', 'capture', 'subreddits', 'subscriber', 'count', 'high', 'however', 'obtained', 'sufficiently', 'representative', 'subreddits', 'unique', 'subscriber', 'ratio', 'median', 'performed', 'onetime', 'collection', 'using', 'reddit', 'api', 'gave', 'u', 'set', 'recent', 'subreddit', 'total', 'added', 'obtained', 'step', 'following', 'deduplication', 'note', 'procedure', 'skew', 'yearly', 'distribution', 'across', 'subreddits', 'skew', 'yearly', 'rate', 'change', 'filling', 'respectively', 'found', 'statistically', 'equivalent', 'based', 'twosample', 'equivalence', 'test', 'p', 'p', 'test', 'us', 'two', 'onesided', 'ttests', 'beforeafter', 'yearly', 'rate', 'change', 'side', 'chosen', 'difference', 'interval']","['first obtained', 'obtained list', 'list ranked', 'ranked major', 'major university', 'university united', 'united state', 'state crawling', 'crawling u', 'u news', 'news world', 'world report', 'report website', 'website list', 'list constructed', 'constructed based', 'based carnegie', 'carnegie classification', 'classification employed', 'employed extensively', 'extensively higher', 'higher education', 'education researcher', 'researcher using', 'using set', 'set indicator', 'indicator academic', 'academic excellence', 'excellence defined', 'defined u', 'u news', 'news list', 'list includes', 'includes variety', 'variety university', 'university spread', 'spread across', 'across u', 'u different', 'different setting', 'setting eg', 'eg urban', 'urban rural', 'rural wide', 'wide range', 'range student', 'student enrollment', 'enrollment size', 'size figure', 'figure show', 'show geographic', 'geographic distribution', 'distribution part', 'part crawl', 'crawl also', 'also obtained', 'obtained university', 'university metadata', 'metadata gender', 'gender distribution', 'distribution student', 'student average', 'average tuition', 'tuition fee', 'fee academic', 'academic calendar', 'calendar semesterquarter', 'semesterquarter obtain', 'obtain information', 'information nature', 'nature student', 'student body', 'body crawled', 'crawled wikipedia', 'wikipedia page', 'page university', 'university page', 'page extracted', 'extracted size', 'size student', 'student enrollment', 'enrollment type', 'type publicprivate', 'publicprivate setting', 'setting ruralsuburbanurbancity', 'ruralsuburbanurbancity every', 'every institution', 'institution definition', 'definition come', 'come formal', 'formal categorization', 'categorization scheme', 'scheme u', 'u department', 'department education', 'education student', 'student body', 'body enrollment', 'enrollment size', 'size ranged', 'ranged public', 'public private', 'private university', 'university university', 'university reported', 'reported urban', 'urban city', 'city suburban', 'suburban rural', 'rural finally', 'finally obtained', 'obtained information', 'information racial', 'racial diversity', 'diversity university', 'university website', 'website known', 'known priceonomics', 'priceonomics website', 'website calculates', 'calculates herfindahlhirschman', 'herfindahlhirschman index', 'index hhi', 'hhi combining', 'combining raceethnicity', 'raceethnicity distribution', 'distribution student', 'student body', 'body different', 'different university', 'university given', 'given department', 'department education', 'education hhi', 'hhi range', 'range least', 'least diverse', 'diverse population', 'population one', 'one type', 'type n', 'n diverse', 'diverse n', 'n number', 'number different', 'different racial', 'racial category', 'category analyzed', 'analyzed social', 'social medium', 'medium university', 'university next', 'next obtained', 'obtained social', 'social medium', 'medium university', 'university specifically', 'specifically focused', 'focused social', 'social medium', 'medium reddit', 'reddit reddit', 'reddit reddit', 'reddit known', 'known widely', 'widely online', 'online forum', 'forum social', 'social medium', 'medium site', 'site among', 'among college', 'college student', 'student demographic', 'demographic due', 'due forum', 'forum structure', 'structure extensively', 'extensively content', 'content sharing', 'sharing well', 'well obtaining', 'obtaining feedback', 'feedback information', 'information community', 'community interest', 'interest reddit', 'reddit harbor', 'harbor variety', 'variety community', 'community known', 'known subreddits', 'subreddits including', 'including many', 'many dedicated', 'dedicated specific', 'specific university', 'university campus', 'campus allows', 'allows large', 'large sample', 'sample shared', 'shared student', 'student university', 'university collected', 'collected one', 'one place', 'place preliminary', 'preliminary manual', 'manual inspection', 'inspection university', 'university subreddits', 'subreddits eg', 'eg rgatech', 'rgatech rkstate', 'rkstate revealed', 'revealed subreddits', 'subreddits appropriated', 'appropriated student', 'student discus', 'discus college', 'college topic', 'topic table', 'table focusing', 'focusing public', 'public reddit', 'reddit community', 'community also', 'also doe', 'doe require', 'require explicit', 'explicit collection', 'collection effort', 'effort coordinated', 'coordinated university', 'university site', 'site although', 'although student', 'student likely', 'likely use', 'use facebook', 'facebook due', 'due largely', 'largely privately', 'privately shared', 'shared content', 'content challenging', 'challenging obtain', 'obtain access', 'access large', 'large dataset', 'dataset university', 'university student', 'student next', 'next also', 'also widely', 'widely adopted', 'adopted without', 'without explicit', 'explicit selfreported', 'selfreported information', 'information challenging', 'challenging identify', 'identify college', 'college student', 'student account', 'account finally', 'finally prior', 'prior work', 'work note', 'note semianonymity', 'semianonymity reddit', 'reddit enables', 'enables candid', 'candid self', 'self disclosure', 'disclosure around', 'around stigmatized', 'stigmatized topic', 'topic like', 'like initial', 'initial acquisition', 'acquisition leveraged', 'leveraged archive', 'archive reddit', 'reddit made', 'made available', 'available google', 'google bigquery', 'bigquery bigquery', 'bigquery cloud', 'cloud based', 'based managed', 'managed warehouse', 'warehouse allows', 'allows third', 'third party', 'party access', 'access large', 'large publicly', 'publicly available', 'available dataset', 'dataset simple', 'simple sqltype', 'sqltype query', 'query query', 'query grabbed', 'grabbed ranging', 'ranging june', 'june february', 'february available', 'available reddit', 'reddit archive', 'archive included', 'included unique', 'unique across', 'across university', 'university mean', 'mean unique', 'unique per', 'per subreddit', 'subreddit filling', 'filling gap', 'gap subreddit', 'subreddit second', 'second step', 'step collection', 'collection process', 'process focused', 'focused identifying', 'identifying subreddits', 'subreddits insufficient', 'insufficient supplementing', 'supplementing additional', 'additional alternative', 'alternative collection', 'collection reddits', 'reddits official', 'official api', 'api httpswwwredditcomdevapi', 'httpswwwredditcomdevapi obtained', 'obtained recent', 'recent number', 'number subscriber', 'subscriber university', 'university subreddits', 'subreddits july', 'july investigate', 'investigate extent', 'extent subreddits', 'subreddits may', 'may unusually', 'unusually low', 'low given', 'given step', 'step determined', 'determined median', 'median unique', 'unique subscriber', 'subscriber ratio', 'ratio subreddit', 'subreddit allows', 'allows u', 'u capture', 'capture subreddits', 'subreddits subscriber', 'subscriber count', 'count high', 'high however', 'however obtained', 'obtained sufficiently', 'sufficiently representative', 'representative subreddits', 'subreddits unique', 'unique subscriber', 'subscriber ratio', 'ratio median', 'median performed', 'performed onetime', 'onetime collection', 'collection using', 'using reddit', 'reddit api', 'api gave', 'gave u', 'u set', 'set recent', 'recent subreddit', 'subreddit total', 'total added', 'added obtained', 'obtained step', 'step following', 'following deduplication', 'deduplication note', 'note procedure', 'procedure skew', 'skew yearly', 'yearly distribution', 'distribution across', 'across subreddits', 'subreddits skew', 'skew yearly', 'yearly rate', 'rate change', 'change filling', 'filling respectively', 'respectively found', 'found statistically', 'statistically equivalent', 'equivalent based', 'based twosample', 'twosample equivalence', 'equivalence test', 'test p', 'p p', 'p test', 'test us', 'us two', 'two onesided', 'onesided ttests', 'ttests beforeafter', 'beforeafter yearly', 'yearly rate', 'rate change', 'change side', 'side chosen', 'chosen difference', 'difference interval']","['first obtained list', 'obtained list ranked', 'list ranked major', 'ranked major university', 'major university united', 'university united state', 'united state crawling', 'state crawling u', 'crawling u news', 'u news world', 'news world report', 'world report website', 'report website list', 'website list constructed', 'list constructed based', 'constructed based carnegie', 'based carnegie classification', 'carnegie classification employed', 'classification employed extensively', 'employed extensively higher', 'extensively higher education', 'higher education researcher', 'education researcher using', 'researcher using set', 'using set indicator', 'set indicator academic', 'indicator academic excellence', 'academic excellence defined', 'excellence defined u', 'defined u news', 'u news list', 'news list includes', 'list includes variety', 'includes variety university', 'variety university spread', 'university spread across', 'spread across u', 'across u different', 'u different setting', 'different setting eg', 'setting eg urban', 'eg urban rural', 'urban rural wide', 'rural wide range', 'wide range student', 'range student enrollment', 'student enrollment size', 'enrollment size figure', 'size figure show', 'figure show geographic', 'show geographic distribution', 'geographic distribution part', 'distribution part crawl', 'part crawl also', 'crawl also obtained', 'also obtained university', 'obtained university metadata', 'university metadata gender', 'metadata gender distribution', 'gender distribution student', 'distribution student average', 'student average tuition', 'average tuition fee', 'tuition fee academic', 'fee academic calendar', 'academic calendar semesterquarter', 'calendar semesterquarter obtain', 'semesterquarter obtain information', 'obtain information nature', 'information nature student', 'nature student body', 'student body crawled', 'body crawled wikipedia', 'crawled wikipedia page', 'wikipedia page university', 'page university page', 'university page extracted', 'page extracted size', 'extracted size student', 'size student enrollment', 'student enrollment type', 'enrollment type publicprivate', 'type publicprivate setting', 'publicprivate setting ruralsuburbanurbancity', 'setting ruralsuburbanurbancity every', 'ruralsuburbanurbancity every institution', 'every institution definition', 'institution definition come', 'definition come formal', 'come formal categorization', 'formal categorization scheme', 'categorization scheme u', 'scheme u department', 'u department education', 'department education student', 'education student body', 'student body enrollment', 'body enrollment size', 'enrollment size ranged', 'size ranged public', 'ranged public private', 'public private university', 'private university university', 'university university reported', 'university reported urban', 'reported urban city', 'urban city suburban', 'city suburban rural', 'suburban rural finally', 'rural finally obtained', 'finally obtained information', 'obtained information racial', 'information racial diversity', 'racial diversity university', 'diversity university website', 'university website known', 'website known priceonomics', 'known priceonomics website', 'priceonomics website calculates', 'website calculates herfindahlhirschman', 'calculates herfindahlhirschman index', 'herfindahlhirschman index hhi', 'index hhi combining', 'hhi combining raceethnicity', 'combining raceethnicity distribution', 'raceethnicity distribution student', 'distribution student body', 'student body different', 'body different university', 'different university given', 'university given department', 'given department education', 'department education hhi', 'education hhi range', 'hhi range least', 'range least diverse', 'least diverse population', 'diverse population one', 'population one type', 'one type n', 'type n diverse', 'n diverse n', 'diverse n number', 'n number different', 'number different racial', 'different racial category', 'racial category analyzed', 'category analyzed social', 'analyzed social medium', 'social medium university', 'medium university next', 'university next obtained', 'next obtained social', 'obtained social medium', 'social medium university', 'medium university specifically', 'university specifically focused', 'specifically focused social', 'focused social medium', 'social medium reddit', 'medium reddit reddit', 'reddit reddit reddit', 'reddit reddit known', 'reddit known widely', 'known widely online', 'widely online forum', 'online forum social', 'forum social medium', 'social medium site', 'medium site among', 'site among college', 'among college student', 'college student demographic', 'student demographic due', 'demographic due forum', 'due forum structure', 'forum structure extensively', 'structure extensively content', 'extensively content sharing', 'content sharing well', 'sharing well obtaining', 'well obtaining feedback', 'obtaining feedback information', 'feedback information community', 'information community interest', 'community interest reddit', 'interest reddit harbor', 'reddit harbor variety', 'harbor variety community', 'variety community known', 'community known subreddits', 'known subreddits including', 'subreddits including many', 'including many dedicated', 'many dedicated specific', 'dedicated specific university', 'specific university campus', 'university campus allows', 'campus allows large', 'allows large sample', 'large sample shared', 'sample shared student', 'shared student university', 'student university collected', 'university collected one', 'collected one place', 'one place preliminary', 'place preliminary manual', 'preliminary manual inspection', 'manual inspection university', 'inspection university subreddits', 'university subreddits eg', 'subreddits eg rgatech', 'eg rgatech rkstate', 'rgatech rkstate revealed', 'rkstate revealed subreddits', 'revealed subreddits appropriated', 'subreddits appropriated student', 'appropriated student discus', 'student discus college', 'discus college topic', 'college topic table', 'topic table focusing', 'table focusing public', 'focusing public reddit', 'public reddit community', 'reddit community also', 'community also doe', 'also doe require', 'doe require explicit', 'require explicit collection', 'explicit collection effort', 'collection effort coordinated', 'effort coordinated university', 'coordinated university site', 'university site although', 'site although student', 'although student likely', 'student likely use', 'likely use facebook', 'use facebook due', 'facebook due largely', 'due largely privately', 'largely privately shared', 'privately shared content', 'shared content challenging', 'content challenging obtain', 'challenging obtain access', 'obtain access large', 'access large dataset', 'large dataset university', 'dataset university student', 'university student next', 'student next also', 'next also widely', 'also widely adopted', 'widely adopted without', 'adopted without explicit', 'without explicit selfreported', 'explicit selfreported information', 'selfreported information challenging', 'information challenging identify', 'challenging identify college', 'identify college student', 'college student account', 'student account finally', 'account finally prior', 'finally prior work', 'prior work note', 'work note semianonymity', 'note semianonymity reddit', 'semianonymity reddit enables', 'reddit enables candid', 'enables candid self', 'candid self disclosure', 'self disclosure around', 'disclosure around stigmatized', 'around stigmatized topic', 'stigmatized topic like', 'topic like initial', 'like initial acquisition', 'initial acquisition leveraged', 'acquisition leveraged archive', 'leveraged archive reddit', 'archive reddit made', 'reddit made available', 'made available google', 'available google bigquery', 'google bigquery bigquery', 'bigquery bigquery cloud', 'bigquery cloud based', 'cloud based managed', 'based managed warehouse', 'managed warehouse allows', 'warehouse allows third', 'allows third party', 'third party access', 'party access large', 'access large publicly', 'large publicly available', 'publicly available dataset', 'available dataset simple', 'dataset simple sqltype', 'simple sqltype query', 'sqltype query query', 'query query grabbed', 'query grabbed ranging', 'grabbed ranging june', 'ranging june february', 'june february available', 'february available reddit', 'available reddit archive', 'reddit archive included', 'archive included unique', 'included unique across', 'unique across university', 'across university mean', 'university mean unique', 'mean unique per', 'unique per subreddit', 'per subreddit filling', 'subreddit filling gap', 'filling gap subreddit', 'gap subreddit second', 'subreddit second step', 'second step collection', 'step collection process', 'collection process focused', 'process focused identifying', 'focused identifying subreddits', 'identifying subreddits insufficient', 'subreddits insufficient supplementing', 'insufficient supplementing additional', 'supplementing additional alternative', 'additional alternative collection', 'alternative collection reddits', 'collection reddits official', 'reddits official api', 'official api httpswwwredditcomdevapi', 'api httpswwwredditcomdevapi obtained', 'httpswwwredditcomdevapi obtained recent', 'obtained recent number', 'recent number subscriber', 'number subscriber university', 'subscriber university subreddits', 'university subreddits july', 'subreddits july investigate', 'july investigate extent', 'investigate extent subreddits', 'extent subreddits may', 'subreddits may unusually', 'may unusually low', 'unusually low given', 'low given step', 'given step determined', 'step determined median', 'determined median unique', 'median unique subscriber', 'unique subscriber ratio', 'subscriber ratio subreddit', 'ratio subreddit allows', 'subreddit allows u', 'allows u capture', 'u capture subreddits', 'capture subreddits subscriber', 'subreddits subscriber count', 'subscriber count high', 'count high however', 'high however obtained', 'however obtained sufficiently', 'obtained sufficiently representative', 'sufficiently representative subreddits', 'representative subreddits unique', 'subreddits unique subscriber', 'unique subscriber ratio', 'subscriber ratio median', 'ratio median performed', 'median performed onetime', 'performed onetime collection', 'onetime collection using', 'collection using reddit', 'using reddit api', 'reddit api gave', 'api gave u', 'gave u set', 'u set recent', 'set recent subreddit', 'recent subreddit total', 'subreddit total added', 'total added obtained', 'added obtained step', 'obtained step following', 'step following deduplication', 'following deduplication note', 'deduplication note procedure', 'note procedure skew', 'procedure skew yearly', 'skew yearly distribution', 'yearly distribution across', 'distribution across subreddits', 'across subreddits skew', 'subreddits skew yearly', 'skew yearly rate', 'yearly rate change', 'rate change filling', 'change filling respectively', 'filling respectively found', 'respectively found statistically', 'found statistically equivalent', 'statistically equivalent based', 'equivalent based twosample', 'based twosample equivalence', 'twosample equivalence test', 'equivalence test p', 'test p p', 'p p test', 'p test us', 'test us two', 'us two onesided', 'two onesided ttests', 'onesided ttests beforeafter', 'ttests beforeafter yearly', 'beforeafter yearly rate', 'yearly rate change', 'rate change side', 'change side chosen', 'side chosen difference', 'chosen difference interval']"
https://ieeexplore.ieee.org/abstract/document/7752434,0,To train our models we require information from two different types of users: patients and non-patients. Therefore we employed a combined - manual effort and keyword matching - data collection approach to efficiently collect data for these users. For the collection of patients we manually collect the community portals relevant to both mental disorders. 2 From these portals' followers list we select the self-reported users who explicitly state in their profile description that they suffer from a mental illness; i.e. for a given user we are checking if his/her profile contains any keyword related to a target disorder (e.g. “borderline” “bpd” “bipolar”). Non-patients are referred to as random active Twitter users who are not explicitly stating that they are suffering from Bipolar disorder (hereinafter referred to as “BD”) or Borderline Personality Disorder (hereinafter referred to as “BPD”). To obtain these users we randomly sampled Twitter IDs. Thereafter we proceeded to download the tweets from the selected IDs. After the users have been identified we manually label them into one of two categories: 1) Patient: a person who is suffering from a mental disorder 2) Not-related: any user who we don't consider to be a patient. Lastly after having obtained the final list of patients we retrieve their tweets. These steps are applied for the collection of both BPD and BD patient datasets.,to train our model we require information from two different type of user patient and nonpatients therefore we employed a combined manual effort and keyword matching data collection approach to efficiently collect data for these user for the collection of patient we manually collect the community portal relevant to both mental disorder from these portal follower list we select the selfreported user who explicitly state in their profile description that they suffer from a mental illness ie for a given user we are checking if hisher profile contains any keyword related to a target disorder eg borderline bpd bipolar nonpatients are referred to a random active twitter user who are not explicitly stating that they are suffering from bipolar disorder hereinafter referred to a bd or borderline personality disorder hereinafter referred to a bpd to obtain these user we randomly sampled twitter id thereafter we proceeded to download the tweet from the selected id after the user have been identified we manually label them into one of two category patient a person who is suffering from a mental disorder notrelated any user who we dont consider to be a patient lastly after having obtained the final list of patient we retrieve their tweet these step are applied for the collection of both bpd and bd patient datasets,"['train', 'model', 'require', 'information', 'two', 'different', 'type', 'patient', 'nonpatients', 'therefore', 'employed', 'combined', 'manual', 'effort', 'keyword', 'matching', 'collection', 'approach', 'efficiently', 'collect', 'collection', 'patient', 'manually', 'collect', 'community', 'portal', 'relevant', 'disorder', 'portal', 'follower', 'list', 'select', 'selfreported', 'explicitly', 'state', 'profile', 'description', 'suffer', 'illness', 'ie', 'given', 'checking', 'hisher', 'profile', 'contains', 'keyword', 'related', 'target', 'disorder', 'eg', 'borderline', 'bpd', 'bipolar', 'nonpatients', 'referred', 'random', 'active', 'explicitly', 'stating', 'suffering', 'bipolar', 'disorder', 'hereinafter', 'referred', 'bd', 'borderline', 'personality', 'disorder', 'hereinafter', 'referred', 'bpd', 'obtain', 'randomly', 'sampled', 'id', 'thereafter', 'proceeded', 'download', 'selected', 'id', 'identified', 'manually', 'label', 'one', 'two', 'category', 'patient', 'person', 'suffering', 'disorder', 'notrelated', 'dont', 'consider', 'patient', 'lastly', 'obtained', 'final', 'list', 'patient', 'retrieve', 'step', 'applied', 'collection', 'bpd', 'bd', 'patient', 'datasets']","['train model', 'model require', 'require information', 'information two', 'two different', 'different type', 'type patient', 'patient nonpatients', 'nonpatients therefore', 'therefore employed', 'employed combined', 'combined manual', 'manual effort', 'effort keyword', 'keyword matching', 'matching collection', 'collection approach', 'approach efficiently', 'efficiently collect', 'collect collection', 'collection patient', 'patient manually', 'manually collect', 'collect community', 'community portal', 'portal relevant', 'relevant disorder', 'disorder portal', 'portal follower', 'follower list', 'list select', 'select selfreported', 'selfreported explicitly', 'explicitly state', 'state profile', 'profile description', 'description suffer', 'suffer illness', 'illness ie', 'ie given', 'given checking', 'checking hisher', 'hisher profile', 'profile contains', 'contains keyword', 'keyword related', 'related target', 'target disorder', 'disorder eg', 'eg borderline', 'borderline bpd', 'bpd bipolar', 'bipolar nonpatients', 'nonpatients referred', 'referred random', 'random active', 'active explicitly', 'explicitly stating', 'stating suffering', 'suffering bipolar', 'bipolar disorder', 'disorder hereinafter', 'hereinafter referred', 'referred bd', 'bd borderline', 'borderline personality', 'personality disorder', 'disorder hereinafter', 'hereinafter referred', 'referred bpd', 'bpd obtain', 'obtain randomly', 'randomly sampled', 'sampled id', 'id thereafter', 'thereafter proceeded', 'proceeded download', 'download selected', 'selected id', 'id identified', 'identified manually', 'manually label', 'label one', 'one two', 'two category', 'category patient', 'patient person', 'person suffering', 'suffering disorder', 'disorder notrelated', 'notrelated dont', 'dont consider', 'consider patient', 'patient lastly', 'lastly obtained', 'obtained final', 'final list', 'list patient', 'patient retrieve', 'retrieve step', 'step applied', 'applied collection', 'collection bpd', 'bpd bd', 'bd patient', 'patient datasets']","['train model require', 'model require information', 'require information two', 'information two different', 'two different type', 'different type patient', 'type patient nonpatients', 'patient nonpatients therefore', 'nonpatients therefore employed', 'therefore employed combined', 'employed combined manual', 'combined manual effort', 'manual effort keyword', 'effort keyword matching', 'keyword matching collection', 'matching collection approach', 'collection approach efficiently', 'approach efficiently collect', 'efficiently collect collection', 'collect collection patient', 'collection patient manually', 'patient manually collect', 'manually collect community', 'collect community portal', 'community portal relevant', 'portal relevant disorder', 'relevant disorder portal', 'disorder portal follower', 'portal follower list', 'follower list select', 'list select selfreported', 'select selfreported explicitly', 'selfreported explicitly state', 'explicitly state profile', 'state profile description', 'profile description suffer', 'description suffer illness', 'suffer illness ie', 'illness ie given', 'ie given checking', 'given checking hisher', 'checking hisher profile', 'hisher profile contains', 'profile contains keyword', 'contains keyword related', 'keyword related target', 'related target disorder', 'target disorder eg', 'disorder eg borderline', 'eg borderline bpd', 'borderline bpd bipolar', 'bpd bipolar nonpatients', 'bipolar nonpatients referred', 'nonpatients referred random', 'referred random active', 'random active explicitly', 'active explicitly stating', 'explicitly stating suffering', 'stating suffering bipolar', 'suffering bipolar disorder', 'bipolar disorder hereinafter', 'disorder hereinafter referred', 'hereinafter referred bd', 'referred bd borderline', 'bd borderline personality', 'borderline personality disorder', 'personality disorder hereinafter', 'disorder hereinafter referred', 'hereinafter referred bpd', 'referred bpd obtain', 'bpd obtain randomly', 'obtain randomly sampled', 'randomly sampled id', 'sampled id thereafter', 'id thereafter proceeded', 'thereafter proceeded download', 'proceeded download selected', 'download selected id', 'selected id identified', 'id identified manually', 'identified manually label', 'manually label one', 'label one two', 'one two category', 'two category patient', 'category patient person', 'patient person suffering', 'person suffering disorder', 'suffering disorder notrelated', 'disorder notrelated dont', 'notrelated dont consider', 'dont consider patient', 'consider patient lastly', 'patient lastly obtained', 'lastly obtained final', 'obtained final list', 'final list patient', 'list patient retrieve', 'patient retrieve step', 'retrieve step applied', 'step applied collection', 'applied collection bpd', 'collection bpd bd', 'bpd bd patient', 'bd patient datasets']"
https://www.nature.com/articles/s41598-020-68764-y,1,Detecting mental illness problems in early stages and providing appropriate solutions can help potential mental disorder sufferers23. By collecting and analyzing data from mental-health-related subreddits in Reddit that focus on mental disorder issues we introduced a deep learning model with natural language processing methods to identify the users with potential mental illness based on their posts. We believe that our method can open up a new research era where online social media can play a role as an efficient source for identifying potential mental illness based on users’ specific posts24. However a majority of people who may have mental illness are still in social blind spots and lacks appropriate treatment due to several reasons such as difficulty in revealing their status to someone in person or having difficulties in physically accessing the clinics23. Based on the lessons learned the following implications are presented. First deep learning approaches with appropriate natural language processing methods can be used to detect users’ potential mental illnesses by their posts. With the employment of easily accessible social media data the approaches used in this study can be adopted to alert the users who may be suffered from specific mental disorders before they visit counseling centers. Second this study provides notable evidence supporting the possibility of utilizing online platforms that can help people in need of mental treatment. Specifically for example online platform service providers may ask a user’s consent first to access one’s account and if agreed can provide the probabilities of each mental disorder predicted through our validated models based on the user’s posts. Lastly the current study suggests detecting mental illness in social media can be a prominent research area in the future. The findings of the current study reveal the potential for social media platforms that can play a role in providing a space to interact with others who are suffered by mental disorder. However there are a few limitations in this study. The current study did not consider several factors (e.g. socio-demographic and regional differences) that could affect the classification models. These factors can be considered in future research which can improve the quality or accuracy of the deep learning models. In addition we collected the data from the public social media Reddit which may be different from the personal feed of social network services in expressing users’ emotions. We did not conduct additional validation procedures of our model with another independent dataset as mentioned above which would need to be further investigated. Although postings in online social media could not explicitly tell the symptoms compared to posts in users’ personal pages that may say they are diagnosed with clinical mental illnesses online social media have a potential to be used to identify mental disorder sufferers because they share their symptoms relatively accurately under the semi-anonymity system. Also we trained our model on a specific mental state to directly classify the symptom and provide the predicted probabilities for each symptom. In this way we could not accurately measure the co-morbid mental illness status which is left for future work. In future study we could adopt an ensemble approach with our multiple binary classification models which can be utilized to identify the real-world mental conditions such as co-morbid illness. We also plan to validate our proposed model in posts of users who may have uncertain mental disease in other social network services such as Facebook or Twitter. In addition a time-series user-level analysis that tracks a users’ longitudinal behavior pattern can help to develop a user-level detection model for mental illness using a recurrent neural network. Based on the lessons learned the following implications are presented. First deep learning approaches with appropriate natural language processing methods can be used to detect users’ potential mental illnesses by their posts. With the employment of easily accessible social media data the approaches used in this study can be adopted to alert the users who may be suffered from specific mental disorders before they visit counseling centers. Second this study provides notable evidence supporting the possibility of utilizing online platforms that can help people in need of mental treatment. Specifically for example online platform service providers may ask a user’s consent first to access one’s account and if agreed can provide the probabilities of each mental disorder predicted through our validated models based on the user’s posts. Lastly the current study suggests detecting mental illness in social media can be a prominent research area in the future. The findings of the current study reveal the potential for social media platforms that can play a role in providing a space to interact with others who are suffered by mental disorder. However there are a few limitations in this study. The current study did not consider several factors (e.g. socio-demographic and regional differences) that could affect the classification models. These factors can be considered in future research which can improve the quality or accuracy of the deep learning models. In addition we collected the data from the public social media Reddit which may be different from the personal feed of social network services in expressing users’ emotions. We did not conduct additional validation procedures of our model with another independent dataset as mentioned above which would need to be further investigated. Although postings in online social media could not explicitly tell the symptoms compared to posts in users’ personal pages that may say they are diagnosed with clinical mental illnesses online social media have a potential to be used to identify mental disorder sufferers because they share their symptoms relatively accurately under the semi-anonymity system. Also we trained our model on a specific mental state to directly classify the symptom and provide the predicted probabilities for each symptom. In this way we could not accurately measure the co-morbid mental illness status which is left for future work. In future study we could adopt an ensemble approach with our multiple binary classification models which can be utilized to identify the real-world mental conditions such as co-morbid illness. We also plan to validate our proposed model in posts of users who may have uncertain mental disease in other social network services such as Facebook or Twitter. In addition a time-series user-level analysis that tracks a users’ longitudinal behavior pattern can help to develop a user-level detection model for mental illness using a recurrent neural network.,detecting mental illness problem in early stage and providing appropriate solution can help potential mental disorder sufferer by collecting and analyzing data from mentalhealthrelated subreddits in reddit that focus on mental disorder issue we introduced a deep learning model with natural language processing method to identify the user with potential mental illness based on their post we believe that our method can open up a new research era where online social medium can play a role a an efficient source for identifying potential mental illness based on user specific post however a majority of people who may have mental illness are still in social blind spot and lack appropriate treatment due to several reason such a difficulty in revealing their status to someone in person or having difficulty in physically accessing the clinic based on the lesson learned the following implication are presented first deep learning approach with appropriate natural language processing method can be used to detect user potential mental illness by their post with the employment of easily accessible social medium data the approach used in this study can be adopted to alert the user who may be suffered from specific mental disorder before they visit counseling center second this study provides notable evidence supporting the possibility of utilizing online platform that can help people in need of mental treatment specifically for example online platform service provider may ask a user consent first to access one account and if agreed can provide the probability of each mental disorder predicted through our validated model based on the user post lastly the current study suggests detecting mental illness in social medium can be a prominent research area in the future the finding of the current study reveal the potential for social medium platform that can play a role in providing a space to interact with others who are suffered by mental disorder however there are a few limitation in this study the current study did not consider several factor eg sociodemographic and regional difference that could affect the classification model these factor can be considered in future research which can improve the quality or accuracy of the deep learning model in addition we collected the data from the public social medium reddit which may be different from the personal feed of social network service in expressing user emotion we did not conduct additional validation procedure of our model with another independent dataset a mentioned above which would need to be further investigated although posting in online social medium could not explicitly tell the symptom compared to post in user personal page that may say they are diagnosed with clinical mental illness online social medium have a potential to be used to identify mental disorder sufferer because they share their symptom relatively accurately under the semianonymity system also we trained our model on a specific mental state to directly classify the symptom and provide the predicted probability for each symptom in this way we could not accurately measure the comorbid mental illness status which is left for future work in future study we could adopt an ensemble approach with our multiple binary classification model which can be utilized to identify the realworld mental condition such a comorbid illness we also plan to validate our proposed model in post of user who may have uncertain mental disease in other social network service such a facebook or twitter in addition a timeseries userlevel analysis that track a user longitudinal behavior pattern can help to develop a userlevel detection model for mental illness using a recurrent neural network based on the lesson learned the following implication are presented first deep learning approach with appropriate natural language processing method can be used to detect user potential mental illness by their post with the employment of easily accessible social medium data the approach used in this study can be adopted to alert the user who may be suffered from specific mental disorder before they visit counseling center second this study provides notable evidence supporting the possibility of utilizing online platform that can help people in need of mental treatment specifically for example online platform service provider may ask a user consent first to access one account and if agreed can provide the probability of each mental disorder predicted through our validated model based on the user post lastly the current study suggests detecting mental illness in social medium can be a prominent research area in the future the finding of the current study reveal the potential for social medium platform that can play a role in providing a space to interact with others who are suffered by mental disorder however there are a few limitation in this study the current study did not consider several factor eg sociodemographic and regional difference that could affect the classification model these factor can be considered in future research which can improve the quality or accuracy of the deep learning model in addition we collected the data from the public social medium reddit which may be different from the personal feed of social network service in expressing user emotion we did not conduct additional validation procedure of our model with another independent dataset a mentioned above which would need to be further investigated although posting in online social medium could not explicitly tell the symptom compared to post in user personal page that may say they are diagnosed with clinical mental illness online social medium have a potential to be used to identify mental disorder sufferer because they share their symptom relatively accurately under the semianonymity system also we trained our model on a specific mental state to directly classify the symptom and provide the predicted probability for each symptom in this way we could not accurately measure the comorbid mental illness status which is left for future work in future study we could adopt an ensemble approach with our multiple binary classification model which can be utilized to identify the realworld mental condition such a comorbid illness we also plan to validate our proposed model in post of user who may have uncertain mental disease in other social network service such a facebook or twitter in addition a timeseries userlevel analysis that track a user longitudinal behavior pattern can help to develop a userlevel detection model for mental illness using a recurrent neural network,"['detecting', 'illness', 'problem', 'early', 'stage', 'providing', 'appropriate', 'solution', 'help', 'potential', 'disorder', 'sufferer', 'collecting', 'analyzing', 'mentalhealthrelated', 'subreddits', 'reddit', 'focus', 'disorder', 'issue', 'introduced', 'deep', 'learning', 'model', 'natural', 'language', 'processing', 'method', 'identify', 'potential', 'illness', 'based', 'believe', 'method', 'open', 'new', 'research', 'era', 'online', 'social', 'medium', 'play', 'role', 'efficient', 'source', 'identifying', 'potential', 'illness', 'based', 'specific', 'however', 'majority', 'people', 'may', 'illness', 'still', 'social', 'blind', 'spot', 'lack', 'appropriate', 'treatment', 'due', 'several', 'reason', 'difficulty', 'revealing', 'status', 'someone', 'person', 'difficulty', 'physically', 'accessing', 'clinic', 'based', 'lesson', 'learned', 'following', 'implication', 'presented', 'first', 'deep', 'learning', 'approach', 'appropriate', 'natural', 'language', 'processing', 'method', 'detect', 'potential', 'illness', 'employment', 'easily', 'accessible', 'social', 'medium', 'approach', 'study', 'adopted', 'alert', 'may', 'suffered', 'specific', 'disorder', 'visit', 'counseling', 'center', 'second', 'study', 'provides', 'notable', 'evidence', 'supporting', 'possibility', 'utilizing', 'online', 'platform', 'help', 'people', 'need', 'treatment', 'specifically', 'example', 'online', 'platform', 'service', 'provider', 'may', 'ask', 'consent', 'first', 'access', 'one', 'account', 'agreed', 'provide', 'probability', 'disorder', 'predicted', 'validated', 'model', 'based', 'lastly', 'current', 'study', 'suggests', 'detecting', 'illness', 'social', 'medium', 'prominent', 'research', 'area', 'future', 'finding', 'current', 'study', 'reveal', 'potential', 'social', 'medium', 'platform', 'play', 'role', 'providing', 'space', 'interact', 'others', 'suffered', 'disorder', 'however', 'limitation', 'study', 'current', 'study', 'consider', 'several', 'factor', 'eg', 'sociodemographic', 'regional', 'difference', 'could', 'affect', 'classification', 'model', 'factor', 'considered', 'future', 'research', 'improve', 'quality', 'accuracy', 'deep', 'learning', 'model', 'addition', 'collected', 'public', 'social', 'medium', 'reddit', 'may', 'different', 'personal', 'feed', 'social', 'network', 'service', 'expressing', 'emotion', 'conduct', 'additional', 'validation', 'procedure', 'model', 'another', 'independent', 'dataset', 'mentioned', 'would', 'need', 'investigated', 'although', 'posting', 'online', 'social', 'medium', 'could', 'explicitly', 'tell', 'symptom', 'compared', 'personal', 'page', 'may', 'say', 'diagnosed', 'clinical', 'illness', 'online', 'social', 'medium', 'potential', 'identify', 'disorder', 'sufferer', 'share', 'symptom', 'relatively', 'accurately', 'semianonymity', 'system', 'also', 'trained', 'model', 'specific', 'state', 'directly', 'classify', 'symptom', 'provide', 'predicted', 'probability', 'symptom', 'way', 'could', 'accurately', 'measure', 'comorbid', 'illness', 'status', 'left', 'future', 'work', 'future', 'study', 'could', 'adopt', 'ensemble', 'approach', 'multiple', 'binary', 'classification', 'model', 'utilized', 'identify', 'realworld', 'condition', 'comorbid', 'illness', 'also', 'plan', 'validate', 'proposed', 'model', 'may', 'uncertain', 'disease', 'social', 'network', 'service', 'facebook', 'addition', 'timeseries', 'userlevel', 'track', 'longitudinal', 'behavior', 'pattern', 'help', 'develop', 'userlevel', 'detection', 'model', 'illness', 'using', 'recurrent', 'neural', 'network', 'based', 'lesson', 'learned', 'following', 'implication', 'presented', 'first', 'deep', 'learning', 'approach', 'appropriate', 'natural', 'language', 'processing', 'method', 'detect', 'potential', 'illness', 'employment', 'easily', 'accessible', 'social', 'medium', 'approach', 'study', 'adopted', 'alert', 'may', 'suffered', 'specific', 'disorder', 'visit', 'counseling', 'center', 'second', 'study', 'provides', 'notable', 'evidence', 'supporting', 'possibility', 'utilizing', 'online', 'platform', 'help', 'people', 'need', 'treatment', 'specifically', 'example', 'online', 'platform', 'service', 'provider', 'may', 'ask', 'consent', 'first', 'access', 'one', 'account', 'agreed', 'provide', 'probability', 'disorder', 'predicted', 'validated', 'model', 'based', 'lastly', 'current', 'study', 'suggests', 'detecting', 'illness', 'social', 'medium', 'prominent', 'research', 'area', 'future', 'finding', 'current', 'study', 'reveal', 'potential', 'social', 'medium', 'platform', 'play', 'role', 'providing', 'space', 'interact', 'others', 'suffered', 'disorder', 'however', 'limitation', 'study', 'current', 'study', 'consider', 'several', 'factor', 'eg', 'sociodemographic', 'regional', 'difference', 'could', 'affect', 'classification', 'model', 'factor', 'considered', 'future', 'research', 'improve', 'quality', 'accuracy', 'deep', 'learning', 'model', 'addition', 'collected', 'public', 'social', 'medium', 'reddit', 'may', 'different', 'personal', 'feed', 'social', 'network', 'service', 'expressing', 'emotion', 'conduct', 'additional', 'validation', 'procedure', 'model', 'another', 'independent', 'dataset', 'mentioned', 'would', 'need', 'investigated', 'although', 'posting', 'online', 'social', 'medium', 'could', 'explicitly', 'tell', 'symptom', 'compared', 'personal', 'page', 'may', 'say', 'diagnosed', 'clinical', 'illness', 'online', 'social', 'medium', 'potential', 'identify', 'disorder', 'sufferer', 'share', 'symptom', 'relatively', 'accurately', 'semianonymity', 'system', 'also', 'trained', 'model', 'specific', 'state', 'directly', 'classify', 'symptom', 'provide', 'predicted', 'probability', 'symptom', 'way', 'could', 'accurately', 'measure', 'comorbid', 'illness', 'status', 'left', 'future', 'work', 'future', 'study', 'could', 'adopt', 'ensemble', 'approach', 'multiple', 'binary', 'classification', 'model', 'utilized', 'identify', 'realworld', 'condition', 'comorbid', 'illness', 'also', 'plan', 'validate', 'proposed', 'model', 'may', 'uncertain', 'disease', 'social', 'network', 'service', 'facebook', 'addition', 'timeseries', 'userlevel', 'track', 'longitudinal', 'behavior', 'pattern', 'help', 'develop', 'userlevel', 'detection', 'model', 'illness', 'using', 'recurrent', 'neural', 'network']","['detecting illness', 'illness problem', 'problem early', 'early stage', 'stage providing', 'providing appropriate', 'appropriate solution', 'solution help', 'help potential', 'potential disorder', 'disorder sufferer', 'sufferer collecting', 'collecting analyzing', 'analyzing mentalhealthrelated', 'mentalhealthrelated subreddits', 'subreddits reddit', 'reddit focus', 'focus disorder', 'disorder issue', 'issue introduced', 'introduced deep', 'deep learning', 'learning model', 'model natural', 'natural language', 'language processing', 'processing method', 'method identify', 'identify potential', 'potential illness', 'illness based', 'based believe', 'believe method', 'method open', 'open new', 'new research', 'research era', 'era online', 'online social', 'social medium', 'medium play', 'play role', 'role efficient', 'efficient source', 'source identifying', 'identifying potential', 'potential illness', 'illness based', 'based specific', 'specific however', 'however majority', 'majority people', 'people may', 'may illness', 'illness still', 'still social', 'social blind', 'blind spot', 'spot lack', 'lack appropriate', 'appropriate treatment', 'treatment due', 'due several', 'several reason', 'reason difficulty', 'difficulty revealing', 'revealing status', 'status someone', 'someone person', 'person difficulty', 'difficulty physically', 'physically accessing', 'accessing clinic', 'clinic based', 'based lesson', 'lesson learned', 'learned following', 'following implication', 'implication presented', 'presented first', 'first deep', 'deep learning', 'learning approach', 'approach appropriate', 'appropriate natural', 'natural language', 'language processing', 'processing method', 'method detect', 'detect potential', 'potential illness', 'illness employment', 'employment easily', 'easily accessible', 'accessible social', 'social medium', 'medium approach', 'approach study', 'study adopted', 'adopted alert', 'alert may', 'may suffered', 'suffered specific', 'specific disorder', 'disorder visit', 'visit counseling', 'counseling center', 'center second', 'second study', 'study provides', 'provides notable', 'notable evidence', 'evidence supporting', 'supporting possibility', 'possibility utilizing', 'utilizing online', 'online platform', 'platform help', 'help people', 'people need', 'need treatment', 'treatment specifically', 'specifically example', 'example online', 'online platform', 'platform service', 'service provider', 'provider may', 'may ask', 'ask consent', 'consent first', 'first access', 'access one', 'one account', 'account agreed', 'agreed provide', 'provide probability', 'probability disorder', 'disorder predicted', 'predicted validated', 'validated model', 'model based', 'based lastly', 'lastly current', 'current study', 'study suggests', 'suggests detecting', 'detecting illness', 'illness social', 'social medium', 'medium prominent', 'prominent research', 'research area', 'area future', 'future finding', 'finding current', 'current study', 'study reveal', 'reveal potential', 'potential social', 'social medium', 'medium platform', 'platform play', 'play role', 'role providing', 'providing space', 'space interact', 'interact others', 'others suffered', 'suffered disorder', 'disorder however', 'however limitation', 'limitation study', 'study current', 'current study', 'study consider', 'consider several', 'several factor', 'factor eg', 'eg sociodemographic', 'sociodemographic regional', 'regional difference', 'difference could', 'could affect', 'affect classification', 'classification model', 'model factor', 'factor considered', 'considered future', 'future research', 'research improve', 'improve quality', 'quality accuracy', 'accuracy deep', 'deep learning', 'learning model', 'model addition', 'addition collected', 'collected public', 'public social', 'social medium', 'medium reddit', 'reddit may', 'may different', 'different personal', 'personal feed', 'feed social', 'social network', 'network service', 'service expressing', 'expressing emotion', 'emotion conduct', 'conduct additional', 'additional validation', 'validation procedure', 'procedure model', 'model another', 'another independent', 'independent dataset', 'dataset mentioned', 'mentioned would', 'would need', 'need investigated', 'investigated although', 'although posting', 'posting online', 'online social', 'social medium', 'medium could', 'could explicitly', 'explicitly tell', 'tell symptom', 'symptom compared', 'compared personal', 'personal page', 'page may', 'may say', 'say diagnosed', 'diagnosed clinical', 'clinical illness', 'illness online', 'online social', 'social medium', 'medium potential', 'potential identify', 'identify disorder', 'disorder sufferer', 'sufferer share', 'share symptom', 'symptom relatively', 'relatively accurately', 'accurately semianonymity', 'semianonymity system', 'system also', 'also trained', 'trained model', 'model specific', 'specific state', 'state directly', 'directly classify', 'classify symptom', 'symptom provide', 'provide predicted', 'predicted probability', 'probability symptom', 'symptom way', 'way could', 'could accurately', 'accurately measure', 'measure comorbid', 'comorbid illness', 'illness status', 'status left', 'left future', 'future work', 'work future', 'future study', 'study could', 'could adopt', 'adopt ensemble', 'ensemble approach', 'approach multiple', 'multiple binary', 'binary classification', 'classification model', 'model utilized', 'utilized identify', 'identify realworld', 'realworld condition', 'condition comorbid', 'comorbid illness', 'illness also', 'also plan', 'plan validate', 'validate proposed', 'proposed model', 'model may', 'may uncertain', 'uncertain disease', 'disease social', 'social network', 'network service', 'service facebook', 'facebook addition', 'addition timeseries', 'timeseries userlevel', 'userlevel track', 'track longitudinal', 'longitudinal behavior', 'behavior pattern', 'pattern help', 'help develop', 'develop userlevel', 'userlevel detection', 'detection model', 'model illness', 'illness using', 'using recurrent', 'recurrent neural', 'neural network', 'network based', 'based lesson', 'lesson learned', 'learned following', 'following implication', 'implication presented', 'presented first', 'first deep', 'deep learning', 'learning approach', 'approach appropriate', 'appropriate natural', 'natural language', 'language processing', 'processing method', 'method detect', 'detect potential', 'potential illness', 'illness employment', 'employment easily', 'easily accessible', 'accessible social', 'social medium', 'medium approach', 'approach study', 'study adopted', 'adopted alert', 'alert may', 'may suffered', 'suffered specific', 'specific disorder', 'disorder visit', 'visit counseling', 'counseling center', 'center second', 'second study', 'study provides', 'provides notable', 'notable evidence', 'evidence supporting', 'supporting possibility', 'possibility utilizing', 'utilizing online', 'online platform', 'platform help', 'help people', 'people need', 'need treatment', 'treatment specifically', 'specifically example', 'example online', 'online platform', 'platform service', 'service provider', 'provider may', 'may ask', 'ask consent', 'consent first', 'first access', 'access one', 'one account', 'account agreed', 'agreed provide', 'provide probability', 'probability disorder', 'disorder predicted', 'predicted validated', 'validated model', 'model based', 'based lastly', 'lastly current', 'current study', 'study suggests', 'suggests detecting', 'detecting illness', 'illness social', 'social medium', 'medium prominent', 'prominent research', 'research area', 'area future', 'future finding', 'finding current', 'current study', 'study reveal', 'reveal potential', 'potential social', 'social medium', 'medium platform', 'platform play', 'play role', 'role providing', 'providing space', 'space interact', 'interact others', 'others suffered', 'suffered disorder', 'disorder however', 'however limitation', 'limitation study', 'study current', 'current study', 'study consider', 'consider several', 'several factor', 'factor eg', 'eg sociodemographic', 'sociodemographic regional', 'regional difference', 'difference could', 'could affect', 'affect classification', 'classification model', 'model factor', 'factor considered', 'considered future', 'future research', 'research improve', 'improve quality', 'quality accuracy', 'accuracy deep', 'deep learning', 'learning model', 'model addition', 'addition collected', 'collected public', 'public social', 'social medium', 'medium reddit', 'reddit may', 'may different', 'different personal', 'personal feed', 'feed social', 'social network', 'network service', 'service expressing', 'expressing emotion', 'emotion conduct', 'conduct additional', 'additional validation', 'validation procedure', 'procedure model', 'model another', 'another independent', 'independent dataset', 'dataset mentioned', 'mentioned would', 'would need', 'need investigated', 'investigated although', 'although posting', 'posting online', 'online social', 'social medium', 'medium could', 'could explicitly', 'explicitly tell', 'tell symptom', 'symptom compared', 'compared personal', 'personal page', 'page may', 'may say', 'say diagnosed', 'diagnosed clinical', 'clinical illness', 'illness online', 'online social', 'social medium', 'medium potential', 'potential identify', 'identify disorder', 'disorder sufferer', 'sufferer share', 'share symptom', 'symptom relatively', 'relatively accurately', 'accurately semianonymity', 'semianonymity system', 'system also', 'also trained', 'trained model', 'model specific', 'specific state', 'state directly', 'directly classify', 'classify symptom', 'symptom provide', 'provide predicted', 'predicted probability', 'probability symptom', 'symptom way', 'way could', 'could accurately', 'accurately measure', 'measure comorbid', 'comorbid illness', 'illness status', 'status left', 'left future', 'future work', 'work future', 'future study', 'study could', 'could adopt', 'adopt ensemble', 'ensemble approach', 'approach multiple', 'multiple binary', 'binary classification', 'classification model', 'model utilized', 'utilized identify', 'identify realworld', 'realworld condition', 'condition comorbid', 'comorbid illness', 'illness also', 'also plan', 'plan validate', 'validate proposed', 'proposed model', 'model may', 'may uncertain', 'uncertain disease', 'disease social', 'social network', 'network service', 'service facebook', 'facebook addition', 'addition timeseries', 'timeseries userlevel', 'userlevel track', 'track longitudinal', 'longitudinal behavior', 'behavior pattern', 'pattern help', 'help develop', 'develop userlevel', 'userlevel detection', 'detection model', 'model illness', 'illness using', 'using recurrent', 'recurrent neural', 'neural network']","['detecting illness problem', 'illness problem early', 'problem early stage', 'early stage providing', 'stage providing appropriate', 'providing appropriate solution', 'appropriate solution help', 'solution help potential', 'help potential disorder', 'potential disorder sufferer', 'disorder sufferer collecting', 'sufferer collecting analyzing', 'collecting analyzing mentalhealthrelated', 'analyzing mentalhealthrelated subreddits', 'mentalhealthrelated subreddits reddit', 'subreddits reddit focus', 'reddit focus disorder', 'focus disorder issue', 'disorder issue introduced', 'issue introduced deep', 'introduced deep learning', 'deep learning model', 'learning model natural', 'model natural language', 'natural language processing', 'language processing method', 'processing method identify', 'method identify potential', 'identify potential illness', 'potential illness based', 'illness based believe', 'based believe method', 'believe method open', 'method open new', 'open new research', 'new research era', 'research era online', 'era online social', 'online social medium', 'social medium play', 'medium play role', 'play role efficient', 'role efficient source', 'efficient source identifying', 'source identifying potential', 'identifying potential illness', 'potential illness based', 'illness based specific', 'based specific however', 'specific however majority', 'however majority people', 'majority people may', 'people may illness', 'may illness still', 'illness still social', 'still social blind', 'social blind spot', 'blind spot lack', 'spot lack appropriate', 'lack appropriate treatment', 'appropriate treatment due', 'treatment due several', 'due several reason', 'several reason difficulty', 'reason difficulty revealing', 'difficulty revealing status', 'revealing status someone', 'status someone person', 'someone person difficulty', 'person difficulty physically', 'difficulty physically accessing', 'physically accessing clinic', 'accessing clinic based', 'clinic based lesson', 'based lesson learned', 'lesson learned following', 'learned following implication', 'following implication presented', 'implication presented first', 'presented first deep', 'first deep learning', 'deep learning approach', 'learning approach appropriate', 'approach appropriate natural', 'appropriate natural language', 'natural language processing', 'language processing method', 'processing method detect', 'method detect potential', 'detect potential illness', 'potential illness employment', 'illness employment easily', 'employment easily accessible', 'easily accessible social', 'accessible social medium', 'social medium approach', 'medium approach study', 'approach study adopted', 'study adopted alert', 'adopted alert may', 'alert may suffered', 'may suffered specific', 'suffered specific disorder', 'specific disorder visit', 'disorder visit counseling', 'visit counseling center', 'counseling center second', 'center second study', 'second study provides', 'study provides notable', 'provides notable evidence', 'notable evidence supporting', 'evidence supporting possibility', 'supporting possibility utilizing', 'possibility utilizing online', 'utilizing online platform', 'online platform help', 'platform help people', 'help people need', 'people need treatment', 'need treatment specifically', 'treatment specifically example', 'specifically example online', 'example online platform', 'online platform service', 'platform service provider', 'service provider may', 'provider may ask', 'may ask consent', 'ask consent first', 'consent first access', 'first access one', 'access one account', 'one account agreed', 'account agreed provide', 'agreed provide probability', 'provide probability disorder', 'probability disorder predicted', 'disorder predicted validated', 'predicted validated model', 'validated model based', 'model based lastly', 'based lastly current', 'lastly current study', 'current study suggests', 'study suggests detecting', 'suggests detecting illness', 'detecting illness social', 'illness social medium', 'social medium prominent', 'medium prominent research', 'prominent research area', 'research area future', 'area future finding', 'future finding current', 'finding current study', 'current study reveal', 'study reveal potential', 'reveal potential social', 'potential social medium', 'social medium platform', 'medium platform play', 'platform play role', 'play role providing', 'role providing space', 'providing space interact', 'space interact others', 'interact others suffered', 'others suffered disorder', 'suffered disorder however', 'disorder however limitation', 'however limitation study', 'limitation study current', 'study current study', 'current study consider', 'study consider several', 'consider several factor', 'several factor eg', 'factor eg sociodemographic', 'eg sociodemographic regional', 'sociodemographic regional difference', 'regional difference could', 'difference could affect', 'could affect classification', 'affect classification model', 'classification model factor', 'model factor considered', 'factor considered future', 'considered future research', 'future research improve', 'research improve quality', 'improve quality accuracy', 'quality accuracy deep', 'accuracy deep learning', 'deep learning model', 'learning model addition', 'model addition collected', 'addition collected public', 'collected public social', 'public social medium', 'social medium reddit', 'medium reddit may', 'reddit may different', 'may different personal', 'different personal feed', 'personal feed social', 'feed social network', 'social network service', 'network service expressing', 'service expressing emotion', 'expressing emotion conduct', 'emotion conduct additional', 'conduct additional validation', 'additional validation procedure', 'validation procedure model', 'procedure model another', 'model another independent', 'another independent dataset', 'independent dataset mentioned', 'dataset mentioned would', 'mentioned would need', 'would need investigated', 'need investigated although', 'investigated although posting', 'although posting online', 'posting online social', 'online social medium', 'social medium could', 'medium could explicitly', 'could explicitly tell', 'explicitly tell symptom', 'tell symptom compared', 'symptom compared personal', 'compared personal page', 'personal page may', 'page may say', 'may say diagnosed', 'say diagnosed clinical', 'diagnosed clinical illness', 'clinical illness online', 'illness online social', 'online social medium', 'social medium potential', 'medium potential identify', 'potential identify disorder', 'identify disorder sufferer', 'disorder sufferer share', 'sufferer share symptom', 'share symptom relatively', 'symptom relatively accurately', 'relatively accurately semianonymity', 'accurately semianonymity system', 'semianonymity system also', 'system also trained', 'also trained model', 'trained model specific', 'model specific state', 'specific state directly', 'state directly classify', 'directly classify symptom', 'classify symptom provide', 'symptom provide predicted', 'provide predicted probability', 'predicted probability symptom', 'probability symptom way', 'symptom way could', 'way could accurately', 'could accurately measure', 'accurately measure comorbid', 'measure comorbid illness', 'comorbid illness status', 'illness status left', 'status left future', 'left future work', 'future work future', 'work future study', 'future study could', 'study could adopt', 'could adopt ensemble', 'adopt ensemble approach', 'ensemble approach multiple', 'approach multiple binary', 'multiple binary classification', 'binary classification model', 'classification model utilized', 'model utilized identify', 'utilized identify realworld', 'identify realworld condition', 'realworld condition comorbid', 'condition comorbid illness', 'comorbid illness also', 'illness also plan', 'also plan validate', 'plan validate proposed', 'validate proposed model', 'proposed model may', 'model may uncertain', 'may uncertain disease', 'uncertain disease social', 'disease social network', 'social network service', 'network service facebook', 'service facebook addition', 'facebook addition timeseries', 'addition timeseries userlevel', 'timeseries userlevel track', 'userlevel track longitudinal', 'track longitudinal behavior', 'longitudinal behavior pattern', 'behavior pattern help', 'pattern help develop', 'help develop userlevel', 'develop userlevel detection', 'userlevel detection model', 'detection model illness', 'model illness using', 'illness using recurrent', 'using recurrent neural', 'recurrent neural network', 'neural network based', 'network based lesson', 'based lesson learned', 'lesson learned following', 'learned following implication', 'following implication presented', 'implication presented first', 'presented first deep', 'first deep learning', 'deep learning approach', 'learning approach appropriate', 'approach appropriate natural', 'appropriate natural language', 'natural language processing', 'language processing method', 'processing method detect', 'method detect potential', 'detect potential illness', 'potential illness employment', 'illness employment easily', 'employment easily accessible', 'easily accessible social', 'accessible social medium', 'social medium approach', 'medium approach study', 'approach study adopted', 'study adopted alert', 'adopted alert may', 'alert may suffered', 'may suffered specific', 'suffered specific disorder', 'specific disorder visit', 'disorder visit counseling', 'visit counseling center', 'counseling center second', 'center second study', 'second study provides', 'study provides notable', 'provides notable evidence', 'notable evidence supporting', 'evidence supporting possibility', 'supporting possibility utilizing', 'possibility utilizing online', 'utilizing online platform', 'online platform help', 'platform help people', 'help people need', 'people need treatment', 'need treatment specifically', 'treatment specifically example', 'specifically example online', 'example online platform', 'online platform service', 'platform service provider', 'service provider may', 'provider may ask', 'may ask consent', 'ask consent first', 'consent first access', 'first access one', 'access one account', 'one account agreed', 'account agreed provide', 'agreed provide probability', 'provide probability disorder', 'probability disorder predicted', 'disorder predicted validated', 'predicted validated model', 'validated model based', 'model based lastly', 'based lastly current', 'lastly current study', 'current study suggests', 'study suggests detecting', 'suggests detecting illness', 'detecting illness social', 'illness social medium', 'social medium prominent', 'medium prominent research', 'prominent research area', 'research area future', 'area future finding', 'future finding current', 'finding current study', 'current study reveal', 'study reveal potential', 'reveal potential social', 'potential social medium', 'social medium platform', 'medium platform play', 'platform play role', 'play role providing', 'role providing space', 'providing space interact', 'space interact others', 'interact others suffered', 'others suffered disorder', 'suffered disorder however', 'disorder however limitation', 'however limitation study', 'limitation study current', 'study current study', 'current study consider', 'study consider several', 'consider several factor', 'several factor eg', 'factor eg sociodemographic', 'eg sociodemographic regional', 'sociodemographic regional difference', 'regional difference could', 'difference could affect', 'could affect classification', 'affect classification model', 'classification model factor', 'model factor considered', 'factor considered future', 'considered future research', 'future research improve', 'research improve quality', 'improve quality accuracy', 'quality accuracy deep', 'accuracy deep learning', 'deep learning model', 'learning model addition', 'model addition collected', 'addition collected public', 'collected public social', 'public social medium', 'social medium reddit', 'medium reddit may', 'reddit may different', 'may different personal', 'different personal feed', 'personal feed social', 'feed social network', 'social network service', 'network service expressing', 'service expressing emotion', 'expressing emotion conduct', 'emotion conduct additional', 'conduct additional validation', 'additional validation procedure', 'validation procedure model', 'procedure model another', 'model another independent', 'another independent dataset', 'independent dataset mentioned', 'dataset mentioned would', 'mentioned would need', 'would need investigated', 'need investigated although', 'investigated although posting', 'although posting online', 'posting online social', 'online social medium', 'social medium could', 'medium could explicitly', 'could explicitly tell', 'explicitly tell symptom', 'tell symptom compared', 'symptom compared personal', 'compared personal page', 'personal page may', 'page may say', 'may say diagnosed', 'say diagnosed clinical', 'diagnosed clinical illness', 'clinical illness online', 'illness online social', 'online social medium', 'social medium potential', 'medium potential identify', 'potential identify disorder', 'identify disorder sufferer', 'disorder sufferer share', 'sufferer share symptom', 'share symptom relatively', 'symptom relatively accurately', 'relatively accurately semianonymity', 'accurately semianonymity system', 'semianonymity system also', 'system also trained', 'also trained model', 'trained model specific', 'model specific state', 'specific state directly', 'state directly classify', 'directly classify symptom', 'classify symptom provide', 'symptom provide predicted', 'provide predicted probability', 'predicted probability symptom', 'probability symptom way', 'symptom way could', 'way could accurately', 'could accurately measure', 'accurately measure comorbid', 'measure comorbid illness', 'comorbid illness status', 'illness status left', 'status left future', 'left future work', 'future work future', 'work future study', 'future study could', 'study could adopt', 'could adopt ensemble', 'adopt ensemble approach', 'ensemble approach multiple', 'approach multiple binary', 'multiple binary classification', 'binary classification model', 'classification model utilized', 'model utilized identify', 'utilized identify realworld', 'identify realworld condition', 'realworld condition comorbid', 'condition comorbid illness', 'comorbid illness also', 'illness also plan', 'also plan validate', 'plan validate proposed', 'validate proposed model', 'proposed model may', 'model may uncertain', 'may uncertain disease', 'uncertain disease social', 'disease social network', 'social network service', 'network service facebook', 'service facebook addition', 'facebook addition timeseries', 'addition timeseries userlevel', 'timeseries userlevel track', 'userlevel track longitudinal', 'track longitudinal behavior', 'longitudinal behavior pattern', 'behavior pattern help', 'pattern help develop', 'help develop userlevel', 'develop userlevel detection', 'userlevel detection model', 'detection model illness', 'model illness using', 'illness using recurrent', 'using recurrent neural', 'recurrent neural network']"
https://aclanthology.org/W19-3013.pdf,1,The majority of social media analysis approaches try to extract signals from individual posts and thus do not need to record any personal information. However as we start moving towards userlevel analyses we are collecting and storing complete records of social media users communications. Even though this information is publicly available people might not be consciously aware of the implications of sharing all their data and certainly have not given explicit consent for their data to be analyzed in aggregate. This is even more pertinent for analyses involving sensitive information (e.g. health related issues). As it has been demonstrated by the recent incidents involving companies inadvertently sharing or failing to protect users personal data there is a serious danger of abuse and exploitation for systems that collect and store large amounts of personal data. Even though this is in large part an ethical question there are technical solutions that can be used to partially address this issue. One is to use anonymization techniques to obfuscate any details that allow third parties (even analysts) to identify the individuals that are involved in the study. Another is to store only abstract representations — which can still be updated and consumed by predictive models —  and discard the actual content. In regards to consent there are initiatives to support voluntary data donation for research purposes e.g. the Our Data Helps program6 .,the majority of social medium analysis approach try to extract signal from individual post and thus do not need to record any personal information however a we start moving towards userlevel analysis we are collecting and storing complete record of social medium user communication even though this information is publicly available people might not be consciously aware of the implication of sharing all their data and certainly have not given explicit consent for their data to be analyzed in aggregate this is even more pertinent for analysis involving sensitive information eg health related issue a it ha been demonstrated by the recent incident involving company inadvertently sharing or failing to protect user personal data there is a serious danger of abuse and exploitation for system that collect and store large amount of personal data even though this is in large part an ethical question there are technical solution that can be used to partially address this issue one is to use anonymization technique to obfuscate any detail that allow third party even analyst to identify the individual that are involved in the study another is to store only abstract representation which can still be updated and consumed by predictive model and discard the actual content in regard to consent there are initiative to support voluntary data donation for research purpose eg the our data help program,"['majority', 'social', 'medium', 'approach', 'try', 'extract', 'signal', 'individual', 'thus', 'need', 'record', 'personal', 'information', 'however', 'start', 'moving', 'towards', 'userlevel', 'collecting', 'storing', 'complete', 'record', 'social', 'medium', 'communication', 'even', 'though', 'information', 'publicly', 'available', 'people', 'might', 'consciously', 'aware', 'implication', 'sharing', 'certainly', 'given', 'explicit', 'consent', 'analyzed', 'aggregate', 'even', 'pertinent', 'involving', 'sensitive', 'information', 'eg', 'related', 'issue', 'ha', 'demonstrated', 'recent', 'incident', 'involving', 'company', 'inadvertently', 'sharing', 'failing', 'protect', 'personal', 'serious', 'danger', 'abuse', 'exploitation', 'system', 'collect', 'store', 'large', 'amount', 'personal', 'even', 'though', 'large', 'part', 'ethical', 'question', 'technical', 'solution', 'partially', 'address', 'issue', 'one', 'use', 'anonymization', 'technique', 'obfuscate', 'detail', 'allow', 'third', 'party', 'even', 'analyst', 'identify', 'individual', 'involved', 'study', 'another', 'store', 'abstract', 'representation', 'still', 'updated', 'consumed', 'predictive', 'model', 'discard', 'actual', 'content', 'regard', 'consent', 'initiative', 'support', 'voluntary', 'donation', 'research', 'purpose', 'eg', 'help', 'program']","['majority social', 'social medium', 'medium approach', 'approach try', 'try extract', 'extract signal', 'signal individual', 'individual thus', 'thus need', 'need record', 'record personal', 'personal information', 'information however', 'however start', 'start moving', 'moving towards', 'towards userlevel', 'userlevel collecting', 'collecting storing', 'storing complete', 'complete record', 'record social', 'social medium', 'medium communication', 'communication even', 'even though', 'though information', 'information publicly', 'publicly available', 'available people', 'people might', 'might consciously', 'consciously aware', 'aware implication', 'implication sharing', 'sharing certainly', 'certainly given', 'given explicit', 'explicit consent', 'consent analyzed', 'analyzed aggregate', 'aggregate even', 'even pertinent', 'pertinent involving', 'involving sensitive', 'sensitive information', 'information eg', 'eg related', 'related issue', 'issue ha', 'ha demonstrated', 'demonstrated recent', 'recent incident', 'incident involving', 'involving company', 'company inadvertently', 'inadvertently sharing', 'sharing failing', 'failing protect', 'protect personal', 'personal serious', 'serious danger', 'danger abuse', 'abuse exploitation', 'exploitation system', 'system collect', 'collect store', 'store large', 'large amount', 'amount personal', 'personal even', 'even though', 'though large', 'large part', 'part ethical', 'ethical question', 'question technical', 'technical solution', 'solution partially', 'partially address', 'address issue', 'issue one', 'one use', 'use anonymization', 'anonymization technique', 'technique obfuscate', 'obfuscate detail', 'detail allow', 'allow third', 'third party', 'party even', 'even analyst', 'analyst identify', 'identify individual', 'individual involved', 'involved study', 'study another', 'another store', 'store abstract', 'abstract representation', 'representation still', 'still updated', 'updated consumed', 'consumed predictive', 'predictive model', 'model discard', 'discard actual', 'actual content', 'content regard', 'regard consent', 'consent initiative', 'initiative support', 'support voluntary', 'voluntary donation', 'donation research', 'research purpose', 'purpose eg', 'eg help', 'help program']","['majority social medium', 'social medium approach', 'medium approach try', 'approach try extract', 'try extract signal', 'extract signal individual', 'signal individual thus', 'individual thus need', 'thus need record', 'need record personal', 'record personal information', 'personal information however', 'information however start', 'however start moving', 'start moving towards', 'moving towards userlevel', 'towards userlevel collecting', 'userlevel collecting storing', 'collecting storing complete', 'storing complete record', 'complete record social', 'record social medium', 'social medium communication', 'medium communication even', 'communication even though', 'even though information', 'though information publicly', 'information publicly available', 'publicly available people', 'available people might', 'people might consciously', 'might consciously aware', 'consciously aware implication', 'aware implication sharing', 'implication sharing certainly', 'sharing certainly given', 'certainly given explicit', 'given explicit consent', 'explicit consent analyzed', 'consent analyzed aggregate', 'analyzed aggregate even', 'aggregate even pertinent', 'even pertinent involving', 'pertinent involving sensitive', 'involving sensitive information', 'sensitive information eg', 'information eg related', 'eg related issue', 'related issue ha', 'issue ha demonstrated', 'ha demonstrated recent', 'demonstrated recent incident', 'recent incident involving', 'incident involving company', 'involving company inadvertently', 'company inadvertently sharing', 'inadvertently sharing failing', 'sharing failing protect', 'failing protect personal', 'protect personal serious', 'personal serious danger', 'serious danger abuse', 'danger abuse exploitation', 'abuse exploitation system', 'exploitation system collect', 'system collect store', 'collect store large', 'store large amount', 'large amount personal', 'amount personal even', 'personal even though', 'even though large', 'though large part', 'large part ethical', 'part ethical question', 'ethical question technical', 'question technical solution', 'technical solution partially', 'solution partially address', 'partially address issue', 'address issue one', 'issue one use', 'one use anonymization', 'use anonymization technique', 'anonymization technique obfuscate', 'technique obfuscate detail', 'obfuscate detail allow', 'detail allow third', 'allow third party', 'third party even', 'party even analyst', 'even analyst identify', 'analyst identify individual', 'identify individual involved', 'individual involved study', 'involved study another', 'study another store', 'another store abstract', 'store abstract representation', 'abstract representation still', 'representation still updated', 'still updated consumed', 'updated consumed predictive', 'consumed predictive model', 'predictive model discard', 'model discard actual', 'discard actual content', 'actual content regard', 'content regard consent', 'regard consent initiative', 'consent initiative support', 'initiative support voluntary', 'support voluntary donation', 'voluntary donation research', 'donation research purpose', 'research purpose eg', 'purpose eg help', 'eg help program']"
https://link.springer.com/chapter/10.1007/978-3-319-67186-4_6,1,We analyze two datasets: (1) user communities on Reddit and (2) journals from a mental health journalling mobile app. We omit the name of the app for privacy and we refer to it as the “journalling app”. Reddit is a social media platform that was originally used for sharing and rating content such as news documentaries and music. Users post in and subscribe to self-organized communities known as subreddits; subscribing to a subreddit allows a user to view all posts from that subreddit. An advantage of analyzing Reddit data is that the subreddits are labelled according to their topics. Utilizing curated lists from volunteer Reddit users we crawled all subreddits related to mental health as well as all subreddits linked by these communities. The second dataset consists of anonymized journal posts from a mobile app designed to help people track their moods and share them anonymously if they desire. For each journal post the app requires the user to label the journal post with at least one mood selected from a pre-populated list including “happy” “sad” etc. We obtained all journals and the associated moods written between January 2016 and January 2017. This amounts to over 1.2 million journals written by approximately 75000 users. Figure 1 plots the number of journals posted over time. Most of the journals were written in the first half of 2016 although we inspected topic distributions per month and did not find seasonal effects. Towards the beginning of 2016 many new users registered on the app and eventually stopped using it. Like weight-loss and productivity apps we believe this influx is tied to users looking to improve their habits as a New Year’s resolution. Each journal can be set to be private or public (visible to all other users of the app). Roughly one third of all journals are public. Figure 2 plots the number of users on the y-axis versus the percentage of journals they posted publicly. Most users are either mostly private or mostly public. Most journals are relatively short just like Twitter posts that are at most 140 characters. The average length of a journal with text in it is 128 characters; there are roughly 100000 journal that have no text only a mood label. We observed that private users tend to write journals that are slightly but statistically significantly longer than those written by public users by approximately 10 characters. Figure 3 shows the distribution of journal lengths where the spikes correspond to 0 length (mood only) 200 characters (the default limit set by the app) and 300 characters (set as the maximum for visualization purposes). Users of the app can optionally enter their location age and gender. While most users did not enter this information we found that those who revealed their location are mostly from North America those who revealed their gender are predominantly female and those who revealed their age have an average age of 25.,we analyze two datasets user community on reddit and journal from a mental health journalling mobile app we omit the name of the app for privacy and we refer to it a the journalling app reddit is a social medium platform that wa originally used for sharing and rating content such a news documentary and music user post in and subscribe to selforganized community known a subreddits subscribing to a subreddit allows a user to view all post from that subreddit an advantage of analyzing reddit data is that the subreddits are labelled according to their topic utilizing curated list from volunteer reddit user we crawled all subreddits related to mental health a well a all subreddits linked by these community the second dataset consists of anonymized journal post from a mobile app designed to help people track their mood and share them anonymously if they desire for each journal post the app requires the user to label the journal post with at least one mood selected from a prepopulated list including happy sad etc we obtained all journal and the associated mood written between january and january this amount to over million journal written by approximately user figure plot the number of journal posted over time most of the journal were written in the first half of although we inspected topic distribution per month and did not find seasonal effect towards the beginning of many new user registered on the app and eventually stopped using it like weightloss and productivity apps we believe this influx is tied to user looking to improve their habit a a new year resolution each journal can be set to be private or public visible to all other user of the app roughly one third of all journal are public figure plot the number of user on the yaxis versus the percentage of journal they posted publicly most user are either mostly private or mostly public most journal are relatively short just like twitter post that are at most character the average length of a journal with text in it is character there are roughly journal that have no text only a mood label we observed that private user tend to write journal that are slightly but statistically significantly longer than those written by public user by approximately character figure show the distribution of journal length where the spike correspond to length mood only character the default limit set by the app and character set a the maximum for visualization purpose user of the app can optionally enter their location age and gender while most user did not enter this information we found that those who revealed their location are mostly from north america those who revealed their gender are predominantly female and those who revealed their age have an average age of,"['analyze', 'two', 'datasets', 'community', 'reddit', 'journal', 'journalling', 'mobile', 'app', 'omit', 'name', 'app', 'privacy', 'refer', 'journalling', 'app', 'reddit', 'social', 'medium', 'platform', 'originally', 'sharing', 'rating', 'content', 'news', 'documentary', 'music', 'subscribe', 'selforganized', 'community', 'known', 'subreddits', 'subscribing', 'subreddit', 'allows', 'view', 'subreddit', 'advantage', 'analyzing', 'reddit', 'subreddits', 'labelled', 'according', 'topic', 'utilizing', 'curated', 'list', 'volunteer', 'reddit', 'crawled', 'subreddits', 'related', 'well', 'subreddits', 'linked', 'community', 'second', 'dataset', 'consists', 'anonymized', 'journal', 'mobile', 'app', 'designed', 'help', 'people', 'track', 'mood', 'share', 'anonymously', 'desire', 'journal', 'app', 'requires', 'label', 'journal', 'least', 'one', 'mood', 'selected', 'prepopulated', 'list', 'including', 'happy', 'sad', 'etc', 'obtained', 'journal', 'associated', 'mood', 'written', 'january', 'january', 'amount', 'million', 'journal', 'written', 'approximately', 'figure', 'plot', 'number', 'journal', 'posted', 'time', 'journal', 'written', 'first', 'half', 'although', 'inspected', 'topic', 'distribution', 'per', 'month', 'find', 'seasonal', 'effect', 'towards', 'beginning', 'many', 'new', 'registered', 'app', 'eventually', 'stopped', 'using', 'like', 'weightloss', 'productivity', 'apps', 'believe', 'influx', 'tied', 'looking', 'improve', 'habit', 'new', 'year', 'resolution', 'journal', 'set', 'private', 'public', 'visible', 'app', 'roughly', 'one', 'third', 'journal', 'public', 'figure', 'plot', 'number', 'yaxis', 'versus', 'percentage', 'journal', 'posted', 'publicly', 'either', 'mostly', 'private', 'mostly', 'public', 'journal', 'relatively', 'short', 'like', 'character', 'average', 'length', 'journal', 'text', 'character', 'roughly', 'journal', 'text', 'mood', 'label', 'observed', 'private', 'tend', 'write', 'journal', 'slightly', 'statistically', 'significantly', 'longer', 'written', 'public', 'approximately', 'character', 'figure', 'show', 'distribution', 'journal', 'length', 'spike', 'correspond', 'length', 'mood', 'character', 'default', 'limit', 'set', 'app', 'character', 'set', 'maximum', 'visualization', 'purpose', 'app', 'optionally', 'enter', 'location', 'age', 'gender', 'enter', 'information', 'found', 'revealed', 'location', 'mostly', 'north', 'america', 'revealed', 'gender', 'predominantly', 'female', 'revealed', 'age', 'average', 'age']","['analyze two', 'two datasets', 'datasets community', 'community reddit', 'reddit journal', 'journal journalling', 'journalling mobile', 'mobile app', 'app omit', 'omit name', 'name app', 'app privacy', 'privacy refer', 'refer journalling', 'journalling app', 'app reddit', 'reddit social', 'social medium', 'medium platform', 'platform originally', 'originally sharing', 'sharing rating', 'rating content', 'content news', 'news documentary', 'documentary music', 'music subscribe', 'subscribe selforganized', 'selforganized community', 'community known', 'known subreddits', 'subreddits subscribing', 'subscribing subreddit', 'subreddit allows', 'allows view', 'view subreddit', 'subreddit advantage', 'advantage analyzing', 'analyzing reddit', 'reddit subreddits', 'subreddits labelled', 'labelled according', 'according topic', 'topic utilizing', 'utilizing curated', 'curated list', 'list volunteer', 'volunteer reddit', 'reddit crawled', 'crawled subreddits', 'subreddits related', 'related well', 'well subreddits', 'subreddits linked', 'linked community', 'community second', 'second dataset', 'dataset consists', 'consists anonymized', 'anonymized journal', 'journal mobile', 'mobile app', 'app designed', 'designed help', 'help people', 'people track', 'track mood', 'mood share', 'share anonymously', 'anonymously desire', 'desire journal', 'journal app', 'app requires', 'requires label', 'label journal', 'journal least', 'least one', 'one mood', 'mood selected', 'selected prepopulated', 'prepopulated list', 'list including', 'including happy', 'happy sad', 'sad etc', 'etc obtained', 'obtained journal', 'journal associated', 'associated mood', 'mood written', 'written january', 'january january', 'january amount', 'amount million', 'million journal', 'journal written', 'written approximately', 'approximately figure', 'figure plot', 'plot number', 'number journal', 'journal posted', 'posted time', 'time journal', 'journal written', 'written first', 'first half', 'half although', 'although inspected', 'inspected topic', 'topic distribution', 'distribution per', 'per month', 'month find', 'find seasonal', 'seasonal effect', 'effect towards', 'towards beginning', 'beginning many', 'many new', 'new registered', 'registered app', 'app eventually', 'eventually stopped', 'stopped using', 'using like', 'like weightloss', 'weightloss productivity', 'productivity apps', 'apps believe', 'believe influx', 'influx tied', 'tied looking', 'looking improve', 'improve habit', 'habit new', 'new year', 'year resolution', 'resolution journal', 'journal set', 'set private', 'private public', 'public visible', 'visible app', 'app roughly', 'roughly one', 'one third', 'third journal', 'journal public', 'public figure', 'figure plot', 'plot number', 'number yaxis', 'yaxis versus', 'versus percentage', 'percentage journal', 'journal posted', 'posted publicly', 'publicly either', 'either mostly', 'mostly private', 'private mostly', 'mostly public', 'public journal', 'journal relatively', 'relatively short', 'short like', 'like character', 'character average', 'average length', 'length journal', 'journal text', 'text character', 'character roughly', 'roughly journal', 'journal text', 'text mood', 'mood label', 'label observed', 'observed private', 'private tend', 'tend write', 'write journal', 'journal slightly', 'slightly statistically', 'statistically significantly', 'significantly longer', 'longer written', 'written public', 'public approximately', 'approximately character', 'character figure', 'figure show', 'show distribution', 'distribution journal', 'journal length', 'length spike', 'spike correspond', 'correspond length', 'length mood', 'mood character', 'character default', 'default limit', 'limit set', 'set app', 'app character', 'character set', 'set maximum', 'maximum visualization', 'visualization purpose', 'purpose app', 'app optionally', 'optionally enter', 'enter location', 'location age', 'age gender', 'gender enter', 'enter information', 'information found', 'found revealed', 'revealed location', 'location mostly', 'mostly north', 'north america', 'america revealed', 'revealed gender', 'gender predominantly', 'predominantly female', 'female revealed', 'revealed age', 'age average', 'average age']","['analyze two datasets', 'two datasets community', 'datasets community reddit', 'community reddit journal', 'reddit journal journalling', 'journal journalling mobile', 'journalling mobile app', 'mobile app omit', 'app omit name', 'omit name app', 'name app privacy', 'app privacy refer', 'privacy refer journalling', 'refer journalling app', 'journalling app reddit', 'app reddit social', 'reddit social medium', 'social medium platform', 'medium platform originally', 'platform originally sharing', 'originally sharing rating', 'sharing rating content', 'rating content news', 'content news documentary', 'news documentary music', 'documentary music subscribe', 'music subscribe selforganized', 'subscribe selforganized community', 'selforganized community known', 'community known subreddits', 'known subreddits subscribing', 'subreddits subscribing subreddit', 'subscribing subreddit allows', 'subreddit allows view', 'allows view subreddit', 'view subreddit advantage', 'subreddit advantage analyzing', 'advantage analyzing reddit', 'analyzing reddit subreddits', 'reddit subreddits labelled', 'subreddits labelled according', 'labelled according topic', 'according topic utilizing', 'topic utilizing curated', 'utilizing curated list', 'curated list volunteer', 'list volunteer reddit', 'volunteer reddit crawled', 'reddit crawled subreddits', 'crawled subreddits related', 'subreddits related well', 'related well subreddits', 'well subreddits linked', 'subreddits linked community', 'linked community second', 'community second dataset', 'second dataset consists', 'dataset consists anonymized', 'consists anonymized journal', 'anonymized journal mobile', 'journal mobile app', 'mobile app designed', 'app designed help', 'designed help people', 'help people track', 'people track mood', 'track mood share', 'mood share anonymously', 'share anonymously desire', 'anonymously desire journal', 'desire journal app', 'journal app requires', 'app requires label', 'requires label journal', 'label journal least', 'journal least one', 'least one mood', 'one mood selected', 'mood selected prepopulated', 'selected prepopulated list', 'prepopulated list including', 'list including happy', 'including happy sad', 'happy sad etc', 'sad etc obtained', 'etc obtained journal', 'obtained journal associated', 'journal associated mood', 'associated mood written', 'mood written january', 'written january january', 'january january amount', 'january amount million', 'amount million journal', 'million journal written', 'journal written approximately', 'written approximately figure', 'approximately figure plot', 'figure plot number', 'plot number journal', 'number journal posted', 'journal posted time', 'posted time journal', 'time journal written', 'journal written first', 'written first half', 'first half although', 'half although inspected', 'although inspected topic', 'inspected topic distribution', 'topic distribution per', 'distribution per month', 'per month find', 'month find seasonal', 'find seasonal effect', 'seasonal effect towards', 'effect towards beginning', 'towards beginning many', 'beginning many new', 'many new registered', 'new registered app', 'registered app eventually', 'app eventually stopped', 'eventually stopped using', 'stopped using like', 'using like weightloss', 'like weightloss productivity', 'weightloss productivity apps', 'productivity apps believe', 'apps believe influx', 'believe influx tied', 'influx tied looking', 'tied looking improve', 'looking improve habit', 'improve habit new', 'habit new year', 'new year resolution', 'year resolution journal', 'resolution journal set', 'journal set private', 'set private public', 'private public visible', 'public visible app', 'visible app roughly', 'app roughly one', 'roughly one third', 'one third journal', 'third journal public', 'journal public figure', 'public figure plot', 'figure plot number', 'plot number yaxis', 'number yaxis versus', 'yaxis versus percentage', 'versus percentage journal', 'percentage journal posted', 'journal posted publicly', 'posted publicly either', 'publicly either mostly', 'either mostly private', 'mostly private mostly', 'private mostly public', 'mostly public journal', 'public journal relatively', 'journal relatively short', 'relatively short like', 'short like character', 'like character average', 'character average length', 'average length journal', 'length journal text', 'journal text character', 'text character roughly', 'character roughly journal', 'roughly journal text', 'journal text mood', 'text mood label', 'mood label observed', 'label observed private', 'observed private tend', 'private tend write', 'tend write journal', 'write journal slightly', 'journal slightly statistically', 'slightly statistically significantly', 'statistically significantly longer', 'significantly longer written', 'longer written public', 'written public approximately', 'public approximately character', 'approximately character figure', 'character figure show', 'figure show distribution', 'show distribution journal', 'distribution journal length', 'journal length spike', 'length spike correspond', 'spike correspond length', 'correspond length mood', 'length mood character', 'mood character default', 'character default limit', 'default limit set', 'limit set app', 'set app character', 'app character set', 'character set maximum', 'set maximum visualization', 'maximum visualization purpose', 'visualization purpose app', 'purpose app optionally', 'app optionally enter', 'optionally enter location', 'enter location age', 'location age gender', 'age gender enter', 'gender enter information', 'enter information found', 'information found revealed', 'found revealed location', 'revealed location mostly', 'location mostly north', 'mostly north america', 'north america revealed', 'america revealed gender', 'revealed gender predominantly', 'gender predominantly female', 'predominantly female revealed', 'female revealed age', 'revealed age average', 'age average age']"
https://dl.acm.org/doi/abs/10.1145/2556288.2557214,1,We focus on the social media platform Twitter a popular microblogging service used by 18% of U.S. Internet users and whose popularity continues to increase [28]. Twitter is particularly interesting to study since nearly all posts are public; the public nature of tweets provides an interesting counterpoint to the private nature of search engine activity. We gathered a 15-month sample of Twitter’s Firehose stream (which includes all public tweets) between November 1 2011 and March 31 2013 made available to us under contract focusing on English-language tweets. Twitter post count and unique user count were computed for each condition and aggregated over the full time period. Specifically we considered a post to belong to a certain health condition if there was a regular expression match of the condition to the text of the post (this would not permit substring matches within terms). To reduce noise we excluded posts that were retweets or contained hyperlinks since they were likely related to general news and not a user’s personal health. Using this method we obtained 125166549 tweets on the 165 health conditions from 62269225 users in the time period of interest. The median number of posts was 51687 per condition from a median of 40152 users per condition.,we focus on the social medium platform twitter a popular microblogging service used by of u internet user and whose popularity continues to increase twitter is particularly interesting to study since nearly all post are public the public nature of tweet provides an interesting counterpoint to the private nature of search engine activity we gathered a month sample of twitter firehose stream which includes all public tweet between november and march made available to u under contract focusing on englishlanguage tweet twitter post count and unique user count were computed for each condition and aggregated over the full time period specifically we considered a post to belong to a certain health condition if there wa a regular expression match of the condition to the text of the post this would not permit substring match within term to reduce noise we excluded post that were retweets or contained hyperlink since they were likely related to general news and not a user personal health using this method we obtained tweet on the health condition from user in the time period of interest the median number of post wa per condition from a median of user per condition,"['focus', 'social', 'medium', 'platform', 'popular', 'microblogging', 'service', 'u', 'internet', 'whose', 'popularity', 'continues', 'increase', 'particularly', 'interesting', 'study', 'since', 'nearly', 'public', 'public', 'nature', 'provides', 'interesting', 'counterpoint', 'private', 'nature', 'search', 'engine', 'activity', 'gathered', 'month', 'sample', 'firehose', 'stream', 'includes', 'public', 'november', 'march', 'made', 'available', 'u', 'contract', 'focusing', 'englishlanguage', 'count', 'unique', 'count', 'computed', 'condition', 'aggregated', 'full', 'time', 'period', 'specifically', 'considered', 'belong', 'certain', 'condition', 'regular', 'expression', 'match', 'condition', 'text', 'would', 'permit', 'substring', 'match', 'within', 'term', 'reduce', 'noise', 'excluded', 'retweets', 'contained', 'hyperlink', 'since', 'likely', 'related', 'general', 'news', 'personal', 'using', 'method', 'obtained', 'condition', 'time', 'period', 'interest', 'median', 'number', 'per', 'condition', 'median', 'per', 'condition']","['focus social', 'social medium', 'medium platform', 'platform popular', 'popular microblogging', 'microblogging service', 'service u', 'u internet', 'internet whose', 'whose popularity', 'popularity continues', 'continues increase', 'increase particularly', 'particularly interesting', 'interesting study', 'study since', 'since nearly', 'nearly public', 'public public', 'public nature', 'nature provides', 'provides interesting', 'interesting counterpoint', 'counterpoint private', 'private nature', 'nature search', 'search engine', 'engine activity', 'activity gathered', 'gathered month', 'month sample', 'sample firehose', 'firehose stream', 'stream includes', 'includes public', 'public november', 'november march', 'march made', 'made available', 'available u', 'u contract', 'contract focusing', 'focusing englishlanguage', 'englishlanguage count', 'count unique', 'unique count', 'count computed', 'computed condition', 'condition aggregated', 'aggregated full', 'full time', 'time period', 'period specifically', 'specifically considered', 'considered belong', 'belong certain', 'certain condition', 'condition regular', 'regular expression', 'expression match', 'match condition', 'condition text', 'text would', 'would permit', 'permit substring', 'substring match', 'match within', 'within term', 'term reduce', 'reduce noise', 'noise excluded', 'excluded retweets', 'retweets contained', 'contained hyperlink', 'hyperlink since', 'since likely', 'likely related', 'related general', 'general news', 'news personal', 'personal using', 'using method', 'method obtained', 'obtained condition', 'condition time', 'time period', 'period interest', 'interest median', 'median number', 'number per', 'per condition', 'condition median', 'median per', 'per condition']","['focus social medium', 'social medium platform', 'medium platform popular', 'platform popular microblogging', 'popular microblogging service', 'microblogging service u', 'service u internet', 'u internet whose', 'internet whose popularity', 'whose popularity continues', 'popularity continues increase', 'continues increase particularly', 'increase particularly interesting', 'particularly interesting study', 'interesting study since', 'study since nearly', 'since nearly public', 'nearly public public', 'public public nature', 'public nature provides', 'nature provides interesting', 'provides interesting counterpoint', 'interesting counterpoint private', 'counterpoint private nature', 'private nature search', 'nature search engine', 'search engine activity', 'engine activity gathered', 'activity gathered month', 'gathered month sample', 'month sample firehose', 'sample firehose stream', 'firehose stream includes', 'stream includes public', 'includes public november', 'public november march', 'november march made', 'march made available', 'made available u', 'available u contract', 'u contract focusing', 'contract focusing englishlanguage', 'focusing englishlanguage count', 'englishlanguage count unique', 'count unique count', 'unique count computed', 'count computed condition', 'computed condition aggregated', 'condition aggregated full', 'aggregated full time', 'full time period', 'time period specifically', 'period specifically considered', 'specifically considered belong', 'considered belong certain', 'belong certain condition', 'certain condition regular', 'condition regular expression', 'regular expression match', 'expression match condition', 'match condition text', 'condition text would', 'text would permit', 'would permit substring', 'permit substring match', 'substring match within', 'match within term', 'within term reduce', 'term reduce noise', 'reduce noise excluded', 'noise excluded retweets', 'excluded retweets contained', 'retweets contained hyperlink', 'contained hyperlink since', 'hyperlink since likely', 'since likely related', 'likely related general', 'related general news', 'general news personal', 'news personal using', 'personal using method', 'using method obtained', 'method obtained condition', 'obtained condition time', 'condition time period', 'time period interest', 'period interest median', 'interest median number', 'median number per', 'number per condition', 'per condition median', 'condition median per', 'median per condition']"
https://www.aaai.org/ocs/index.php/ICWSM/ICWSM14/paper/viewPaper/8075,1,reddit is a social news website where registered users submit content in the form of links or text posts. Users also known as “redditors” can then vote each submission “up” or “down” to rank the post and determine its position or prominence on the site’s pages. These two attributes associated with a post are referred to as “upvotes” and “downvotes”. Redditors can also comment on posts and respond back in a conversation tree of comments. Content entries that is the posts are organized by areas of interest or sub-communities called “subreddits” such as politics programming or science. As of 2013 reddit’s official statistics included 56 billion page views 731 million unique visitors 40855032 posts and 404603286 comments (http://blog.reddit.com/2013/ 12/top-posts-of-2013-stats-and-snoo-years.html). We used of reddit’s official API (http://www.reddit.com/ dev /api) to collect posts comments and associated metadata from several mental health subreddits: specifically using a Python wrapper PRAW (https://praw.readthedocs.org/en/ latest/index.html). The subreddits we crawled were: alcoholism anxiety bipolarreddit depression mentalhealth MMFB (Make Me Feel Better) socialanxiety SuicideWatch. All of these subreddits host public content. In order to arrive at a comprehensive list of subreddits to focus on we utilized reddit’s native subreddit search feature (http://www.reddit.com/reddits) and searched for subreddits on “mental health”. Two researchers familiar with reddit employed an initial filtering step on the search results returned so that we focus on high precision subreddits discussing mental health concerns and issues. Thereafter we focused on a snowball approach in which starting with a few seed subreddits (mentalhealth depression) we compiled a second list of “related” or “similar” subreddits that are listed in the profile pages of the seed subreddits. Following a second filtering step we arrived at the list of subreddits listed above. For each of these subreddits we obtained daily crawls of their posts in the New category. Corresponding to each post we collected information on the title of the post the body or textual content id timestamp when the post was made author id and the number of upvotes and downvotes it obtained. Since posts gather comments over a period of time following the time of sharing we crawled all of the comments per post that were shared over a three day period after the post was made. Qualitative examinations of the subreddits of interest revealed that 90% or more of the comments to any post were typically made in a three day window following the time the post is made—hence the choice. The crawl of the subreddits used in this paper We present some descriptive statistics of our crawled data. Our dataset contained 20411 posts with at least one comment and 97661 comments in all with 27102 unique users who made posts comments or both. A set of 7823 users (28.79%) were found to write both at least one post and comment. CDF of the user distribution over posts and comments is given in Figure 1. The figure shows the expected heavy tail trend observed in several social phenomena. Also see Figure 2 for the distribution of comments over time following post share. It illustrates the quick responsivity culture in the communities we study (peak at 3 hours). Some of the additional statistics of our dataset are given in Table 1. Further example titles of a few,reddit is a social news website where registered user submit content in the form of link or text post user also known a redditors can then vote each submission up or down to rank the post and determine it position or prominence on the site page these two attribute associated with a post are referred to a upvotes and downvotes redditors can also comment on post and respond back in a conversation tree of comment content entry that is the post are organized by area of interest or subcommunities called subreddits such a politics programming or science a of reddits official statistic included billion page view million unique visitor post and comment httpblogredditcom toppostsofstatsandsnooyearshtml we used of reddits official api httpwwwredditcom dev api to collect post comment and associated metadata from several mental health subreddits specifically using a python wrapper praw httpsprawreadthedocsorgen latestindexhtml the subreddits we crawled were alcoholism anxiety bipolarreddit depression mentalhealth mmfb make me feel better socialanxiety suicidewatch all of these subreddits host public content in order to arrive at a comprehensive list of subreddits to focus on we utilized reddits native subreddit search feature httpwwwredditcomreddits and searched for subreddits on mental health two researcher familiar with reddit employed an initial filtering step on the search result returned so that we focus on high precision subreddits discussing mental health concern and issue thereafter we focused on a snowball approach in which starting with a few seed subreddits mentalhealth depression we compiled a second list of related or similar subreddits that are listed in the profile page of the seed subreddits following a second filtering step we arrived at the list of subreddits listed above for each of these subreddits we obtained daily crawl of their post in the new category corresponding to each post we collected information on the title of the post the body or textual content id timestamp when the post wa made author id and the number of upvotes and downvotes it obtained since post gather comment over a period of time following the time of sharing we crawled all of the comment per post that were shared over a three day period after the post wa made qualitative examination of the subreddits of interest revealed that or more of the comment to any post were typically made in a three day window following the time the post is madehence the choice the crawl of the subreddits used in this paper we present some descriptive statistic of our crawled data our dataset contained post with at least one comment and comment in all with unique user who made post comment or both a set of user were found to write both at least one post and comment cdf of the user distribution over post and comment is given in figure the figure show the expected heavy tail trend observed in several social phenomenon also see figure for the distribution of comment over time following post share it illustrates the quick responsivity culture in the community we study peak at hour some of the additional statistic of our dataset are given in table further example title of a few,"['reddit', 'social', 'news', 'website', 'registered', 'submit', 'content', 'form', 'link', 'text', 'also', 'known', 'redditors', 'vote', 'submission', 'rank', 'determine', 'position', 'prominence', 'site', 'page', 'two', 'attribute', 'associated', 'referred', 'upvotes', 'downvotes', 'redditors', 'also', 'comment', 'respond', 'back', 'conversation', 'tree', 'comment', 'content', 'entry', 'organized', 'area', 'interest', 'subcommunities', 'called', 'subreddits', 'politics', 'programming', 'science', 'reddits', 'official', 'statistic', 'included', 'billion', 'page', 'view', 'million', 'unique', 'visitor', 'comment', 'httpblogredditcom', 'toppostsofstatsandsnooyearshtml', 'reddits', 'official', 'api', 'httpwwwredditcom', 'dev', 'api', 'collect', 'comment', 'associated', 'metadata', 'several', 'subreddits', 'specifically', 'using', 'python', 'wrapper', 'praw', 'httpsprawreadthedocsorgen', 'latestindexhtml', 'subreddits', 'crawled', 'alcoholism', 'anxiety', 'bipolarreddit', 'mentalhealth', 'mmfb', 'make', 'feel', 'better', 'socialanxiety', 'suicidewatch', 'subreddits', 'host', 'public', 'content', 'order', 'arrive', 'comprehensive', 'list', 'subreddits', 'focus', 'utilized', 'reddits', 'native', 'subreddit', 'search', 'feature', 'httpwwwredditcomreddits', 'searched', 'subreddits', 'two', 'researcher', 'familiar', 'reddit', 'employed', 'initial', 'filtering', 'step', 'search', 'result', 'returned', 'focus', 'high', 'precision', 'subreddits', 'discussing', 'concern', 'issue', 'thereafter', 'focused', 'snowball', 'approach', 'starting', 'seed', 'subreddits', 'mentalhealth', 'compiled', 'second', 'list', 'related', 'similar', 'subreddits', 'listed', 'profile', 'page', 'seed', 'subreddits', 'following', 'second', 'filtering', 'step', 'arrived', 'list', 'subreddits', 'listed', 'subreddits', 'obtained', 'daily', 'crawl', 'new', 'category', 'corresponding', 'collected', 'information', 'title', 'body', 'textual', 'content', 'id', 'timestamp', 'made', 'author', 'id', 'number', 'upvotes', 'downvotes', 'obtained', 'since', 'gather', 'comment', 'period', 'time', 'following', 'time', 'sharing', 'crawled', 'comment', 'per', 'shared', 'three', 'day', 'period', 'made', 'qualitative', 'examination', 'subreddits', 'interest', 'revealed', 'comment', 'typically', 'made', 'three', 'day', 'window', 'following', 'time', 'madehence', 'choice', 'crawl', 'subreddits', 'paper', 'present', 'descriptive', 'statistic', 'crawled', 'dataset', 'contained', 'least', 'one', 'comment', 'comment', 'unique', 'made', 'comment', 'set', 'found', 'write', 'least', 'one', 'comment', 'cdf', 'distribution', 'comment', 'given', 'figure', 'figure', 'show', 'expected', 'heavy', 'tail', 'trend', 'observed', 'several', 'social', 'phenomenon', 'also', 'see', 'figure', 'distribution', 'comment', 'time', 'following', 'share', 'illustrates', 'quick', 'responsivity', 'culture', 'community', 'study', 'peak', 'hour', 'additional', 'statistic', 'dataset', 'given', 'table', 'example', 'title']","['reddit social', 'social news', 'news website', 'website registered', 'registered submit', 'submit content', 'content form', 'form link', 'link text', 'text also', 'also known', 'known redditors', 'redditors vote', 'vote submission', 'submission rank', 'rank determine', 'determine position', 'position prominence', 'prominence site', 'site page', 'page two', 'two attribute', 'attribute associated', 'associated referred', 'referred upvotes', 'upvotes downvotes', 'downvotes redditors', 'redditors also', 'also comment', 'comment respond', 'respond back', 'back conversation', 'conversation tree', 'tree comment', 'comment content', 'content entry', 'entry organized', 'organized area', 'area interest', 'interest subcommunities', 'subcommunities called', 'called subreddits', 'subreddits politics', 'politics programming', 'programming science', 'science reddits', 'reddits official', 'official statistic', 'statistic included', 'included billion', 'billion page', 'page view', 'view million', 'million unique', 'unique visitor', 'visitor comment', 'comment httpblogredditcom', 'httpblogredditcom toppostsofstatsandsnooyearshtml', 'toppostsofstatsandsnooyearshtml reddits', 'reddits official', 'official api', 'api httpwwwredditcom', 'httpwwwredditcom dev', 'dev api', 'api collect', 'collect comment', 'comment associated', 'associated metadata', 'metadata several', 'several subreddits', 'subreddits specifically', 'specifically using', 'using python', 'python wrapper', 'wrapper praw', 'praw httpsprawreadthedocsorgen', 'httpsprawreadthedocsorgen latestindexhtml', 'latestindexhtml subreddits', 'subreddits crawled', 'crawled alcoholism', 'alcoholism anxiety', 'anxiety bipolarreddit', 'bipolarreddit mentalhealth', 'mentalhealth mmfb', 'mmfb make', 'make feel', 'feel better', 'better socialanxiety', 'socialanxiety suicidewatch', 'suicidewatch subreddits', 'subreddits host', 'host public', 'public content', 'content order', 'order arrive', 'arrive comprehensive', 'comprehensive list', 'list subreddits', 'subreddits focus', 'focus utilized', 'utilized reddits', 'reddits native', 'native subreddit', 'subreddit search', 'search feature', 'feature httpwwwredditcomreddits', 'httpwwwredditcomreddits searched', 'searched subreddits', 'subreddits two', 'two researcher', 'researcher familiar', 'familiar reddit', 'reddit employed', 'employed initial', 'initial filtering', 'filtering step', 'step search', 'search result', 'result returned', 'returned focus', 'focus high', 'high precision', 'precision subreddits', 'subreddits discussing', 'discussing concern', 'concern issue', 'issue thereafter', 'thereafter focused', 'focused snowball', 'snowball approach', 'approach starting', 'starting seed', 'seed subreddits', 'subreddits mentalhealth', 'mentalhealth compiled', 'compiled second', 'second list', 'list related', 'related similar', 'similar subreddits', 'subreddits listed', 'listed profile', 'profile page', 'page seed', 'seed subreddits', 'subreddits following', 'following second', 'second filtering', 'filtering step', 'step arrived', 'arrived list', 'list subreddits', 'subreddits listed', 'listed subreddits', 'subreddits obtained', 'obtained daily', 'daily crawl', 'crawl new', 'new category', 'category corresponding', 'corresponding collected', 'collected information', 'information title', 'title body', 'body textual', 'textual content', 'content id', 'id timestamp', 'timestamp made', 'made author', 'author id', 'id number', 'number upvotes', 'upvotes downvotes', 'downvotes obtained', 'obtained since', 'since gather', 'gather comment', 'comment period', 'period time', 'time following', 'following time', 'time sharing', 'sharing crawled', 'crawled comment', 'comment per', 'per shared', 'shared three', 'three day', 'day period', 'period made', 'made qualitative', 'qualitative examination', 'examination subreddits', 'subreddits interest', 'interest revealed', 'revealed comment', 'comment typically', 'typically made', 'made three', 'three day', 'day window', 'window following', 'following time', 'time madehence', 'madehence choice', 'choice crawl', 'crawl subreddits', 'subreddits paper', 'paper present', 'present descriptive', 'descriptive statistic', 'statistic crawled', 'crawled dataset', 'dataset contained', 'contained least', 'least one', 'one comment', 'comment comment', 'comment unique', 'unique made', 'made comment', 'comment set', 'set found', 'found write', 'write least', 'least one', 'one comment', 'comment cdf', 'cdf distribution', 'distribution comment', 'comment given', 'given figure', 'figure figure', 'figure show', 'show expected', 'expected heavy', 'heavy tail', 'tail trend', 'trend observed', 'observed several', 'several social', 'social phenomenon', 'phenomenon also', 'also see', 'see figure', 'figure distribution', 'distribution comment', 'comment time', 'time following', 'following share', 'share illustrates', 'illustrates quick', 'quick responsivity', 'responsivity culture', 'culture community', 'community study', 'study peak', 'peak hour', 'hour additional', 'additional statistic', 'statistic dataset', 'dataset given', 'given table', 'table example', 'example title']","['reddit social news', 'social news website', 'news website registered', 'website registered submit', 'registered submit content', 'submit content form', 'content form link', 'form link text', 'link text also', 'text also known', 'also known redditors', 'known redditors vote', 'redditors vote submission', 'vote submission rank', 'submission rank determine', 'rank determine position', 'determine position prominence', 'position prominence site', 'prominence site page', 'site page two', 'page two attribute', 'two attribute associated', 'attribute associated referred', 'associated referred upvotes', 'referred upvotes downvotes', 'upvotes downvotes redditors', 'downvotes redditors also', 'redditors also comment', 'also comment respond', 'comment respond back', 'respond back conversation', 'back conversation tree', 'conversation tree comment', 'tree comment content', 'comment content entry', 'content entry organized', 'entry organized area', 'organized area interest', 'area interest subcommunities', 'interest subcommunities called', 'subcommunities called subreddits', 'called subreddits politics', 'subreddits politics programming', 'politics programming science', 'programming science reddits', 'science reddits official', 'reddits official statistic', 'official statistic included', 'statistic included billion', 'included billion page', 'billion page view', 'page view million', 'view million unique', 'million unique visitor', 'unique visitor comment', 'visitor comment httpblogredditcom', 'comment httpblogredditcom toppostsofstatsandsnooyearshtml', 'httpblogredditcom toppostsofstatsandsnooyearshtml reddits', 'toppostsofstatsandsnooyearshtml reddits official', 'reddits official api', 'official api httpwwwredditcom', 'api httpwwwredditcom dev', 'httpwwwredditcom dev api', 'dev api collect', 'api collect comment', 'collect comment associated', 'comment associated metadata', 'associated metadata several', 'metadata several subreddits', 'several subreddits specifically', 'subreddits specifically using', 'specifically using python', 'using python wrapper', 'python wrapper praw', 'wrapper praw httpsprawreadthedocsorgen', 'praw httpsprawreadthedocsorgen latestindexhtml', 'httpsprawreadthedocsorgen latestindexhtml subreddits', 'latestindexhtml subreddits crawled', 'subreddits crawled alcoholism', 'crawled alcoholism anxiety', 'alcoholism anxiety bipolarreddit', 'anxiety bipolarreddit mentalhealth', 'bipolarreddit mentalhealth mmfb', 'mentalhealth mmfb make', 'mmfb make feel', 'make feel better', 'feel better socialanxiety', 'better socialanxiety suicidewatch', 'socialanxiety suicidewatch subreddits', 'suicidewatch subreddits host', 'subreddits host public', 'host public content', 'public content order', 'content order arrive', 'order arrive comprehensive', 'arrive comprehensive list', 'comprehensive list subreddits', 'list subreddits focus', 'subreddits focus utilized', 'focus utilized reddits', 'utilized reddits native', 'reddits native subreddit', 'native subreddit search', 'subreddit search feature', 'search feature httpwwwredditcomreddits', 'feature httpwwwredditcomreddits searched', 'httpwwwredditcomreddits searched subreddits', 'searched subreddits two', 'subreddits two researcher', 'two researcher familiar', 'researcher familiar reddit', 'familiar reddit employed', 'reddit employed initial', 'employed initial filtering', 'initial filtering step', 'filtering step search', 'step search result', 'search result returned', 'result returned focus', 'returned focus high', 'focus high precision', 'high precision subreddits', 'precision subreddits discussing', 'subreddits discussing concern', 'discussing concern issue', 'concern issue thereafter', 'issue thereafter focused', 'thereafter focused snowball', 'focused snowball approach', 'snowball approach starting', 'approach starting seed', 'starting seed subreddits', 'seed subreddits mentalhealth', 'subreddits mentalhealth compiled', 'mentalhealth compiled second', 'compiled second list', 'second list related', 'list related similar', 'related similar subreddits', 'similar subreddits listed', 'subreddits listed profile', 'listed profile page', 'profile page seed', 'page seed subreddits', 'seed subreddits following', 'subreddits following second', 'following second filtering', 'second filtering step', 'filtering step arrived', 'step arrived list', 'arrived list subreddits', 'list subreddits listed', 'subreddits listed subreddits', 'listed subreddits obtained', 'subreddits obtained daily', 'obtained daily crawl', 'daily crawl new', 'crawl new category', 'new category corresponding', 'category corresponding collected', 'corresponding collected information', 'collected information title', 'information title body', 'title body textual', 'body textual content', 'textual content id', 'content id timestamp', 'id timestamp made', 'timestamp made author', 'made author id', 'author id number', 'id number upvotes', 'number upvotes downvotes', 'upvotes downvotes obtained', 'downvotes obtained since', 'obtained since gather', 'since gather comment', 'gather comment period', 'comment period time', 'period time following', 'time following time', 'following time sharing', 'time sharing crawled', 'sharing crawled comment', 'crawled comment per', 'comment per shared', 'per shared three', 'shared three day', 'three day period', 'day period made', 'period made qualitative', 'made qualitative examination', 'qualitative examination subreddits', 'examination subreddits interest', 'subreddits interest revealed', 'interest revealed comment', 'revealed comment typically', 'comment typically made', 'typically made three', 'made three day', 'three day window', 'day window following', 'window following time', 'following time madehence', 'time madehence choice', 'madehence choice crawl', 'choice crawl subreddits', 'crawl subreddits paper', 'subreddits paper present', 'paper present descriptive', 'present descriptive statistic', 'descriptive statistic crawled', 'statistic crawled dataset', 'crawled dataset contained', 'dataset contained least', 'contained least one', 'least one comment', 'one comment comment', 'comment comment unique', 'comment unique made', 'unique made comment', 'made comment set', 'comment set found', 'set found write', 'found write least', 'write least one', 'least one comment', 'one comment cdf', 'comment cdf distribution', 'cdf distribution comment', 'distribution comment given', 'comment given figure', 'given figure figure', 'figure figure show', 'figure show expected', 'show expected heavy', 'expected heavy tail', 'heavy tail trend', 'tail trend observed', 'trend observed several', 'observed several social', 'several social phenomenon', 'social phenomenon also', 'phenomenon also see', 'also see figure', 'see figure distribution', 'figure distribution comment', 'distribution comment time', 'comment time following', 'time following share', 'following share illustrates', 'share illustrates quick', 'illustrates quick responsivity', 'quick responsivity culture', 'responsivity culture community', 'culture community study', 'community study peak', 'study peak hour', 'peak hour additional', 'hour additional statistic', 'additional statistic dataset', 'statistic dataset given', 'dataset given table', 'given table example', 'table example title']"
https://dl.acm.org/doi/abs/10.1145/3025453.3025932,1,We utilized Instagram’s official API1 to obtain the dataset used in this paper. Each post in this dataset is public and contains post-related information such as the image caption likes comments hashtags filter and geolocation if tagged. Referring to prior literature [10] we adopted an iterative approach to first identify a set of appropriate distinguishing hashtags around different prominent mental illnesses prevalent in social media. With the seed tags we performed an initial data collection of 1.5 million posts shared on Instagram between Dec 2010 and Nov 2015. Then by leveraging an association rule mining approach we compiled the top k (k = 39 frequency ≥ 5000) co-occurring tags in the 1.5M posts and then appended them to the original seed tag list for further data collection. Table 1 lists a sample set of tags used to crawl the dataset. This final list of 45 tags was thereafter passed on to a psychiatry researcher to be categorized into different disorder types. For tags that described experiences or symptoms crosscutting across different conditions (e.g. “anxiety”) they were counted toward each disorder type. Table 2 gives a list of the ten different disorders identified in our data. We additionally consulted the Diagnostic and Statistical Manual of Mental Health Disorders (DSM-V [5]) that indicates these disorders to be prominent mental health challenges in populations. This categorization of the mental health challenges was conducted to ensure that our data used in the ensuing analysis focused on well-validated and clinically recognized conditions. At the same time it allowed us to focus on a diverse range of disorders expressed on social media rather than specific ones studied in prior work [12 13 27]; thus enabling us to discover generalized patterns in visual disclosures of mental health challenges in social media. Our final crawl included 2757044 posts from 151638 users spanning these disorders.,we utilized instagrams official api to obtain the dataset used in this paper each post in this dataset is public and contains postrelated information such a the image caption like comment hashtags filter and geolocation if tagged referring to prior literature we adopted an iterative approach to first identify a set of appropriate distinguishing hashtags around different prominent mental illness prevalent in social medium with the seed tag we performed an initial data collection of million post shared on instagram between dec and nov then by leveraging an association rule mining approach we compiled the top k k frequency cooccurring tag in the m post and then appended them to the original seed tag list for further data collection table list a sample set of tag used to crawl the dataset this final list of tag wa thereafter passed on to a psychiatry researcher to be categorized into different disorder type for tag that described experience or symptom crosscutting across different condition eg anxiety they were counted toward each disorder type table give a list of the ten different disorder identified in our data we additionally consulted the diagnostic and statistical manual of mental health disorder dsmv that indicates these disorder to be prominent mental health challenge in population this categorization of the mental health challenge wa conducted to ensure that our data used in the ensuing analysis focused on wellvalidated and clinically recognized condition at the same time it allowed u to focus on a diverse range of disorder expressed on social medium rather than specific one studied in prior work thus enabling u to discover generalized pattern in visual disclosure of mental health challenge in social medium our final crawl included post from user spanning these disorder,"['utilized', 'instagrams', 'official', 'api', 'obtain', 'dataset', 'paper', 'dataset', 'public', 'contains', 'postrelated', 'information', 'image', 'caption', 'like', 'comment', 'hashtags', 'filter', 'geolocation', 'tagged', 'referring', 'prior', 'literature', 'adopted', 'iterative', 'approach', 'first', 'identify', 'set', 'appropriate', 'distinguishing', 'hashtags', 'around', 'different', 'prominent', 'illness', 'prevalent', 'social', 'medium', 'seed', 'tag', 'performed', 'initial', 'collection', 'million', 'shared', 'instagram', 'dec', 'nov', 'leveraging', 'association', 'rule', 'mining', 'approach', 'compiled', 'top', 'k', 'k', 'frequency', 'cooccurring', 'tag', 'appended', 'original', 'seed', 'tag', 'list', 'collection', 'table', 'list', 'sample', 'set', 'tag', 'crawl', 'dataset', 'final', 'list', 'tag', 'thereafter', 'passed', 'psychiatry', 'researcher', 'categorized', 'different', 'disorder', 'type', 'tag', 'described', 'experience', 'symptom', 'crosscutting', 'across', 'different', 'condition', 'eg', 'anxiety', 'counted', 'toward', 'disorder', 'type', 'table', 'give', 'list', 'ten', 'different', 'disorder', 'identified', 'additionally', 'consulted', 'diagnostic', 'statistical', 'manual', 'disorder', 'dsmv', 'indicates', 'disorder', 'prominent', 'challenge', 'population', 'categorization', 'challenge', 'conducted', 'ensure', 'ensuing', 'focused', 'wellvalidated', 'clinically', 'recognized', 'condition', 'time', 'allowed', 'u', 'focus', 'diverse', 'range', 'disorder', 'expressed', 'social', 'medium', 'rather', 'specific', 'one', 'studied', 'prior', 'work', 'thus', 'enabling', 'u', 'discover', 'generalized', 'pattern', 'visual', 'disclosure', 'challenge', 'social', 'medium', 'final', 'crawl', 'included', 'spanning', 'disorder']","['utilized instagrams', 'instagrams official', 'official api', 'api obtain', 'obtain dataset', 'dataset paper', 'paper dataset', 'dataset public', 'public contains', 'contains postrelated', 'postrelated information', 'information image', 'image caption', 'caption like', 'like comment', 'comment hashtags', 'hashtags filter', 'filter geolocation', 'geolocation tagged', 'tagged referring', 'referring prior', 'prior literature', 'literature adopted', 'adopted iterative', 'iterative approach', 'approach first', 'first identify', 'identify set', 'set appropriate', 'appropriate distinguishing', 'distinguishing hashtags', 'hashtags around', 'around different', 'different prominent', 'prominent illness', 'illness prevalent', 'prevalent social', 'social medium', 'medium seed', 'seed tag', 'tag performed', 'performed initial', 'initial collection', 'collection million', 'million shared', 'shared instagram', 'instagram dec', 'dec nov', 'nov leveraging', 'leveraging association', 'association rule', 'rule mining', 'mining approach', 'approach compiled', 'compiled top', 'top k', 'k k', 'k frequency', 'frequency cooccurring', 'cooccurring tag', 'tag appended', 'appended original', 'original seed', 'seed tag', 'tag list', 'list collection', 'collection table', 'table list', 'list sample', 'sample set', 'set tag', 'tag crawl', 'crawl dataset', 'dataset final', 'final list', 'list tag', 'tag thereafter', 'thereafter passed', 'passed psychiatry', 'psychiatry researcher', 'researcher categorized', 'categorized different', 'different disorder', 'disorder type', 'type tag', 'tag described', 'described experience', 'experience symptom', 'symptom crosscutting', 'crosscutting across', 'across different', 'different condition', 'condition eg', 'eg anxiety', 'anxiety counted', 'counted toward', 'toward disorder', 'disorder type', 'type table', 'table give', 'give list', 'list ten', 'ten different', 'different disorder', 'disorder identified', 'identified additionally', 'additionally consulted', 'consulted diagnostic', 'diagnostic statistical', 'statistical manual', 'manual disorder', 'disorder dsmv', 'dsmv indicates', 'indicates disorder', 'disorder prominent', 'prominent challenge', 'challenge population', 'population categorization', 'categorization challenge', 'challenge conducted', 'conducted ensure', 'ensure ensuing', 'ensuing focused', 'focused wellvalidated', 'wellvalidated clinically', 'clinically recognized', 'recognized condition', 'condition time', 'time allowed', 'allowed u', 'u focus', 'focus diverse', 'diverse range', 'range disorder', 'disorder expressed', 'expressed social', 'social medium', 'medium rather', 'rather specific', 'specific one', 'one studied', 'studied prior', 'prior work', 'work thus', 'thus enabling', 'enabling u', 'u discover', 'discover generalized', 'generalized pattern', 'pattern visual', 'visual disclosure', 'disclosure challenge', 'challenge social', 'social medium', 'medium final', 'final crawl', 'crawl included', 'included spanning', 'spanning disorder']","['utilized instagrams official', 'instagrams official api', 'official api obtain', 'api obtain dataset', 'obtain dataset paper', 'dataset paper dataset', 'paper dataset public', 'dataset public contains', 'public contains postrelated', 'contains postrelated information', 'postrelated information image', 'information image caption', 'image caption like', 'caption like comment', 'like comment hashtags', 'comment hashtags filter', 'hashtags filter geolocation', 'filter geolocation tagged', 'geolocation tagged referring', 'tagged referring prior', 'referring prior literature', 'prior literature adopted', 'literature adopted iterative', 'adopted iterative approach', 'iterative approach first', 'approach first identify', 'first identify set', 'identify set appropriate', 'set appropriate distinguishing', 'appropriate distinguishing hashtags', 'distinguishing hashtags around', 'hashtags around different', 'around different prominent', 'different prominent illness', 'prominent illness prevalent', 'illness prevalent social', 'prevalent social medium', 'social medium seed', 'medium seed tag', 'seed tag performed', 'tag performed initial', 'performed initial collection', 'initial collection million', 'collection million shared', 'million shared instagram', 'shared instagram dec', 'instagram dec nov', 'dec nov leveraging', 'nov leveraging association', 'leveraging association rule', 'association rule mining', 'rule mining approach', 'mining approach compiled', 'approach compiled top', 'compiled top k', 'top k k', 'k k frequency', 'k frequency cooccurring', 'frequency cooccurring tag', 'cooccurring tag appended', 'tag appended original', 'appended original seed', 'original seed tag', 'seed tag list', 'tag list collection', 'list collection table', 'collection table list', 'table list sample', 'list sample set', 'sample set tag', 'set tag crawl', 'tag crawl dataset', 'crawl dataset final', 'dataset final list', 'final list tag', 'list tag thereafter', 'tag thereafter passed', 'thereafter passed psychiatry', 'passed psychiatry researcher', 'psychiatry researcher categorized', 'researcher categorized different', 'categorized different disorder', 'different disorder type', 'disorder type tag', 'type tag described', 'tag described experience', 'described experience symptom', 'experience symptom crosscutting', 'symptom crosscutting across', 'crosscutting across different', 'across different condition', 'different condition eg', 'condition eg anxiety', 'eg anxiety counted', 'anxiety counted toward', 'counted toward disorder', 'toward disorder type', 'disorder type table', 'type table give', 'table give list', 'give list ten', 'list ten different', 'ten different disorder', 'different disorder identified', 'disorder identified additionally', 'identified additionally consulted', 'additionally consulted diagnostic', 'consulted diagnostic statistical', 'diagnostic statistical manual', 'statistical manual disorder', 'manual disorder dsmv', 'disorder dsmv indicates', 'dsmv indicates disorder', 'indicates disorder prominent', 'disorder prominent challenge', 'prominent challenge population', 'challenge population categorization', 'population categorization challenge', 'categorization challenge conducted', 'challenge conducted ensure', 'conducted ensure ensuing', 'ensure ensuing focused', 'ensuing focused wellvalidated', 'focused wellvalidated clinically', 'wellvalidated clinically recognized', 'clinically recognized condition', 'recognized condition time', 'condition time allowed', 'time allowed u', 'allowed u focus', 'u focus diverse', 'focus diverse range', 'diverse range disorder', 'range disorder expressed', 'disorder expressed social', 'expressed social medium', 'social medium rather', 'medium rather specific', 'rather specific one', 'specific one studied', 'one studied prior', 'studied prior work', 'prior work thus', 'work thus enabling', 'thus enabling u', 'enabling u discover', 'u discover generalized', 'discover generalized pattern', 'generalized pattern visual', 'pattern visual disclosure', 'visual disclosure challenge', 'disclosure challenge social', 'challenge social medium', 'social medium final', 'medium final crawl', 'final crawl included', 'crawl included spanning', 'included spanning disorder']"
https://www.sciencedirect.com/science/article/pii/S0747563215300996,1,The Twitter data in the current study is public. The study protocol was approved by the Washington University Institutional Review Board.,the twitter data in the current study is public the study protocol wa approved by the washington university institutional review board,"['current', 'study', 'public', 'study', 'protocol', 'approved', 'washington', 'university', 'institutional', 'review', 'board']","['current study', 'study public', 'public study', 'study protocol', 'protocol approved', 'approved washington', 'washington university', 'university institutional', 'institutional review', 'review board']","['current study public', 'study public study', 'public study protocol', 'study protocol approved', 'protocol approved washington', 'approved washington university', 'washington university institutional', 'university institutional review', 'institutional review board']"
https://aclanthology.org/W15-1202.pdf,1,We follow the data acquisition and curation process of Coppersmith et al. (2014a) summarizing the major points here: Social media such as Twitter contains frequent public statements by users reporting diagnoses for various medical conditions. Many talk about physical health conditions (e.g. cancer flu) but some also discuss mental illness including schizophrenia. There are a variety of motivations for users to share this information on social media: to offer or seek support to fight the stigma of mental illness or perhaps to offer an explanation for certain behaviors.4 We obtain messages with these self-reported diagnoses using the Twitter API and filtered via (caseinsensitive) regular expression to require “schizo” or a close phonetic approximation to be present; our expression matched “schizophrenia” its subtypes and various approximations: “schizo” “skitzo” “skitso” “schizotypal” “schizoid” etc. All data we collect are public posts made between 2008 and 2015 and exclude any message marked as ‘private’ by the author. All use of the data reported in this paper has been approved by the appropriate Institutional Review Board (IRB). Each self-stated diagnosis included in this study was examined by a human annotator (one of the authors) to verify that it appeared to be a genuine statement of a schizophrenia diagnosis excluding jokes quotes or disingenuous statements. We obtained 174 users with an apparently genuine selfstated diagnosis of a schizophrenia-related condition. Note that we cannot be certain that the Twitter user was actually diagnosed with schizophrenia only that their statement of being diagnosed appears to be genuine. Previous work indicates that interannotator agreement for this task is good: κ = 0.77 (Coppersmith et al. 2014a). For each user we obtained a set of their public Twitter posts via the Twitter API collecting up to 3200 tweets.5 As we wish to focus on user-authored content we exclude from analysis all retweets and any tweets that contain a URL (which often contain text that the user did not author). We lowercase all words and convert any non-standard characters (including emoji) to a systematic ASCII representation via Unidecode.6 For our community controls we used randomlyselected Twitter users who primarily tweet in English. Specifically during a two week period in early 2014 each Twitter user who was included in Twitter’s 1% “spritzer” sample had an equal chance for inclusion in our pool of community controls. We then collected some of their historic tweets and assessed the language(s) they tweeted in according to the Chromium Compact Language Detector.7 Users were excluded from our community controls if their tweets were less than 75% English.8,we follow the data acquisition and curation process of coppersmith et al a summarizing the major point here social medium such a twitter contains frequent public statement by user reporting diagnosis for various medical condition many talk about physical health condition eg cancer flu but some also discus mental illness including schizophrenia there are a variety of motivation for user to share this information on social medium to offer or seek support to fight the stigma of mental illness or perhaps to offer an explanation for certain behavior we obtain message with these selfreported diagnosis using the twitter api and filtered via caseinsensitive regular expression to require schizo or a close phonetic approximation to be present our expression matched schizophrenia it subtypes and various approximation schizo skitzo skitso schizotypal schizoid etc all data we collect are public post made between and and exclude any message marked a private by the author all use of the data reported in this paper ha been approved by the appropriate institutional review board irb each selfstated diagnosis included in this study wa examined by a human annotator one of the author to verify that it appeared to be a genuine statement of a schizophrenia diagnosis excluding joke quote or disingenuous statement we obtained user with an apparently genuine selfstated diagnosis of a schizophreniarelated condition note that we cannot be certain that the twitter user wa actually diagnosed with schizophrenia only that their statement of being diagnosed appears to be genuine previous work indicates that interannotator agreement for this task is good coppersmith et al a for each user we obtained a set of their public twitter post via the twitter api collecting up to tweet a we wish to focus on userauthored content we exclude from analysis all retweets and any tweet that contain a url which often contain text that the user did not author we lowercase all word and convert any nonstandard character including emoji to a systematic ascii representation via unidecode for our community control we used randomlyselected twitter user who primarily tweet in english specifically during a two week period in early each twitter user who wa included in twitter spritzer sample had an equal chance for inclusion in our pool of community control we then collected some of their historic tweet and assessed the language they tweeted in according to the chromium compact language detector user were excluded from our community control if their tweet were le than english,"['follow', 'acquisition', 'curation', 'process', 'coppersmith', 'et', 'al', 'summarizing', 'major', 'point', 'social', 'medium', 'contains', 'frequent', 'public', 'statement', 'reporting', 'diagnosis', 'various', 'medical', 'condition', 'many', 'talk', 'physical', 'condition', 'eg', 'cancer', 'flu', 'also', 'discus', 'illness', 'including', 'schizophrenia', 'variety', 'motivation', 'share', 'information', 'social', 'medium', 'offer', 'seek', 'support', 'fight', 'stigma', 'illness', 'perhaps', 'offer', 'explanation', 'certain', 'behavior', 'obtain', 'message', 'selfreported', 'diagnosis', 'using', 'api', 'filtered', 'via', 'caseinsensitive', 'regular', 'expression', 'require', 'schizo', 'close', 'phonetic', 'approximation', 'present', 'expression', 'matched', 'schizophrenia', 'subtypes', 'various', 'approximation', 'schizo', 'skitzo', 'skitso', 'schizotypal', 'schizoid', 'etc', 'collect', 'public', 'made', 'exclude', 'message', 'marked', 'private', 'author', 'use', 'reported', 'paper', 'ha', 'approved', 'appropriate', 'institutional', 'review', 'board', 'irb', 'selfstated', 'diagnosis', 'included', 'study', 'examined', 'human', 'annotator', 'one', 'author', 'verify', 'appeared', 'genuine', 'statement', 'schizophrenia', 'diagnosis', 'excluding', 'joke', 'quote', 'disingenuous', 'statement', 'obtained', 'apparently', 'genuine', 'selfstated', 'diagnosis', 'schizophreniarelated', 'condition', 'note', 'cannot', 'certain', 'actually', 'diagnosed', 'schizophrenia', 'statement', 'diagnosed', 'appears', 'genuine', 'previous', 'work', 'indicates', 'interannotator', 'agreement', 'task', 'good', 'coppersmith', 'et', 'al', 'obtained', 'set', 'public', 'via', 'api', 'collecting', 'wish', 'focus', 'userauthored', 'content', 'exclude', 'retweets', 'contain', 'url', 'often', 'contain', 'text', 'author', 'lowercase', 'word', 'convert', 'nonstandard', 'character', 'including', 'emoji', 'systematic', 'ascii', 'representation', 'via', 'unidecode', 'community', 'control', 'randomlyselected', 'primarily', 'english', 'specifically', 'two', 'week', 'period', 'early', 'included', 'spritzer', 'sample', 'equal', 'chance', 'inclusion', 'pool', 'community', 'control', 'collected', 'historic', 'assessed', 'language', 'tweeted', 'according', 'chromium', 'compact', 'language', 'detector', 'excluded', 'community', 'control', 'le', 'english']","['follow acquisition', 'acquisition curation', 'curation process', 'process coppersmith', 'coppersmith et', 'et al', 'al summarizing', 'summarizing major', 'major point', 'point social', 'social medium', 'medium contains', 'contains frequent', 'frequent public', 'public statement', 'statement reporting', 'reporting diagnosis', 'diagnosis various', 'various medical', 'medical condition', 'condition many', 'many talk', 'talk physical', 'physical condition', 'condition eg', 'eg cancer', 'cancer flu', 'flu also', 'also discus', 'discus illness', 'illness including', 'including schizophrenia', 'schizophrenia variety', 'variety motivation', 'motivation share', 'share information', 'information social', 'social medium', 'medium offer', 'offer seek', 'seek support', 'support fight', 'fight stigma', 'stigma illness', 'illness perhaps', 'perhaps offer', 'offer explanation', 'explanation certain', 'certain behavior', 'behavior obtain', 'obtain message', 'message selfreported', 'selfreported diagnosis', 'diagnosis using', 'using api', 'api filtered', 'filtered via', 'via caseinsensitive', 'caseinsensitive regular', 'regular expression', 'expression require', 'require schizo', 'schizo close', 'close phonetic', 'phonetic approximation', 'approximation present', 'present expression', 'expression matched', 'matched schizophrenia', 'schizophrenia subtypes', 'subtypes various', 'various approximation', 'approximation schizo', 'schizo skitzo', 'skitzo skitso', 'skitso schizotypal', 'schizotypal schizoid', 'schizoid etc', 'etc collect', 'collect public', 'public made', 'made exclude', 'exclude message', 'message marked', 'marked private', 'private author', 'author use', 'use reported', 'reported paper', 'paper ha', 'ha approved', 'approved appropriate', 'appropriate institutional', 'institutional review', 'review board', 'board irb', 'irb selfstated', 'selfstated diagnosis', 'diagnosis included', 'included study', 'study examined', 'examined human', 'human annotator', 'annotator one', 'one author', 'author verify', 'verify appeared', 'appeared genuine', 'genuine statement', 'statement schizophrenia', 'schizophrenia diagnosis', 'diagnosis excluding', 'excluding joke', 'joke quote', 'quote disingenuous', 'disingenuous statement', 'statement obtained', 'obtained apparently', 'apparently genuine', 'genuine selfstated', 'selfstated diagnosis', 'diagnosis schizophreniarelated', 'schizophreniarelated condition', 'condition note', 'note cannot', 'cannot certain', 'certain actually', 'actually diagnosed', 'diagnosed schizophrenia', 'schizophrenia statement', 'statement diagnosed', 'diagnosed appears', 'appears genuine', 'genuine previous', 'previous work', 'work indicates', 'indicates interannotator', 'interannotator agreement', 'agreement task', 'task good', 'good coppersmith', 'coppersmith et', 'et al', 'al obtained', 'obtained set', 'set public', 'public via', 'via api', 'api collecting', 'collecting wish', 'wish focus', 'focus userauthored', 'userauthored content', 'content exclude', 'exclude retweets', 'retweets contain', 'contain url', 'url often', 'often contain', 'contain text', 'text author', 'author lowercase', 'lowercase word', 'word convert', 'convert nonstandard', 'nonstandard character', 'character including', 'including emoji', 'emoji systematic', 'systematic ascii', 'ascii representation', 'representation via', 'via unidecode', 'unidecode community', 'community control', 'control randomlyselected', 'randomlyselected primarily', 'primarily english', 'english specifically', 'specifically two', 'two week', 'week period', 'period early', 'early included', 'included spritzer', 'spritzer sample', 'sample equal', 'equal chance', 'chance inclusion', 'inclusion pool', 'pool community', 'community control', 'control collected', 'collected historic', 'historic assessed', 'assessed language', 'language tweeted', 'tweeted according', 'according chromium', 'chromium compact', 'compact language', 'language detector', 'detector excluded', 'excluded community', 'community control', 'control le', 'le english']","['follow acquisition curation', 'acquisition curation process', 'curation process coppersmith', 'process coppersmith et', 'coppersmith et al', 'et al summarizing', 'al summarizing major', 'summarizing major point', 'major point social', 'point social medium', 'social medium contains', 'medium contains frequent', 'contains frequent public', 'frequent public statement', 'public statement reporting', 'statement reporting diagnosis', 'reporting diagnosis various', 'diagnosis various medical', 'various medical condition', 'medical condition many', 'condition many talk', 'many talk physical', 'talk physical condition', 'physical condition eg', 'condition eg cancer', 'eg cancer flu', 'cancer flu also', 'flu also discus', 'also discus illness', 'discus illness including', 'illness including schizophrenia', 'including schizophrenia variety', 'schizophrenia variety motivation', 'variety motivation share', 'motivation share information', 'share information social', 'information social medium', 'social medium offer', 'medium offer seek', 'offer seek support', 'seek support fight', 'support fight stigma', 'fight stigma illness', 'stigma illness perhaps', 'illness perhaps offer', 'perhaps offer explanation', 'offer explanation certain', 'explanation certain behavior', 'certain behavior obtain', 'behavior obtain message', 'obtain message selfreported', 'message selfreported diagnosis', 'selfreported diagnosis using', 'diagnosis using api', 'using api filtered', 'api filtered via', 'filtered via caseinsensitive', 'via caseinsensitive regular', 'caseinsensitive regular expression', 'regular expression require', 'expression require schizo', 'require schizo close', 'schizo close phonetic', 'close phonetic approximation', 'phonetic approximation present', 'approximation present expression', 'present expression matched', 'expression matched schizophrenia', 'matched schizophrenia subtypes', 'schizophrenia subtypes various', 'subtypes various approximation', 'various approximation schizo', 'approximation schizo skitzo', 'schizo skitzo skitso', 'skitzo skitso schizotypal', 'skitso schizotypal schizoid', 'schizotypal schizoid etc', 'schizoid etc collect', 'etc collect public', 'collect public made', 'public made exclude', 'made exclude message', 'exclude message marked', 'message marked private', 'marked private author', 'private author use', 'author use reported', 'use reported paper', 'reported paper ha', 'paper ha approved', 'ha approved appropriate', 'approved appropriate institutional', 'appropriate institutional review', 'institutional review board', 'review board irb', 'board irb selfstated', 'irb selfstated diagnosis', 'selfstated diagnosis included', 'diagnosis included study', 'included study examined', 'study examined human', 'examined human annotator', 'human annotator one', 'annotator one author', 'one author verify', 'author verify appeared', 'verify appeared genuine', 'appeared genuine statement', 'genuine statement schizophrenia', 'statement schizophrenia diagnosis', 'schizophrenia diagnosis excluding', 'diagnosis excluding joke', 'excluding joke quote', 'joke quote disingenuous', 'quote disingenuous statement', 'disingenuous statement obtained', 'statement obtained apparently', 'obtained apparently genuine', 'apparently genuine selfstated', 'genuine selfstated diagnosis', 'selfstated diagnosis schizophreniarelated', 'diagnosis schizophreniarelated condition', 'schizophreniarelated condition note', 'condition note cannot', 'note cannot certain', 'cannot certain actually', 'certain actually diagnosed', 'actually diagnosed schizophrenia', 'diagnosed schizophrenia statement', 'schizophrenia statement diagnosed', 'statement diagnosed appears', 'diagnosed appears genuine', 'appears genuine previous', 'genuine previous work', 'previous work indicates', 'work indicates interannotator', 'indicates interannotator agreement', 'interannotator agreement task', 'agreement task good', 'task good coppersmith', 'good coppersmith et', 'coppersmith et al', 'et al obtained', 'al obtained set', 'obtained set public', 'set public via', 'public via api', 'via api collecting', 'api collecting wish', 'collecting wish focus', 'wish focus userauthored', 'focus userauthored content', 'userauthored content exclude', 'content exclude retweets', 'exclude retweets contain', 'retweets contain url', 'contain url often', 'url often contain', 'often contain text', 'contain text author', 'text author lowercase', 'author lowercase word', 'lowercase word convert', 'word convert nonstandard', 'convert nonstandard character', 'nonstandard character including', 'character including emoji', 'including emoji systematic', 'emoji systematic ascii', 'systematic ascii representation', 'ascii representation via', 'representation via unidecode', 'via unidecode community', 'unidecode community control', 'community control randomlyselected', 'control randomlyselected primarily', 'randomlyselected primarily english', 'primarily english specifically', 'english specifically two', 'specifically two week', 'two week period', 'week period early', 'period early included', 'early included spritzer', 'included spritzer sample', 'spritzer sample equal', 'sample equal chance', 'equal chance inclusion', 'chance inclusion pool', 'inclusion pool community', 'pool community control', 'community control collected', 'control collected historic', 'collected historic assessed', 'historic assessed language', 'assessed language tweeted', 'language tweeted according', 'tweeted according chromium', 'according chromium compact', 'chromium compact language', 'compact language detector', 'language detector excluded', 'detector excluded community', 'excluded community control', 'community control le', 'control le english']"
https://dl.acm.org/doi/abs/10.1145/2700171.2791026,1,Next we develop a control to establish that changes in volume of posts in SW succeeding a celebrity suicide compared to that preceding it is attributed to the topic of suicide in particular and such changes are not part of a broader shift in interest in mental health topics. For this purpose we identified a set of “control group” subreddits which are on topics related to mental health but are unlikely to be specifically about suicide or suicidal ideation. These mental health subreddits (henceforth referred to as MH subreddits) were compiled based on our prior work in [11]; refer to the paper for details on how these subreddits are identified and crawled. Table 3 lists the control subreddits crawled in the same timeframe as SW. We obtained 32509 posts from 23807 unique users. Like SW all of these subreddits are public.,next we develop a control to establish that change in volume of post in sw succeeding a celebrity suicide compared to that preceding it is attributed to the topic of suicide in particular and such change are not part of a broader shift in interest in mental health topic for this purpose we identified a set of control group subreddits which are on topic related to mental health but are unlikely to be specifically about suicide or suicidal ideation these mental health subreddits henceforth referred to a mh subreddits were compiled based on our prior work in refer to the paper for detail on how these subreddits are identified and crawled table list the control subreddits crawled in the same timeframe a sw we obtained post from unique user like sw all of these subreddits are public,"['next', 'develop', 'control', 'establish', 'change', 'volume', 'sw', 'succeeding', 'celebrity', 'suicide', 'compared', 'preceding', 'attributed', 'topic', 'suicide', 'particular', 'change', 'part', 'broader', 'shift', 'interest', 'topic', 'purpose', 'identified', 'set', 'control', 'group', 'subreddits', 'topic', 'related', 'unlikely', 'specifically', 'suicide', 'suicidal', 'ideation', 'subreddits', 'henceforth', 'referred', 'mh', 'subreddits', 'compiled', 'based', 'prior', 'work', 'refer', 'paper', 'detail', 'subreddits', 'identified', 'crawled', 'table', 'list', 'control', 'subreddits', 'crawled', 'timeframe', 'sw', 'obtained', 'unique', 'like', 'sw', 'subreddits', 'public']","['next develop', 'develop control', 'control establish', 'establish change', 'change volume', 'volume sw', 'sw succeeding', 'succeeding celebrity', 'celebrity suicide', 'suicide compared', 'compared preceding', 'preceding attributed', 'attributed topic', 'topic suicide', 'suicide particular', 'particular change', 'change part', 'part broader', 'broader shift', 'shift interest', 'interest topic', 'topic purpose', 'purpose identified', 'identified set', 'set control', 'control group', 'group subreddits', 'subreddits topic', 'topic related', 'related unlikely', 'unlikely specifically', 'specifically suicide', 'suicide suicidal', 'suicidal ideation', 'ideation subreddits', 'subreddits henceforth', 'henceforth referred', 'referred mh', 'mh subreddits', 'subreddits compiled', 'compiled based', 'based prior', 'prior work', 'work refer', 'refer paper', 'paper detail', 'detail subreddits', 'subreddits identified', 'identified crawled', 'crawled table', 'table list', 'list control', 'control subreddits', 'subreddits crawled', 'crawled timeframe', 'timeframe sw', 'sw obtained', 'obtained unique', 'unique like', 'like sw', 'sw subreddits', 'subreddits public']","['next develop control', 'develop control establish', 'control establish change', 'establish change volume', 'change volume sw', 'volume sw succeeding', 'sw succeeding celebrity', 'succeeding celebrity suicide', 'celebrity suicide compared', 'suicide compared preceding', 'compared preceding attributed', 'preceding attributed topic', 'attributed topic suicide', 'topic suicide particular', 'suicide particular change', 'particular change part', 'change part broader', 'part broader shift', 'broader shift interest', 'shift interest topic', 'interest topic purpose', 'topic purpose identified', 'purpose identified set', 'identified set control', 'set control group', 'control group subreddits', 'group subreddits topic', 'subreddits topic related', 'topic related unlikely', 'related unlikely specifically', 'unlikely specifically suicide', 'specifically suicide suicidal', 'suicide suicidal ideation', 'suicidal ideation subreddits', 'ideation subreddits henceforth', 'subreddits henceforth referred', 'henceforth referred mh', 'referred mh subreddits', 'mh subreddits compiled', 'subreddits compiled based', 'compiled based prior', 'based prior work', 'prior work refer', 'work refer paper', 'refer paper detail', 'paper detail subreddits', 'detail subreddits identified', 'subreddits identified crawled', 'identified crawled table', 'crawled table list', 'table list control', 'list control subreddits', 'control subreddits crawled', 'subreddits crawled timeframe', 'crawled timeframe sw', 'timeframe sw obtained', 'sw obtained unique', 'obtained unique like', 'unique like sw', 'like sw subreddits', 'sw subreddits public']"
https://aclanthology.org/W17-3110.pdf,1,We briefly explain the data collection method here but we refer the interested reader with further questions on the methodology to Coppersmith et al. (2016) for the suicide attempt data and Coppersmith et al. (2014a) for all other conditions. The data for these analyses are Twitter posts collected via two methods. Most of the data come from users who have publicly discussed their mental health conditions. These users are frequently referred to as “self-stated diagnosis” users as they state publicly something like “I was diagnosed with schizophrenia” or “I’m so thankful to have survived my suicide attempt last year”. The data for users with a suicide attempt was supplemented by data from OurDataHelps.org a data donation site where people provide access to their public posts and fill out a short questionnaire about their mental health history. Data are then deidentified and made available to researchers addressing questions of interest to the mental health community. Donors provide consent for their data to be used in mental health research upon signup. Of the users who attempted suicide 146 came from OurDataHelps.org. Specifically we examine generalized anxiety disorder eating disorders panic attacks schizophrenia and attempted suicides. These conditions were selected based on the theory that there are important timing aspects to their symptoms – ebbing and flowing of symptoms as treatment is effective (especially schizophrenia) onset and exacerbation of symptoms by external events and stress and punctuated events in time of psychological symptoms (suicide attempts panic attacks and binging/purging behavior with eating disorders). We use the Twitter streaming API to collect a sample of users who used a series of mental health words or phrases in their tweet text (e.g. ‘schizophrenia‘ or ‘suicide attempt‘). Each tweet that uses one of these phrases is examined via regular expression to indicate that the user is talking about themselves. Finally those tweets that pass the regular expression are examined by a human to confirm (to the best of our ability) that their selfstatement of diagnosis appears to be genuine. This results in a dataset with users that have a self-stated diagnosis of generalized anxiety disorder (n = 2408) an eating disorder (749) panic attacks (263) schizophrenia (350) or someone who would go on to attempt suicide (423). Some of these users do not exhibit the sort of posting behavior required to create micropatterns (i.e. they rarely post multiple times within a 3 hour time window). We exclude these users from our analysis which is 5-9% of users for most conditions with the exception of those with a suicide attempt where a little over half the users do not exhibit this posting behavior. The resultant dataset used for analyses is: generalized anxiety disorder (n = 2271) eating disorders (687) panic attacks (247) schizophrenia (318) suicide attempts (157). In order to allow comparisons of each condition to control users we gather a random sample of 10000 Twitter users for whom at least 75% of their posts are identified by Twitter as English. All the users with a self-stated diagnoses and all members of this control population have their age and gender estimated according to Sap et al. (2014). For each user with a self-stated diagnosis we find a matched control through the following procedure: create a pool of users where the estimated gender matches and the estimated age is within the same 10-year bracket (the suggested accuracy of the age estimator). From that pool of age- and gender- matched users we select the user whose tweets start and end over the most similar timeframe. We will refer to these age- gender- and time-matched controls simply as “matched controls” throughout the rest of this paper. All tweets were publicly posted by their author (i.e. no users marked at “protected” or “private” were included). On average users had 2949 tweets. The distribution of estimated age and genders for users with each self-stated condition can be seen in Figure 1. For most conditions the population skews female though for schizophrenia the genders are roughly balanced. The average age tends to be in the early-to-mid 20s.,we briefly explain the data collection method here but we refer the interested reader with further question on the methodology to coppersmith et al for the suicide attempt data and coppersmith et al a for all other condition the data for these analysis are twitter post collected via two method most of the data come from user who have publicly discussed their mental health condition these user are frequently referred to a selfstated diagnosis user a they state publicly something like i wa diagnosed with schizophrenia or im so thankful to have survived my suicide attempt last year the data for user with a suicide attempt wa supplemented by data from ourdatahelpsorg a data donation site where people provide access to their public post and fill out a short questionnaire about their mental health history data are then deidentified and made available to researcher addressing question of interest to the mental health community donor provide consent for their data to be used in mental health research upon signup of the user who attempted suicide came from ourdatahelpsorg specifically we examine generalized anxiety disorder eating disorder panic attack schizophrenia and attempted suicide these condition were selected based on the theory that there are important timing aspect to their symptom ebbing and flowing of symptom a treatment is effective especially schizophrenia onset and exacerbation of symptom by external event and stress and punctuated event in time of psychological symptom suicide attempt panic attack and bingingpurging behavior with eating disorder we use the twitter streaming api to collect a sample of user who used a series of mental health word or phrase in their tweet text eg schizophrenia or suicide attempt each tweet that us one of these phrase is examined via regular expression to indicate that the user is talking about themselves finally those tweet that pas the regular expression are examined by a human to confirm to the best of our ability that their selfstatement of diagnosis appears to be genuine this result in a dataset with user that have a selfstated diagnosis of generalized anxiety disorder n an eating disorder panic attack schizophrenia or someone who would go on to attempt suicide some of these user do not exhibit the sort of posting behavior required to create micropatterns ie they rarely post multiple time within a hour time window we exclude these user from our analysis which is of user for most condition with the exception of those with a suicide attempt where a little over half the user do not exhibit this posting behavior the resultant dataset used for analysis is generalized anxiety disorder n eating disorder panic attack schizophrenia suicide attempt in order to allow comparison of each condition to control user we gather a random sample of twitter user for whom at least of their post are identified by twitter a english all the user with a selfstated diagnosis and all member of this control population have their age and gender estimated according to sap et al for each user with a selfstated diagnosis we find a matched control through the following procedure create a pool of user where the estimated gender match and the estimated age is within the same year bracket the suggested accuracy of the age estimator from that pool of age and gender matched user we select the user whose tweet start and end over the most similar timeframe we will refer to these age gender and timematched control simply a matched control throughout the rest of this paper all tweet were publicly posted by their author ie no user marked at protected or private were included on average user had tweet the distribution of estimated age and gender for user with each selfstated condition can be seen in figure for most condition the population skews female though for schizophrenia the gender are roughly balanced the average age tends to be in the earlytomid s,"['briefly', 'explain', 'collection', 'method', 'refer', 'interested', 'reader', 'question', 'methodology', 'coppersmith', 'et', 'al', 'suicide', 'attempt', 'coppersmith', 'et', 'al', 'condition', 'collected', 'via', 'two', 'method', 'come', 'publicly', 'discussed', 'condition', 'frequently', 'referred', 'selfstated', 'diagnosis', 'state', 'publicly', 'something', 'like', 'diagnosed', 'schizophrenia', 'im', 'thankful', 'survived', 'suicide', 'attempt', 'last', 'year', 'suicide', 'attempt', 'supplemented', 'ourdatahelpsorg', 'donation', 'site', 'people', 'provide', 'access', 'public', 'fill', 'short', 'questionnaire', 'history', 'deidentified', 'made', 'available', 'researcher', 'addressing', 'question', 'interest', 'community', 'donor', 'provide', 'consent', 'research', 'upon', 'signup', 'attempted', 'suicide', 'came', 'ourdatahelpsorg', 'specifically', 'examine', 'generalized', 'anxiety', 'disorder', 'eating', 'disorder', 'panic', 'attack', 'schizophrenia', 'attempted', 'suicide', 'condition', 'selected', 'based', 'theory', 'important', 'timing', 'aspect', 'symptom', 'ebbing', 'flowing', 'symptom', 'treatment', 'effective', 'especially', 'schizophrenia', 'onset', 'exacerbation', 'symptom', 'external', 'event', 'stress', 'punctuated', 'event', 'time', 'psychological', 'symptom', 'suicide', 'attempt', 'panic', 'attack', 'bingingpurging', 'behavior', 'eating', 'disorder', 'use', 'streaming', 'api', 'collect', 'sample', 'series', 'word', 'phrase', 'text', 'eg', 'schizophrenia', 'suicide', 'attempt', 'us', 'one', 'phrase', 'examined', 'via', 'regular', 'expression', 'indicate', 'talking', 'finally', 'pas', 'regular', 'expression', 'examined', 'human', 'confirm', 'best', 'ability', 'selfstatement', 'diagnosis', 'appears', 'genuine', 'result', 'dataset', 'selfstated', 'diagnosis', 'generalized', 'anxiety', 'disorder', 'n', 'eating', 'disorder', 'panic', 'attack', 'schizophrenia', 'someone', 'would', 'go', 'attempt', 'suicide', 'exhibit', 'sort', 'posting', 'behavior', 'required', 'create', 'micropatterns', 'ie', 'rarely', 'multiple', 'time', 'within', 'hour', 'time', 'window', 'exclude', 'condition', 'exception', 'suicide', 'attempt', 'little', 'half', 'exhibit', 'posting', 'behavior', 'resultant', 'dataset', 'generalized', 'anxiety', 'disorder', 'n', 'eating', 'disorder', 'panic', 'attack', 'schizophrenia', 'suicide', 'attempt', 'order', 'allow', 'comparison', 'condition', 'control', 'gather', 'random', 'sample', 'least', 'identified', 'english', 'selfstated', 'diagnosis', 'member', 'control', 'population', 'age', 'gender', 'estimated', 'according', 'sap', 'et', 'al', 'selfstated', 'diagnosis', 'find', 'matched', 'control', 'following', 'procedure', 'create', 'pool', 'estimated', 'gender', 'match', 'estimated', 'age', 'within', 'year', 'bracket', 'suggested', 'accuracy', 'age', 'estimator', 'pool', 'age', 'gender', 'matched', 'select', 'whose', 'start', 'end', 'similar', 'timeframe', 'refer', 'age', 'gender', 'timematched', 'control', 'simply', 'matched', 'control', 'throughout', 'rest', 'paper', 'publicly', 'posted', 'author', 'ie', 'marked', 'protected', 'private', 'included', 'average', 'distribution', 'estimated', 'age', 'gender', 'selfstated', 'condition', 'seen', 'figure', 'condition', 'population', 'skews', 'female', 'though', 'schizophrenia', 'gender', 'roughly', 'balanced', 'average', 'age', 'tends', 'earlytomid']","['briefly explain', 'explain collection', 'collection method', 'method refer', 'refer interested', 'interested reader', 'reader question', 'question methodology', 'methodology coppersmith', 'coppersmith et', 'et al', 'al suicide', 'suicide attempt', 'attempt coppersmith', 'coppersmith et', 'et al', 'al condition', 'condition collected', 'collected via', 'via two', 'two method', 'method come', 'come publicly', 'publicly discussed', 'discussed condition', 'condition frequently', 'frequently referred', 'referred selfstated', 'selfstated diagnosis', 'diagnosis state', 'state publicly', 'publicly something', 'something like', 'like diagnosed', 'diagnosed schizophrenia', 'schizophrenia im', 'im thankful', 'thankful survived', 'survived suicide', 'suicide attempt', 'attempt last', 'last year', 'year suicide', 'suicide attempt', 'attempt supplemented', 'supplemented ourdatahelpsorg', 'ourdatahelpsorg donation', 'donation site', 'site people', 'people provide', 'provide access', 'access public', 'public fill', 'fill short', 'short questionnaire', 'questionnaire history', 'history deidentified', 'deidentified made', 'made available', 'available researcher', 'researcher addressing', 'addressing question', 'question interest', 'interest community', 'community donor', 'donor provide', 'provide consent', 'consent research', 'research upon', 'upon signup', 'signup attempted', 'attempted suicide', 'suicide came', 'came ourdatahelpsorg', 'ourdatahelpsorg specifically', 'specifically examine', 'examine generalized', 'generalized anxiety', 'anxiety disorder', 'disorder eating', 'eating disorder', 'disorder panic', 'panic attack', 'attack schizophrenia', 'schizophrenia attempted', 'attempted suicide', 'suicide condition', 'condition selected', 'selected based', 'based theory', 'theory important', 'important timing', 'timing aspect', 'aspect symptom', 'symptom ebbing', 'ebbing flowing', 'flowing symptom', 'symptom treatment', 'treatment effective', 'effective especially', 'especially schizophrenia', 'schizophrenia onset', 'onset exacerbation', 'exacerbation symptom', 'symptom external', 'external event', 'event stress', 'stress punctuated', 'punctuated event', 'event time', 'time psychological', 'psychological symptom', 'symptom suicide', 'suicide attempt', 'attempt panic', 'panic attack', 'attack bingingpurging', 'bingingpurging behavior', 'behavior eating', 'eating disorder', 'disorder use', 'use streaming', 'streaming api', 'api collect', 'collect sample', 'sample series', 'series word', 'word phrase', 'phrase text', 'text eg', 'eg schizophrenia', 'schizophrenia suicide', 'suicide attempt', 'attempt us', 'us one', 'one phrase', 'phrase examined', 'examined via', 'via regular', 'regular expression', 'expression indicate', 'indicate talking', 'talking finally', 'finally pas', 'pas regular', 'regular expression', 'expression examined', 'examined human', 'human confirm', 'confirm best', 'best ability', 'ability selfstatement', 'selfstatement diagnosis', 'diagnosis appears', 'appears genuine', 'genuine result', 'result dataset', 'dataset selfstated', 'selfstated diagnosis', 'diagnosis generalized', 'generalized anxiety', 'anxiety disorder', 'disorder n', 'n eating', 'eating disorder', 'disorder panic', 'panic attack', 'attack schizophrenia', 'schizophrenia someone', 'someone would', 'would go', 'go attempt', 'attempt suicide', 'suicide exhibit', 'exhibit sort', 'sort posting', 'posting behavior', 'behavior required', 'required create', 'create micropatterns', 'micropatterns ie', 'ie rarely', 'rarely multiple', 'multiple time', 'time within', 'within hour', 'hour time', 'time window', 'window exclude', 'exclude condition', 'condition exception', 'exception suicide', 'suicide attempt', 'attempt little', 'little half', 'half exhibit', 'exhibit posting', 'posting behavior', 'behavior resultant', 'resultant dataset', 'dataset generalized', 'generalized anxiety', 'anxiety disorder', 'disorder n', 'n eating', 'eating disorder', 'disorder panic', 'panic attack', 'attack schizophrenia', 'schizophrenia suicide', 'suicide attempt', 'attempt order', 'order allow', 'allow comparison', 'comparison condition', 'condition control', 'control gather', 'gather random', 'random sample', 'sample least', 'least identified', 'identified english', 'english selfstated', 'selfstated diagnosis', 'diagnosis member', 'member control', 'control population', 'population age', 'age gender', 'gender estimated', 'estimated according', 'according sap', 'sap et', 'et al', 'al selfstated', 'selfstated diagnosis', 'diagnosis find', 'find matched', 'matched control', 'control following', 'following procedure', 'procedure create', 'create pool', 'pool estimated', 'estimated gender', 'gender match', 'match estimated', 'estimated age', 'age within', 'within year', 'year bracket', 'bracket suggested', 'suggested accuracy', 'accuracy age', 'age estimator', 'estimator pool', 'pool age', 'age gender', 'gender matched', 'matched select', 'select whose', 'whose start', 'start end', 'end similar', 'similar timeframe', 'timeframe refer', 'refer age', 'age gender', 'gender timematched', 'timematched control', 'control simply', 'simply matched', 'matched control', 'control throughout', 'throughout rest', 'rest paper', 'paper publicly', 'publicly posted', 'posted author', 'author ie', 'ie marked', 'marked protected', 'protected private', 'private included', 'included average', 'average distribution', 'distribution estimated', 'estimated age', 'age gender', 'gender selfstated', 'selfstated condition', 'condition seen', 'seen figure', 'figure condition', 'condition population', 'population skews', 'skews female', 'female though', 'though schizophrenia', 'schizophrenia gender', 'gender roughly', 'roughly balanced', 'balanced average', 'average age', 'age tends', 'tends earlytomid']","['briefly explain collection', 'explain collection method', 'collection method refer', 'method refer interested', 'refer interested reader', 'interested reader question', 'reader question methodology', 'question methodology coppersmith', 'methodology coppersmith et', 'coppersmith et al', 'et al suicide', 'al suicide attempt', 'suicide attempt coppersmith', 'attempt coppersmith et', 'coppersmith et al', 'et al condition', 'al condition collected', 'condition collected via', 'collected via two', 'via two method', 'two method come', 'method come publicly', 'come publicly discussed', 'publicly discussed condition', 'discussed condition frequently', 'condition frequently referred', 'frequently referred selfstated', 'referred selfstated diagnosis', 'selfstated diagnosis state', 'diagnosis state publicly', 'state publicly something', 'publicly something like', 'something like diagnosed', 'like diagnosed schizophrenia', 'diagnosed schizophrenia im', 'schizophrenia im thankful', 'im thankful survived', 'thankful survived suicide', 'survived suicide attempt', 'suicide attempt last', 'attempt last year', 'last year suicide', 'year suicide attempt', 'suicide attempt supplemented', 'attempt supplemented ourdatahelpsorg', 'supplemented ourdatahelpsorg donation', 'ourdatahelpsorg donation site', 'donation site people', 'site people provide', 'people provide access', 'provide access public', 'access public fill', 'public fill short', 'fill short questionnaire', 'short questionnaire history', 'questionnaire history deidentified', 'history deidentified made', 'deidentified made available', 'made available researcher', 'available researcher addressing', 'researcher addressing question', 'addressing question interest', 'question interest community', 'interest community donor', 'community donor provide', 'donor provide consent', 'provide consent research', 'consent research upon', 'research upon signup', 'upon signup attempted', 'signup attempted suicide', 'attempted suicide came', 'suicide came ourdatahelpsorg', 'came ourdatahelpsorg specifically', 'ourdatahelpsorg specifically examine', 'specifically examine generalized', 'examine generalized anxiety', 'generalized anxiety disorder', 'anxiety disorder eating', 'disorder eating disorder', 'eating disorder panic', 'disorder panic attack', 'panic attack schizophrenia', 'attack schizophrenia attempted', 'schizophrenia attempted suicide', 'attempted suicide condition', 'suicide condition selected', 'condition selected based', 'selected based theory', 'based theory important', 'theory important timing', 'important timing aspect', 'timing aspect symptom', 'aspect symptom ebbing', 'symptom ebbing flowing', 'ebbing flowing symptom', 'flowing symptom treatment', 'symptom treatment effective', 'treatment effective especially', 'effective especially schizophrenia', 'especially schizophrenia onset', 'schizophrenia onset exacerbation', 'onset exacerbation symptom', 'exacerbation symptom external', 'symptom external event', 'external event stress', 'event stress punctuated', 'stress punctuated event', 'punctuated event time', 'event time psychological', 'time psychological symptom', 'psychological symptom suicide', 'symptom suicide attempt', 'suicide attempt panic', 'attempt panic attack', 'panic attack bingingpurging', 'attack bingingpurging behavior', 'bingingpurging behavior eating', 'behavior eating disorder', 'eating disorder use', 'disorder use streaming', 'use streaming api', 'streaming api collect', 'api collect sample', 'collect sample series', 'sample series word', 'series word phrase', 'word phrase text', 'phrase text eg', 'text eg schizophrenia', 'eg schizophrenia suicide', 'schizophrenia suicide attempt', 'suicide attempt us', 'attempt us one', 'us one phrase', 'one phrase examined', 'phrase examined via', 'examined via regular', 'via regular expression', 'regular expression indicate', 'expression indicate talking', 'indicate talking finally', 'talking finally pas', 'finally pas regular', 'pas regular expression', 'regular expression examined', 'expression examined human', 'examined human confirm', 'human confirm best', 'confirm best ability', 'best ability selfstatement', 'ability selfstatement diagnosis', 'selfstatement diagnosis appears', 'diagnosis appears genuine', 'appears genuine result', 'genuine result dataset', 'result dataset selfstated', 'dataset selfstated diagnosis', 'selfstated diagnosis generalized', 'diagnosis generalized anxiety', 'generalized anxiety disorder', 'anxiety disorder n', 'disorder n eating', 'n eating disorder', 'eating disorder panic', 'disorder panic attack', 'panic attack schizophrenia', 'attack schizophrenia someone', 'schizophrenia someone would', 'someone would go', 'would go attempt', 'go attempt suicide', 'attempt suicide exhibit', 'suicide exhibit sort', 'exhibit sort posting', 'sort posting behavior', 'posting behavior required', 'behavior required create', 'required create micropatterns', 'create micropatterns ie', 'micropatterns ie rarely', 'ie rarely multiple', 'rarely multiple time', 'multiple time within', 'time within hour', 'within hour time', 'hour time window', 'time window exclude', 'window exclude condition', 'exclude condition exception', 'condition exception suicide', 'exception suicide attempt', 'suicide attempt little', 'attempt little half', 'little half exhibit', 'half exhibit posting', 'exhibit posting behavior', 'posting behavior resultant', 'behavior resultant dataset', 'resultant dataset generalized', 'dataset generalized anxiety', 'generalized anxiety disorder', 'anxiety disorder n', 'disorder n eating', 'n eating disorder', 'eating disorder panic', 'disorder panic attack', 'panic attack schizophrenia', 'attack schizophrenia suicide', 'schizophrenia suicide attempt', 'suicide attempt order', 'attempt order allow', 'order allow comparison', 'allow comparison condition', 'comparison condition control', 'condition control gather', 'control gather random', 'gather random sample', 'random sample least', 'sample least identified', 'least identified english', 'identified english selfstated', 'english selfstated diagnosis', 'selfstated diagnosis member', 'diagnosis member control', 'member control population', 'control population age', 'population age gender', 'age gender estimated', 'gender estimated according', 'estimated according sap', 'according sap et', 'sap et al', 'et al selfstated', 'al selfstated diagnosis', 'selfstated diagnosis find', 'diagnosis find matched', 'find matched control', 'matched control following', 'control following procedure', 'following procedure create', 'procedure create pool', 'create pool estimated', 'pool estimated gender', 'estimated gender match', 'gender match estimated', 'match estimated age', 'estimated age within', 'age within year', 'within year bracket', 'year bracket suggested', 'bracket suggested accuracy', 'suggested accuracy age', 'accuracy age estimator', 'age estimator pool', 'estimator pool age', 'pool age gender', 'age gender matched', 'gender matched select', 'matched select whose', 'select whose start', 'whose start end', 'start end similar', 'end similar timeframe', 'similar timeframe refer', 'timeframe refer age', 'refer age gender', 'age gender timematched', 'gender timematched control', 'timematched control simply', 'control simply matched', 'simply matched control', 'matched control throughout', 'control throughout rest', 'throughout rest paper', 'rest paper publicly', 'paper publicly posted', 'publicly posted author', 'posted author ie', 'author ie marked', 'ie marked protected', 'marked protected private', 'protected private included', 'private included average', 'included average distribution', 'average distribution estimated', 'distribution estimated age', 'estimated age gender', 'age gender selfstated', 'gender selfstated condition', 'selfstated condition seen', 'condition seen figure', 'seen figure condition', 'figure condition population', 'condition population skews', 'population skews female', 'skews female though', 'female though schizophrenia', 'though schizophrenia gender', 'schizophrenia gender roughly', 'gender roughly balanced', 'roughly balanced average', 'balanced average age', 'average age tends', 'age tends earlytomid']"
https://dl.acm.org/doi/abs/10.1145/2998181.2998220,1,We leverage public data from Twitter and Reddit for our work; hence our work did not qualify for approval from our Institutional Review Board. Nevertheless we took greater care in de-identifying and paraphrasing any content we present as examples to support our investigation. Importantly our work does not make any diagnostic claims about mental illness experiences of the population we study.,we leverage public data from twitter and reddit for our work hence our work did not qualify for approval from our institutional review board nevertheless we took greater care in deidentifying and paraphrasing any content we present a example to support our investigation importantly our work doe not make any diagnostic claim about mental illness experience of the population we study,"['leverage', 'public', 'reddit', 'work', 'hence', 'work', 'qualify', 'approval', 'institutional', 'review', 'board', 'nevertheless', 'took', 'greater', 'care', 'deidentifying', 'paraphrasing', 'content', 'present', 'example', 'support', 'investigation', 'importantly', 'work', 'doe', 'make', 'diagnostic', 'claim', 'illness', 'experience', 'population', 'study']","['leverage public', 'public reddit', 'reddit work', 'work hence', 'hence work', 'work qualify', 'qualify approval', 'approval institutional', 'institutional review', 'review board', 'board nevertheless', 'nevertheless took', 'took greater', 'greater care', 'care deidentifying', 'deidentifying paraphrasing', 'paraphrasing content', 'content present', 'present example', 'example support', 'support investigation', 'investigation importantly', 'importantly work', 'work doe', 'doe make', 'make diagnostic', 'diagnostic claim', 'claim illness', 'illness experience', 'experience population', 'population study']","['leverage public reddit', 'public reddit work', 'reddit work hence', 'work hence work', 'hence work qualify', 'work qualify approval', 'qualify approval institutional', 'approval institutional review', 'institutional review board', 'review board nevertheless', 'board nevertheless took', 'nevertheless took greater', 'took greater care', 'greater care deidentifying', 'care deidentifying paraphrasing', 'deidentifying paraphrasing content', 'paraphrasing content present', 'content present example', 'present example support', 'example support investigation', 'support investigation importantly', 'investigation importantly work', 'importantly work doe', 'work doe make', 'doe make diagnostic', 'make diagnostic claim', 'diagnostic claim illness', 'claim illness experience', 'illness experience population', 'experience population study']"
https://www.jmir.org/2019/6/e14199/,1,This study was designed and developed in 2 steps with the aim of analyzing the linguistic patterns and behavioral features of Twitter users suffering from depression in comparison with the general population of Twitter users. The study was focused on tweets written in Spanish. In the first step the selection of users and the compilation of tweets were performed. Given the design and purpose of the study we decided to use the Twitter Application Programming Interface (API) [41]. Using this API 3 datasets of tweets were created: The depressive users dataset was made up of the timeline of 90 users who publicly mentioned on their Twitter profile that they suffer from depression. The control dataset was made up of the timeline of 450 randomly selected Twitter users. The depressive tweets dataset was constituted by a manual selection of tweets from the depressive users dataset which specifically included expressions indicative of depression. In the second step comparison and analysis of the 3 datasets of tweets (control depressive users and depressive tweets datasets) were carried out to spot their distinguishing features. In the rest of this section we will describe the methodology in detail. The flow diagram of the study is depicted in Figure 1.,this study wa designed and developed in step with the aim of analyzing the linguistic pattern and behavioral feature of twitter user suffering from depression in comparison with the general population of twitter user the study wa focused on tweet written in spanish in the first step the selection of user and the compilation of tweet were performed given the design and purpose of the study we decided to use the twitter application programming interface api using this api datasets of tweet were created the depressive user dataset wa made up of the timeline of user who publicly mentioned on their twitter profile that they suffer from depression the control dataset wa made up of the timeline of randomly selected twitter user the depressive tweet dataset wa constituted by a manual selection of tweet from the depressive user dataset which specifically included expression indicative of depression in the second step comparison and analysis of the datasets of tweet control depressive user and depressive tweet datasets were carried out to spot their distinguishing feature in the rest of this section we will describe the methodology in detail the flow diagram of the study is depicted in figure,"['study', 'designed', 'developed', 'step', 'aim', 'analyzing', 'linguistic', 'pattern', 'behavioral', 'feature', 'suffering', 'comparison', 'general', 'population', 'study', 'focused', 'written', 'spanish', 'first', 'step', 'selection', 'compilation', 'performed', 'given', 'design', 'purpose', 'study', 'decided', 'use', 'application', 'programming', 'interface', 'api', 'using', 'api', 'datasets', 'created', 'depressive', 'dataset', 'made', 'timeline', 'publicly', 'mentioned', 'profile', 'suffer', 'control', 'dataset', 'made', 'timeline', 'randomly', 'selected', 'depressive', 'dataset', 'constituted', 'manual', 'selection', 'depressive', 'dataset', 'specifically', 'included', 'expression', 'indicative', 'second', 'step', 'comparison', 'datasets', 'control', 'depressive', 'depressive', 'datasets', 'carried', 'spot', 'distinguishing', 'feature', 'rest', 'section', 'describe', 'methodology', 'detail', 'flow', 'diagram', 'study', 'depicted', 'figure']","['study designed', 'designed developed', 'developed step', 'step aim', 'aim analyzing', 'analyzing linguistic', 'linguistic pattern', 'pattern behavioral', 'behavioral feature', 'feature suffering', 'suffering comparison', 'comparison general', 'general population', 'population study', 'study focused', 'focused written', 'written spanish', 'spanish first', 'first step', 'step selection', 'selection compilation', 'compilation performed', 'performed given', 'given design', 'design purpose', 'purpose study', 'study decided', 'decided use', 'use application', 'application programming', 'programming interface', 'interface api', 'api using', 'using api', 'api datasets', 'datasets created', 'created depressive', 'depressive dataset', 'dataset made', 'made timeline', 'timeline publicly', 'publicly mentioned', 'mentioned profile', 'profile suffer', 'suffer control', 'control dataset', 'dataset made', 'made timeline', 'timeline randomly', 'randomly selected', 'selected depressive', 'depressive dataset', 'dataset constituted', 'constituted manual', 'manual selection', 'selection depressive', 'depressive dataset', 'dataset specifically', 'specifically included', 'included expression', 'expression indicative', 'indicative second', 'second step', 'step comparison', 'comparison datasets', 'datasets control', 'control depressive', 'depressive depressive', 'depressive datasets', 'datasets carried', 'carried spot', 'spot distinguishing', 'distinguishing feature', 'feature rest', 'rest section', 'section describe', 'describe methodology', 'methodology detail', 'detail flow', 'flow diagram', 'diagram study', 'study depicted', 'depicted figure']","['study designed developed', 'designed developed step', 'developed step aim', 'step aim analyzing', 'aim analyzing linguistic', 'analyzing linguistic pattern', 'linguistic pattern behavioral', 'pattern behavioral feature', 'behavioral feature suffering', 'feature suffering comparison', 'suffering comparison general', 'comparison general population', 'general population study', 'population study focused', 'study focused written', 'focused written spanish', 'written spanish first', 'spanish first step', 'first step selection', 'step selection compilation', 'selection compilation performed', 'compilation performed given', 'performed given design', 'given design purpose', 'design purpose study', 'purpose study decided', 'study decided use', 'decided use application', 'use application programming', 'application programming interface', 'programming interface api', 'interface api using', 'api using api', 'using api datasets', 'api datasets created', 'datasets created depressive', 'created depressive dataset', 'depressive dataset made', 'dataset made timeline', 'made timeline publicly', 'timeline publicly mentioned', 'publicly mentioned profile', 'mentioned profile suffer', 'profile suffer control', 'suffer control dataset', 'control dataset made', 'dataset made timeline', 'made timeline randomly', 'timeline randomly selected', 'randomly selected depressive', 'selected depressive dataset', 'depressive dataset constituted', 'dataset constituted manual', 'constituted manual selection', 'manual selection depressive', 'selection depressive dataset', 'depressive dataset specifically', 'dataset specifically included', 'specifically included expression', 'included expression indicative', 'expression indicative second', 'indicative second step', 'second step comparison', 'step comparison datasets', 'comparison datasets control', 'datasets control depressive', 'control depressive depressive', 'depressive depressive datasets', 'depressive datasets carried', 'datasets carried spot', 'carried spot distinguishing', 'spot distinguishing feature', 'distinguishing feature rest', 'feature rest section', 'rest section describe', 'section describe methodology', 'describe methodology detail', 'methodology detail flow', 'detail flow diagram', 'flow diagram study', 'diagram study depicted', 'study depicted figure']"
https://aclanthology.org/W18-0608.pdf,0,Data was collected from 7 Cups of Tea an anonymous online chat-based peer support community for emotional distress1 . Users agree at signup that their data may be used for the purposes of research. All the data used for the current study was anonymous and securely stored. This research was performed in line with the ethical and privacy protocols outlined in detail in (Benton et al. 2017). Data from 7 Cups takes the form of written dialogue between users of the service and volunteers who are trained as “active listeners”. A fragment of an exchange between the user of the service (U) and the volunteer (V) might go as follows: For the analyses reported in this paper we used only text generated by users of the service not the volunteers providing peer support. Users who reported depression as their primary concern at sign up were eligible for inclusion in analyses. Our original sample was comprised of 23048 conversations involving 1937 unique users. Users were excluded from the sample if they did not indicate their culture or if they selected ‘Other’. This resulted in the exclusion of 199 and 130 users respectively. The original sample also included users identifying as Native American or American Indian. This group was excluded from analyses since the majority of the data among these users was not English. This resulted in the removal of 15 users leaving a total sample size of 1593.,data wa collected from cup of tea an anonymous online chatbased peer support community for emotional distress user agree at signup that their data may be used for the purpose of research all the data used for the current study wa anonymous and securely stored this research wa performed in line with the ethical and privacy protocol outlined in detail in benton et al data from cup take the form of written dialogue between user of the service and volunteer who are trained a active listener a fragment of an exchange between the user of the service u and the volunteer v might go a follows for the analysis reported in this paper we used only text generated by user of the service not the volunteer providing peer support user who reported depression a their primary concern at sign up were eligible for inclusion in analysis our original sample wa comprised of conversation involving unique user user were excluded from the sample if they did not indicate their culture or if they selected other this resulted in the exclusion of and user respectively the original sample also included user identifying a native american or american indian this group wa excluded from analysis since the majority of the data among these user wa not english this resulted in the removal of user leaving a total sample size of,"['collected', 'cup', 'tea', 'anonymous', 'online', 'chatbased', 'peer', 'support', 'community', 'emotional', 'distress', 'agree', 'signup', 'may', 'purpose', 'research', 'current', 'study', 'anonymous', 'securely', 'stored', 'research', 'performed', 'line', 'ethical', 'privacy', 'protocol', 'outlined', 'detail', 'benton', 'et', 'al', 'cup', 'take', 'form', 'written', 'dialogue', 'service', 'volunteer', 'trained', 'active', 'listener', 'fragment', 'exchange', 'service', 'u', 'volunteer', 'v', 'might', 'go', 'follows', 'reported', 'paper', 'text', 'generated', 'service', 'volunteer', 'providing', 'peer', 'support', 'reported', 'primary', 'concern', 'sign', 'eligible', 'inclusion', 'original', 'sample', 'comprised', 'conversation', 'involving', 'unique', 'excluded', 'sample', 'indicate', 'culture', 'selected', 'resulted', 'exclusion', 'respectively', 'original', 'sample', 'also', 'included', 'identifying', 'native', 'american', 'american', 'indian', 'group', 'excluded', 'since', 'majority', 'among', 'english', 'resulted', 'removal', 'leaving', 'total', 'sample', 'size']","['collected cup', 'cup tea', 'tea anonymous', 'anonymous online', 'online chatbased', 'chatbased peer', 'peer support', 'support community', 'community emotional', 'emotional distress', 'distress agree', 'agree signup', 'signup may', 'may purpose', 'purpose research', 'research current', 'current study', 'study anonymous', 'anonymous securely', 'securely stored', 'stored research', 'research performed', 'performed line', 'line ethical', 'ethical privacy', 'privacy protocol', 'protocol outlined', 'outlined detail', 'detail benton', 'benton et', 'et al', 'al cup', 'cup take', 'take form', 'form written', 'written dialogue', 'dialogue service', 'service volunteer', 'volunteer trained', 'trained active', 'active listener', 'listener fragment', 'fragment exchange', 'exchange service', 'service u', 'u volunteer', 'volunteer v', 'v might', 'might go', 'go follows', 'follows reported', 'reported paper', 'paper text', 'text generated', 'generated service', 'service volunteer', 'volunteer providing', 'providing peer', 'peer support', 'support reported', 'reported primary', 'primary concern', 'concern sign', 'sign eligible', 'eligible inclusion', 'inclusion original', 'original sample', 'sample comprised', 'comprised conversation', 'conversation involving', 'involving unique', 'unique excluded', 'excluded sample', 'sample indicate', 'indicate culture', 'culture selected', 'selected resulted', 'resulted exclusion', 'exclusion respectively', 'respectively original', 'original sample', 'sample also', 'also included', 'included identifying', 'identifying native', 'native american', 'american american', 'american indian', 'indian group', 'group excluded', 'excluded since', 'since majority', 'majority among', 'among english', 'english resulted', 'resulted removal', 'removal leaving', 'leaving total', 'total sample', 'sample size']","['collected cup tea', 'cup tea anonymous', 'tea anonymous online', 'anonymous online chatbased', 'online chatbased peer', 'chatbased peer support', 'peer support community', 'support community emotional', 'community emotional distress', 'emotional distress agree', 'distress agree signup', 'agree signup may', 'signup may purpose', 'may purpose research', 'purpose research current', 'research current study', 'current study anonymous', 'study anonymous securely', 'anonymous securely stored', 'securely stored research', 'stored research performed', 'research performed line', 'performed line ethical', 'line ethical privacy', 'ethical privacy protocol', 'privacy protocol outlined', 'protocol outlined detail', 'outlined detail benton', 'detail benton et', 'benton et al', 'et al cup', 'al cup take', 'cup take form', 'take form written', 'form written dialogue', 'written dialogue service', 'dialogue service volunteer', 'service volunteer trained', 'volunteer trained active', 'trained active listener', 'active listener fragment', 'listener fragment exchange', 'fragment exchange service', 'exchange service u', 'service u volunteer', 'u volunteer v', 'volunteer v might', 'v might go', 'might go follows', 'go follows reported', 'follows reported paper', 'reported paper text', 'paper text generated', 'text generated service', 'generated service volunteer', 'service volunteer providing', 'volunteer providing peer', 'providing peer support', 'peer support reported', 'support reported primary', 'reported primary concern', 'primary concern sign', 'concern sign eligible', 'sign eligible inclusion', 'eligible inclusion original', 'inclusion original sample', 'original sample comprised', 'sample comprised conversation', 'comprised conversation involving', 'conversation involving unique', 'involving unique excluded', 'unique excluded sample', 'excluded sample indicate', 'sample indicate culture', 'indicate culture selected', 'culture selected resulted', 'selected resulted exclusion', 'resulted exclusion respectively', 'exclusion respectively original', 'respectively original sample', 'original sample also', 'sample also included', 'also included identifying', 'included identifying native', 'identifying native american', 'native american american', 'american american indian', 'american indian group', 'indian group excluded', 'group excluded since', 'excluded since majority', 'since majority among', 'majority among english', 'among english resulted', 'english resulted removal', 'resulted removal leaving', 'removal leaving total', 'leaving total sample', 'total sample size']"
https://dl.acm.org/doi/pdf/10.1145/3359169,0,All data analyzed in this study was sourced (with license and consent) from the Talklife and 7Cups platforms. Additionally to maintain user anonymity all personally identifiable information was removed from the dataset before any findings were reported. Additionally all work was approved by our institution’s Institutional Review Board.,all data analyzed in this study wa sourced with license and consent from the talklife and cup platform additionally to maintain user anonymity all personally identifiable information wa removed from the dataset before any finding were reported additionally all work wa approved by our institution institutional review board,"['analyzed', 'study', 'sourced', 'license', 'consent', 'talklife', 'cup', 'platform', 'additionally', 'maintain', 'anonymity', 'personally', 'identifiable', 'information', 'removed', 'dataset', 'finding', 'reported', 'additionally', 'work', 'approved', 'institution', 'institutional', 'review', 'board']","['analyzed study', 'study sourced', 'sourced license', 'license consent', 'consent talklife', 'talklife cup', 'cup platform', 'platform additionally', 'additionally maintain', 'maintain anonymity', 'anonymity personally', 'personally identifiable', 'identifiable information', 'information removed', 'removed dataset', 'dataset finding', 'finding reported', 'reported additionally', 'additionally work', 'work approved', 'approved institution', 'institution institutional', 'institutional review', 'review board']","['analyzed study sourced', 'study sourced license', 'sourced license consent', 'license consent talklife', 'consent talklife cup', 'talklife cup platform', 'cup platform additionally', 'platform additionally maintain', 'additionally maintain anonymity', 'maintain anonymity personally', 'anonymity personally identifiable', 'personally identifiable information', 'identifiable information removed', 'information removed dataset', 'removed dataset finding', 'dataset finding reported', 'finding reported additionally', 'reported additionally work', 'additionally work approved', 'work approved institution', 'approved institution institutional', 'institution institutional review', 'institutional review board']"
https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-018-2197-z,1,To evaluate our models we first subjectively evaluated the latent topics represented by clusters of words. We then compared these topics to risk factors generated by domain experts. Our in-depth analysis revealed several key findings. First we found that the topics discovered by our analysis had a large scope. Topics ranged from crying to clothing to the calendar. This illustrates that our model was able to identify different latent topics within the corpus and separate them into meaningful clusters. It also shows that there are topics that people discuss which are not directly related to suicide as not every word is on the topic of suicide. When comparing our automatically generated topics to previously identified risk factors we found that there were some differences in the focus of the topics compared to that of the risk factors. In the case of “Drug Abuse” people tended to discuss recreational drugs specifically alcohol separately from medications and pills. This difference in focus shows how the public view of these two topics may fit under the umbrella term provided by experts but differ enough to be separate topics. On the other hand in the case of “Family Violence and Discord” and “Suicide Around Individual” the topics generated by our model seemed to indicate a broader topic rather than topics as specific as these risk factors. A result of collecting data from public users with presumably no professional medical experience is the difference in precision of language between users and medical professionals. An indicator of this difference is in discussing depression. While professionals made a difference between “Depressive Feelings” and “Depressive Symptoms” the topics identified from users’ posts overlapped these ideas. This may be partly due to the fact that depressive feelings are a symptom of depression but also to a lack in precise use of language to describe specific experiences and symptoms. Our contribution to this field is the discovery of latent topics within textual data known to contain suicidal ideation. A common method for identifying suicidal ideation in social media is to use a filter designed by medical professionals to extract data. Such a technique may impose a structure on the data by medical professionals that does not reflect the actual language used by those experiencing suicidal ideation. Our method uses topic modeling to uncover informal latent topics directly from social media posts which captures the ideas deemed important by those who are sharing their experiences with an online community. This information will inform the medical community which informal topics are important to monitor in informal contexts such as social media to effectively identify suicidal ideation.When comparing our automatically generated topics to previously identified risk factors we found that there were some differences in the focus of the topics compared to that of the risk factors. In the case of “Drug Abuse” people tended to discuss recreational drugs specifically alcohol separately from medications and pills. This difference in focus shows how the public view of these two topics may fit under the umbrella term provided by experts but differ enough to be separate topics. On the other hand in the case of “Family Violence and Discord” and “Suicide Around Individual” the topics generated by our model seemed to indicate a broader topic rather than topics as specific as these risk factors. A result of collecting data from public users with presumably no professional medical experience is the difference in precision of language between users and medical professionals. An indicator of this difference is in discussing depression. While professionals made a difference between “Depressive Feelings” and “Depressive Symptoms” the topics identified from users’ posts overlapped these ideas. This may be partly due to the fact that depressive feelings are a symptom of depression but also to a lack in precise use of language to describe specific experiences and symptoms. Our contribution to this field is the discovery of latent topics within textual data known to contain suicidal ideation. A common method for identifying suicidal ideation in social media is to use a filter designed by medical professionals to extract data. Such a technique may impose a structure on the data by medical professionals that does not reflect the actual language used by those experiencing suicidal ideation. Our method uses topic modeling to uncover informal latent topics directly from social media posts which captures the ideas deemed important by those who are sharing their experiences with an online community. This information will inform the medical community which informal topics are important to monitor in informal contexts such as social media to effectively identify suicidal ideation.,to evaluate our model we first subjectively evaluated the latent topic represented by cluster of word we then compared these topic to risk factor generated by domain expert our indepth analysis revealed several key finding first we found that the topic discovered by our analysis had a large scope topic ranged from cry to clothing to the calendar this illustrates that our model wa able to identify different latent topic within the corpus and separate them into meaningful cluster it also show that there are topic that people discus which are not directly related to suicide a not every word is on the topic of suicide when comparing our automatically generated topic to previously identified risk factor we found that there were some difference in the focus of the topic compared to that of the risk factor in the case of drug abuse people tended to discus recreational drug specifically alcohol separately from medication and pill this difference in focus show how the public view of these two topic may fit under the umbrella term provided by expert but differ enough to be separate topic on the other hand in the case of family violence and discord and suicide around individual the topic generated by our model seemed to indicate a broader topic rather than topic a specific a these risk factor a result of collecting data from public user with presumably no professional medical experience is the difference in precision of language between user and medical professional an indicator of this difference is in discussing depression while professional made a difference between depressive feeling and depressive symptom the topic identified from user post overlapped these idea this may be partly due to the fact that depressive feeling are a symptom of depression but also to a lack in precise use of language to describe specific experience and symptom our contribution to this field is the discovery of latent topic within textual data known to contain suicidal ideation a common method for identifying suicidal ideation in social medium is to use a filter designed by medical professional to extract data such a technique may impose a structure on the data by medical professional that doe not reflect the actual language used by those experiencing suicidal ideation our method us topic modeling to uncover informal latent topic directly from social medium post which capture the idea deemed important by those who are sharing their experience with an online community this information will inform the medical community which informal topic are important to monitor in informal context such a social medium to effectively identify suicidal ideationwhen comparing our automatically generated topic to previously identified risk factor we found that there were some difference in the focus of the topic compared to that of the risk factor in the case of drug abuse people tended to discus recreational drug specifically alcohol separately from medication and pill this difference in focus show how the public view of these two topic may fit under the umbrella term provided by expert but differ enough to be separate topic on the other hand in the case of family violence and discord and suicide around individual the topic generated by our model seemed to indicate a broader topic rather than topic a specific a these risk factor a result of collecting data from public user with presumably no professional medical experience is the difference in precision of language between user and medical professional an indicator of this difference is in discussing depression while professional made a difference between depressive feeling and depressive symptom the topic identified from user post overlapped these idea this may be partly due to the fact that depressive feeling are a symptom of depression but also to a lack in precise use of language to describe specific experience and symptom our contribution to this field is the discovery of latent topic within textual data known to contain suicidal ideation a common method for identifying suicidal ideation in social medium is to use a filter designed by medical professional to extract data such a technique may impose a structure on the data by medical professional that doe not reflect the actual language used by those experiencing suicidal ideation our method us topic modeling to uncover informal latent topic directly from social medium post which capture the idea deemed important by those who are sharing their experience with an online community this information will inform the medical community which informal topic are important to monitor in informal context such a social medium to effectively identify suicidal ideation,"['evaluate', 'model', 'first', 'subjectively', 'evaluated', 'latent', 'topic', 'represented', 'cluster', 'word', 'compared', 'topic', 'risk', 'factor', 'generated', 'domain', 'expert', 'indepth', 'revealed', 'several', 'key', 'finding', 'first', 'found', 'topic', 'discovered', 'large', 'scope', 'topic', 'ranged', 'cry', 'clothing', 'calendar', 'illustrates', 'model', 'able', 'identify', 'different', 'latent', 'topic', 'within', 'corpus', 'separate', 'meaningful', 'cluster', 'also', 'show', 'topic', 'people', 'discus', 'directly', 'related', 'suicide', 'every', 'word', 'topic', 'suicide', 'comparing', 'automatically', 'generated', 'topic', 'previously', 'identified', 'risk', 'factor', 'found', 'difference', 'focus', 'topic', 'compared', 'risk', 'factor', 'case', 'drug', 'abuse', 'people', 'tended', 'discus', 'recreational', 'drug', 'specifically', 'alcohol', 'separately', 'medication', 'pill', 'difference', 'focus', 'show', 'public', 'view', 'two', 'topic', 'may', 'fit', 'umbrella', 'term', 'provided', 'expert', 'differ', 'enough', 'separate', 'topic', 'hand', 'case', 'family', 'violence', 'discord', 'suicide', 'around', 'individual', 'topic', 'generated', 'model', 'seemed', 'indicate', 'broader', 'topic', 'rather', 'topic', 'specific', 'risk', 'factor', 'result', 'collecting', 'public', 'presumably', 'professional', 'medical', 'experience', 'difference', 'precision', 'language', 'medical', 'professional', 'indicator', 'difference', 'discussing', 'professional', 'made', 'difference', 'depressive', 'feeling', 'depressive', 'symptom', 'topic', 'identified', 'overlapped', 'idea', 'may', 'partly', 'due', 'fact', 'depressive', 'feeling', 'symptom', 'also', 'lack', 'precise', 'use', 'language', 'describe', 'specific', 'experience', 'symptom', 'contribution', 'field', 'discovery', 'latent', 'topic', 'within', 'textual', 'known', 'contain', 'suicidal', 'ideation', 'common', 'method', 'identifying', 'suicidal', 'ideation', 'social', 'medium', 'use', 'filter', 'designed', 'medical', 'professional', 'extract', 'technique', 'may', 'impose', 'structure', 'medical', 'professional', 'doe', 'reflect', 'actual', 'language', 'experiencing', 'suicidal', 'ideation', 'method', 'us', 'topic', 'modeling', 'uncover', 'informal', 'latent', 'topic', 'directly', 'social', 'medium', 'capture', 'idea', 'deemed', 'important', 'sharing', 'experience', 'online', 'community', 'information', 'inform', 'medical', 'community', 'informal', 'topic', 'important', 'monitor', 'informal', 'context', 'social', 'medium', 'effectively', 'identify', 'suicidal', 'ideationwhen', 'comparing', 'automatically', 'generated', 'topic', 'previously', 'identified', 'risk', 'factor', 'found', 'difference', 'focus', 'topic', 'compared', 'risk', 'factor', 'case', 'drug', 'abuse', 'people', 'tended', 'discus', 'recreational', 'drug', 'specifically', 'alcohol', 'separately', 'medication', 'pill', 'difference', 'focus', 'show', 'public', 'view', 'two', 'topic', 'may', 'fit', 'umbrella', 'term', 'provided', 'expert', 'differ', 'enough', 'separate', 'topic', 'hand', 'case', 'family', 'violence', 'discord', 'suicide', 'around', 'individual', 'topic', 'generated', 'model', 'seemed', 'indicate', 'broader', 'topic', 'rather', 'topic', 'specific', 'risk', 'factor', 'result', 'collecting', 'public', 'presumably', 'professional', 'medical', 'experience', 'difference', 'precision', 'language', 'medical', 'professional', 'indicator', 'difference', 'discussing', 'professional', 'made', 'difference', 'depressive', 'feeling', 'depressive', 'symptom', 'topic', 'identified', 'overlapped', 'idea', 'may', 'partly', 'due', 'fact', 'depressive', 'feeling', 'symptom', 'also', 'lack', 'precise', 'use', 'language', 'describe', 'specific', 'experience', 'symptom', 'contribution', 'field', 'discovery', 'latent', 'topic', 'within', 'textual', 'known', 'contain', 'suicidal', 'ideation', 'common', 'method', 'identifying', 'suicidal', 'ideation', 'social', 'medium', 'use', 'filter', 'designed', 'medical', 'professional', 'extract', 'technique', 'may', 'impose', 'structure', 'medical', 'professional', 'doe', 'reflect', 'actual', 'language', 'experiencing', 'suicidal', 'ideation', 'method', 'us', 'topic', 'modeling', 'uncover', 'informal', 'latent', 'topic', 'directly', 'social', 'medium', 'capture', 'idea', 'deemed', 'important', 'sharing', 'experience', 'online', 'community', 'information', 'inform', 'medical', 'community', 'informal', 'topic', 'important', 'monitor', 'informal', 'context', 'social', 'medium', 'effectively', 'identify', 'suicidal', 'ideation']","['evaluate model', 'model first', 'first subjectively', 'subjectively evaluated', 'evaluated latent', 'latent topic', 'topic represented', 'represented cluster', 'cluster word', 'word compared', 'compared topic', 'topic risk', 'risk factor', 'factor generated', 'generated domain', 'domain expert', 'expert indepth', 'indepth revealed', 'revealed several', 'several key', 'key finding', 'finding first', 'first found', 'found topic', 'topic discovered', 'discovered large', 'large scope', 'scope topic', 'topic ranged', 'ranged cry', 'cry clothing', 'clothing calendar', 'calendar illustrates', 'illustrates model', 'model able', 'able identify', 'identify different', 'different latent', 'latent topic', 'topic within', 'within corpus', 'corpus separate', 'separate meaningful', 'meaningful cluster', 'cluster also', 'also show', 'show topic', 'topic people', 'people discus', 'discus directly', 'directly related', 'related suicide', 'suicide every', 'every word', 'word topic', 'topic suicide', 'suicide comparing', 'comparing automatically', 'automatically generated', 'generated topic', 'topic previously', 'previously identified', 'identified risk', 'risk factor', 'factor found', 'found difference', 'difference focus', 'focus topic', 'topic compared', 'compared risk', 'risk factor', 'factor case', 'case drug', 'drug abuse', 'abuse people', 'people tended', 'tended discus', 'discus recreational', 'recreational drug', 'drug specifically', 'specifically alcohol', 'alcohol separately', 'separately medication', 'medication pill', 'pill difference', 'difference focus', 'focus show', 'show public', 'public view', 'view two', 'two topic', 'topic may', 'may fit', 'fit umbrella', 'umbrella term', 'term provided', 'provided expert', 'expert differ', 'differ enough', 'enough separate', 'separate topic', 'topic hand', 'hand case', 'case family', 'family violence', 'violence discord', 'discord suicide', 'suicide around', 'around individual', 'individual topic', 'topic generated', 'generated model', 'model seemed', 'seemed indicate', 'indicate broader', 'broader topic', 'topic rather', 'rather topic', 'topic specific', 'specific risk', 'risk factor', 'factor result', 'result collecting', 'collecting public', 'public presumably', 'presumably professional', 'professional medical', 'medical experience', 'experience difference', 'difference precision', 'precision language', 'language medical', 'medical professional', 'professional indicator', 'indicator difference', 'difference discussing', 'discussing professional', 'professional made', 'made difference', 'difference depressive', 'depressive feeling', 'feeling depressive', 'depressive symptom', 'symptom topic', 'topic identified', 'identified overlapped', 'overlapped idea', 'idea may', 'may partly', 'partly due', 'due fact', 'fact depressive', 'depressive feeling', 'feeling symptom', 'symptom also', 'also lack', 'lack precise', 'precise use', 'use language', 'language describe', 'describe specific', 'specific experience', 'experience symptom', 'symptom contribution', 'contribution field', 'field discovery', 'discovery latent', 'latent topic', 'topic within', 'within textual', 'textual known', 'known contain', 'contain suicidal', 'suicidal ideation', 'ideation common', 'common method', 'method identifying', 'identifying suicidal', 'suicidal ideation', 'ideation social', 'social medium', 'medium use', 'use filter', 'filter designed', 'designed medical', 'medical professional', 'professional extract', 'extract technique', 'technique may', 'may impose', 'impose structure', 'structure medical', 'medical professional', 'professional doe', 'doe reflect', 'reflect actual', 'actual language', 'language experiencing', 'experiencing suicidal', 'suicidal ideation', 'ideation method', 'method us', 'us topic', 'topic modeling', 'modeling uncover', 'uncover informal', 'informal latent', 'latent topic', 'topic directly', 'directly social', 'social medium', 'medium capture', 'capture idea', 'idea deemed', 'deemed important', 'important sharing', 'sharing experience', 'experience online', 'online community', 'community information', 'information inform', 'inform medical', 'medical community', 'community informal', 'informal topic', 'topic important', 'important monitor', 'monitor informal', 'informal context', 'context social', 'social medium', 'medium effectively', 'effectively identify', 'identify suicidal', 'suicidal ideationwhen', 'ideationwhen comparing', 'comparing automatically', 'automatically generated', 'generated topic', 'topic previously', 'previously identified', 'identified risk', 'risk factor', 'factor found', 'found difference', 'difference focus', 'focus topic', 'topic compared', 'compared risk', 'risk factor', 'factor case', 'case drug', 'drug abuse', 'abuse people', 'people tended', 'tended discus', 'discus recreational', 'recreational drug', 'drug specifically', 'specifically alcohol', 'alcohol separately', 'separately medication', 'medication pill', 'pill difference', 'difference focus', 'focus show', 'show public', 'public view', 'view two', 'two topic', 'topic may', 'may fit', 'fit umbrella', 'umbrella term', 'term provided', 'provided expert', 'expert differ', 'differ enough', 'enough separate', 'separate topic', 'topic hand', 'hand case', 'case family', 'family violence', 'violence discord', 'discord suicide', 'suicide around', 'around individual', 'individual topic', 'topic generated', 'generated model', 'model seemed', 'seemed indicate', 'indicate broader', 'broader topic', 'topic rather', 'rather topic', 'topic specific', 'specific risk', 'risk factor', 'factor result', 'result collecting', 'collecting public', 'public presumably', 'presumably professional', 'professional medical', 'medical experience', 'experience difference', 'difference precision', 'precision language', 'language medical', 'medical professional', 'professional indicator', 'indicator difference', 'difference discussing', 'discussing professional', 'professional made', 'made difference', 'difference depressive', 'depressive feeling', 'feeling depressive', 'depressive symptom', 'symptom topic', 'topic identified', 'identified overlapped', 'overlapped idea', 'idea may', 'may partly', 'partly due', 'due fact', 'fact depressive', 'depressive feeling', 'feeling symptom', 'symptom also', 'also lack', 'lack precise', 'precise use', 'use language', 'language describe', 'describe specific', 'specific experience', 'experience symptom', 'symptom contribution', 'contribution field', 'field discovery', 'discovery latent', 'latent topic', 'topic within', 'within textual', 'textual known', 'known contain', 'contain suicidal', 'suicidal ideation', 'ideation common', 'common method', 'method identifying', 'identifying suicidal', 'suicidal ideation', 'ideation social', 'social medium', 'medium use', 'use filter', 'filter designed', 'designed medical', 'medical professional', 'professional extract', 'extract technique', 'technique may', 'may impose', 'impose structure', 'structure medical', 'medical professional', 'professional doe', 'doe reflect', 'reflect actual', 'actual language', 'language experiencing', 'experiencing suicidal', 'suicidal ideation', 'ideation method', 'method us', 'us topic', 'topic modeling', 'modeling uncover', 'uncover informal', 'informal latent', 'latent topic', 'topic directly', 'directly social', 'social medium', 'medium capture', 'capture idea', 'idea deemed', 'deemed important', 'important sharing', 'sharing experience', 'experience online', 'online community', 'community information', 'information inform', 'inform medical', 'medical community', 'community informal', 'informal topic', 'topic important', 'important monitor', 'monitor informal', 'informal context', 'context social', 'social medium', 'medium effectively', 'effectively identify', 'identify suicidal', 'suicidal ideation']","['evaluate model first', 'model first subjectively', 'first subjectively evaluated', 'subjectively evaluated latent', 'evaluated latent topic', 'latent topic represented', 'topic represented cluster', 'represented cluster word', 'cluster word compared', 'word compared topic', 'compared topic risk', 'topic risk factor', 'risk factor generated', 'factor generated domain', 'generated domain expert', 'domain expert indepth', 'expert indepth revealed', 'indepth revealed several', 'revealed several key', 'several key finding', 'key finding first', 'finding first found', 'first found topic', 'found topic discovered', 'topic discovered large', 'discovered large scope', 'large scope topic', 'scope topic ranged', 'topic ranged cry', 'ranged cry clothing', 'cry clothing calendar', 'clothing calendar illustrates', 'calendar illustrates model', 'illustrates model able', 'model able identify', 'able identify different', 'identify different latent', 'different latent topic', 'latent topic within', 'topic within corpus', 'within corpus separate', 'corpus separate meaningful', 'separate meaningful cluster', 'meaningful cluster also', 'cluster also show', 'also show topic', 'show topic people', 'topic people discus', 'people discus directly', 'discus directly related', 'directly related suicide', 'related suicide every', 'suicide every word', 'every word topic', 'word topic suicide', 'topic suicide comparing', 'suicide comparing automatically', 'comparing automatically generated', 'automatically generated topic', 'generated topic previously', 'topic previously identified', 'previously identified risk', 'identified risk factor', 'risk factor found', 'factor found difference', 'found difference focus', 'difference focus topic', 'focus topic compared', 'topic compared risk', 'compared risk factor', 'risk factor case', 'factor case drug', 'case drug abuse', 'drug abuse people', 'abuse people tended', 'people tended discus', 'tended discus recreational', 'discus recreational drug', 'recreational drug specifically', 'drug specifically alcohol', 'specifically alcohol separately', 'alcohol separately medication', 'separately medication pill', 'medication pill difference', 'pill difference focus', 'difference focus show', 'focus show public', 'show public view', 'public view two', 'view two topic', 'two topic may', 'topic may fit', 'may fit umbrella', 'fit umbrella term', 'umbrella term provided', 'term provided expert', 'provided expert differ', 'expert differ enough', 'differ enough separate', 'enough separate topic', 'separate topic hand', 'topic hand case', 'hand case family', 'case family violence', 'family violence discord', 'violence discord suicide', 'discord suicide around', 'suicide around individual', 'around individual topic', 'individual topic generated', 'topic generated model', 'generated model seemed', 'model seemed indicate', 'seemed indicate broader', 'indicate broader topic', 'broader topic rather', 'topic rather topic', 'rather topic specific', 'topic specific risk', 'specific risk factor', 'risk factor result', 'factor result collecting', 'result collecting public', 'collecting public presumably', 'public presumably professional', 'presumably professional medical', 'professional medical experience', 'medical experience difference', 'experience difference precision', 'difference precision language', 'precision language medical', 'language medical professional', 'medical professional indicator', 'professional indicator difference', 'indicator difference discussing', 'difference discussing professional', 'discussing professional made', 'professional made difference', 'made difference depressive', 'difference depressive feeling', 'depressive feeling depressive', 'feeling depressive symptom', 'depressive symptom topic', 'symptom topic identified', 'topic identified overlapped', 'identified overlapped idea', 'overlapped idea may', 'idea may partly', 'may partly due', 'partly due fact', 'due fact depressive', 'fact depressive feeling', 'depressive feeling symptom', 'feeling symptom also', 'symptom also lack', 'also lack precise', 'lack precise use', 'precise use language', 'use language describe', 'language describe specific', 'describe specific experience', 'specific experience symptom', 'experience symptom contribution', 'symptom contribution field', 'contribution field discovery', 'field discovery latent', 'discovery latent topic', 'latent topic within', 'topic within textual', 'within textual known', 'textual known contain', 'known contain suicidal', 'contain suicidal ideation', 'suicidal ideation common', 'ideation common method', 'common method identifying', 'method identifying suicidal', 'identifying suicidal ideation', 'suicidal ideation social', 'ideation social medium', 'social medium use', 'medium use filter', 'use filter designed', 'filter designed medical', 'designed medical professional', 'medical professional extract', 'professional extract technique', 'extract technique may', 'technique may impose', 'may impose structure', 'impose structure medical', 'structure medical professional', 'medical professional doe', 'professional doe reflect', 'doe reflect actual', 'reflect actual language', 'actual language experiencing', 'language experiencing suicidal', 'experiencing suicidal ideation', 'suicidal ideation method', 'ideation method us', 'method us topic', 'us topic modeling', 'topic modeling uncover', 'modeling uncover informal', 'uncover informal latent', 'informal latent topic', 'latent topic directly', 'topic directly social', 'directly social medium', 'social medium capture', 'medium capture idea', 'capture idea deemed', 'idea deemed important', 'deemed important sharing', 'important sharing experience', 'sharing experience online', 'experience online community', 'online community information', 'community information inform', 'information inform medical', 'inform medical community', 'medical community informal', 'community informal topic', 'informal topic important', 'topic important monitor', 'important monitor informal', 'monitor informal context', 'informal context social', 'context social medium', 'social medium effectively', 'medium effectively identify', 'effectively identify suicidal', 'identify suicidal ideationwhen', 'suicidal ideationwhen comparing', 'ideationwhen comparing automatically', 'comparing automatically generated', 'automatically generated topic', 'generated topic previously', 'topic previously identified', 'previously identified risk', 'identified risk factor', 'risk factor found', 'factor found difference', 'found difference focus', 'difference focus topic', 'focus topic compared', 'topic compared risk', 'compared risk factor', 'risk factor case', 'factor case drug', 'case drug abuse', 'drug abuse people', 'abuse people tended', 'people tended discus', 'tended discus recreational', 'discus recreational drug', 'recreational drug specifically', 'drug specifically alcohol', 'specifically alcohol separately', 'alcohol separately medication', 'separately medication pill', 'medication pill difference', 'pill difference focus', 'difference focus show', 'focus show public', 'show public view', 'public view two', 'view two topic', 'two topic may', 'topic may fit', 'may fit umbrella', 'fit umbrella term', 'umbrella term provided', 'term provided expert', 'provided expert differ', 'expert differ enough', 'differ enough separate', 'enough separate topic', 'separate topic hand', 'topic hand case', 'hand case family', 'case family violence', 'family violence discord', 'violence discord suicide', 'discord suicide around', 'suicide around individual', 'around individual topic', 'individual topic generated', 'topic generated model', 'generated model seemed', 'model seemed indicate', 'seemed indicate broader', 'indicate broader topic', 'broader topic rather', 'topic rather topic', 'rather topic specific', 'topic specific risk', 'specific risk factor', 'risk factor result', 'factor result collecting', 'result collecting public', 'collecting public presumably', 'public presumably professional', 'presumably professional medical', 'professional medical experience', 'medical experience difference', 'experience difference precision', 'difference precision language', 'precision language medical', 'language medical professional', 'medical professional indicator', 'professional indicator difference', 'indicator difference discussing', 'difference discussing professional', 'discussing professional made', 'professional made difference', 'made difference depressive', 'difference depressive feeling', 'depressive feeling depressive', 'feeling depressive symptom', 'depressive symptom topic', 'symptom topic identified', 'topic identified overlapped', 'identified overlapped idea', 'overlapped idea may', 'idea may partly', 'may partly due', 'partly due fact', 'due fact depressive', 'fact depressive feeling', 'depressive feeling symptom', 'feeling symptom also', 'symptom also lack', 'also lack precise', 'lack precise use', 'precise use language', 'use language describe', 'language describe specific', 'describe specific experience', 'specific experience symptom', 'experience symptom contribution', 'symptom contribution field', 'contribution field discovery', 'field discovery latent', 'discovery latent topic', 'latent topic within', 'topic within textual', 'within textual known', 'textual known contain', 'known contain suicidal', 'contain suicidal ideation', 'suicidal ideation common', 'ideation common method', 'common method identifying', 'method identifying suicidal', 'identifying suicidal ideation', 'suicidal ideation social', 'ideation social medium', 'social medium use', 'medium use filter', 'use filter designed', 'filter designed medical', 'designed medical professional', 'medical professional extract', 'professional extract technique', 'extract technique may', 'technique may impose', 'may impose structure', 'impose structure medical', 'structure medical professional', 'medical professional doe', 'professional doe reflect', 'doe reflect actual', 'reflect actual language', 'actual language experiencing', 'language experiencing suicidal', 'experiencing suicidal ideation', 'suicidal ideation method', 'ideation method us', 'method us topic', 'us topic modeling', 'topic modeling uncover', 'modeling uncover informal', 'uncover informal latent', 'informal latent topic', 'latent topic directly', 'topic directly social', 'directly social medium', 'social medium capture', 'medium capture idea', 'capture idea deemed', 'idea deemed important', 'deemed important sharing', 'important sharing experience', 'sharing experience online', 'experience online community', 'online community information', 'community information inform', 'information inform medical', 'inform medical community', 'medical community informal', 'community informal topic', 'informal topic important', 'topic important monitor', 'important monitor informal', 'monitor informal context', 'informal context social', 'context social medium', 'social medium effectively', 'medium effectively identify', 'effectively identify suicidal', 'identify suicidal ideation']"
https://ieeexplore.ieee.org/abstract/document/8609647,0,Reddit is a multilingual Online Social Network founded in 2005 and organized in subcommunities by areas of interest called subreddits. We obtained data from the Reddit's data repository4 focusing on four subreddits where people discuss issues related to mental heath disorders: Depression (/r/depression) Suicide Watch (/r/Suicide Watch) Anxiety (/r/anxiety) and Bipolar (/r/bipolar). Our dataset is comprised of user activities (posts and comments) that took place between 2011 and 201 7. Here we focus on data from January 2017 to December 2017. In total we obtained 261511 posts and 1256669 comments from 184708 unique users. Table I shows the total number of users posts and comments per subreddit. The total number of comments in each community is at least 4.2 times larger than the number of posts which suggests a supportive behavior among users.,reddit is a multilingual online social network founded in and organized in subcommunities by area of interest called subreddits we obtained data from the reddits data repository focusing on four subreddits where people discus issue related to mental heath disorder depression rdepression suicide watch rsuicide watch anxiety ranxiety and bipolar rbipolar our dataset is comprised of user activity post and comment that took place between and here we focus on data from january to december in total we obtained post and comment from unique user table i show the total number of user post and comment per subreddit the total number of comment in each community is at least time larger than the number of post which suggests a supportive behavior among user,"['reddit', 'multilingual', 'online', 'social', 'network', 'founded', 'organized', 'subcommunities', 'area', 'interest', 'called', 'subreddits', 'obtained', 'reddits', 'repository', 'focusing', 'four', 'subreddits', 'people', 'discus', 'issue', 'related', 'heath', 'disorder', 'rdepression', 'suicide', 'watch', 'rsuicide', 'watch', 'anxiety', 'ranxiety', 'bipolar', 'rbipolar', 'dataset', 'comprised', 'activity', 'comment', 'took', 'place', 'focus', 'january', 'december', 'total', 'obtained', 'comment', 'unique', 'table', 'show', 'total', 'number', 'comment', 'per', 'subreddit', 'total', 'number', 'comment', 'community', 'least', 'time', 'larger', 'number', 'suggests', 'supportive', 'behavior', 'among']","['reddit multilingual', 'multilingual online', 'online social', 'social network', 'network founded', 'founded organized', 'organized subcommunities', 'subcommunities area', 'area interest', 'interest called', 'called subreddits', 'subreddits obtained', 'obtained reddits', 'reddits repository', 'repository focusing', 'focusing four', 'four subreddits', 'subreddits people', 'people discus', 'discus issue', 'issue related', 'related heath', 'heath disorder', 'disorder rdepression', 'rdepression suicide', 'suicide watch', 'watch rsuicide', 'rsuicide watch', 'watch anxiety', 'anxiety ranxiety', 'ranxiety bipolar', 'bipolar rbipolar', 'rbipolar dataset', 'dataset comprised', 'comprised activity', 'activity comment', 'comment took', 'took place', 'place focus', 'focus january', 'january december', 'december total', 'total obtained', 'obtained comment', 'comment unique', 'unique table', 'table show', 'show total', 'total number', 'number comment', 'comment per', 'per subreddit', 'subreddit total', 'total number', 'number comment', 'comment community', 'community least', 'least time', 'time larger', 'larger number', 'number suggests', 'suggests supportive', 'supportive behavior', 'behavior among']","['reddit multilingual online', 'multilingual online social', 'online social network', 'social network founded', 'network founded organized', 'founded organized subcommunities', 'organized subcommunities area', 'subcommunities area interest', 'area interest called', 'interest called subreddits', 'called subreddits obtained', 'subreddits obtained reddits', 'obtained reddits repository', 'reddits repository focusing', 'repository focusing four', 'focusing four subreddits', 'four subreddits people', 'subreddits people discus', 'people discus issue', 'discus issue related', 'issue related heath', 'related heath disorder', 'heath disorder rdepression', 'disorder rdepression suicide', 'rdepression suicide watch', 'suicide watch rsuicide', 'watch rsuicide watch', 'rsuicide watch anxiety', 'watch anxiety ranxiety', 'anxiety ranxiety bipolar', 'ranxiety bipolar rbipolar', 'bipolar rbipolar dataset', 'rbipolar dataset comprised', 'dataset comprised activity', 'comprised activity comment', 'activity comment took', 'comment took place', 'took place focus', 'place focus january', 'focus january december', 'january december total', 'december total obtained', 'total obtained comment', 'obtained comment unique', 'comment unique table', 'unique table show', 'table show total', 'show total number', 'total number comment', 'number comment per', 'comment per subreddit', 'per subreddit total', 'subreddit total number', 'total number comment', 'number comment community', 'comment community least', 'community least time', 'least time larger', 'time larger number', 'larger number suggests', 'number suggests supportive', 'suggests supportive behavior', 'supportive behavior among']"
