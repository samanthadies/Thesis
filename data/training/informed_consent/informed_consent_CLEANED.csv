Link to paper,Score,Text,Cleaned,unigrams,bigrams,trigrams
https://link.springer.com/content/pdf/10.1140/epjds/s13688-017-0110-z.pdf,1,Data collection was crowdsourced using Amazon’s Mechanical Turk (MTurk) crowdwork platform. Separate surveys were created for depressed and healthy individuals. In the depressed survey participants were invited to complete a survey that involved passing a series of inclusion criteria responding to a standardized clinical depression survey answering questions related to demographics and history of depression and sharing social media history. We used the CES-D (Center for Epidemiologic Studies Depression Scale) questionnaire to screen participant depression levels []. CES-D assessment quality has been demonstrated as on-par with other depression inventories including the Beck Depression Inventory and the Kellner Symptom Questionnaire [ ]. Healthy participants were screened to ensure no history of depression and active Instagram use. See Additional file  for actual survey text. Qualified participants were asked to share their Instagram usernames and history. An app embedded in the survey allowed participants to securely log into their Instagram accounts and agree to share their data.b Upon securing consent we made a one-time collection of participants’ entire Instagram posting history. In total we collected  photographs from  Instagram users  of whom had a history of depression. We asked a different set of MTurk crowdworkers to rate the Instagram photographs collected. This new task asked participants to rate a random selection of  photos from the data we collected. Raters were asked to judge how interesting likable happy and sad each photo seemed on a continuous - scale. Each photo was rated by at least three different raters and ratings were averaged across raters. Raters were not informed that photos were from Instagram nor were they given any information about the study participants who provided the photos including mental health status. Each ratings category showed good inter-rater agreement. Only a subset of participant Instagram photos were rated (N = ). We limited ratings data to a subset because this task was time-consuming for crowdworkers and so proved a costly form of data collection. For the depressed sample ratings were only made for photos posted within a year in either direction of the date of first depression diagnosis. Within this subset for each user the nearest  posts prior to the diagnosis date were rated. For the control population the most recent  photos from each user’s date of participation in this study were rated.Data privacy was a concern for this study. Strict anonymity was nearly impossible to guarantee to participants given that usernames and personal photographs posted to Instagram often contain identifiable features. We made sure participants were informed of the risks of being personally identified and assured them that no data with personal identifiers including usernames would be made public or published in any format.,data collection wa crowdsourced using amazon mechanical turk mturk crowdwork platform separate survey were created for depressed and healthy individual in the depressed survey participant were invited to complete a survey that involved passing a series of inclusion criterion responding to a standardized clinical depression survey answering question related to demographic and history of depression and sharing social medium history we used the cesd center for epidemiologic study depression scale questionnaire to screen participant depression level cesd assessment quality ha been demonstrated a onpar with other depression inventory including the beck depression inventory and the kellner symptom questionnaire healthy participant were screened to ensure no history of depression and active instagram use see additional file for actual survey text qualified participant were asked to share their instagram usernames and history an app embedded in the survey allowed participant to securely log into their instagram account and agree to share their datab upon securing consent we made a onetime collection of participant entire instagram posting history in total we collected photograph from instagram user of whom had a history of depression we asked a different set of mturk crowdworkers to rate the instagram photograph collected this new task asked participant to rate a random selection of photo from the data we collected raters were asked to judge how interesting likable happy and sad each photo seemed on a continuous scale each photo wa rated by at least three different raters and rating were averaged across raters raters were not informed that photo were from instagram nor were they given any information about the study participant who provided the photo including mental health status each rating category showed good interrater agreement only a subset of participant instagram photo were rated n we limited rating data to a subset because this task wa timeconsuming for crowdworkers and so proved a costly form of data collection for the depressed sample rating were only made for photo posted within a year in either direction of the date of first depression diagnosis within this subset for each user the nearest post prior to the diagnosis date were rated for the control population the most recent photo from each user date of participation in this study were rateddata privacy wa a concern for this study strict anonymity wa nearly impossible to guarantee to participant given that usernames and personal photograph posted to instagram often contain identifiable feature we made sure participant were informed of the risk of being personally identified and assured them that no data with personal identifier including usernames would be made public or published in any format,"['collection', 'crowdsourced', 'amazon', 'mechanical', 'turk', 'mturk', 'crowdwork', 'platform', 'separate', 'survey', 'created', 'depressed', 'healthy', 'individual', 'depressed', 'survey', 'invited', 'complete', 'survey', 'involved', 'passing', 'series', 'inclusion', 'criterion', 'responding', 'standardized', 'clinical', 'survey', 'answering', 'question', 'related', 'demographic', 'history', 'sharing', 'medium', 'history', 'cesd', 'center', 'epidemiologic', 'study', 'scale', 'questionnaire', 'screen', 'level', 'cesd', 'assessment', 'quality', 'ha', 'demonstrated', 'onpar', 'inventory', 'including', 'beck', 'inventory', 'kellner', 'symptom', 'questionnaire', 'healthy', 'screened', 'ensure', 'history', 'active', 'instagram', 'use', 'see', 'additional', 'file', 'actual', 'survey', 'text', 'qualified', 'asked', 'share', 'instagram', 'usernames', 'history', 'app', 'embedded', 'survey', 'allowed', 'securely', 'log', 'instagram', 'account', 'agree', 'share', 'datab', 'upon', 'securing', 'consent', 'onetime', 'collection', 'entire', 'instagram', 'posting', 'history', 'total', 'photograph', 'instagram', 'history', 'asked', 'different', 'mturk', 'crowdworkers', 'rate', 'instagram', 'photograph', 'new', 'task', 'asked', 'rate', 'random', 'selection', 'photo', 'raters', 'asked', 'judge', 'interesting', 'likable', 'happy', 'sad', 'photo', 'seemed', 'continuous', 'scale', 'photo', 'rated', 'least', 'three', 'different', 'raters', 'rating', 'averaged', 'across', 'raters', 'raters', 'informed', 'photo', 'instagram', 'given', 'study', 'provided', 'photo', 'including', 'status', 'rating', 'category', 'showed', 'good', 'interrater', 'agreement', 'subset', 'instagram', 'photo', 'rated', 'n', 'limited', 'rating', 'subset', 'task', 'timeconsuming', 'crowdworkers', 'proved', 'costly', 'form', 'collection', 'depressed', 'sample', 'rating', 'photo', 'posted', 'within', 'year', 'either', 'direction', 'date', 'first', 'within', 'subset', 'nearest', 'prior', 'date', 'rated', 'population', 'recent', 'photo', 'date', 'participation', 'study', 'rateddata', 'privacy', 'concern', 'study', 'strict', 'anonymity', 'nearly', 'impossible', 'guarantee', 'given', 'usernames', 'personal', 'photograph', 'posted', 'instagram', 'often', 'contain', 'identifiable', 'feature', 'sure', 'informed', 'risk', 'personally', 'identified', 'assured', 'personal', 'identifier', 'including', 'usernames', 'would', 'public', 'published', 'format']","['collection crowdsourced', 'crowdsourced amazon', 'amazon mechanical', 'mechanical turk', 'turk mturk', 'mturk crowdwork', 'crowdwork platform', 'platform separate', 'separate survey', 'survey created', 'created depressed', 'depressed healthy', 'healthy individual', 'individual depressed', 'depressed survey', 'survey invited', 'invited complete', 'complete survey', 'survey involved', 'involved passing', 'passing series', 'series inclusion', 'inclusion criterion', 'criterion responding', 'responding standardized', 'standardized clinical', 'clinical survey', 'survey answering', 'answering question', 'question related', 'related demographic', 'demographic history', 'history sharing', 'sharing medium', 'medium history', 'history cesd', 'cesd center', 'center epidemiologic', 'epidemiologic study', 'study scale', 'scale questionnaire', 'questionnaire screen', 'screen level', 'level cesd', 'cesd assessment', 'assessment quality', 'quality ha', 'ha demonstrated', 'demonstrated onpar', 'onpar inventory', 'inventory including', 'including beck', 'beck inventory', 'inventory kellner', 'kellner symptom', 'symptom questionnaire', 'questionnaire healthy', 'healthy screened', 'screened ensure', 'ensure history', 'history active', 'active instagram', 'instagram use', 'use see', 'see additional', 'additional file', 'file actual', 'actual survey', 'survey text', 'text qualified', 'qualified asked', 'asked share', 'share instagram', 'instagram usernames', 'usernames history', 'history app', 'app embedded', 'embedded survey', 'survey allowed', 'allowed securely', 'securely log', 'log instagram', 'instagram account', 'account agree', 'agree share', 'share datab', 'datab upon', 'upon securing', 'securing consent', 'consent onetime', 'onetime collection', 'collection entire', 'entire instagram', 'instagram posting', 'posting history', 'history total', 'total photograph', 'photograph instagram', 'instagram history', 'history asked', 'asked different', 'different mturk', 'mturk crowdworkers', 'crowdworkers rate', 'rate instagram', 'instagram photograph', 'photograph new', 'new task', 'task asked', 'asked rate', 'rate random', 'random selection', 'selection photo', 'photo raters', 'raters asked', 'asked judge', 'judge interesting', 'interesting likable', 'likable happy', 'happy sad', 'sad photo', 'photo seemed', 'seemed continuous', 'continuous scale', 'scale photo', 'photo rated', 'rated least', 'least three', 'three different', 'different raters', 'raters rating', 'rating averaged', 'averaged across', 'across raters', 'raters raters', 'raters informed', 'informed photo', 'photo instagram', 'instagram given', 'given study', 'study provided', 'provided photo', 'photo including', 'including status', 'status rating', 'rating category', 'category showed', 'showed good', 'good interrater', 'interrater agreement', 'agreement subset', 'subset instagram', 'instagram photo', 'photo rated', 'rated n', 'n limited', 'limited rating', 'rating subset', 'subset task', 'task timeconsuming', 'timeconsuming crowdworkers', 'crowdworkers proved', 'proved costly', 'costly form', 'form collection', 'collection depressed', 'depressed sample', 'sample rating', 'rating photo', 'photo posted', 'posted within', 'within year', 'year either', 'either direction', 'direction date', 'date first', 'first within', 'within subset', 'subset nearest', 'nearest prior', 'prior date', 'date rated', 'rated population', 'population recent', 'recent photo', 'photo date', 'date participation', 'participation study', 'study rateddata', 'rateddata privacy', 'privacy concern', 'concern study', 'study strict', 'strict anonymity', 'anonymity nearly', 'nearly impossible', 'impossible guarantee', 'guarantee given', 'given usernames', 'usernames personal', 'personal photograph', 'photograph posted', 'posted instagram', 'instagram often', 'often contain', 'contain identifiable', 'identifiable feature', 'feature sure', 'sure informed', 'informed risk', 'risk personally', 'personally identified', 'identified assured', 'assured personal', 'personal identifier', 'identifier including', 'including usernames', 'usernames would', 'would public', 'public published', 'published format']","['collection crowdsourced amazon', 'crowdsourced amazon mechanical', 'amazon mechanical turk', 'mechanical turk mturk', 'turk mturk crowdwork', 'mturk crowdwork platform', 'crowdwork platform separate', 'platform separate survey', 'separate survey created', 'survey created depressed', 'created depressed healthy', 'depressed healthy individual', 'healthy individual depressed', 'individual depressed survey', 'depressed survey invited', 'survey invited complete', 'invited complete survey', 'complete survey involved', 'survey involved passing', 'involved passing series', 'passing series inclusion', 'series inclusion criterion', 'inclusion criterion responding', 'criterion responding standardized', 'responding standardized clinical', 'standardized clinical survey', 'clinical survey answering', 'survey answering question', 'answering question related', 'question related demographic', 'related demographic history', 'demographic history sharing', 'history sharing medium', 'sharing medium history', 'medium history cesd', 'history cesd center', 'cesd center epidemiologic', 'center epidemiologic study', 'epidemiologic study scale', 'study scale questionnaire', 'scale questionnaire screen', 'questionnaire screen level', 'screen level cesd', 'level cesd assessment', 'cesd assessment quality', 'assessment quality ha', 'quality ha demonstrated', 'ha demonstrated onpar', 'demonstrated onpar inventory', 'onpar inventory including', 'inventory including beck', 'including beck inventory', 'beck inventory kellner', 'inventory kellner symptom', 'kellner symptom questionnaire', 'symptom questionnaire healthy', 'questionnaire healthy screened', 'healthy screened ensure', 'screened ensure history', 'ensure history active', 'history active instagram', 'active instagram use', 'instagram use see', 'use see additional', 'see additional file', 'additional file actual', 'file actual survey', 'actual survey text', 'survey text qualified', 'text qualified asked', 'qualified asked share', 'asked share instagram', 'share instagram usernames', 'instagram usernames history', 'usernames history app', 'history app embedded', 'app embedded survey', 'embedded survey allowed', 'survey allowed securely', 'allowed securely log', 'securely log instagram', 'log instagram account', 'instagram account agree', 'account agree share', 'agree share datab', 'share datab upon', 'datab upon securing', 'upon securing consent', 'securing consent onetime', 'consent onetime collection', 'onetime collection entire', 'collection entire instagram', 'entire instagram posting', 'instagram posting history', 'posting history total', 'history total photograph', 'total photograph instagram', 'photograph instagram history', 'instagram history asked', 'history asked different', 'asked different mturk', 'different mturk crowdworkers', 'mturk crowdworkers rate', 'crowdworkers rate instagram', 'rate instagram photograph', 'instagram photograph new', 'photograph new task', 'new task asked', 'task asked rate', 'asked rate random', 'rate random selection', 'random selection photo', 'selection photo raters', 'photo raters asked', 'raters asked judge', 'asked judge interesting', 'judge interesting likable', 'interesting likable happy', 'likable happy sad', 'happy sad photo', 'sad photo seemed', 'photo seemed continuous', 'seemed continuous scale', 'continuous scale photo', 'scale photo rated', 'photo rated least', 'rated least three', 'least three different', 'three different raters', 'different raters rating', 'raters rating averaged', 'rating averaged across', 'averaged across raters', 'across raters raters', 'raters raters informed', 'raters informed photo', 'informed photo instagram', 'photo instagram given', 'instagram given study', 'given study provided', 'study provided photo', 'provided photo including', 'photo including status', 'including status rating', 'status rating category', 'rating category showed', 'category showed good', 'showed good interrater', 'good interrater agreement', 'interrater agreement subset', 'agreement subset instagram', 'subset instagram photo', 'instagram photo rated', 'photo rated n', 'rated n limited', 'n limited rating', 'limited rating subset', 'rating subset task', 'subset task timeconsuming', 'task timeconsuming crowdworkers', 'timeconsuming crowdworkers proved', 'crowdworkers proved costly', 'proved costly form', 'costly form collection', 'form collection depressed', 'collection depressed sample', 'depressed sample rating', 'sample rating photo', 'rating photo posted', 'photo posted within', 'posted within year', 'within year either', 'year either direction', 'either direction date', 'direction date first', 'date first within', 'first within subset', 'within subset nearest', 'subset nearest prior', 'nearest prior date', 'prior date rated', 'date rated population', 'rated population recent', 'population recent photo', 'recent photo date', 'photo date participation', 'date participation study', 'participation study rateddata', 'study rateddata privacy', 'rateddata privacy concern', 'privacy concern study', 'concern study strict', 'study strict anonymity', 'strict anonymity nearly', 'anonymity nearly impossible', 'nearly impossible guarantee', 'impossible guarantee given', 'guarantee given usernames', 'given usernames personal', 'usernames personal photograph', 'personal photograph posted', 'photograph posted instagram', 'posted instagram often', 'instagram often contain', 'often contain identifiable', 'contain identifiable feature', 'identifiable feature sure', 'feature sure informed', 'sure informed risk', 'informed risk personally', 'risk personally identified', 'personally identified assured', 'identified assured personal', 'assured personal identifier', 'personal identifier including', 'identifier including usernames', 'including usernames would', 'usernames would public', 'would public published', 'public published format']"
https://dl.acm.org/doi/abs/10.1145/2858036.2858207 ,0,Privacy Ethics and Disclosure. We use public data from Reddit. Personally identifiable information was removed and content was de-identified and paraphrased before being reported in the paper for exemplary purposes. This work has been approved by the appropriate Institutional Review Board (IRB). Our work does not make any diagnostic claims related to mental illness or suicide.,privacy ethic and disclosure we use public data from reddit personally identifiable information wa removed and content wa deidentified and paraphrased before being reported in the paper for exemplary purpose this work ha been approved by the appropriate institutional review board irb our work doe not make any diagnostic claim related to mental illness or suicide,"['privacy', 'ethic', 'disclosure', 'use', 'public', 'reddit', 'personally', 'identifiable', 'removed', 'content', 'deidentified', 'paraphrased', 'reported', 'paper', 'exemplary', 'purpose', 'ha', 'approved', 'appropriate', 'institutional', 'review', 'board', 'irb', 'doe', 'make', 'diagnostic', 'claim', 'related', 'illness']","['privacy ethic', 'ethic disclosure', 'disclosure use', 'use public', 'public reddit', 'reddit personally', 'personally identifiable', 'identifiable removed', 'removed content', 'content deidentified', 'deidentified paraphrased', 'paraphrased reported', 'reported paper', 'paper exemplary', 'exemplary purpose', 'purpose ha', 'ha approved', 'approved appropriate', 'appropriate institutional', 'institutional review', 'review board', 'board irb', 'irb doe', 'doe make', 'make diagnostic', 'diagnostic claim', 'claim related', 'related illness']","['privacy ethic disclosure', 'ethic disclosure use', 'disclosure use public', 'use public reddit', 'public reddit personally', 'reddit personally identifiable', 'personally identifiable removed', 'identifiable removed content', 'removed content deidentified', 'content deidentified paraphrased', 'deidentified paraphrased reported', 'paraphrased reported paper', 'reported paper exemplary', 'paper exemplary purpose', 'exemplary purpose ha', 'purpose ha approved', 'ha approved appropriate', 'approved appropriate institutional', 'appropriate institutional review', 'institutional review board', 'review board irb', 'board irb doe', 'irb doe make', 'doe make diagnostic', 'make diagnostic claim', 'diagnostic claim related', 'claim related illness']"
https://dl.acm.org/doi/abs/10.1145/2702613.2732733,0,Based on the training data thus created we pursued the use of supervised learning to develop a classifier which would indicate whether a post is of high low or no self-disclosure. We tested a variety of different classification techniques (decision trees k Nearest Neighbor naive Bayes). The best performing classifier was found to be a perceptron classifier with adaptive boosting used to amplify performance [17] whose results will be used in the remainder of this paper. We used the following feature generation rules: First we eliminated stopwords from each post based on standard list provided by Python’s NLTK library. Next we performed stemming using Porter Stemmer. We extracted uni- bi- and tri-grams from each post and considered those with five or more occurrences. We also computed two additional features – length of each post and whether the author of the post is an exclusive poster on mental health forums or is observed in our dataset to post on other forums as well. Thus each post was characterized by 1070 features. We used standard 10-fold cross validation (CV) to evaluate the classifier and ran our model over 100 random 10-fold CV assignments for generalizability of the results. We report the average accuracy precision recall F1 specificity as metrics of performance. We find that our classifier based on the perception model yields an average accuracy of 78.4% in detecting high or low self-disclosure with .74 precision and .86 recall (see Table 4 for details). Other methods like k-NN (k=5) give higher precision but at the expense of very low recall. Figure 1 gives the ROC (receiver operating characteristic) curves for all the models. Per the ROC curve corresponding to the perceptron model we find it to yield the maximum area under curve (.81) hence best performance. We further identify in Table 5 the n-grams (or features) with the highest weights given by the perceptron – it implies these features were the most significant in the classification task. We provide some brief qualitative examinations of these n-grams in the light of prior psychology literature on selfdisclosure and mental health [10 11]. We find that the ngrams primarily are associated with vulnerable and selfloathing thoughts (e.g. thoughts of suicide) bear a negative tone or depict confessional experiences. Based on prior research [10 11 12] and our own work on mental health discourse on Reddit [4] we find that these are the topical dimensions along which high self-disclosure and low/no selfdisclosure posts vary. In essence high self-disclosure posts share extensively their personal beliefs and fear for instance their vital constructs and private sensitive informational attributes. The post excerpts below have been classified to be of high self-disclosure and through them we demonstrate the use of some of the n-grams in Table 7: \“I don’t want to kill myself I haven’t felt suicidal in a long time but I just want to stop life for a while you know?” “My dad would beat the living shit out of me […]. I’ve been to the hospital so many times I’ve lost track” “I hate this. I hate myself. I don't want to f****** be this person anymore. I'm unmotivated unfocused immature.”,based on the training data thus created we pursued the use of supervised learning to develop a classifier which would indicate whether a post is of high low or no selfdisclosure we tested a variety of different classification technique decision tree k nearest neighbor naive bayes the best performing classifier wa found to be a perceptron classifier with adaptive boosting used to amplify performance whose result will be used in the remainder of this paper we used the following feature generation rule first we eliminated stopwords from each post based on standard list provided by python nltk library next we performed stemming using porter stemmer we extracted uni bi and trigram from each post and considered those with five or more occurrence we also computed two additional feature length of each post and whether the author of the post is an exclusive poster on mental health forum or is observed in our dataset to post on other forum a well thus each post wa characterized by feature we used standard fold cross validation cv to evaluate the classifier and ran our model over random fold cv assignment for generalizability of the result we report the average accuracy precision recall f specificity a metric of performance we find that our classifier based on the perception model yield an average accuracy of in detecting high or low selfdisclosure with precision and recall see table for detail other method like knn k give higher precision but at the expense of very low recall figure give the roc receiver operating characteristic curve for all the model per the roc curve corresponding to the perceptron model we find it to yield the maximum area under curve hence best performance we further identify in table the ngrams or feature with the highest weight given by the perceptron it implies these feature were the most significant in the classification task we provide some brief qualitative examination of these ngrams in the light of prior psychology literature on selfdisclosure and mental health we find that the ngrams primarily are associated with vulnerable and selfloathing thought eg thought of suicide bear a negative tone or depict confessional experience based on prior research and our own work on mental health discourse on reddit we find that these are the topical dimension along which high selfdisclosure and lowno selfdisclosure post vary in essence high selfdisclosure post share extensively their personal belief and fear for instance their vital construct and private sensitive informational attribute the post excerpt below have been classified to be of high selfdisclosure and through them we demonstrate the use of some of the ngrams in table i dont want to kill myself i havent felt suicidal in a long time but i just want to stop life for a while you know my dad would beat the living shit out of me ive been to the hospital so many time ive lost track i hate this i hate myself i dont want to f be this person anymore im unmotivated unfocused immature,"['based', 'training', 'thus', 'created', 'pursued', 'use', 'supervised', 'learning', 'develop', 'classifier', 'would', 'indicate', 'whether', 'high', 'low', 'selfdisclosure', 'tested', 'variety', 'different', 'classification', 'technique', 'decision', 'tree', 'k', 'nearest', 'neighbor', 'naive', 'bayes', 'best', 'performing', 'classifier', 'found', 'perceptron', 'classifier', 'adaptive', 'boosting', 'amplify', 'performance', 'whose', 'result', 'remainder', 'paper', 'following', 'feature', 'generation', 'rule', 'first', 'eliminated', 'stopwords', 'based', 'standard', 'list', 'provided', 'python', 'nltk', 'library', 'next', 'performed', 'stemming', 'porter', 'stemmer', 'extracted', 'uni', 'bi', 'trigram', 'considered', 'five', 'occurrence', 'also', 'computed', 'two', 'additional', 'feature', 'length', 'whether', 'author', 'exclusive', 'poster', 'forum', 'observed', 'forum', 'well', 'thus', 'characterized', 'feature', 'standard', 'fold', 'cross', 'validation', 'cv', 'evaluate', 'classifier', 'ran', 'model', 'random', 'fold', 'cv', 'assignment', 'generalizability', 'result', 'report', 'average', 'accuracy', 'precision', 'recall', 'f', 'specificity', 'metric', 'performance', 'find', 'classifier', 'based', 'perception', 'model', 'yield', 'average', 'accuracy', 'detecting', 'high', 'low', 'selfdisclosure', 'precision', 'recall', 'see', 'table', 'detail', 'method', 'like', 'knn', 'k', 'give', 'higher', 'precision', 'expense', 'low', 'recall', 'figure', 'give', 'roc', 'receiver', 'operating', 'characteristic', 'curve', 'model', 'per', 'roc', 'curve', 'corresponding', 'perceptron', 'model', 'find', 'yield', 'maximum', 'area', 'curve', 'hence', 'best', 'performance', 'identify', 'table', 'ngrams', 'feature', 'highest', 'weight', 'given', 'perceptron', 'implies', 'feature', 'significant', 'classification', 'task', 'provide', 'brief', 'qualitative', 'examination', 'ngrams', 'light', 'prior', 'psychology', 'literature', 'selfdisclosure', 'find', 'ngrams', 'primarily', 'associated', 'vulnerable', 'selfloathing', 'thought', 'eg', 'thought', 'bear', 'negative', 'tone', 'depict', 'confessional', 'experience', 'based', 'prior', 'research', 'discourse', 'reddit', 'find', 'topical', 'dimension', 'along', 'high', 'selfdisclosure', 'lowno', 'selfdisclosure', 'vary', 'essence', 'high', 'selfdisclosure', 'share', 'extensively', 'personal', 'belief', 'fear', 'instance', 'vital', 'construct', 'private', 'sensitive', 'informational', 'attribute', 'excerpt', 'classified', 'high', 'selfdisclosure', 'demonstrate', 'use', 'ngrams', 'table', 'dont', 'want', 'kill', 'havent', 'felt', 'suicidal', 'long', 'want', 'stop', 'life', 'know', 'dad', 'would', 'beat', 'living', 'shit', 'ive', 'hospital', 'many', 'ive', 'lost', 'track', 'hate', 'hate', 'dont', 'want', 'f', 'person', 'anymore', 'im', 'unmotivated', 'unfocused', 'immature']","['based training', 'training thus', 'thus created', 'created pursued', 'pursued use', 'use supervised', 'supervised learning', 'learning develop', 'develop classifier', 'classifier would', 'would indicate', 'indicate whether', 'whether high', 'high low', 'low selfdisclosure', 'selfdisclosure tested', 'tested variety', 'variety different', 'different classification', 'classification technique', 'technique decision', 'decision tree', 'tree k', 'k nearest', 'nearest neighbor', 'neighbor naive', 'naive bayes', 'bayes best', 'best performing', 'performing classifier', 'classifier found', 'found perceptron', 'perceptron classifier', 'classifier adaptive', 'adaptive boosting', 'boosting amplify', 'amplify performance', 'performance whose', 'whose result', 'result remainder', 'remainder paper', 'paper following', 'following feature', 'feature generation', 'generation rule', 'rule first', 'first eliminated', 'eliminated stopwords', 'stopwords based', 'based standard', 'standard list', 'list provided', 'provided python', 'python nltk', 'nltk library', 'library next', 'next performed', 'performed stemming', 'stemming porter', 'porter stemmer', 'stemmer extracted', 'extracted uni', 'uni bi', 'bi trigram', 'trigram considered', 'considered five', 'five occurrence', 'occurrence also', 'also computed', 'computed two', 'two additional', 'additional feature', 'feature length', 'length whether', 'whether author', 'author exclusive', 'exclusive poster', 'poster forum', 'forum observed', 'observed forum', 'forum well', 'well thus', 'thus characterized', 'characterized feature', 'feature standard', 'standard fold', 'fold cross', 'cross validation', 'validation cv', 'cv evaluate', 'evaluate classifier', 'classifier ran', 'ran model', 'model random', 'random fold', 'fold cv', 'cv assignment', 'assignment generalizability', 'generalizability result', 'result report', 'report average', 'average accuracy', 'accuracy precision', 'precision recall', 'recall f', 'f specificity', 'specificity metric', 'metric performance', 'performance find', 'find classifier', 'classifier based', 'based perception', 'perception model', 'model yield', 'yield average', 'average accuracy', 'accuracy detecting', 'detecting high', 'high low', 'low selfdisclosure', 'selfdisclosure precision', 'precision recall', 'recall see', 'see table', 'table detail', 'detail method', 'method like', 'like knn', 'knn k', 'k give', 'give higher', 'higher precision', 'precision expense', 'expense low', 'low recall', 'recall figure', 'figure give', 'give roc', 'roc receiver', 'receiver operating', 'operating characteristic', 'characteristic curve', 'curve model', 'model per', 'per roc', 'roc curve', 'curve corresponding', 'corresponding perceptron', 'perceptron model', 'model find', 'find yield', 'yield maximum', 'maximum area', 'area curve', 'curve hence', 'hence best', 'best performance', 'performance identify', 'identify table', 'table ngrams', 'ngrams feature', 'feature highest', 'highest weight', 'weight given', 'given perceptron', 'perceptron implies', 'implies feature', 'feature significant', 'significant classification', 'classification task', 'task provide', 'provide brief', 'brief qualitative', 'qualitative examination', 'examination ngrams', 'ngrams light', 'light prior', 'prior psychology', 'psychology literature', 'literature selfdisclosure', 'selfdisclosure find', 'find ngrams', 'ngrams primarily', 'primarily associated', 'associated vulnerable', 'vulnerable selfloathing', 'selfloathing thought', 'thought eg', 'eg thought', 'thought bear', 'bear negative', 'negative tone', 'tone depict', 'depict confessional', 'confessional experience', 'experience based', 'based prior', 'prior research', 'research discourse', 'discourse reddit', 'reddit find', 'find topical', 'topical dimension', 'dimension along', 'along high', 'high selfdisclosure', 'selfdisclosure lowno', 'lowno selfdisclosure', 'selfdisclosure vary', 'vary essence', 'essence high', 'high selfdisclosure', 'selfdisclosure share', 'share extensively', 'extensively personal', 'personal belief', 'belief fear', 'fear instance', 'instance vital', 'vital construct', 'construct private', 'private sensitive', 'sensitive informational', 'informational attribute', 'attribute excerpt', 'excerpt classified', 'classified high', 'high selfdisclosure', 'selfdisclosure demonstrate', 'demonstrate use', 'use ngrams', 'ngrams table', 'table dont', 'dont want', 'want kill', 'kill havent', 'havent felt', 'felt suicidal', 'suicidal long', 'long want', 'want stop', 'stop life', 'life know', 'know dad', 'dad would', 'would beat', 'beat living', 'living shit', 'shit ive', 'ive hospital', 'hospital many', 'many ive', 'ive lost', 'lost track', 'track hate', 'hate hate', 'hate dont', 'dont want', 'want f', 'f person', 'person anymore', 'anymore im', 'im unmotivated', 'unmotivated unfocused', 'unfocused immature']","['based training thus', 'training thus created', 'thus created pursued', 'created pursued use', 'pursued use supervised', 'use supervised learning', 'supervised learning develop', 'learning develop classifier', 'develop classifier would', 'classifier would indicate', 'would indicate whether', 'indicate whether high', 'whether high low', 'high low selfdisclosure', 'low selfdisclosure tested', 'selfdisclosure tested variety', 'tested variety different', 'variety different classification', 'different classification technique', 'classification technique decision', 'technique decision tree', 'decision tree k', 'tree k nearest', 'k nearest neighbor', 'nearest neighbor naive', 'neighbor naive bayes', 'naive bayes best', 'bayes best performing', 'best performing classifier', 'performing classifier found', 'classifier found perceptron', 'found perceptron classifier', 'perceptron classifier adaptive', 'classifier adaptive boosting', 'adaptive boosting amplify', 'boosting amplify performance', 'amplify performance whose', 'performance whose result', 'whose result remainder', 'result remainder paper', 'remainder paper following', 'paper following feature', 'following feature generation', 'feature generation rule', 'generation rule first', 'rule first eliminated', 'first eliminated stopwords', 'eliminated stopwords based', 'stopwords based standard', 'based standard list', 'standard list provided', 'list provided python', 'provided python nltk', 'python nltk library', 'nltk library next', 'library next performed', 'next performed stemming', 'performed stemming porter', 'stemming porter stemmer', 'porter stemmer extracted', 'stemmer extracted uni', 'extracted uni bi', 'uni bi trigram', 'bi trigram considered', 'trigram considered five', 'considered five occurrence', 'five occurrence also', 'occurrence also computed', 'also computed two', 'computed two additional', 'two additional feature', 'additional feature length', 'feature length whether', 'length whether author', 'whether author exclusive', 'author exclusive poster', 'exclusive poster forum', 'poster forum observed', 'forum observed forum', 'observed forum well', 'forum well thus', 'well thus characterized', 'thus characterized feature', 'characterized feature standard', 'feature standard fold', 'standard fold cross', 'fold cross validation', 'cross validation cv', 'validation cv evaluate', 'cv evaluate classifier', 'evaluate classifier ran', 'classifier ran model', 'ran model random', 'model random fold', 'random fold cv', 'fold cv assignment', 'cv assignment generalizability', 'assignment generalizability result', 'generalizability result report', 'result report average', 'report average accuracy', 'average accuracy precision', 'accuracy precision recall', 'precision recall f', 'recall f specificity', 'f specificity metric', 'specificity metric performance', 'metric performance find', 'performance find classifier', 'find classifier based', 'classifier based perception', 'based perception model', 'perception model yield', 'model yield average', 'yield average accuracy', 'average accuracy detecting', 'accuracy detecting high', 'detecting high low', 'high low selfdisclosure', 'low selfdisclosure precision', 'selfdisclosure precision recall', 'precision recall see', 'recall see table', 'see table detail', 'table detail method', 'detail method like', 'method like knn', 'like knn k', 'knn k give', 'k give higher', 'give higher precision', 'higher precision expense', 'precision expense low', 'expense low recall', 'low recall figure', 'recall figure give', 'figure give roc', 'give roc receiver', 'roc receiver operating', 'receiver operating characteristic', 'operating characteristic curve', 'characteristic curve model', 'curve model per', 'model per roc', 'per roc curve', 'roc curve corresponding', 'curve corresponding perceptron', 'corresponding perceptron model', 'perceptron model find', 'model find yield', 'find yield maximum', 'yield maximum area', 'maximum area curve', 'area curve hence', 'curve hence best', 'hence best performance', 'best performance identify', 'performance identify table', 'identify table ngrams', 'table ngrams feature', 'ngrams feature highest', 'feature highest weight', 'highest weight given', 'weight given perceptron', 'given perceptron implies', 'perceptron implies feature', 'implies feature significant', 'feature significant classification', 'significant classification task', 'classification task provide', 'task provide brief', 'provide brief qualitative', 'brief qualitative examination', 'qualitative examination ngrams', 'examination ngrams light', 'ngrams light prior', 'light prior psychology', 'prior psychology literature', 'psychology literature selfdisclosure', 'literature selfdisclosure find', 'selfdisclosure find ngrams', 'find ngrams primarily', 'ngrams primarily associated', 'primarily associated vulnerable', 'associated vulnerable selfloathing', 'vulnerable selfloathing thought', 'selfloathing thought eg', 'thought eg thought', 'eg thought bear', 'thought bear negative', 'bear negative tone', 'negative tone depict', 'tone depict confessional', 'depict confessional experience', 'confessional experience based', 'experience based prior', 'based prior research', 'prior research discourse', 'research discourse reddit', 'discourse reddit find', 'reddit find topical', 'find topical dimension', 'topical dimension along', 'dimension along high', 'along high selfdisclosure', 'high selfdisclosure lowno', 'selfdisclosure lowno selfdisclosure', 'lowno selfdisclosure vary', 'selfdisclosure vary essence', 'vary essence high', 'essence high selfdisclosure', 'high selfdisclosure share', 'selfdisclosure share extensively', 'share extensively personal', 'extensively personal belief', 'personal belief fear', 'belief fear instance', 'fear instance vital', 'instance vital construct', 'vital construct private', 'construct private sensitive', 'private sensitive informational', 'sensitive informational attribute', 'informational attribute excerpt', 'attribute excerpt classified', 'excerpt classified high', 'classified high selfdisclosure', 'high selfdisclosure demonstrate', 'selfdisclosure demonstrate use', 'demonstrate use ngrams', 'use ngrams table', 'ngrams table dont', 'table dont want', 'dont want kill', 'want kill havent', 'kill havent felt', 'havent felt suicidal', 'felt suicidal long', 'suicidal long want', 'long want stop', 'want stop life', 'stop life know', 'life know dad', 'know dad would', 'dad would beat', 'would beat living', 'beat living shit', 'living shit ive', 'shit ive hospital', 'ive hospital many', 'hospital many ive', 'many ive lost', 'ive lost track', 'lost track hate', 'track hate hate', 'hate hate dont', 'hate dont want', 'dont want f', 'want f person', 'f person anymore', 'person anymore im', 'anymore im unmotivated', 'im unmotivated unfocused', 'unmotivated unfocused immature']"
https://dl.acm.org/doi/abs/10.1145/2702123.2702280,1,In this study we gathered information on depression levels of Twitter users and their activity histories. To do this we published a website to administer a questionnaire and disseminated information about the website over Twitter1. In contrast to De Choudhury et al. [14] who collected data from Englishspeaking users through crowdsourcing this study collected data from Japanese-speaking volunteers. This approach was used to investigate the extent to which depression risk can be estimated for a population different from the population considered by the prior research [14]. Figure 1 shows a screenshot of our website. The website collected the responses to a questionnaire to evaluate the degree of depression of the Twitter users who participated (hereinafter the participants) and to collect the histories of participants activities on Twitter. The activity histories of participants were collected through the Twitter application programming interface (API)2 and the questionnaires to determine degree of depression were completed by participants through their web browsers. Before data collection visitors to the website were presented with a written explanation of the aims of the experiment the information that would be collected and how that information would be handled. Those who consented to become participants after receiving the explanation logged into their individual Twitter accounts through the OAuth authorization process. Next participants were surveyed on gender age occupation and history of depression following which they answered a questionnaire designed to evaluate degree of depression. A message called the “kokoro score” (“kokoro” is a Japanese word meaning “heart”) determined on the basis of answers to the questionnaire and information in the collected tweets was displayed to participants after completion of the questionnaire (Fig. 2). Experiment participants were able to tweet the message displayed which made it possible to promote the website over Twitter by word-of-mouth in a type of snowball sampling. The CES-D questionnaire was used to evaluate the degree of depression [30]. In the CES-D test participants answered 20 questions on a Likert-type 4-point scale. Each answer was assigned a score of 0-3 points with the sum of the points from all answers used as the score to estimate likelihood of depression. Several standards exist by which to determine the appropriate cutoff score for identifying depression. In this research we regarded a score of 22 points or higher as indicating active depression and a score of 21 points or lower as indicating no active depression; these are the same values as used in [14] and give a cutoff score of 22. In addition answers to BDI [2] a depression scale used with characteristics similar to CESD were collected to ensure the reliability of data. For each participant scores were calculated on both scales with poor correlation regarded as indicating unreliable answers. The time taken to answer the questionnaires was also recorded and those completed in too brief a time were excluded. After each participant answered the questionnaire the activity history of that participant on Twitter was collected from Twitter by using the API. At most 3200 tweets were collected for each participant and the number of users following the participant and being followed by the participant were recorded. Tweets published after the questionnaire was taken were discarded. The website was opened to the public on 4 December 2013 at which time the authors publicized it on their Twitter accounts. Between 4 December 2013 and 8 February 2014 219 people participated in the experiment. After eliminating participants who did not tweet and participants who answered the questionnaire in fewer than 30 seconds (as previously mentioned to ensure the reliability of the questionnaire answers) 214 sets of answers remained. Only the first set of answers was used for participants who completed the questionnaire more than once. As a result data about 209 experiment participants (male: 121; female: 88) aged 16 to 55 (mean: 28.8 years; standard deviation: 8.2 years) were analyzed. The correlations between CES-D score and BDI score for these participants were high 0.87 and there were no participants with uncorrelated scores so the data for all 209 participants were used; excluded datasets are not discussed any further. Figure 3 shows the histogram of CES-D scores of 209 participants. Among the participants 81 (resp. 128) were estimated to have (resp. not have) active depression for an incidence of approximately 39%. This incidence is similar to that found by De Choudhury et al. [14] who identified depression in approximately 36% of participants. Table 1 gives statistics on the activity histories of participants.,in this study we gathered information on depression level of twitter user and their activity history to do this we published a website to administer a questionnaire and disseminated information about the website over twitter in contrast to de choudhury et al who collected data from englishspeaking user through crowdsourcing this study collected data from japanesespeaking volunteer this approach wa used to investigate the extent to which depression risk can be estimated for a population different from the population considered by the prior research figure show a screenshot of our website the website collected the response to a questionnaire to evaluate the degree of depression of the twitter user who participated hereinafter the participant and to collect the history of participant activity on twitter the activity history of participant were collected through the twitter application programming interface api and the questionnaire to determine degree of depression were completed by participant through their web browser before data collection visitor to the website were presented with a written explanation of the aim of the experiment the information that would be collected and how that information would be handled those who consented to become participant after receiving the explanation logged into their individual twitter account through the oauth authorization process next participant were surveyed on gender age occupation and history of depression following which they answered a questionnaire designed to evaluate degree of depression a message called the kokoro score kokoro is a japanese word meaning heart determined on the basis of answer to the questionnaire and information in the collected tweet wa displayed to participant after completion of the questionnaire fig experiment participant were able to tweet the message displayed which made it possible to promote the website over twitter by wordofmouth in a type of snowball sampling the cesd questionnaire wa used to evaluate the degree of depression in the cesd test participant answered question on a likerttype point scale each answer wa assigned a score of point with the sum of the point from all answer used a the score to estimate likelihood of depression several standard exist by which to determine the appropriate cutoff score for identifying depression in this research we regarded a score of point or higher a indicating active depression and a score of point or lower a indicating no active depression these are the same value a used in and give a cutoff score of in addition answer to bdi a depression scale used with characteristic similar to cesd were collected to ensure the reliability of data for each participant score were calculated on both scale with poor correlation regarded a indicating unreliable answer the time taken to answer the questionnaire wa also recorded and those completed in too brief a time were excluded after each participant answered the questionnaire the activity history of that participant on twitter wa collected from twitter by using the api at most tweet were collected for each participant and the number of user following the participant and being followed by the participant were recorded tweet published after the questionnaire wa taken were discarded the website wa opened to the public on december at which time the author publicized it on their twitter account between december and february people participated in the experiment after eliminating participant who did not tweet and participant who answered the questionnaire in fewer than second a previously mentioned to ensure the reliability of the questionnaire answer set of answer remained only the first set of answer wa used for participant who completed the questionnaire more than once a a result data about experiment participant male female aged to mean year standard deviation year were analyzed the correlation between cesd score and bdi score for these participant were high and there were no participant with uncorrelated score so the data for all participant were used excluded datasets are not discussed any further figure show the histogram of cesd score of participant among the participant resp were estimated to have resp not have active depression for an incidence of approximately this incidence is similar to that found by de choudhury et al who identified depression in approximately of participant table give statistic on the activity history of participant,"['study', 'gathered', 'level', 'activity', 'history', 'published', 'website', 'administer', 'questionnaire', 'disseminated', 'website', 'contrast', 'de', 'choudhury', 'et', 'al', 'englishspeaking', 'crowdsourcing', 'study', 'japanesespeaking', 'volunteer', 'approach', 'investigate', 'extent', 'risk', 'estimated', 'population', 'different', 'population', 'considered', 'prior', 'research', 'figure', 'show', 'screenshot', 'website', 'website', 'response', 'questionnaire', 'evaluate', 'degree', 'participated', 'hereinafter', 'collect', 'history', 'activity', 'activity', 'history', 'application', 'programming', 'interface', 'api', 'questionnaire', 'determine', 'degree', 'completed', 'web', 'browser', 'collection', 'visitor', 'website', 'presented', 'written', 'explanation', 'aim', 'experiment', 'would', 'would', 'handled', 'consented', 'become', 'receiving', 'explanation', 'logged', 'individual', 'account', 'oauth', 'authorization', 'process', 'next', 'surveyed', 'gender', 'age', 'occupation', 'history', 'following', 'answered', 'questionnaire', 'designed', 'evaluate', 'degree', 'message', 'called', 'kokoro', 'kokoro', 'japanese', 'meaning', 'heart', 'determined', 'basis', 'answer', 'questionnaire', 'displayed', 'completion', 'questionnaire', 'fig', 'experiment', 'able', 'message', 'displayed', 'possible', 'promote', 'website', 'wordofmouth', 'type', 'snowball', 'sampling', 'cesd', 'questionnaire', 'evaluate', 'degree', 'cesd', 'test', 'answered', 'question', 'likerttype', 'point', 'scale', 'answer', 'assigned', 'point', 'sum', 'point', 'answer', 'estimate', 'likelihood', 'several', 'standard', 'exist', 'determine', 'appropriate', 'cutoff', 'identifying', 'research', 'regarded', 'point', 'higher', 'indicating', 'active', 'point', 'lower', 'indicating', 'active', 'value', 'give', 'cutoff', 'addition', 'answer', 'bdi', 'scale', 'characteristic', 'similar', 'cesd', 'ensure', 'reliability', 'calculated', 'scale', 'poor', 'correlation', 'regarded', 'indicating', 'unreliable', 'answer', 'taken', 'answer', 'questionnaire', 'also', 'recorded', 'completed', 'brief', 'excluded', 'answered', 'questionnaire', 'activity', 'history', 'api', 'number', 'following', 'followed', 'recorded', 'published', 'questionnaire', 'taken', 'discarded', 'website', 'opened', 'public', 'december', 'author', 'publicized', 'account', 'december', 'february', 'people', 'participated', 'experiment', 'eliminating', 'answered', 'questionnaire', 'fewer', 'second', 'previously', 'mentioned', 'ensure', 'reliability', 'questionnaire', 'answer', 'answer', 'remained', 'first', 'answer', 'completed', 'questionnaire', 'result', 'experiment', 'male', 'female', 'aged', 'mean', 'year', 'standard', 'deviation', 'year', 'analyzed', 'correlation', 'cesd', 'bdi', 'high', 'uncorrelated', 'excluded', 'datasets', 'discussed', 'figure', 'show', 'histogram', 'cesd', 'among', 'resp', 'estimated', 'resp', 'active', 'incidence', 'approximately', 'incidence', 'similar', 'found', 'de', 'choudhury', 'et', 'al', 'identified', 'approximately', 'table', 'give', 'statistic', 'activity', 'history']","['study gathered', 'gathered level', 'level activity', 'activity history', 'history published', 'published website', 'website administer', 'administer questionnaire', 'questionnaire disseminated', 'disseminated website', 'website contrast', 'contrast de', 'de choudhury', 'choudhury et', 'et al', 'al englishspeaking', 'englishspeaking crowdsourcing', 'crowdsourcing study', 'study japanesespeaking', 'japanesespeaking volunteer', 'volunteer approach', 'approach investigate', 'investigate extent', 'extent risk', 'risk estimated', 'estimated population', 'population different', 'different population', 'population considered', 'considered prior', 'prior research', 'research figure', 'figure show', 'show screenshot', 'screenshot website', 'website website', 'website response', 'response questionnaire', 'questionnaire evaluate', 'evaluate degree', 'degree participated', 'participated hereinafter', 'hereinafter collect', 'collect history', 'history activity', 'activity activity', 'activity history', 'history application', 'application programming', 'programming interface', 'interface api', 'api questionnaire', 'questionnaire determine', 'determine degree', 'degree completed', 'completed web', 'web browser', 'browser collection', 'collection visitor', 'visitor website', 'website presented', 'presented written', 'written explanation', 'explanation aim', 'aim experiment', 'experiment would', 'would would', 'would handled', 'handled consented', 'consented become', 'become receiving', 'receiving explanation', 'explanation logged', 'logged individual', 'individual account', 'account oauth', 'oauth authorization', 'authorization process', 'process next', 'next surveyed', 'surveyed gender', 'gender age', 'age occupation', 'occupation history', 'history following', 'following answered', 'answered questionnaire', 'questionnaire designed', 'designed evaluate', 'evaluate degree', 'degree message', 'message called', 'called kokoro', 'kokoro kokoro', 'kokoro japanese', 'japanese meaning', 'meaning heart', 'heart determined', 'determined basis', 'basis answer', 'answer questionnaire', 'questionnaire displayed', 'displayed completion', 'completion questionnaire', 'questionnaire fig', 'fig experiment', 'experiment able', 'able message', 'message displayed', 'displayed possible', 'possible promote', 'promote website', 'website wordofmouth', 'wordofmouth type', 'type snowball', 'snowball sampling', 'sampling cesd', 'cesd questionnaire', 'questionnaire evaluate', 'evaluate degree', 'degree cesd', 'cesd test', 'test answered', 'answered question', 'question likerttype', 'likerttype point', 'point scale', 'scale answer', 'answer assigned', 'assigned point', 'point sum', 'sum point', 'point answer', 'answer estimate', 'estimate likelihood', 'likelihood several', 'several standard', 'standard exist', 'exist determine', 'determine appropriate', 'appropriate cutoff', 'cutoff identifying', 'identifying research', 'research regarded', 'regarded point', 'point higher', 'higher indicating', 'indicating active', 'active point', 'point lower', 'lower indicating', 'indicating active', 'active value', 'value give', 'give cutoff', 'cutoff addition', 'addition answer', 'answer bdi', 'bdi scale', 'scale characteristic', 'characteristic similar', 'similar cesd', 'cesd ensure', 'ensure reliability', 'reliability calculated', 'calculated scale', 'scale poor', 'poor correlation', 'correlation regarded', 'regarded indicating', 'indicating unreliable', 'unreliable answer', 'answer taken', 'taken answer', 'answer questionnaire', 'questionnaire also', 'also recorded', 'recorded completed', 'completed brief', 'brief excluded', 'excluded answered', 'answered questionnaire', 'questionnaire activity', 'activity history', 'history api', 'api number', 'number following', 'following followed', 'followed recorded', 'recorded published', 'published questionnaire', 'questionnaire taken', 'taken discarded', 'discarded website', 'website opened', 'opened public', 'public december', 'december author', 'author publicized', 'publicized account', 'account december', 'december february', 'february people', 'people participated', 'participated experiment', 'experiment eliminating', 'eliminating answered', 'answered questionnaire', 'questionnaire fewer', 'fewer second', 'second previously', 'previously mentioned', 'mentioned ensure', 'ensure reliability', 'reliability questionnaire', 'questionnaire answer', 'answer answer', 'answer remained', 'remained first', 'first answer', 'answer completed', 'completed questionnaire', 'questionnaire result', 'result experiment', 'experiment male', 'male female', 'female aged', 'aged mean', 'mean year', 'year standard', 'standard deviation', 'deviation year', 'year analyzed', 'analyzed correlation', 'correlation cesd', 'cesd bdi', 'bdi high', 'high uncorrelated', 'uncorrelated excluded', 'excluded datasets', 'datasets discussed', 'discussed figure', 'figure show', 'show histogram', 'histogram cesd', 'cesd among', 'among resp', 'resp estimated', 'estimated resp', 'resp active', 'active incidence', 'incidence approximately', 'approximately incidence', 'incidence similar', 'similar found', 'found de', 'de choudhury', 'choudhury et', 'et al', 'al identified', 'identified approximately', 'approximately table', 'table give', 'give statistic', 'statistic activity', 'activity history']","['study gathered level', 'gathered level activity', 'level activity history', 'activity history published', 'history published website', 'published website administer', 'website administer questionnaire', 'administer questionnaire disseminated', 'questionnaire disseminated website', 'disseminated website contrast', 'website contrast de', 'contrast de choudhury', 'de choudhury et', 'choudhury et al', 'et al englishspeaking', 'al englishspeaking crowdsourcing', 'englishspeaking crowdsourcing study', 'crowdsourcing study japanesespeaking', 'study japanesespeaking volunteer', 'japanesespeaking volunteer approach', 'volunteer approach investigate', 'approach investigate extent', 'investigate extent risk', 'extent risk estimated', 'risk estimated population', 'estimated population different', 'population different population', 'different population considered', 'population considered prior', 'considered prior research', 'prior research figure', 'research figure show', 'figure show screenshot', 'show screenshot website', 'screenshot website website', 'website website response', 'website response questionnaire', 'response questionnaire evaluate', 'questionnaire evaluate degree', 'evaluate degree participated', 'degree participated hereinafter', 'participated hereinafter collect', 'hereinafter collect history', 'collect history activity', 'history activity activity', 'activity activity history', 'activity history application', 'history application programming', 'application programming interface', 'programming interface api', 'interface api questionnaire', 'api questionnaire determine', 'questionnaire determine degree', 'determine degree completed', 'degree completed web', 'completed web browser', 'web browser collection', 'browser collection visitor', 'collection visitor website', 'visitor website presented', 'website presented written', 'presented written explanation', 'written explanation aim', 'explanation aim experiment', 'aim experiment would', 'experiment would would', 'would would handled', 'would handled consented', 'handled consented become', 'consented become receiving', 'become receiving explanation', 'receiving explanation logged', 'explanation logged individual', 'logged individual account', 'individual account oauth', 'account oauth authorization', 'oauth authorization process', 'authorization process next', 'process next surveyed', 'next surveyed gender', 'surveyed gender age', 'gender age occupation', 'age occupation history', 'occupation history following', 'history following answered', 'following answered questionnaire', 'answered questionnaire designed', 'questionnaire designed evaluate', 'designed evaluate degree', 'evaluate degree message', 'degree message called', 'message called kokoro', 'called kokoro kokoro', 'kokoro kokoro japanese', 'kokoro japanese meaning', 'japanese meaning heart', 'meaning heart determined', 'heart determined basis', 'determined basis answer', 'basis answer questionnaire', 'answer questionnaire displayed', 'questionnaire displayed completion', 'displayed completion questionnaire', 'completion questionnaire fig', 'questionnaire fig experiment', 'fig experiment able', 'experiment able message', 'able message displayed', 'message displayed possible', 'displayed possible promote', 'possible promote website', 'promote website wordofmouth', 'website wordofmouth type', 'wordofmouth type snowball', 'type snowball sampling', 'snowball sampling cesd', 'sampling cesd questionnaire', 'cesd questionnaire evaluate', 'questionnaire evaluate degree', 'evaluate degree cesd', 'degree cesd test', 'cesd test answered', 'test answered question', 'answered question likerttype', 'question likerttype point', 'likerttype point scale', 'point scale answer', 'scale answer assigned', 'answer assigned point', 'assigned point sum', 'point sum point', 'sum point answer', 'point answer estimate', 'answer estimate likelihood', 'estimate likelihood several', 'likelihood several standard', 'several standard exist', 'standard exist determine', 'exist determine appropriate', 'determine appropriate cutoff', 'appropriate cutoff identifying', 'cutoff identifying research', 'identifying research regarded', 'research regarded point', 'regarded point higher', 'point higher indicating', 'higher indicating active', 'indicating active point', 'active point lower', 'point lower indicating', 'lower indicating active', 'indicating active value', 'active value give', 'value give cutoff', 'give cutoff addition', 'cutoff addition answer', 'addition answer bdi', 'answer bdi scale', 'bdi scale characteristic', 'scale characteristic similar', 'characteristic similar cesd', 'similar cesd ensure', 'cesd ensure reliability', 'ensure reliability calculated', 'reliability calculated scale', 'calculated scale poor', 'scale poor correlation', 'poor correlation regarded', 'correlation regarded indicating', 'regarded indicating unreliable', 'indicating unreliable answer', 'unreliable answer taken', 'answer taken answer', 'taken answer questionnaire', 'answer questionnaire also', 'questionnaire also recorded', 'also recorded completed', 'recorded completed brief', 'completed brief excluded', 'brief excluded answered', 'excluded answered questionnaire', 'answered questionnaire activity', 'questionnaire activity history', 'activity history api', 'history api number', 'api number following', 'number following followed', 'following followed recorded', 'followed recorded published', 'recorded published questionnaire', 'published questionnaire taken', 'questionnaire taken discarded', 'taken discarded website', 'discarded website opened', 'website opened public', 'opened public december', 'public december author', 'december author publicized', 'author publicized account', 'publicized account december', 'account december february', 'december february people', 'february people participated', 'people participated experiment', 'participated experiment eliminating', 'experiment eliminating answered', 'eliminating answered questionnaire', 'answered questionnaire fewer', 'questionnaire fewer second', 'fewer second previously', 'second previously mentioned', 'previously mentioned ensure', 'mentioned ensure reliability', 'ensure reliability questionnaire', 'reliability questionnaire answer', 'questionnaire answer answer', 'answer answer remained', 'answer remained first', 'remained first answer', 'first answer completed', 'answer completed questionnaire', 'completed questionnaire result', 'questionnaire result experiment', 'result experiment male', 'experiment male female', 'male female aged', 'female aged mean', 'aged mean year', 'mean year standard', 'year standard deviation', 'standard deviation year', 'deviation year analyzed', 'year analyzed correlation', 'analyzed correlation cesd', 'correlation cesd bdi', 'cesd bdi high', 'bdi high uncorrelated', 'high uncorrelated excluded', 'uncorrelated excluded datasets', 'excluded datasets discussed', 'datasets discussed figure', 'discussed figure show', 'figure show histogram', 'show histogram cesd', 'histogram cesd among', 'cesd among resp', 'among resp estimated', 'resp estimated resp', 'estimated resp active', 'resp active incidence', 'active incidence approximately', 'incidence approximately incidence', 'approximately incidence similar', 'incidence similar found', 'similar found de', 'found de choudhury', 'de choudhury et', 'choudhury et al', 'et al identified', 'al identified approximately', 'identified approximately table', 'approximately table give', 'table give statistic', 'give statistic activity', 'statistic activity history']"
https://www.nature.com/articles/s41598-017-12961-9,1,The methods used in recruitment data collection and analysis are adopted from Reece and Danforth12. The present study was reviewed and approved by the Harvard University Institutional Review Board approval #15-2529 as well as the University of Vermont Institutional Review Board approval #CHRMS-16-135. All experimental procedures were performed in accordance with Institutional Review Board guidelines. All study participants provided informed consent and acknowledged all of the study goals expectations and procedures including data privacy prior to any data collection. Surveys were built using the Qualtrics survey platform and analyses were performed using Python and R. Twitter data collection apps were written in Python using the Twitter developer’s Application Programming Interface (API).,the method used in recruitment data collection and analysis are adopted from reece and danforth the present study wa reviewed and approved by the harvard university institutional review board approval a well a the university of vermont institutional review board approval chrms all experimental procedure were performed in accordance with institutional review board guideline all study participant provided informed consent and acknowledged all of the study goal expectation and procedure including data privacy prior to any data collection survey were built using the qualtrics survey platform and analysis were performed using python and r twitter data collection apps were written in python using the twitter developer application programming interface api,"['method', 'recruitment', 'collection', 'analysis', 'adopted', 'reece', 'danforth', 'present', 'study', 'reviewed', 'approved', 'harvard', 'university', 'institutional', 'review', 'board', 'approval', 'well', 'university', 'vermont', 'institutional', 'review', 'board', 'approval', 'chrms', 'experimental', 'procedure', 'performed', 'accordance', 'institutional', 'review', 'board', 'guideline', 'study', 'provided', 'informed', 'consent', 'acknowledged', 'study', 'goal', 'expectation', 'procedure', 'including', 'privacy', 'prior', 'collection', 'survey', 'built', 'qualtrics', 'survey', 'platform', 'analysis', 'performed', 'python', 'r', 'collection', 'apps', 'written', 'python', 'developer', 'application', 'programming', 'interface', 'api']","['method recruitment', 'recruitment collection', 'collection analysis', 'analysis adopted', 'adopted reece', 'reece danforth', 'danforth present', 'present study', 'study reviewed', 'reviewed approved', 'approved harvard', 'harvard university', 'university institutional', 'institutional review', 'review board', 'board approval', 'approval well', 'well university', 'university vermont', 'vermont institutional', 'institutional review', 'review board', 'board approval', 'approval chrms', 'chrms experimental', 'experimental procedure', 'procedure performed', 'performed accordance', 'accordance institutional', 'institutional review', 'review board', 'board guideline', 'guideline study', 'study provided', 'provided informed', 'informed consent', 'consent acknowledged', 'acknowledged study', 'study goal', 'goal expectation', 'expectation procedure', 'procedure including', 'including privacy', 'privacy prior', 'prior collection', 'collection survey', 'survey built', 'built qualtrics', 'qualtrics survey', 'survey platform', 'platform analysis', 'analysis performed', 'performed python', 'python r', 'r collection', 'collection apps', 'apps written', 'written python', 'python developer', 'developer application', 'application programming', 'programming interface', 'interface api']","['method recruitment collection', 'recruitment collection analysis', 'collection analysis adopted', 'analysis adopted reece', 'adopted reece danforth', 'reece danforth present', 'danforth present study', 'present study reviewed', 'study reviewed approved', 'reviewed approved harvard', 'approved harvard university', 'harvard university institutional', 'university institutional review', 'institutional review board', 'review board approval', 'board approval well', 'approval well university', 'well university vermont', 'university vermont institutional', 'vermont institutional review', 'institutional review board', 'review board approval', 'board approval chrms', 'approval chrms experimental', 'chrms experimental procedure', 'experimental procedure performed', 'procedure performed accordance', 'performed accordance institutional', 'accordance institutional review', 'institutional review board', 'review board guideline', 'board guideline study', 'guideline study provided', 'study provided informed', 'provided informed consent', 'informed consent acknowledged', 'consent acknowledged study', 'acknowledged study goal', 'study goal expectation', 'goal expectation procedure', 'expectation procedure including', 'procedure including privacy', 'including privacy prior', 'privacy prior collection', 'prior collection survey', 'collection survey built', 'survey built qualtrics', 'built qualtrics survey', 'qualtrics survey platform', 'survey platform analysis', 'platform analysis performed', 'analysis performed python', 'performed python r', 'python r collection', 'r collection apps', 'collection apps written', 'apps written python', 'written python developer', 'python developer application', 'developer application programming', 'application programming interface', 'programming interface api']"
https://aclanthology.org/W14-3214.pdf,1,We used a dataset of 28749 nonclinical users who opted into a Facebook application (“MyPersonality”; Kosinski and Stillwell 2012) between June 2009 and March 2011 completed a 100-item personality questionnaire (an International Personality Item Pool (IPIP) proxy to the NEO-PI-R (Goldberg 1999) and shared access to their status updates containing at least 500 words. Users wrote on average of 4236 words (69917624 total word instances) and a subset of 16507 users provided gender and age in which 57.0% were female and the mean age was 24.8. The dataset was divided into training and testing samples. In particular the testing sample consisted of a random set of 1000 users who wrote at least 1000 words and completed the personality measure while the training set contained the 27749 remaining users.,we used a dataset of nonclinical user who opted into a facebook application mypersonality kosinski and stillwell between june and march completed a item personality questionnaire an international personality item pool ipip proxy to the neopir goldberg and shared access to their status update containing at least word user wrote on average of word total word instance and a subset of user provided gender and age in which were female and the mean age wa the dataset wa divided into training and testing sample in particular the testing sample consisted of a random set of user who wrote at least word and completed the personality measure while the training set contained the remaining user,"['nonclinical', 'opted', 'facebook', 'application', 'mypersonality', 'kosinski', 'stillwell', 'june', 'march', 'completed', 'item', 'personality', 'questionnaire', 'international', 'personality', 'item', 'pool', 'ipip', 'proxy', 'neopir', 'goldberg', 'shared', 'access', 'status', 'update', 'containing', 'least', 'wrote', 'average', 'total', 'instance', 'subset', 'provided', 'gender', 'age', 'female', 'mean', 'age', 'divided', 'training', 'testing', 'sample', 'particular', 'testing', 'sample', 'consisted', 'random', 'wrote', 'least', 'completed', 'personality', 'measure', 'training', 'contained', 'remaining']","['nonclinical opted', 'opted facebook', 'facebook application', 'application mypersonality', 'mypersonality kosinski', 'kosinski stillwell', 'stillwell june', 'june march', 'march completed', 'completed item', 'item personality', 'personality questionnaire', 'questionnaire international', 'international personality', 'personality item', 'item pool', 'pool ipip', 'ipip proxy', 'proxy neopir', 'neopir goldberg', 'goldberg shared', 'shared access', 'access status', 'status update', 'update containing', 'containing least', 'least wrote', 'wrote average', 'average total', 'total instance', 'instance subset', 'subset provided', 'provided gender', 'gender age', 'age female', 'female mean', 'mean age', 'age divided', 'divided training', 'training testing', 'testing sample', 'sample particular', 'particular testing', 'testing sample', 'sample consisted', 'consisted random', 'random wrote', 'wrote least', 'least completed', 'completed personality', 'personality measure', 'measure training', 'training contained', 'contained remaining']","['nonclinical opted facebook', 'opted facebook application', 'facebook application mypersonality', 'application mypersonality kosinski', 'mypersonality kosinski stillwell', 'kosinski stillwell june', 'stillwell june march', 'june march completed', 'march completed item', 'completed item personality', 'item personality questionnaire', 'personality questionnaire international', 'questionnaire international personality', 'international personality item', 'personality item pool', 'item pool ipip', 'pool ipip proxy', 'ipip proxy neopir', 'proxy neopir goldberg', 'neopir goldberg shared', 'goldberg shared access', 'shared access status', 'access status update', 'status update containing', 'update containing least', 'containing least wrote', 'least wrote average', 'wrote average total', 'average total instance', 'total instance subset', 'instance subset provided', 'subset provided gender', 'provided gender age', 'gender age female', 'age female mean', 'female mean age', 'mean age divided', 'age divided training', 'divided training testing', 'training testing sample', 'testing sample particular', 'sample particular testing', 'particular testing sample', 'testing sample consisted', 'sample consisted random', 'consisted random wrote', 'random wrote least', 'wrote least completed', 'least completed personality', 'completed personality measure', 'personality measure training', 'measure training contained', 'training contained remaining']"
https://ieeexplore.ieee.org/abstract/document/6784326,0,a) CLINICAL Communities: Communities who are interested in ‘depression’ and with at least 200 posts are extracted from LiveJournal. This is identified through the ‘Search communities by interest’2 provided by LiveJournal and results in 24 communities with 38401 posts. The CLINICAL communities are grouped based on name and description of the individual community: depression bipolar self-harm attachment/separation and suicide (See Table 1 for statistics). The earliest community creation date was in 2001 thus our data set spans over 10 years. b) CONTROL communities: We constructed a CONTROL data set using five popular categories of communities in the LiveJournal Directory.3 We select communities who have at least 200 posts resulting in 23 communities with 229563 posts. This set is called CONTROL and the statistics of these 23 communities and their description are shown in Table 2.,a clinical community community who are interested in depression and with at least post are extracted from livejournal this is identified through the search community by interest provided by livejournal and result in community with post the clinical community are grouped based on name and description of the individual community depression bipolar selfharm attachmentseparation and suicide see table for statistic the earliest community creation date wa in thus our data set span over year b control community we constructed a control data set using five popular category of community in the livejournal directory we select community who have at least post resulting in community with post this set is called control and the statistic of these community and their description are shown in table,"['clinical', 'interested', 'least', 'extracted', 'livejournal', 'identified', 'search', 'interest', 'provided', 'livejournal', 'result', 'clinical', 'grouped', 'based', 'name', 'description', 'individual', 'bipolar', 'selfharm', 'attachmentseparation', 'see', 'table', 'statistic', 'earliest', 'creation', 'date', 'thus', 'span', 'year', 'b', 'constructed', 'five', 'popular', 'category', 'livejournal', 'directory', 'select', 'least', 'resulting', 'called', 'statistic', 'description', 'shown', 'table']","['clinical interested', 'interested least', 'least extracted', 'extracted livejournal', 'livejournal identified', 'identified search', 'search interest', 'interest provided', 'provided livejournal', 'livejournal result', 'result clinical', 'clinical grouped', 'grouped based', 'based name', 'name description', 'description individual', 'individual bipolar', 'bipolar selfharm', 'selfharm attachmentseparation', 'attachmentseparation see', 'see table', 'table statistic', 'statistic earliest', 'earliest creation', 'creation date', 'date thus', 'thus span', 'span year', 'year b', 'b constructed', 'constructed five', 'five popular', 'popular category', 'category livejournal', 'livejournal directory', 'directory select', 'select least', 'least resulting', 'resulting called', 'called statistic', 'statistic description', 'description shown', 'shown table']","['clinical interested least', 'interested least extracted', 'least extracted livejournal', 'extracted livejournal identified', 'livejournal identified search', 'identified search interest', 'search interest provided', 'interest provided livejournal', 'provided livejournal result', 'livejournal result clinical', 'result clinical grouped', 'clinical grouped based', 'grouped based name', 'based name description', 'name description individual', 'description individual bipolar', 'individual bipolar selfharm', 'bipolar selfharm attachmentseparation', 'selfharm attachmentseparation see', 'attachmentseparation see table', 'see table statistic', 'table statistic earliest', 'statistic earliest creation', 'earliest creation date', 'creation date thus', 'date thus span', 'thus span year', 'span year b', 'year b constructed', 'b constructed five', 'constructed five popular', 'five popular category', 'popular category livejournal', 'category livejournal directory', 'livejournal directory select', 'directory select least', 'select least resulting', 'least resulting called', 'resulting called statistic', 'called statistic description', 'statistic description shown', 'description shown table']"
https://www.jmir.org/2017/7/e243/,1,A Web-based survey of Weibo users was conducted to assess the respondents’ suicide risk and emotional distress (ie depression anxiety and stress). The invitation letter to participate in this survey was widely sent out to general Weibo users by various promotion activities. For a Weibo user to be eligible for the study she or he had to be 18 years or older (by self-report). A 30 Renminbi incentive for each complete survey was provided to boost the respond rate. With the respondents’ consent their Weibo posts that were posted in the public domain during the 12 months before the survey were downloaded by calling Weibo API. The survey fulfilled the Checklist for Reporting Results of Internet E-Surveys (CHERRIES) checklist and details of the procedure have been reported in previous publications [2232]. In addition when multiple survey feedback were submitted from the same Internet protocol addresses only the first submission was used to avoid duplicate participation. In contrast to a previous study [32] this study excluded those who posted nothing throughout the 12 months but not those who posted fewer than 100 posts. Eventually data provided by 974 respondents remained for further analyses. The study has obtained ethical approvals from the Human Research Ethical Review Committee at the University of Hong Kong and the Institute Review Board of the Institute of Psychology at the Chinese Academy of Sciences. The survey measured respondents’ suicide probability score depression anxiety stress and Weibo suicide communication (WSC) as the outcome variables. In addition the respondents’ Weibo posts language features were extracted as independent variables or features for machine learning. The details of how those data were obtained are elaborated in the following subsections.,a webbased survey of weibo user wa conducted to ass the respondent suicide risk and emotional distress ie depression anxiety and stress the invitation letter to participate in this survey wa widely sent out to general weibo user by various promotion activity for a weibo user to be eligible for the study she or he had to be year or older by selfreport a renminbi incentive for each complete survey wa provided to boost the respond rate with the respondent consent their weibo post that were posted in the public domain during the month before the survey were downloaded by calling weibo api the survey fulfilled the checklist for reporting result of internet esurveys cherry checklist and detail of the procedure have been reported in previous publication in addition when multiple survey feedback were submitted from the same internet protocol address only the first submission wa used to avoid duplicate participation in contrast to a previous study this study excluded those who posted nothing throughout the month but not those who posted fewer than post eventually data provided by respondent remained for further analysis the study ha obtained ethical approval from the human research ethical review committee at the university of hong kong and the institute review board of the institute of psychology at the chinese academy of science the survey measured respondent suicide probability score depression anxiety stress and weibo suicide communication wsc a the outcome variable in addition the respondent weibo post language feature were extracted a independent variable or feature for machine learning the detail of how those data were obtained are elaborated in the following subsection,"['webbased', 'survey', 'weibo', 'conducted', 'ass', 'respondent', 'risk', 'emotional', 'distress', 'ie', 'anxiety', 'stress', 'invitation', 'letter', 'participate', 'survey', 'widely', 'sent', 'general', 'weibo', 'various', 'promotion', 'activity', 'weibo', 'eligible', 'study', 'year', 'older', 'selfreport', 'renminbi', 'incentive', 'complete', 'survey', 'provided', 'boost', 'respond', 'rate', 'respondent', 'consent', 'weibo', 'posted', 'public', 'domain', 'month', 'survey', 'downloaded', 'calling', 'weibo', 'api', 'survey', 'fulfilled', 'checklist', 'reporting', 'result', 'internet', 'esurveys', 'cherry', 'checklist', 'detail', 'procedure', 'reported', 'previous', 'publication', 'addition', 'multiple', 'survey', 'feedback', 'submitted', 'internet', 'protocol', 'address', 'first', 'submission', 'avoid', 'duplicate', 'participation', 'contrast', 'previous', 'study', 'study', 'excluded', 'posted', 'nothing', 'throughout', 'month', 'posted', 'fewer', 'eventually', 'provided', 'respondent', 'remained', 'analysis', 'study', 'ha', 'obtained', 'ethical', 'approval', 'human', 'research', 'ethical', 'review', 'committee', 'university', 'hong', 'kong', 'institute', 'review', 'board', 'institute', 'psychology', 'chinese', 'academy', 'science', 'survey', 'measured', 'respondent', 'probability', 'anxiety', 'stress', 'weibo', 'communication', 'wsc', 'outcome', 'variable', 'addition', 'respondent', 'weibo', 'language', 'feature', 'extracted', 'independent', 'variable', 'feature', 'machine', 'learning', 'detail', 'obtained', 'elaborated', 'following', 'subsection']","['webbased survey', 'survey weibo', 'weibo conducted', 'conducted ass', 'ass respondent', 'respondent risk', 'risk emotional', 'emotional distress', 'distress ie', 'ie anxiety', 'anxiety stress', 'stress invitation', 'invitation letter', 'letter participate', 'participate survey', 'survey widely', 'widely sent', 'sent general', 'general weibo', 'weibo various', 'various promotion', 'promotion activity', 'activity weibo', 'weibo eligible', 'eligible study', 'study year', 'year older', 'older selfreport', 'selfreport renminbi', 'renminbi incentive', 'incentive complete', 'complete survey', 'survey provided', 'provided boost', 'boost respond', 'respond rate', 'rate respondent', 'respondent consent', 'consent weibo', 'weibo posted', 'posted public', 'public domain', 'domain month', 'month survey', 'survey downloaded', 'downloaded calling', 'calling weibo', 'weibo api', 'api survey', 'survey fulfilled', 'fulfilled checklist', 'checklist reporting', 'reporting result', 'result internet', 'internet esurveys', 'esurveys cherry', 'cherry checklist', 'checklist detail', 'detail procedure', 'procedure reported', 'reported previous', 'previous publication', 'publication addition', 'addition multiple', 'multiple survey', 'survey feedback', 'feedback submitted', 'submitted internet', 'internet protocol', 'protocol address', 'address first', 'first submission', 'submission avoid', 'avoid duplicate', 'duplicate participation', 'participation contrast', 'contrast previous', 'previous study', 'study study', 'study excluded', 'excluded posted', 'posted nothing', 'nothing throughout', 'throughout month', 'month posted', 'posted fewer', 'fewer eventually', 'eventually provided', 'provided respondent', 'respondent remained', 'remained analysis', 'analysis study', 'study ha', 'ha obtained', 'obtained ethical', 'ethical approval', 'approval human', 'human research', 'research ethical', 'ethical review', 'review committee', 'committee university', 'university hong', 'hong kong', 'kong institute', 'institute review', 'review board', 'board institute', 'institute psychology', 'psychology chinese', 'chinese academy', 'academy science', 'science survey', 'survey measured', 'measured respondent', 'respondent probability', 'probability anxiety', 'anxiety stress', 'stress weibo', 'weibo communication', 'communication wsc', 'wsc outcome', 'outcome variable', 'variable addition', 'addition respondent', 'respondent weibo', 'weibo language', 'language feature', 'feature extracted', 'extracted independent', 'independent variable', 'variable feature', 'feature machine', 'machine learning', 'learning detail', 'detail obtained', 'obtained elaborated', 'elaborated following', 'following subsection']","['webbased survey weibo', 'survey weibo conducted', 'weibo conducted ass', 'conducted ass respondent', 'ass respondent risk', 'respondent risk emotional', 'risk emotional distress', 'emotional distress ie', 'distress ie anxiety', 'ie anxiety stress', 'anxiety stress invitation', 'stress invitation letter', 'invitation letter participate', 'letter participate survey', 'participate survey widely', 'survey widely sent', 'widely sent general', 'sent general weibo', 'general weibo various', 'weibo various promotion', 'various promotion activity', 'promotion activity weibo', 'activity weibo eligible', 'weibo eligible study', 'eligible study year', 'study year older', 'year older selfreport', 'older selfreport renminbi', 'selfreport renminbi incentive', 'renminbi incentive complete', 'incentive complete survey', 'complete survey provided', 'survey provided boost', 'provided boost respond', 'boost respond rate', 'respond rate respondent', 'rate respondent consent', 'respondent consent weibo', 'consent weibo posted', 'weibo posted public', 'posted public domain', 'public domain month', 'domain month survey', 'month survey downloaded', 'survey downloaded calling', 'downloaded calling weibo', 'calling weibo api', 'weibo api survey', 'api survey fulfilled', 'survey fulfilled checklist', 'fulfilled checklist reporting', 'checklist reporting result', 'reporting result internet', 'result internet esurveys', 'internet esurveys cherry', 'esurveys cherry checklist', 'cherry checklist detail', 'checklist detail procedure', 'detail procedure reported', 'procedure reported previous', 'reported previous publication', 'previous publication addition', 'publication addition multiple', 'addition multiple survey', 'multiple survey feedback', 'survey feedback submitted', 'feedback submitted internet', 'submitted internet protocol', 'internet protocol address', 'protocol address first', 'address first submission', 'first submission avoid', 'submission avoid duplicate', 'avoid duplicate participation', 'duplicate participation contrast', 'participation contrast previous', 'contrast previous study', 'previous study study', 'study study excluded', 'study excluded posted', 'excluded posted nothing', 'posted nothing throughout', 'nothing throughout month', 'throughout month posted', 'month posted fewer', 'posted fewer eventually', 'fewer eventually provided', 'eventually provided respondent', 'provided respondent remained', 'respondent remained analysis', 'remained analysis study', 'analysis study ha', 'study ha obtained', 'ha obtained ethical', 'obtained ethical approval', 'ethical approval human', 'approval human research', 'human research ethical', 'research ethical review', 'ethical review committee', 'review committee university', 'committee university hong', 'university hong kong', 'hong kong institute', 'kong institute review', 'institute review board', 'review board institute', 'board institute psychology', 'institute psychology chinese', 'psychology chinese academy', 'chinese academy science', 'academy science survey', 'science survey measured', 'survey measured respondent', 'measured respondent probability', 'respondent probability anxiety', 'probability anxiety stress', 'anxiety stress weibo', 'stress weibo communication', 'weibo communication wsc', 'communication wsc outcome', 'wsc outcome variable', 'outcome variable addition', 'variable addition respondent', 'addition respondent weibo', 'respondent weibo language', 'weibo language feature', 'language feature extracted', 'feature extracted independent', 'extracted independent variable', 'independent variable feature', 'variable feature machine', 'feature machine learning', 'machine learning detail', 'learning detail obtained', 'detail obtained elaborated', 'obtained elaborated following', 'elaborated following subsection']"
https://dl.acm.org/doi/abs/10.1145/3025453.3025909,0,We gained access to a sample of 63485 public posts from 35038 unique users shared between 2014 and 2016 in a variety of mental health subreddits—this repository of posts has been used in prior work to study mental health selfdisclosure and support seeking manifested in social media [18 50 39 20]. This dataset includes posts and associated metadata spanning 14 mental health related subreddits such as r/depression r/mentalhealth and r/traumatoolbox r/bipolarreddit. From this corpus we excluded posts that contained only a title without a post body. This gave us 21734 posts. We refer to these posts as MH posts. Our control data also relied on a dataset compiled and utilized in prior work [50]; it contains posts from subreddits such as r/WorldNews r/food and r/AskReddit. We randomly sampled an equal number of posts (21734) as the MH posts above for our control dataset. We refer to these posts as CL posts.,we gained access to a sample of public post from unique user shared between and in a variety of mental health subredditsthis repository of post ha been used in prior work to study mental health selfdisclosure and support seeking manifested in social medium this dataset includes post and associated metadata spanning mental health related subreddits such a rdepression rmentalhealth and rtraumatoolbox rbipolarreddit from this corpus we excluded post that contained only a title without a post body this gave u post we refer to these post a mh post our control data also relied on a dataset compiled and utilized in prior work it contains post from subreddits such a rworldnews rfood and raskreddit we randomly sampled an equal number of post a the mh post above for our control dataset we refer to these post a cl post,"['gained', 'access', 'sample', 'public', 'unique', 'shared', 'variety', 'subredditsthis', 'repository', 'ha', 'prior', 'study', 'selfdisclosure', 'support', 'seeking', 'manifested', 'medium', 'includes', 'associated', 'metadata', 'spanning', 'related', 'rdepression', 'rmentalhealth', 'rtraumatoolbox', 'rbipolarreddit', 'corpus', 'excluded', 'contained', 'title', 'without', 'body', 'gave', 'u', 'refer', 'mh', 'also', 'relied', 'compiled', 'utilized', 'prior', 'contains', 'rworldnews', 'rfood', 'raskreddit', 'randomly', 'sampled', 'equal', 'number', 'mh', 'refer', 'cl']","['gained access', 'access sample', 'sample public', 'public unique', 'unique shared', 'shared variety', 'variety subredditsthis', 'subredditsthis repository', 'repository ha', 'ha prior', 'prior study', 'study selfdisclosure', 'selfdisclosure support', 'support seeking', 'seeking manifested', 'manifested medium', 'medium includes', 'includes associated', 'associated metadata', 'metadata spanning', 'spanning related', 'related rdepression', 'rdepression rmentalhealth', 'rmentalhealth rtraumatoolbox', 'rtraumatoolbox rbipolarreddit', 'rbipolarreddit corpus', 'corpus excluded', 'excluded contained', 'contained title', 'title without', 'without body', 'body gave', 'gave u', 'u refer', 'refer mh', 'mh also', 'also relied', 'relied compiled', 'compiled utilized', 'utilized prior', 'prior contains', 'contains rworldnews', 'rworldnews rfood', 'rfood raskreddit', 'raskreddit randomly', 'randomly sampled', 'sampled equal', 'equal number', 'number mh', 'mh refer', 'refer cl']","['gained access sample', 'access sample public', 'sample public unique', 'public unique shared', 'unique shared variety', 'shared variety subredditsthis', 'variety subredditsthis repository', 'subredditsthis repository ha', 'repository ha prior', 'ha prior study', 'prior study selfdisclosure', 'study selfdisclosure support', 'selfdisclosure support seeking', 'support seeking manifested', 'seeking manifested medium', 'manifested medium includes', 'medium includes associated', 'includes associated metadata', 'associated metadata spanning', 'metadata spanning related', 'spanning related rdepression', 'related rdepression rmentalhealth', 'rdepression rmentalhealth rtraumatoolbox', 'rmentalhealth rtraumatoolbox rbipolarreddit', 'rtraumatoolbox rbipolarreddit corpus', 'rbipolarreddit corpus excluded', 'corpus excluded contained', 'excluded contained title', 'contained title without', 'title without body', 'without body gave', 'body gave u', 'gave u refer', 'u refer mh', 'refer mh also', 'mh also relied', 'also relied compiled', 'relied compiled utilized', 'compiled utilized prior', 'utilized prior contains', 'prior contains rworldnews', 'contains rworldnews rfood', 'rworldnews rfood raskreddit', 'rfood raskreddit randomly', 'raskreddit randomly sampled', 'randomly sampled equal', 'sampled equal number', 'equal number mh', 'number mh refer', 'mh refer cl']"
https://ieeexplore.ieee.org/abstract/document/7752434,0,To train our models we require information from two different types of users: patients and non-patients. Therefore we employed a combined - manual effort and keyword matching - data collection approach to efficiently collect data for these users. For the collection of patients we manually collect the community portals relevant to both mental disorders. 2 From these portals' followers list we select the self-reported users who explicitly state in their profile description that they suffer from a mental illness; i.e. for a given user we are checking if his/her profile contains any keyword related to a target disorder (e.g. “borderline” “bpd” “bipolar”). Non-patients are referred to as random active Twitter users who are not explicitly stating that they are suffering from Bipolar disorder (hereinafter referred to as “BD”) or Borderline Personality Disorder (hereinafter referred to as “BPD”). To obtain these users we randomly sampled Twitter IDs. Thereafter we proceeded to download the tweets from the selected IDs. After the users have been identified we manually label them into one of two categories: 1) Patient: a person who is suffering from a mental disorder 2) Not-related: any user who we don't consider to be a patient. Lastly after having obtained the final list of patients we retrieve their tweets. These steps are applied for the collection of both BPD and BD patient datasets.,to train our model we require information from two different type of user patient and nonpatients therefore we employed a combined manual effort and keyword matching data collection approach to efficiently collect data for these user for the collection of patient we manually collect the community portal relevant to both mental disorder from these portal follower list we select the selfreported user who explicitly state in their profile description that they suffer from a mental illness ie for a given user we are checking if hisher profile contains any keyword related to a target disorder eg borderline bpd bipolar nonpatients are referred to a random active twitter user who are not explicitly stating that they are suffering from bipolar disorder hereinafter referred to a bd or borderline personality disorder hereinafter referred to a bpd to obtain these user we randomly sampled twitter id thereafter we proceeded to download the tweet from the selected id after the user have been identified we manually label them into one of two category patient a person who is suffering from a mental disorder notrelated any user who we dont consider to be a patient lastly after having obtained the final list of patient we retrieve their tweet these step are applied for the collection of both bpd and bd patient datasets,"['train', 'model', 'require', 'two', 'different', 'type', 'patient', 'nonpatients', 'therefore', 'employed', 'combined', 'manual', 'effort', 'keyword', 'matching', 'collection', 'approach', 'efficiently', 'collect', 'collection', 'patient', 'manually', 'collect', 'portal', 'relevant', 'portal', 'follower', 'list', 'select', 'selfreported', 'explicitly', 'state', 'profile', 'description', 'suffer', 'illness', 'ie', 'given', 'checking', 'hisher', 'profile', 'contains', 'keyword', 'related', 'target', 'eg', 'borderline', 'bpd', 'bipolar', 'nonpatients', 'referred', 'random', 'active', 'explicitly', 'stating', 'suffering', 'bipolar', 'hereinafter', 'referred', 'bd', 'borderline', 'personality', 'hereinafter', 'referred', 'bpd', 'obtain', 'randomly', 'sampled', 'id', 'thereafter', 'proceeded', 'download', 'selected', 'id', 'identified', 'manually', 'label', 'one', 'two', 'category', 'patient', 'person', 'suffering', 'notrelated', 'dont', 'consider', 'patient', 'lastly', 'obtained', 'final', 'list', 'patient', 'retrieve', 'step', 'applied', 'collection', 'bpd', 'bd', 'patient', 'datasets']","['train model', 'model require', 'require two', 'two different', 'different type', 'type patient', 'patient nonpatients', 'nonpatients therefore', 'therefore employed', 'employed combined', 'combined manual', 'manual effort', 'effort keyword', 'keyword matching', 'matching collection', 'collection approach', 'approach efficiently', 'efficiently collect', 'collect collection', 'collection patient', 'patient manually', 'manually collect', 'collect portal', 'portal relevant', 'relevant portal', 'portal follower', 'follower list', 'list select', 'select selfreported', 'selfreported explicitly', 'explicitly state', 'state profile', 'profile description', 'description suffer', 'suffer illness', 'illness ie', 'ie given', 'given checking', 'checking hisher', 'hisher profile', 'profile contains', 'contains keyword', 'keyword related', 'related target', 'target eg', 'eg borderline', 'borderline bpd', 'bpd bipolar', 'bipolar nonpatients', 'nonpatients referred', 'referred random', 'random active', 'active explicitly', 'explicitly stating', 'stating suffering', 'suffering bipolar', 'bipolar hereinafter', 'hereinafter referred', 'referred bd', 'bd borderline', 'borderline personality', 'personality hereinafter', 'hereinafter referred', 'referred bpd', 'bpd obtain', 'obtain randomly', 'randomly sampled', 'sampled id', 'id thereafter', 'thereafter proceeded', 'proceeded download', 'download selected', 'selected id', 'id identified', 'identified manually', 'manually label', 'label one', 'one two', 'two category', 'category patient', 'patient person', 'person suffering', 'suffering notrelated', 'notrelated dont', 'dont consider', 'consider patient', 'patient lastly', 'lastly obtained', 'obtained final', 'final list', 'list patient', 'patient retrieve', 'retrieve step', 'step applied', 'applied collection', 'collection bpd', 'bpd bd', 'bd patient', 'patient datasets']","['train model require', 'model require two', 'require two different', 'two different type', 'different type patient', 'type patient nonpatients', 'patient nonpatients therefore', 'nonpatients therefore employed', 'therefore employed combined', 'employed combined manual', 'combined manual effort', 'manual effort keyword', 'effort keyword matching', 'keyword matching collection', 'matching collection approach', 'collection approach efficiently', 'approach efficiently collect', 'efficiently collect collection', 'collect collection patient', 'collection patient manually', 'patient manually collect', 'manually collect portal', 'collect portal relevant', 'portal relevant portal', 'relevant portal follower', 'portal follower list', 'follower list select', 'list select selfreported', 'select selfreported explicitly', 'selfreported explicitly state', 'explicitly state profile', 'state profile description', 'profile description suffer', 'description suffer illness', 'suffer illness ie', 'illness ie given', 'ie given checking', 'given checking hisher', 'checking hisher profile', 'hisher profile contains', 'profile contains keyword', 'contains keyword related', 'keyword related target', 'related target eg', 'target eg borderline', 'eg borderline bpd', 'borderline bpd bipolar', 'bpd bipolar nonpatients', 'bipolar nonpatients referred', 'nonpatients referred random', 'referred random active', 'random active explicitly', 'active explicitly stating', 'explicitly stating suffering', 'stating suffering bipolar', 'suffering bipolar hereinafter', 'bipolar hereinafter referred', 'hereinafter referred bd', 'referred bd borderline', 'bd borderline personality', 'borderline personality hereinafter', 'personality hereinafter referred', 'hereinafter referred bpd', 'referred bpd obtain', 'bpd obtain randomly', 'obtain randomly sampled', 'randomly sampled id', 'sampled id thereafter', 'id thereafter proceeded', 'thereafter proceeded download', 'proceeded download selected', 'download selected id', 'selected id identified', 'id identified manually', 'identified manually label', 'manually label one', 'label one two', 'one two category', 'two category patient', 'category patient person', 'patient person suffering', 'person suffering notrelated', 'suffering notrelated dont', 'notrelated dont consider', 'dont consider patient', 'consider patient lastly', 'patient lastly obtained', 'lastly obtained final', 'obtained final list', 'final list patient', 'list patient retrieve', 'patient retrieve step', 'retrieve step applied', 'step applied collection', 'applied collection bpd', 'collection bpd bd', 'bpd bd patient', 'bd patient datasets']"
https://www.nature.com/articles/s41598-020-68764-y,0,This study was approved by the Ethical Committee and Institutional Review Board of the Department of Applied Artificial Intelligence Sungkyunkwan University (#H1AAI2020).We collected post data from the following six mental-health-related subreddits each of which is reported to be associated with a specific disorder10: r/depression r/Anxiety r/bipolar r/BPD r/schizophrenia and r/autism. In addition we further collected post data from the most popular health-related subreddit17 r/mentalhealth to analyze posts with general health information. From each subreddit we collected all the user IDs who had at least one post related to the mental health. Along with user IDs we also collected titles and posts using the PushshiftAPI18. Note that all the user information is anonymized hence no personally identifiable information was not included; we followed all the anonymization process guided by the Sungkyunkwan University Institutional Review Board (IRB). Overall the current study collected information from 248537 users who wrote 633385 posts in the seven subreddits from January 2017 to December 2018. Table 1 summarizes the information of collected data.,this study wa approved by the ethical committee and institutional review board of the department of applied artificial intelligence sungkyunkwan university haaiwe collected post data from the following six mentalhealthrelated subreddits each of which is reported to be associated with a specific disorder rdepression ranxiety rbipolar rbpd rschizophrenia and rautism in addition we further collected post data from the most popular healthrelated subreddit rmentalhealth to analyze post with general health information from each subreddit we collected all the user id who had at least one post related to the mental health along with user id we also collected title and post using the pushshiftapi note that all the user information is anonymized hence no personally identifiable information wa not included we followed all the anonymization process guided by the sungkyunkwan university institutional review board irb overall the current study collected information from user who wrote post in the seven subreddits from january to december table summarizes the information of collected data,"['study', 'approved', 'ethical', 'committee', 'institutional', 'review', 'board', 'department', 'applied', 'artificial', 'intelligence', 'sungkyunkwan', 'university', 'haaiwe', 'following', 'six', 'mentalhealthrelated', 'reported', 'associated', 'specific', 'rdepression', 'ranxiety', 'rbipolar', 'rbpd', 'rschizophrenia', 'rautism', 'addition', 'popular', 'healthrelated', 'subreddit', 'rmentalhealth', 'analyze', 'general', 'subreddit', 'id', 'least', 'one', 'related', 'along', 'id', 'also', 'title', 'pushshiftapi', 'note', 'anonymized', 'hence', 'personally', 'identifiable', 'included', 'followed', 'anonymization', 'process', 'guided', 'sungkyunkwan', 'university', 'institutional', 'review', 'board', 'irb', 'overall', 'current', 'study', 'wrote', 'seven', 'january', 'december', 'table', 'summarizes']","['study approved', 'approved ethical', 'ethical committee', 'committee institutional', 'institutional review', 'review board', 'board department', 'department applied', 'applied artificial', 'artificial intelligence', 'intelligence sungkyunkwan', 'sungkyunkwan university', 'university haaiwe', 'haaiwe following', 'following six', 'six mentalhealthrelated', 'mentalhealthrelated reported', 'reported associated', 'associated specific', 'specific rdepression', 'rdepression ranxiety', 'ranxiety rbipolar', 'rbipolar rbpd', 'rbpd rschizophrenia', 'rschizophrenia rautism', 'rautism addition', 'addition popular', 'popular healthrelated', 'healthrelated subreddit', 'subreddit rmentalhealth', 'rmentalhealth analyze', 'analyze general', 'general subreddit', 'subreddit id', 'id least', 'least one', 'one related', 'related along', 'along id', 'id also', 'also title', 'title pushshiftapi', 'pushshiftapi note', 'note anonymized', 'anonymized hence', 'hence personally', 'personally identifiable', 'identifiable included', 'included followed', 'followed anonymization', 'anonymization process', 'process guided', 'guided sungkyunkwan', 'sungkyunkwan university', 'university institutional', 'institutional review', 'review board', 'board irb', 'irb overall', 'overall current', 'current study', 'study wrote', 'wrote seven', 'seven january', 'january december', 'december table', 'table summarizes']","['study approved ethical', 'approved ethical committee', 'ethical committee institutional', 'committee institutional review', 'institutional review board', 'review board department', 'board department applied', 'department applied artificial', 'applied artificial intelligence', 'artificial intelligence sungkyunkwan', 'intelligence sungkyunkwan university', 'sungkyunkwan university haaiwe', 'university haaiwe following', 'haaiwe following six', 'following six mentalhealthrelated', 'six mentalhealthrelated reported', 'mentalhealthrelated reported associated', 'reported associated specific', 'associated specific rdepression', 'specific rdepression ranxiety', 'rdepression ranxiety rbipolar', 'ranxiety rbipolar rbpd', 'rbipolar rbpd rschizophrenia', 'rbpd rschizophrenia rautism', 'rschizophrenia rautism addition', 'rautism addition popular', 'addition popular healthrelated', 'popular healthrelated subreddit', 'healthrelated subreddit rmentalhealth', 'subreddit rmentalhealth analyze', 'rmentalhealth analyze general', 'analyze general subreddit', 'general subreddit id', 'subreddit id least', 'id least one', 'least one related', 'one related along', 'related along id', 'along id also', 'id also title', 'also title pushshiftapi', 'title pushshiftapi note', 'pushshiftapi note anonymized', 'note anonymized hence', 'anonymized hence personally', 'hence personally identifiable', 'personally identifiable included', 'identifiable included followed', 'included followed anonymization', 'followed anonymization process', 'anonymization process guided', 'process guided sungkyunkwan', 'guided sungkyunkwan university', 'sungkyunkwan university institutional', 'university institutional review', 'institutional review board', 'review board irb', 'board irb overall', 'irb overall current', 'overall current study', 'current study wrote', 'study wrote seven', 'wrote seven january', 'seven january december', 'january december table', 'december table summarizes']"
https://aclanthology.org/W19-3013.pdf,1,The majority of social media analysis approaches try to extract signals from individual posts and thus do not need to record any personal information. However as we start moving towards userlevel analyses we are collecting and storing complete records of social media users communications. Even though this information is publicly available people might not be consciously aware of the implications of sharing all their data and certainly have not given explicit consent for their data to be analyzed in aggregate. This is even more pertinent for analyses involving sensitive information (e.g. health related issues). As it has been demonstrated by the recent incidents involving companies inadvertently sharing or failing to protect users personal data there is a serious danger of abuse and exploitation for systems that collect and store large amounts of personal data. Even though this is in large part an ethical question there are technical solutions that can be used to partially address this issue. One is to use anonymization techniques to obfuscate any details that allow third parties (even analysts) to identify the individuals that are involved in the study. Another is to store only abstract representations — which can still be updated and consumed by predictive models —  and discard the actual content. In regards to consent there are initiatives to support voluntary data donation for research purposes e.g. the Our Data Helps program6 .,the majority of social medium analysis approach try to extract signal from individual post and thus do not need to record any personal information however a we start moving towards userlevel analysis we are collecting and storing complete record of social medium user communication even though this information is publicly available people might not be consciously aware of the implication of sharing all their data and certainly have not given explicit consent for their data to be analyzed in aggregate this is even more pertinent for analysis involving sensitive information eg health related issue a it ha been demonstrated by the recent incident involving company inadvertently sharing or failing to protect user personal data there is a serious danger of abuse and exploitation for system that collect and store large amount of personal data even though this is in large part an ethical question there are technical solution that can be used to partially address this issue one is to use anonymization technique to obfuscate any detail that allow third party even analyst to identify the individual that are involved in the study another is to store only abstract representation which can still be updated and consumed by predictive model and discard the actual content in regard to consent there are initiative to support voluntary data donation for research purpose eg the our data help program,"['majority', 'medium', 'analysis', 'approach', 'try', 'extract', 'signal', 'individual', 'thus', 'need', 'record', 'personal', 'however', 'start', 'moving', 'towards', 'userlevel', 'analysis', 'collecting', 'storing', 'complete', 'record', 'medium', 'communication', 'even', 'though', 'publicly', 'available', 'people', 'might', 'consciously', 'aware', 'implication', 'sharing', 'certainly', 'given', 'explicit', 'consent', 'analyzed', 'aggregate', 'even', 'pertinent', 'analysis', 'involving', 'sensitive', 'eg', 'related', 'issue', 'ha', 'demonstrated', 'recent', 'incident', 'involving', 'company', 'inadvertently', 'sharing', 'failing', 'protect', 'personal', 'serious', 'danger', 'abuse', 'exploitation', 'system', 'collect', 'store', 'large', 'amount', 'personal', 'even', 'though', 'large', 'part', 'ethical', 'question', 'technical', 'solution', 'partially', 'address', 'issue', 'one', 'use', 'anonymization', 'technique', 'obfuscate', 'detail', 'allow', 'third', 'party', 'even', 'analyst', 'identify', 'individual', 'involved', 'study', 'another', 'store', 'abstract', 'representation', 'still', 'updated', 'consumed', 'predictive', 'model', 'discard', 'actual', 'content', 'regard', 'consent', 'initiative', 'support', 'voluntary', 'donation', 'research', 'purpose', 'eg', 'help', 'program']","['majority medium', 'medium analysis', 'analysis approach', 'approach try', 'try extract', 'extract signal', 'signal individual', 'individual thus', 'thus need', 'need record', 'record personal', 'personal however', 'however start', 'start moving', 'moving towards', 'towards userlevel', 'userlevel analysis', 'analysis collecting', 'collecting storing', 'storing complete', 'complete record', 'record medium', 'medium communication', 'communication even', 'even though', 'though publicly', 'publicly available', 'available people', 'people might', 'might consciously', 'consciously aware', 'aware implication', 'implication sharing', 'sharing certainly', 'certainly given', 'given explicit', 'explicit consent', 'consent analyzed', 'analyzed aggregate', 'aggregate even', 'even pertinent', 'pertinent analysis', 'analysis involving', 'involving sensitive', 'sensitive eg', 'eg related', 'related issue', 'issue ha', 'ha demonstrated', 'demonstrated recent', 'recent incident', 'incident involving', 'involving company', 'company inadvertently', 'inadvertently sharing', 'sharing failing', 'failing protect', 'protect personal', 'personal serious', 'serious danger', 'danger abuse', 'abuse exploitation', 'exploitation system', 'system collect', 'collect store', 'store large', 'large amount', 'amount personal', 'personal even', 'even though', 'though large', 'large part', 'part ethical', 'ethical question', 'question technical', 'technical solution', 'solution partially', 'partially address', 'address issue', 'issue one', 'one use', 'use anonymization', 'anonymization technique', 'technique obfuscate', 'obfuscate detail', 'detail allow', 'allow third', 'third party', 'party even', 'even analyst', 'analyst identify', 'identify individual', 'individual involved', 'involved study', 'study another', 'another store', 'store abstract', 'abstract representation', 'representation still', 'still updated', 'updated consumed', 'consumed predictive', 'predictive model', 'model discard', 'discard actual', 'actual content', 'content regard', 'regard consent', 'consent initiative', 'initiative support', 'support voluntary', 'voluntary donation', 'donation research', 'research purpose', 'purpose eg', 'eg help', 'help program']","['majority medium analysis', 'medium analysis approach', 'analysis approach try', 'approach try extract', 'try extract signal', 'extract signal individual', 'signal individual thus', 'individual thus need', 'thus need record', 'need record personal', 'record personal however', 'personal however start', 'however start moving', 'start moving towards', 'moving towards userlevel', 'towards userlevel analysis', 'userlevel analysis collecting', 'analysis collecting storing', 'collecting storing complete', 'storing complete record', 'complete record medium', 'record medium communication', 'medium communication even', 'communication even though', 'even though publicly', 'though publicly available', 'publicly available people', 'available people might', 'people might consciously', 'might consciously aware', 'consciously aware implication', 'aware implication sharing', 'implication sharing certainly', 'sharing certainly given', 'certainly given explicit', 'given explicit consent', 'explicit consent analyzed', 'consent analyzed aggregate', 'analyzed aggregate even', 'aggregate even pertinent', 'even pertinent analysis', 'pertinent analysis involving', 'analysis involving sensitive', 'involving sensitive eg', 'sensitive eg related', 'eg related issue', 'related issue ha', 'issue ha demonstrated', 'ha demonstrated recent', 'demonstrated recent incident', 'recent incident involving', 'incident involving company', 'involving company inadvertently', 'company inadvertently sharing', 'inadvertently sharing failing', 'sharing failing protect', 'failing protect personal', 'protect personal serious', 'personal serious danger', 'serious danger abuse', 'danger abuse exploitation', 'abuse exploitation system', 'exploitation system collect', 'system collect store', 'collect store large', 'store large amount', 'large amount personal', 'amount personal even', 'personal even though', 'even though large', 'though large part', 'large part ethical', 'part ethical question', 'ethical question technical', 'question technical solution', 'technical solution partially', 'solution partially address', 'partially address issue', 'address issue one', 'issue one use', 'one use anonymization', 'use anonymization technique', 'anonymization technique obfuscate', 'technique obfuscate detail', 'obfuscate detail allow', 'detail allow third', 'allow third party', 'third party even', 'party even analyst', 'even analyst identify', 'analyst identify individual', 'identify individual involved', 'individual involved study', 'involved study another', 'study another store', 'another store abstract', 'store abstract representation', 'abstract representation still', 'representation still updated', 'still updated consumed', 'updated consumed predictive', 'consumed predictive model', 'predictive model discard', 'model discard actual', 'discard actual content', 'actual content regard', 'content regard consent', 'regard consent initiative', 'consent initiative support', 'initiative support voluntary', 'support voluntary donation', 'voluntary donation research', 'donation research purpose', 'research purpose eg', 'purpose eg help', 'eg help program']"
https://link.springer.com/chapter/10.1007/978-3-319-67186-4_6,0,We analyze two datasets: (1) user communities on Reddit and (2) journals from a mental health journalling mobile app. We omit the name of the app for privacy and we refer to it as the “journalling app”. Reddit is a social media platform that was originally used for sharing and rating content such as news documentaries and music. Users post in and subscribe to self-organized communities known as subreddits; subscribing to a subreddit allows a user to view all posts from that subreddit. An advantage of analyzing Reddit data is that the subreddits are labelled according to their topics. Utilizing curated lists from volunteer Reddit users we crawled all subreddits related to mental health as well as all subreddits linked by these communities. The second dataset consists of anonymized journal posts from a mobile app designed to help people track their moods and share them anonymously if they desire. For each journal post the app requires the user to label the journal post with at least one mood selected from a pre-populated list including “happy” “sad” etc. We obtained all journals and the associated moods written between January 2016 and January 2017. This amounts to over 1.2 million journals written by approximately 75000 users. Figure 1 plots the number of journals posted over time. Most of the journals were written in the first half of 2016 although we inspected topic distributions per month and did not find seasonal effects. Towards the beginning of 2016 many new users registered on the app and eventually stopped using it. Like weight-loss and productivity apps we believe this influx is tied to users looking to improve their habits as a New Year’s resolution. Each journal can be set to be private or public (visible to all other users of the app). Roughly one third of all journals are public. Figure 2 plots the number of users on the y-axis versus the percentage of journals they posted publicly. Most users are either mostly private or mostly public. Most journals are relatively short just like Twitter posts that are at most 140 characters. The average length of a journal with text in it is 128 characters; there are roughly 100000 journal that have no text only a mood label. We observed that private users tend to write journals that are slightly but statistically significantly longer than those written by public users by approximately 10 characters. Figure 3 shows the distribution of journal lengths where the spikes correspond to 0 length (mood only) 200 characters (the default limit set by the app) and 300 characters (set as the maximum for visualization purposes). Users of the app can optionally enter their location age and gender. While most users did not enter this information we found that those who revealed their location are mostly from North America those who revealed their gender are predominantly female and those who revealed their age have an average age of 25.,we analyze two datasets user community on reddit and journal from a mental health journalling mobile app we omit the name of the app for privacy and we refer to it a the journalling app reddit is a social medium platform that wa originally used for sharing and rating content such a news documentary and music user post in and subscribe to selforganized community known a subreddits subscribing to a subreddit allows a user to view all post from that subreddit an advantage of analyzing reddit data is that the subreddits are labelled according to their topic utilizing curated list from volunteer reddit user we crawled all subreddits related to mental health a well a all subreddits linked by these community the second dataset consists of anonymized journal post from a mobile app designed to help people track their mood and share them anonymously if they desire for each journal post the app requires the user to label the journal post with at least one mood selected from a prepopulated list including happy sad etc we obtained all journal and the associated mood written between january and january this amount to over million journal written by approximately user figure plot the number of journal posted over time most of the journal were written in the first half of although we inspected topic distribution per month and did not find seasonal effect towards the beginning of many new user registered on the app and eventually stopped using it like weightloss and productivity apps we believe this influx is tied to user looking to improve their habit a a new year resolution each journal can be set to be private or public visible to all other user of the app roughly one third of all journal are public figure plot the number of user on the yaxis versus the percentage of journal they posted publicly most user are either mostly private or mostly public most journal are relatively short just like twitter post that are at most character the average length of a journal with text in it is character there are roughly journal that have no text only a mood label we observed that private user tend to write journal that are slightly but statistically significantly longer than those written by public user by approximately character figure show the distribution of journal length where the spike correspond to length mood only character the default limit set by the app and character set a the maximum for visualization purpose user of the app can optionally enter their location age and gender while most user did not enter this information we found that those who revealed their location are mostly from north america those who revealed their gender are predominantly female and those who revealed their age have an average age of,"['analyze', 'two', 'datasets', 'reddit', 'journalling', 'mobile', 'app', 'omit', 'name', 'app', 'privacy', 'refer', 'journalling', 'app', 'reddit', 'medium', 'platform', 'originally', 'sharing', 'rating', 'content', 'news', 'documentary', 'music', 'subscribe', 'selforganized', 'known', 'subscribing', 'subreddit', 'allows', 'view', 'subreddit', 'advantage', 'analyzing', 'reddit', 'labelled', 'according', 'topic', 'utilizing', 'curated', 'list', 'volunteer', 'reddit', 'crawled', 'related', 'well', 'linked', 'second', 'consists', 'anonymized', 'mobile', 'app', 'designed', 'help', 'people', 'track', 'mood', 'share', 'anonymously', 'desire', 'app', 'requires', 'label', 'least', 'one', 'mood', 'selected', 'prepopulated', 'list', 'including', 'happy', 'sad', 'etc', 'obtained', 'associated', 'mood', 'written', 'january', 'january', 'amount', 'million', 'written', 'approximately', 'figure', 'plot', 'number', 'posted', 'written', 'first', 'half', 'although', 'inspected', 'topic', 'distribution', 'per', 'month', 'find', 'seasonal', 'effect', 'towards', 'beginning', 'many', 'new', 'registered', 'app', 'eventually', 'stopped', 'like', 'weightloss', 'productivity', 'apps', 'believe', 'influx', 'tied', 'looking', 'improve', 'habit', 'new', 'year', 'resolution', 'private', 'public', 'visible', 'app', 'roughly', 'one', 'third', 'public', 'figure', 'plot', 'number', 'yaxis', 'versus', 'percentage', 'posted', 'publicly', 'either', 'mostly', 'private', 'mostly', 'public', 'relatively', 'short', 'like', 'character', 'average', 'length', 'text', 'character', 'roughly', 'text', 'mood', 'label', 'observed', 'private', 'tend', 'write', 'slightly', 'statistically', 'significantly', 'longer', 'written', 'public', 'approximately', 'character', 'figure', 'show', 'distribution', 'length', 'spike', 'correspond', 'length', 'mood', 'character', 'default', 'limit', 'app', 'character', 'maximum', 'visualization', 'purpose', 'app', 'optionally', 'enter', 'location', 'age', 'gender', 'enter', 'found', 'revealed', 'location', 'mostly', 'north', 'america', 'revealed', 'gender', 'predominantly', 'female', 'revealed', 'age', 'average', 'age']","['analyze two', 'two datasets', 'datasets reddit', 'reddit journalling', 'journalling mobile', 'mobile app', 'app omit', 'omit name', 'name app', 'app privacy', 'privacy refer', 'refer journalling', 'journalling app', 'app reddit', 'reddit medium', 'medium platform', 'platform originally', 'originally sharing', 'sharing rating', 'rating content', 'content news', 'news documentary', 'documentary music', 'music subscribe', 'subscribe selforganized', 'selforganized known', 'known subscribing', 'subscribing subreddit', 'subreddit allows', 'allows view', 'view subreddit', 'subreddit advantage', 'advantage analyzing', 'analyzing reddit', 'reddit labelled', 'labelled according', 'according topic', 'topic utilizing', 'utilizing curated', 'curated list', 'list volunteer', 'volunteer reddit', 'reddit crawled', 'crawled related', 'related well', 'well linked', 'linked second', 'second consists', 'consists anonymized', 'anonymized mobile', 'mobile app', 'app designed', 'designed help', 'help people', 'people track', 'track mood', 'mood share', 'share anonymously', 'anonymously desire', 'desire app', 'app requires', 'requires label', 'label least', 'least one', 'one mood', 'mood selected', 'selected prepopulated', 'prepopulated list', 'list including', 'including happy', 'happy sad', 'sad etc', 'etc obtained', 'obtained associated', 'associated mood', 'mood written', 'written january', 'january january', 'january amount', 'amount million', 'million written', 'written approximately', 'approximately figure', 'figure plot', 'plot number', 'number posted', 'posted written', 'written first', 'first half', 'half although', 'although inspected', 'inspected topic', 'topic distribution', 'distribution per', 'per month', 'month find', 'find seasonal', 'seasonal effect', 'effect towards', 'towards beginning', 'beginning many', 'many new', 'new registered', 'registered app', 'app eventually', 'eventually stopped', 'stopped like', 'like weightloss', 'weightloss productivity', 'productivity apps', 'apps believe', 'believe influx', 'influx tied', 'tied looking', 'looking improve', 'improve habit', 'habit new', 'new year', 'year resolution', 'resolution private', 'private public', 'public visible', 'visible app', 'app roughly', 'roughly one', 'one third', 'third public', 'public figure', 'figure plot', 'plot number', 'number yaxis', 'yaxis versus', 'versus percentage', 'percentage posted', 'posted publicly', 'publicly either', 'either mostly', 'mostly private', 'private mostly', 'mostly public', 'public relatively', 'relatively short', 'short like', 'like character', 'character average', 'average length', 'length text', 'text character', 'character roughly', 'roughly text', 'text mood', 'mood label', 'label observed', 'observed private', 'private tend', 'tend write', 'write slightly', 'slightly statistically', 'statistically significantly', 'significantly longer', 'longer written', 'written public', 'public approximately', 'approximately character', 'character figure', 'figure show', 'show distribution', 'distribution length', 'length spike', 'spike correspond', 'correspond length', 'length mood', 'mood character', 'character default', 'default limit', 'limit app', 'app character', 'character maximum', 'maximum visualization', 'visualization purpose', 'purpose app', 'app optionally', 'optionally enter', 'enter location', 'location age', 'age gender', 'gender enter', 'enter found', 'found revealed', 'revealed location', 'location mostly', 'mostly north', 'north america', 'america revealed', 'revealed gender', 'gender predominantly', 'predominantly female', 'female revealed', 'revealed age', 'age average', 'average age']","['analyze two datasets', 'two datasets reddit', 'datasets reddit journalling', 'reddit journalling mobile', 'journalling mobile app', 'mobile app omit', 'app omit name', 'omit name app', 'name app privacy', 'app privacy refer', 'privacy refer journalling', 'refer journalling app', 'journalling app reddit', 'app reddit medium', 'reddit medium platform', 'medium platform originally', 'platform originally sharing', 'originally sharing rating', 'sharing rating content', 'rating content news', 'content news documentary', 'news documentary music', 'documentary music subscribe', 'music subscribe selforganized', 'subscribe selforganized known', 'selforganized known subscribing', 'known subscribing subreddit', 'subscribing subreddit allows', 'subreddit allows view', 'allows view subreddit', 'view subreddit advantage', 'subreddit advantage analyzing', 'advantage analyzing reddit', 'analyzing reddit labelled', 'reddit labelled according', 'labelled according topic', 'according topic utilizing', 'topic utilizing curated', 'utilizing curated list', 'curated list volunteer', 'list volunteer reddit', 'volunteer reddit crawled', 'reddit crawled related', 'crawled related well', 'related well linked', 'well linked second', 'linked second consists', 'second consists anonymized', 'consists anonymized mobile', 'anonymized mobile app', 'mobile app designed', 'app designed help', 'designed help people', 'help people track', 'people track mood', 'track mood share', 'mood share anonymously', 'share anonymously desire', 'anonymously desire app', 'desire app requires', 'app requires label', 'requires label least', 'label least one', 'least one mood', 'one mood selected', 'mood selected prepopulated', 'selected prepopulated list', 'prepopulated list including', 'list including happy', 'including happy sad', 'happy sad etc', 'sad etc obtained', 'etc obtained associated', 'obtained associated mood', 'associated mood written', 'mood written january', 'written january january', 'january january amount', 'january amount million', 'amount million written', 'million written approximately', 'written approximately figure', 'approximately figure plot', 'figure plot number', 'plot number posted', 'number posted written', 'posted written first', 'written first half', 'first half although', 'half although inspected', 'although inspected topic', 'inspected topic distribution', 'topic distribution per', 'distribution per month', 'per month find', 'month find seasonal', 'find seasonal effect', 'seasonal effect towards', 'effect towards beginning', 'towards beginning many', 'beginning many new', 'many new registered', 'new registered app', 'registered app eventually', 'app eventually stopped', 'eventually stopped like', 'stopped like weightloss', 'like weightloss productivity', 'weightloss productivity apps', 'productivity apps believe', 'apps believe influx', 'believe influx tied', 'influx tied looking', 'tied looking improve', 'looking improve habit', 'improve habit new', 'habit new year', 'new year resolution', 'year resolution private', 'resolution private public', 'private public visible', 'public visible app', 'visible app roughly', 'app roughly one', 'roughly one third', 'one third public', 'third public figure', 'public figure plot', 'figure plot number', 'plot number yaxis', 'number yaxis versus', 'yaxis versus percentage', 'versus percentage posted', 'percentage posted publicly', 'posted publicly either', 'publicly either mostly', 'either mostly private', 'mostly private mostly', 'private mostly public', 'mostly public relatively', 'public relatively short', 'relatively short like', 'short like character', 'like character average', 'character average length', 'average length text', 'length text character', 'text character roughly', 'character roughly text', 'roughly text mood', 'text mood label', 'mood label observed', 'label observed private', 'observed private tend', 'private tend write', 'tend write slightly', 'write slightly statistically', 'slightly statistically significantly', 'statistically significantly longer', 'significantly longer written', 'longer written public', 'written public approximately', 'public approximately character', 'approximately character figure', 'character figure show', 'figure show distribution', 'show distribution length', 'distribution length spike', 'length spike correspond', 'spike correspond length', 'correspond length mood', 'length mood character', 'mood character default', 'character default limit', 'default limit app', 'limit app character', 'app character maximum', 'character maximum visualization', 'maximum visualization purpose', 'visualization purpose app', 'purpose app optionally', 'app optionally enter', 'optionally enter location', 'enter location age', 'location age gender', 'age gender enter', 'gender enter found', 'enter found revealed', 'found revealed location', 'revealed location mostly', 'location mostly north', 'mostly north america', 'north america revealed', 'america revealed gender', 'revealed gender predominantly', 'gender predominantly female', 'predominantly female revealed', 'female revealed age', 'revealed age average', 'age average age']"
https://dl.acm.org/doi/abs/10.1145/2556288.2557214,0,To gain qualitative insight into people’s health information seeking and sharing practices we conducted an online survey during June 2013 using a recruiting service (Cint) that offers “Census representative sampling” in terms of gender and age throughout regions of the U.S. Respondents were paid approximately 4 USD to complete the survey and were required to have a Twitter account to qualify to participate. The survey comprised 37 questions and took approximately 10 minutes to complete. Participants were asked if they had ever sought health information on a search engine such as Google or Bing or on Twitter and whether they had ever shared health information on Twitter. If they answered affirmatively they were asked to describe the most recent occasion on which they did so including the health condition that motivated them to search or share and their objective in performing the activity. The survey included questions about how often participants used search engines and Twitter for various types of information seeking or sharing views about risks associated with each platform and basic demographics. In total 237 respondents completed the survey. After discarding low quality responses (as determined by nonsensical or sarcastic responses to open questions) 210 valid survey responses were analyzed. Of these respondents 53% were female they resided in 38 U.S. states and the District of Columbia and 43% had a college degree or higher. Ages ranged from 18 to 70 years (median = 35 years). Respondents reported using search engines frequently (76% at least once per day with only 7% using them less than once per week). 71% of respondents had public Twitter accounts while the remaining 29% had “protected” accounts (i.e. only approved followers could view their postings).,to gain qualitative insight into people health information seeking and sharing practice we conducted an online survey during june using a recruiting service cint that offer census representative sampling in term of gender and age throughout region of the u respondent were paid approximately usd to complete the survey and were required to have a twitter account to qualify to participate the survey comprised question and took approximately minute to complete participant were asked if they had ever sought health information on a search engine such a google or bing or on twitter and whether they had ever shared health information on twitter if they answered affirmatively they were asked to describe the most recent occasion on which they did so including the health condition that motivated them to search or share and their objective in performing the activity the survey included question about how often participant used search engine and twitter for various type of information seeking or sharing view about risk associated with each platform and basic demographic in total respondent completed the survey after discarding low quality response a determined by nonsensical or sarcastic response to open question valid survey response were analyzed of these respondent were female they resided in u state and the district of columbia and had a college degree or higher age ranged from to year median year respondent reported using search engine frequently at least once per day with only using them le than once per week of respondent had public twitter account while the remaining had protected account ie only approved follower could view their posting,"['gain', 'qualitative', 'insight', 'people', 'seeking', 'sharing', 'practice', 'conducted', 'online', 'survey', 'june', 'recruiting', 'service', 'cint', 'offer', 'census', 'representative', 'sampling', 'term', 'gender', 'age', 'throughout', 'region', 'u', 'respondent', 'paid', 'approximately', 'usd', 'complete', 'survey', 'required', 'account', 'qualify', 'participate', 'survey', 'comprised', 'question', 'took', 'approximately', 'minute', 'complete', 'asked', 'ever', 'sought', 'search', 'engine', 'google', 'bing', 'whether', 'ever', 'shared', 'answered', 'affirmatively', 'asked', 'describe', 'recent', 'occasion', 'including', 'motivated', 'search', 'share', 'objective', 'performing', 'activity', 'survey', 'included', 'question', 'often', 'search', 'engine', 'various', 'type', 'seeking', 'sharing', 'view', 'risk', 'associated', 'platform', 'basic', 'demographic', 'total', 'respondent', 'completed', 'survey', 'discarding', 'low', 'quality', 'response', 'determined', 'nonsensical', 'sarcastic', 'response', 'open', 'question', 'valid', 'survey', 'response', 'analyzed', 'respondent', 'female', 'resided', 'u', 'state', 'district', 'columbia', 'college', 'degree', 'higher', 'age', 'ranged', 'year', 'median', 'year', 'respondent', 'reported', 'search', 'engine', 'frequently', 'least', 'per', 'day', 'le', 'per', 'week', 'respondent', 'public', 'account', 'remaining', 'protected', 'account', 'ie', 'approved', 'follower', 'could', 'view', 'posting']","['gain qualitative', 'qualitative insight', 'insight people', 'people seeking', 'seeking sharing', 'sharing practice', 'practice conducted', 'conducted online', 'online survey', 'survey june', 'june recruiting', 'recruiting service', 'service cint', 'cint offer', 'offer census', 'census representative', 'representative sampling', 'sampling term', 'term gender', 'gender age', 'age throughout', 'throughout region', 'region u', 'u respondent', 'respondent paid', 'paid approximately', 'approximately usd', 'usd complete', 'complete survey', 'survey required', 'required account', 'account qualify', 'qualify participate', 'participate survey', 'survey comprised', 'comprised question', 'question took', 'took approximately', 'approximately minute', 'minute complete', 'complete asked', 'asked ever', 'ever sought', 'sought search', 'search engine', 'engine google', 'google bing', 'bing whether', 'whether ever', 'ever shared', 'shared answered', 'answered affirmatively', 'affirmatively asked', 'asked describe', 'describe recent', 'recent occasion', 'occasion including', 'including motivated', 'motivated search', 'search share', 'share objective', 'objective performing', 'performing activity', 'activity survey', 'survey included', 'included question', 'question often', 'often search', 'search engine', 'engine various', 'various type', 'type seeking', 'seeking sharing', 'sharing view', 'view risk', 'risk associated', 'associated platform', 'platform basic', 'basic demographic', 'demographic total', 'total respondent', 'respondent completed', 'completed survey', 'survey discarding', 'discarding low', 'low quality', 'quality response', 'response determined', 'determined nonsensical', 'nonsensical sarcastic', 'sarcastic response', 'response open', 'open question', 'question valid', 'valid survey', 'survey response', 'response analyzed', 'analyzed respondent', 'respondent female', 'female resided', 'resided u', 'u state', 'state district', 'district columbia', 'columbia college', 'college degree', 'degree higher', 'higher age', 'age ranged', 'ranged year', 'year median', 'median year', 'year respondent', 'respondent reported', 'reported search', 'search engine', 'engine frequently', 'frequently least', 'least per', 'per day', 'day le', 'le per', 'per week', 'week respondent', 'respondent public', 'public account', 'account remaining', 'remaining protected', 'protected account', 'account ie', 'ie approved', 'approved follower', 'follower could', 'could view', 'view posting']","['gain qualitative insight', 'qualitative insight people', 'insight people seeking', 'people seeking sharing', 'seeking sharing practice', 'sharing practice conducted', 'practice conducted online', 'conducted online survey', 'online survey june', 'survey june recruiting', 'june recruiting service', 'recruiting service cint', 'service cint offer', 'cint offer census', 'offer census representative', 'census representative sampling', 'representative sampling term', 'sampling term gender', 'term gender age', 'gender age throughout', 'age throughout region', 'throughout region u', 'region u respondent', 'u respondent paid', 'respondent paid approximately', 'paid approximately usd', 'approximately usd complete', 'usd complete survey', 'complete survey required', 'survey required account', 'required account qualify', 'account qualify participate', 'qualify participate survey', 'participate survey comprised', 'survey comprised question', 'comprised question took', 'question took approximately', 'took approximately minute', 'approximately minute complete', 'minute complete asked', 'complete asked ever', 'asked ever sought', 'ever sought search', 'sought search engine', 'search engine google', 'engine google bing', 'google bing whether', 'bing whether ever', 'whether ever shared', 'ever shared answered', 'shared answered affirmatively', 'answered affirmatively asked', 'affirmatively asked describe', 'asked describe recent', 'describe recent occasion', 'recent occasion including', 'occasion including motivated', 'including motivated search', 'motivated search share', 'search share objective', 'share objective performing', 'objective performing activity', 'performing activity survey', 'activity survey included', 'survey included question', 'included question often', 'question often search', 'often search engine', 'search engine various', 'engine various type', 'various type seeking', 'type seeking sharing', 'seeking sharing view', 'sharing view risk', 'view risk associated', 'risk associated platform', 'associated platform basic', 'platform basic demographic', 'basic demographic total', 'demographic total respondent', 'total respondent completed', 'respondent completed survey', 'completed survey discarding', 'survey discarding low', 'discarding low quality', 'low quality response', 'quality response determined', 'response determined nonsensical', 'determined nonsensical sarcastic', 'nonsensical sarcastic response', 'sarcastic response open', 'response open question', 'open question valid', 'question valid survey', 'valid survey response', 'survey response analyzed', 'response analyzed respondent', 'analyzed respondent female', 'respondent female resided', 'female resided u', 'resided u state', 'u state district', 'state district columbia', 'district columbia college', 'columbia college degree', 'college degree higher', 'degree higher age', 'higher age ranged', 'age ranged year', 'ranged year median', 'year median year', 'median year respondent', 'year respondent reported', 'respondent reported search', 'reported search engine', 'search engine frequently', 'engine frequently least', 'frequently least per', 'least per day', 'per day le', 'day le per', 'le per week', 'per week respondent', 'week respondent public', 'respondent public account', 'public account remaining', 'account remaining protected', 'remaining protected account', 'protected account ie', 'account ie approved', 'ie approved follower', 'approved follower could', 'follower could view', 'could view posting']"
https://www.aaai.org/ocs/index.php/ICWSM/ICWSM14/paper/viewPaper/8075,0,reddit is a social news website where registered users submit content in the form of links or text posts. Users also known as “redditors” can then vote each submission “up” or “down” to rank the post and determine its position or prominence on the site’s pages. These two attributes associated with a post are referred to as “upvotes” and “downvotes”. Redditors can also comment on posts and respond back in a conversation tree of comments. Content entries that is the posts are organized by areas of interest or sub-communities called “subreddits” such as politics programming or science. As of 2013 reddit’s official statistics included 56 billion page views 731 million unique visitors 40855032 posts and 404603286 comments (http://blog.reddit.com/2013/ 12/top-posts-of-2013-stats-and-snoo-years.html). We used of reddit’s official API (http://www.reddit.com/ dev /api) to collect posts comments and associated metadata from several mental health subreddits: specifically using a Python wrapper PRAW (https://praw.readthedocs.org/en/ latest/index.html). The subreddits we crawled were: alcoholism anxiety bipolarreddit depression mentalhealth MMFB (Make Me Feel Better) socialanxiety SuicideWatch. All of these subreddits host public content. In order to arrive at a comprehensive list of subreddits to focus on we utilized reddit’s native subreddit search feature (http://www.reddit.com/reddits) and searched for subreddits on “mental health”. Two researchers familiar with reddit employed an initial filtering step on the search results returned so that we focus on high precision subreddits discussing mental health concerns and issues. Thereafter we focused on a snowball approach in which starting with a few seed subreddits (mentalhealth depression) we compiled a second list of “related” or “similar” subreddits that are listed in the profile pages of the seed subreddits. Following a second filtering step we arrived at the list of subreddits listed above. For each of these subreddits we obtained daily crawls of their posts in the New category. Corresponding to each post we collected information on the title of the post the body or textual content id timestamp when the post was made author id and the number of upvotes and downvotes it obtained. Since posts gather comments over a period of time following the time of sharing we crawled all of the comments per post that were shared over a three day period after the post was made. Qualitative examinations of the subreddits of interest revealed that 90% or more of the comments to any post were typically made in a three day window following the time the post is made—hence the choice. The crawl of the subreddits used in this paper We present some descriptive statistics of our crawled data. Our dataset contained 20411 posts with at least one comment and 97661 comments in all with 27102 unique users who made posts comments or both. A set of 7823 users (28.79%) were found to write both at least one post and comment. CDF of the user distribution over posts and comments is given in Figure 1. The figure shows the expected heavy tail trend observed in several social phenomena. Also see Figure 2 for the distribution of comments over time following post share. It illustrates the quick responsivity culture in the communities we study (peak at 3 hours). Some of the additional statistics of our dataset are given in Table 1. Further example titles of a few,reddit is a social news website where registered user submit content in the form of link or text post user also known a redditors can then vote each submission up or down to rank the post and determine it position or prominence on the site page these two attribute associated with a post are referred to a upvotes and downvotes redditors can also comment on post and respond back in a conversation tree of comment content entry that is the post are organized by area of interest or subcommunities called subreddits such a politics programming or science a of reddits official statistic included billion page view million unique visitor post and comment httpblogredditcom toppostsofstatsandsnooyearshtml we used of reddits official api httpwwwredditcom dev api to collect post comment and associated metadata from several mental health subreddits specifically using a python wrapper praw httpsprawreadthedocsorgen latestindexhtml the subreddits we crawled were alcoholism anxiety bipolarreddit depression mentalhealth mmfb make me feel better socialanxiety suicidewatch all of these subreddits host public content in order to arrive at a comprehensive list of subreddits to focus on we utilized reddits native subreddit search feature httpwwwredditcomreddits and searched for subreddits on mental health two researcher familiar with reddit employed an initial filtering step on the search result returned so that we focus on high precision subreddits discussing mental health concern and issue thereafter we focused on a snowball approach in which starting with a few seed subreddits mentalhealth depression we compiled a second list of related or similar subreddits that are listed in the profile page of the seed subreddits following a second filtering step we arrived at the list of subreddits listed above for each of these subreddits we obtained daily crawl of their post in the new category corresponding to each post we collected information on the title of the post the body or textual content id timestamp when the post wa made author id and the number of upvotes and downvotes it obtained since post gather comment over a period of time following the time of sharing we crawled all of the comment per post that were shared over a three day period after the post wa made qualitative examination of the subreddits of interest revealed that or more of the comment to any post were typically made in a three day window following the time the post is madehence the choice the crawl of the subreddits used in this paper we present some descriptive statistic of our crawled data our dataset contained post with at least one comment and comment in all with unique user who made post comment or both a set of user were found to write both at least one post and comment cdf of the user distribution over post and comment is given in figure the figure show the expected heavy tail trend observed in several social phenomenon also see figure for the distribution of comment over time following post share it illustrates the quick responsivity culture in the community we study peak at hour some of the additional statistic of our dataset are given in table further example title of a few,"['reddit', 'news', 'website', 'registered', 'submit', 'content', 'form', 'link', 'text', 'also', 'known', 'redditors', 'vote', 'submission', 'rank', 'determine', 'position', 'prominence', 'site', 'page', 'two', 'attribute', 'associated', 'referred', 'upvotes', 'downvotes', 'redditors', 'also', 'respond', 'back', 'conversation', 'tree', 'content', 'entry', 'organized', 'area', 'interest', 'subcommunities', 'called', 'politics', 'programming', 'science', 'reddits', 'official', 'statistic', 'included', 'billion', 'page', 'view', 'million', 'unique', 'visitor', 'httpblogredditcom', 'toppostsofstatsandsnooyearshtml', 'reddits', 'official', 'api', 'httpwwwredditcom', 'dev', 'api', 'collect', 'associated', 'metadata', 'several', 'specifically', 'python', 'wrapper', 'praw', 'httpsprawreadthedocsorgen', 'latestindexhtml', 'crawled', 'alcoholism', 'anxiety', 'bipolarreddit', 'mentalhealth', 'mmfb', 'make', 'feel', 'better', 'socialanxiety', 'suicidewatch', 'host', 'public', 'content', 'order', 'arrive', 'comprehensive', 'list', 'focus', 'utilized', 'reddits', 'native', 'subreddit', 'search', 'feature', 'httpwwwredditcomreddits', 'searched', 'two', 'researcher', 'familiar', 'reddit', 'employed', 'initial', 'filtering', 'step', 'search', 'result', 'returned', 'focus', 'high', 'precision', 'discussing', 'concern', 'issue', 'thereafter', 'focused', 'snowball', 'approach', 'starting', 'seed', 'mentalhealth', 'compiled', 'second', 'list', 'related', 'similar', 'listed', 'profile', 'page', 'seed', 'following', 'second', 'filtering', 'step', 'arrived', 'list', 'listed', 'obtained', 'daily', 'crawl', 'new', 'category', 'corresponding', 'title', 'body', 'textual', 'content', 'id', 'timestamp', 'author', 'id', 'number', 'upvotes', 'downvotes', 'obtained', 'since', 'gather', 'period', 'following', 'sharing', 'crawled', 'per', 'shared', 'three', 'day', 'period', 'qualitative', 'examination', 'interest', 'revealed', 'typically', 'three', 'day', 'window', 'following', 'madehence', 'choice', 'crawl', 'paper', 'present', 'descriptive', 'statistic', 'crawled', 'contained', 'least', 'one', 'unique', 'found', 'write', 'least', 'one', 'cdf', 'distribution', 'given', 'figure', 'figure', 'show', 'expected', 'heavy', 'tail', 'trend', 'observed', 'several', 'phenomenon', 'also', 'see', 'figure', 'distribution', 'following', 'share', 'illustrates', 'quick', 'responsivity', 'culture', 'study', 'peak', 'hour', 'additional', 'statistic', 'given', 'table', 'example', 'title']","['reddit news', 'news website', 'website registered', 'registered submit', 'submit content', 'content form', 'form link', 'link text', 'text also', 'also known', 'known redditors', 'redditors vote', 'vote submission', 'submission rank', 'rank determine', 'determine position', 'position prominence', 'prominence site', 'site page', 'page two', 'two attribute', 'attribute associated', 'associated referred', 'referred upvotes', 'upvotes downvotes', 'downvotes redditors', 'redditors also', 'also respond', 'respond back', 'back conversation', 'conversation tree', 'tree content', 'content entry', 'entry organized', 'organized area', 'area interest', 'interest subcommunities', 'subcommunities called', 'called politics', 'politics programming', 'programming science', 'science reddits', 'reddits official', 'official statistic', 'statistic included', 'included billion', 'billion page', 'page view', 'view million', 'million unique', 'unique visitor', 'visitor httpblogredditcom', 'httpblogredditcom toppostsofstatsandsnooyearshtml', 'toppostsofstatsandsnooyearshtml reddits', 'reddits official', 'official api', 'api httpwwwredditcom', 'httpwwwredditcom dev', 'dev api', 'api collect', 'collect associated', 'associated metadata', 'metadata several', 'several specifically', 'specifically python', 'python wrapper', 'wrapper praw', 'praw httpsprawreadthedocsorgen', 'httpsprawreadthedocsorgen latestindexhtml', 'latestindexhtml crawled', 'crawled alcoholism', 'alcoholism anxiety', 'anxiety bipolarreddit', 'bipolarreddit mentalhealth', 'mentalhealth mmfb', 'mmfb make', 'make feel', 'feel better', 'better socialanxiety', 'socialanxiety suicidewatch', 'suicidewatch host', 'host public', 'public content', 'content order', 'order arrive', 'arrive comprehensive', 'comprehensive list', 'list focus', 'focus utilized', 'utilized reddits', 'reddits native', 'native subreddit', 'subreddit search', 'search feature', 'feature httpwwwredditcomreddits', 'httpwwwredditcomreddits searched', 'searched two', 'two researcher', 'researcher familiar', 'familiar reddit', 'reddit employed', 'employed initial', 'initial filtering', 'filtering step', 'step search', 'search result', 'result returned', 'returned focus', 'focus high', 'high precision', 'precision discussing', 'discussing concern', 'concern issue', 'issue thereafter', 'thereafter focused', 'focused snowball', 'snowball approach', 'approach starting', 'starting seed', 'seed mentalhealth', 'mentalhealth compiled', 'compiled second', 'second list', 'list related', 'related similar', 'similar listed', 'listed profile', 'profile page', 'page seed', 'seed following', 'following second', 'second filtering', 'filtering step', 'step arrived', 'arrived list', 'list listed', 'listed obtained', 'obtained daily', 'daily crawl', 'crawl new', 'new category', 'category corresponding', 'corresponding title', 'title body', 'body textual', 'textual content', 'content id', 'id timestamp', 'timestamp author', 'author id', 'id number', 'number upvotes', 'upvotes downvotes', 'downvotes obtained', 'obtained since', 'since gather', 'gather period', 'period following', 'following sharing', 'sharing crawled', 'crawled per', 'per shared', 'shared three', 'three day', 'day period', 'period qualitative', 'qualitative examination', 'examination interest', 'interest revealed', 'revealed typically', 'typically three', 'three day', 'day window', 'window following', 'following madehence', 'madehence choice', 'choice crawl', 'crawl paper', 'paper present', 'present descriptive', 'descriptive statistic', 'statistic crawled', 'crawled contained', 'contained least', 'least one', 'one unique', 'unique found', 'found write', 'write least', 'least one', 'one cdf', 'cdf distribution', 'distribution given', 'given figure', 'figure figure', 'figure show', 'show expected', 'expected heavy', 'heavy tail', 'tail trend', 'trend observed', 'observed several', 'several phenomenon', 'phenomenon also', 'also see', 'see figure', 'figure distribution', 'distribution following', 'following share', 'share illustrates', 'illustrates quick', 'quick responsivity', 'responsivity culture', 'culture study', 'study peak', 'peak hour', 'hour additional', 'additional statistic', 'statistic given', 'given table', 'table example', 'example title']","['reddit news website', 'news website registered', 'website registered submit', 'registered submit content', 'submit content form', 'content form link', 'form link text', 'link text also', 'text also known', 'also known redditors', 'known redditors vote', 'redditors vote submission', 'vote submission rank', 'submission rank determine', 'rank determine position', 'determine position prominence', 'position prominence site', 'prominence site page', 'site page two', 'page two attribute', 'two attribute associated', 'attribute associated referred', 'associated referred upvotes', 'referred upvotes downvotes', 'upvotes downvotes redditors', 'downvotes redditors also', 'redditors also respond', 'also respond back', 'respond back conversation', 'back conversation tree', 'conversation tree content', 'tree content entry', 'content entry organized', 'entry organized area', 'organized area interest', 'area interest subcommunities', 'interest subcommunities called', 'subcommunities called politics', 'called politics programming', 'politics programming science', 'programming science reddits', 'science reddits official', 'reddits official statistic', 'official statistic included', 'statistic included billion', 'included billion page', 'billion page view', 'page view million', 'view million unique', 'million unique visitor', 'unique visitor httpblogredditcom', 'visitor httpblogredditcom toppostsofstatsandsnooyearshtml', 'httpblogredditcom toppostsofstatsandsnooyearshtml reddits', 'toppostsofstatsandsnooyearshtml reddits official', 'reddits official api', 'official api httpwwwredditcom', 'api httpwwwredditcom dev', 'httpwwwredditcom dev api', 'dev api collect', 'api collect associated', 'collect associated metadata', 'associated metadata several', 'metadata several specifically', 'several specifically python', 'specifically python wrapper', 'python wrapper praw', 'wrapper praw httpsprawreadthedocsorgen', 'praw httpsprawreadthedocsorgen latestindexhtml', 'httpsprawreadthedocsorgen latestindexhtml crawled', 'latestindexhtml crawled alcoholism', 'crawled alcoholism anxiety', 'alcoholism anxiety bipolarreddit', 'anxiety bipolarreddit mentalhealth', 'bipolarreddit mentalhealth mmfb', 'mentalhealth mmfb make', 'mmfb make feel', 'make feel better', 'feel better socialanxiety', 'better socialanxiety suicidewatch', 'socialanxiety suicidewatch host', 'suicidewatch host public', 'host public content', 'public content order', 'content order arrive', 'order arrive comprehensive', 'arrive comprehensive list', 'comprehensive list focus', 'list focus utilized', 'focus utilized reddits', 'utilized reddits native', 'reddits native subreddit', 'native subreddit search', 'subreddit search feature', 'search feature httpwwwredditcomreddits', 'feature httpwwwredditcomreddits searched', 'httpwwwredditcomreddits searched two', 'searched two researcher', 'two researcher familiar', 'researcher familiar reddit', 'familiar reddit employed', 'reddit employed initial', 'employed initial filtering', 'initial filtering step', 'filtering step search', 'step search result', 'search result returned', 'result returned focus', 'returned focus high', 'focus high precision', 'high precision discussing', 'precision discussing concern', 'discussing concern issue', 'concern issue thereafter', 'issue thereafter focused', 'thereafter focused snowball', 'focused snowball approach', 'snowball approach starting', 'approach starting seed', 'starting seed mentalhealth', 'seed mentalhealth compiled', 'mentalhealth compiled second', 'compiled second list', 'second list related', 'list related similar', 'related similar listed', 'similar listed profile', 'listed profile page', 'profile page seed', 'page seed following', 'seed following second', 'following second filtering', 'second filtering step', 'filtering step arrived', 'step arrived list', 'arrived list listed', 'list listed obtained', 'listed obtained daily', 'obtained daily crawl', 'daily crawl new', 'crawl new category', 'new category corresponding', 'category corresponding title', 'corresponding title body', 'title body textual', 'body textual content', 'textual content id', 'content id timestamp', 'id timestamp author', 'timestamp author id', 'author id number', 'id number upvotes', 'number upvotes downvotes', 'upvotes downvotes obtained', 'downvotes obtained since', 'obtained since gather', 'since gather period', 'gather period following', 'period following sharing', 'following sharing crawled', 'sharing crawled per', 'crawled per shared', 'per shared three', 'shared three day', 'three day period', 'day period qualitative', 'period qualitative examination', 'qualitative examination interest', 'examination interest revealed', 'interest revealed typically', 'revealed typically three', 'typically three day', 'three day window', 'day window following', 'window following madehence', 'following madehence choice', 'madehence choice crawl', 'choice crawl paper', 'crawl paper present', 'paper present descriptive', 'present descriptive statistic', 'descriptive statistic crawled', 'statistic crawled contained', 'crawled contained least', 'contained least one', 'least one unique', 'one unique found', 'unique found write', 'found write least', 'write least one', 'least one cdf', 'one cdf distribution', 'cdf distribution given', 'distribution given figure', 'given figure figure', 'figure figure show', 'figure show expected', 'show expected heavy', 'expected heavy tail', 'heavy tail trend', 'tail trend observed', 'trend observed several', 'observed several phenomenon', 'several phenomenon also', 'phenomenon also see', 'also see figure', 'see figure distribution', 'figure distribution following', 'distribution following share', 'following share illustrates', 'share illustrates quick', 'illustrates quick responsivity', 'quick responsivity culture', 'responsivity culture study', 'culture study peak', 'study peak hour', 'peak hour additional', 'hour additional statistic', 'additional statistic given', 'statistic given table', 'given table example', 'table example title']"
https://dl.acm.org/doi/abs/10.1145/3025453.3025932,0,We utilized Instagram’s official API1 to obtain the dataset used in this paper. Each post in this dataset is public and contains post-related information such as the image caption likes comments hashtags filter and geolocation if tagged. Referring to prior literature [10] we adopted an iterative approach to first identify a set of appropriate distinguishing hashtags around different prominent mental illnesses prevalent in social media. With the seed tags we performed an initial data collection of 1.5 million posts shared on Instagram between Dec 2010 and Nov 2015. Then by leveraging an association rule mining approach we compiled the top k (k = 39 frequency ≥ 5000) co-occurring tags in the 1.5M posts and then appended them to the original seed tag list for further data collection. Table 1 lists a sample set of tags used to crawl the dataset. This final list of 45 tags was thereafter passed on to a psychiatry researcher to be categorized into different disorder types. For tags that described experiences or symptoms crosscutting across different conditions (e.g. “anxiety”) they were counted toward each disorder type. Table 2 gives a list of the ten different disorders identified in our data. We additionally consulted the Diagnostic and Statistical Manual of Mental Health Disorders (DSM-V [5]) that indicates these disorders to be prominent mental health challenges in populations. This categorization of the mental health challenges was conducted to ensure that our data used in the ensuing analysis focused on well-validated and clinically recognized conditions. At the same time it allowed us to focus on a diverse range of disorders expressed on social media rather than specific ones studied in prior work [12 13 27]; thus enabling us to discover generalized patterns in visual disclosures of mental health challenges in social media. Our final crawl included 2757044 posts from 151638 users spanning these disorders.,we utilized instagrams official api to obtain the dataset used in this paper each post in this dataset is public and contains postrelated information such a the image caption like comment hashtags filter and geolocation if tagged referring to prior literature we adopted an iterative approach to first identify a set of appropriate distinguishing hashtags around different prominent mental illness prevalent in social medium with the seed tag we performed an initial data collection of million post shared on instagram between dec and nov then by leveraging an association rule mining approach we compiled the top k k frequency cooccurring tag in the m post and then appended them to the original seed tag list for further data collection table list a sample set of tag used to crawl the dataset this final list of tag wa thereafter passed on to a psychiatry researcher to be categorized into different disorder type for tag that described experience or symptom crosscutting across different condition eg anxiety they were counted toward each disorder type table give a list of the ten different disorder identified in our data we additionally consulted the diagnostic and statistical manual of mental health disorder dsmv that indicates these disorder to be prominent mental health challenge in population this categorization of the mental health challenge wa conducted to ensure that our data used in the ensuing analysis focused on wellvalidated and clinically recognized condition at the same time it allowed u to focus on a diverse range of disorder expressed on social medium rather than specific one studied in prior work thus enabling u to discover generalized pattern in visual disclosure of mental health challenge in social medium our final crawl included post from user spanning these disorder,"['utilized', 'instagrams', 'official', 'api', 'obtain', 'paper', 'public', 'contains', 'postrelated', 'image', 'caption', 'like', 'hashtags', 'filter', 'geolocation', 'tagged', 'referring', 'prior', 'literature', 'adopted', 'iterative', 'approach', 'first', 'identify', 'appropriate', 'distinguishing', 'hashtags', 'around', 'different', 'prominent', 'illness', 'prevalent', 'medium', 'seed', 'tag', 'performed', 'initial', 'collection', 'million', 'shared', 'instagram', 'dec', 'nov', 'leveraging', 'association', 'rule', 'mining', 'approach', 'compiled', 'top', 'k', 'k', 'frequency', 'cooccurring', 'tag', 'appended', 'original', 'seed', 'tag', 'list', 'collection', 'table', 'list', 'sample', 'tag', 'crawl', 'final', 'list', 'tag', 'thereafter', 'passed', 'psychiatry', 'researcher', 'categorized', 'different', 'type', 'tag', 'described', 'experience', 'symptom', 'crosscutting', 'across', 'different', 'eg', 'anxiety', 'counted', 'toward', 'type', 'table', 'give', 'list', 'ten', 'different', 'identified', 'additionally', 'consulted', 'diagnostic', 'statistical', 'manual', 'dsmv', 'indicates', 'prominent', 'challenge', 'population', 'categorization', 'challenge', 'conducted', 'ensure', 'ensuing', 'analysis', 'focused', 'wellvalidated', 'clinically', 'recognized', 'allowed', 'u', 'focus', 'diverse', 'range', 'expressed', 'medium', 'rather', 'specific', 'one', 'studied', 'prior', 'thus', 'enabling', 'u', 'discover', 'generalized', 'pattern', 'visual', 'disclosure', 'challenge', 'medium', 'final', 'crawl', 'included', 'spanning']","['utilized instagrams', 'instagrams official', 'official api', 'api obtain', 'obtain paper', 'paper public', 'public contains', 'contains postrelated', 'postrelated image', 'image caption', 'caption like', 'like hashtags', 'hashtags filter', 'filter geolocation', 'geolocation tagged', 'tagged referring', 'referring prior', 'prior literature', 'literature adopted', 'adopted iterative', 'iterative approach', 'approach first', 'first identify', 'identify appropriate', 'appropriate distinguishing', 'distinguishing hashtags', 'hashtags around', 'around different', 'different prominent', 'prominent illness', 'illness prevalent', 'prevalent medium', 'medium seed', 'seed tag', 'tag performed', 'performed initial', 'initial collection', 'collection million', 'million shared', 'shared instagram', 'instagram dec', 'dec nov', 'nov leveraging', 'leveraging association', 'association rule', 'rule mining', 'mining approach', 'approach compiled', 'compiled top', 'top k', 'k k', 'k frequency', 'frequency cooccurring', 'cooccurring tag', 'tag appended', 'appended original', 'original seed', 'seed tag', 'tag list', 'list collection', 'collection table', 'table list', 'list sample', 'sample tag', 'tag crawl', 'crawl final', 'final list', 'list tag', 'tag thereafter', 'thereafter passed', 'passed psychiatry', 'psychiatry researcher', 'researcher categorized', 'categorized different', 'different type', 'type tag', 'tag described', 'described experience', 'experience symptom', 'symptom crosscutting', 'crosscutting across', 'across different', 'different eg', 'eg anxiety', 'anxiety counted', 'counted toward', 'toward type', 'type table', 'table give', 'give list', 'list ten', 'ten different', 'different identified', 'identified additionally', 'additionally consulted', 'consulted diagnostic', 'diagnostic statistical', 'statistical manual', 'manual dsmv', 'dsmv indicates', 'indicates prominent', 'prominent challenge', 'challenge population', 'population categorization', 'categorization challenge', 'challenge conducted', 'conducted ensure', 'ensure ensuing', 'ensuing analysis', 'analysis focused', 'focused wellvalidated', 'wellvalidated clinically', 'clinically recognized', 'recognized allowed', 'allowed u', 'u focus', 'focus diverse', 'diverse range', 'range expressed', 'expressed medium', 'medium rather', 'rather specific', 'specific one', 'one studied', 'studied prior', 'prior thus', 'thus enabling', 'enabling u', 'u discover', 'discover generalized', 'generalized pattern', 'pattern visual', 'visual disclosure', 'disclosure challenge', 'challenge medium', 'medium final', 'final crawl', 'crawl included', 'included spanning']","['utilized instagrams official', 'instagrams official api', 'official api obtain', 'api obtain paper', 'obtain paper public', 'paper public contains', 'public contains postrelated', 'contains postrelated image', 'postrelated image caption', 'image caption like', 'caption like hashtags', 'like hashtags filter', 'hashtags filter geolocation', 'filter geolocation tagged', 'geolocation tagged referring', 'tagged referring prior', 'referring prior literature', 'prior literature adopted', 'literature adopted iterative', 'adopted iterative approach', 'iterative approach first', 'approach first identify', 'first identify appropriate', 'identify appropriate distinguishing', 'appropriate distinguishing hashtags', 'distinguishing hashtags around', 'hashtags around different', 'around different prominent', 'different prominent illness', 'prominent illness prevalent', 'illness prevalent medium', 'prevalent medium seed', 'medium seed tag', 'seed tag performed', 'tag performed initial', 'performed initial collection', 'initial collection million', 'collection million shared', 'million shared instagram', 'shared instagram dec', 'instagram dec nov', 'dec nov leveraging', 'nov leveraging association', 'leveraging association rule', 'association rule mining', 'rule mining approach', 'mining approach compiled', 'approach compiled top', 'compiled top k', 'top k k', 'k k frequency', 'k frequency cooccurring', 'frequency cooccurring tag', 'cooccurring tag appended', 'tag appended original', 'appended original seed', 'original seed tag', 'seed tag list', 'tag list collection', 'list collection table', 'collection table list', 'table list sample', 'list sample tag', 'sample tag crawl', 'tag crawl final', 'crawl final list', 'final list tag', 'list tag thereafter', 'tag thereafter passed', 'thereafter passed psychiatry', 'passed psychiatry researcher', 'psychiatry researcher categorized', 'researcher categorized different', 'categorized different type', 'different type tag', 'type tag described', 'tag described experience', 'described experience symptom', 'experience symptom crosscutting', 'symptom crosscutting across', 'crosscutting across different', 'across different eg', 'different eg anxiety', 'eg anxiety counted', 'anxiety counted toward', 'counted toward type', 'toward type table', 'type table give', 'table give list', 'give list ten', 'list ten different', 'ten different identified', 'different identified additionally', 'identified additionally consulted', 'additionally consulted diagnostic', 'consulted diagnostic statistical', 'diagnostic statistical manual', 'statistical manual dsmv', 'manual dsmv indicates', 'dsmv indicates prominent', 'indicates prominent challenge', 'prominent challenge population', 'challenge population categorization', 'population categorization challenge', 'categorization challenge conducted', 'challenge conducted ensure', 'conducted ensure ensuing', 'ensure ensuing analysis', 'ensuing analysis focused', 'analysis focused wellvalidated', 'focused wellvalidated clinically', 'wellvalidated clinically recognized', 'clinically recognized allowed', 'recognized allowed u', 'allowed u focus', 'u focus diverse', 'focus diverse range', 'diverse range expressed', 'range expressed medium', 'expressed medium rather', 'medium rather specific', 'rather specific one', 'specific one studied', 'one studied prior', 'studied prior thus', 'prior thus enabling', 'thus enabling u', 'enabling u discover', 'u discover generalized', 'discover generalized pattern', 'generalized pattern visual', 'pattern visual disclosure', 'visual disclosure challenge', 'disclosure challenge medium', 'challenge medium final', 'medium final crawl', 'final crawl included', 'crawl included spanning']"
https://www.sciencedirect.com/science/article/pii/S0747563215300996,0,Most of the tweets (n = 1806 92%) were from ordinary people or other Twitter accounts that did not fall into the above categories. Only 6% (n = 112) of the tweets were from health focused handles such as health or government organizations or handles promoting healthy lifestyles (e.g. Doctor's Nutrition @drsnutritionetx Natural Health @naturalhealth92). In addition only 3% (n = 60) were from clinicians or therapists.,most of the tweet n were from ordinary people or other twitter account that did not fall into the above category only n of the tweet were from health focused handle such a health or government organization or handle promoting healthy lifestyle eg doctor nutrition drsnutritionetx natural health naturalhealth in addition only n were from clinician or therapist,"['n', 'ordinary', 'people', 'account', 'fall', 'category', 'n', 'focused', 'handle', 'government', 'organization', 'handle', 'promoting', 'healthy', 'lifestyle', 'eg', 'doctor', 'nutrition', 'drsnutritionetx', 'natural', 'naturalhealth', 'addition', 'n', 'clinician', 'therapist']","['n ordinary', 'ordinary people', 'people account', 'account fall', 'fall category', 'category n', 'n focused', 'focused handle', 'handle government', 'government organization', 'organization handle', 'handle promoting', 'promoting healthy', 'healthy lifestyle', 'lifestyle eg', 'eg doctor', 'doctor nutrition', 'nutrition drsnutritionetx', 'drsnutritionetx natural', 'natural naturalhealth', 'naturalhealth addition', 'addition n', 'n clinician', 'clinician therapist']","['n ordinary people', 'ordinary people account', 'people account fall', 'account fall category', 'fall category n', 'category n focused', 'n focused handle', 'focused handle government', 'handle government organization', 'government organization handle', 'organization handle promoting', 'handle promoting healthy', 'promoting healthy lifestyle', 'healthy lifestyle eg', 'lifestyle eg doctor', 'eg doctor nutrition', 'doctor nutrition drsnutritionetx', 'nutrition drsnutritionetx natural', 'drsnutritionetx natural naturalhealth', 'natural naturalhealth addition', 'naturalhealth addition n', 'addition n clinician', 'n clinician therapist']"
https://aclanthology.org/W15-1202.pdf,0,We follow the data acquisition and curation process of Coppersmith et al. (2014a) summarizing the major points here: Social media such as Twitter contains frequent public statements by users reporting diagnoses for various medical conditions. Many talk about physical health conditions (e.g. cancer flu) but some also discuss mental illness including schizophrenia. There are a variety of motivations for users to share this information on social media: to offer or seek support to fight the stigma of mental illness or perhaps to offer an explanation for certain behaviors.4 We obtain messages with these self-reported diagnoses using the Twitter API and filtered via (caseinsensitive) regular expression to require “schizo” or a close phonetic approximation to be present; our expression matched “schizophrenia” its subtypes and various approximations: “schizo” “skitzo” “skitso” “schizotypal” “schizoid” etc. All data we collect are public posts made between 2008 and 2015 and exclude any message marked as ‘private’ by the author. All use of the data reported in this paper has been approved by the appropriate Institutional Review Board (IRB). Each self-stated diagnosis included in this study was examined by a human annotator (one of the authors) to verify that it appeared to be a genuine statement of a schizophrenia diagnosis excluding jokes quotes or disingenuous statements. We obtained 174 users with an apparently genuine selfstated diagnosis of a schizophrenia-related condition. Note that we cannot be certain that the Twitter user was actually diagnosed with schizophrenia only that their statement of being diagnosed appears to be genuine. Previous work indicates that interannotator agreement for this task is good: κ = 0.77 (Coppersmith et al. 2014a). For each user we obtained a set of their public Twitter posts via the Twitter API collecting up to 3200 tweets.5 As we wish to focus on user-authored content we exclude from analysis all retweets and any tweets that contain a URL (which often contain text that the user did not author). We lowercase all words and convert any non-standard characters (including emoji) to a systematic ASCII representation via Unidecode.6 For our community controls we used randomlyselected Twitter users who primarily tweet in English. Specifically during a two week period in early 2014 each Twitter user who was included in Twitter’s 1% “spritzer” sample had an equal chance for inclusion in our pool of community controls. We then collected some of their historic tweets and assessed the language(s) they tweeted in according to the Chromium Compact Language Detector.7 Users were excluded from our community controls if their tweets were less than 75% English.8,we follow the data acquisition and curation process of coppersmith et al a summarizing the major point here social medium such a twitter contains frequent public statement by user reporting diagnosis for various medical condition many talk about physical health condition eg cancer flu but some also discus mental illness including schizophrenia there are a variety of motivation for user to share this information on social medium to offer or seek support to fight the stigma of mental illness or perhaps to offer an explanation for certain behavior we obtain message with these selfreported diagnosis using the twitter api and filtered via caseinsensitive regular expression to require schizo or a close phonetic approximation to be present our expression matched schizophrenia it subtypes and various approximation schizo skitzo skitso schizotypal schizoid etc all data we collect are public post made between and and exclude any message marked a private by the author all use of the data reported in this paper ha been approved by the appropriate institutional review board irb each selfstated diagnosis included in this study wa examined by a human annotator one of the author to verify that it appeared to be a genuine statement of a schizophrenia diagnosis excluding joke quote or disingenuous statement we obtained user with an apparently genuine selfstated diagnosis of a schizophreniarelated condition note that we cannot be certain that the twitter user wa actually diagnosed with schizophrenia only that their statement of being diagnosed appears to be genuine previous work indicates that interannotator agreement for this task is good coppersmith et al a for each user we obtained a set of their public twitter post via the twitter api collecting up to tweet a we wish to focus on userauthored content we exclude from analysis all retweets and any tweet that contain a url which often contain text that the user did not author we lowercase all word and convert any nonstandard character including emoji to a systematic ascii representation via unidecode for our community control we used randomlyselected twitter user who primarily tweet in english specifically during a two week period in early each twitter user who wa included in twitter spritzer sample had an equal chance for inclusion in our pool of community control we then collected some of their historic tweet and assessed the language they tweeted in according to the chromium compact language detector user were excluded from our community control if their tweet were le than english,"['follow', 'acquisition', 'curation', 'process', 'coppersmith', 'et', 'al', 'summarizing', 'major', 'point', 'medium', 'contains', 'frequent', 'public', 'statement', 'reporting', 'various', 'medical', 'many', 'talk', 'physical', 'eg', 'cancer', 'flu', 'also', 'discus', 'illness', 'including', 'variety', 'motivation', 'share', 'medium', 'offer', 'seek', 'support', 'fight', 'stigma', 'illness', 'perhaps', 'offer', 'explanation', 'certain', 'behavior', 'obtain', 'message', 'selfreported', 'api', 'filtered', 'via', 'caseinsensitive', 'regular', 'expression', 'require', 'schizo', 'close', 'phonetic', 'approximation', 'present', 'expression', 'matched', 'subtypes', 'various', 'approximation', 'schizo', 'skitzo', 'skitso', 'schizotypal', 'schizoid', 'etc', 'collect', 'public', 'exclude', 'message', 'marked', 'private', 'author', 'use', 'reported', 'paper', 'ha', 'approved', 'appropriate', 'institutional', 'review', 'board', 'irb', 'selfstated', 'included', 'study', 'examined', 'human', 'annotator', 'one', 'author', 'verify', 'appeared', 'genuine', 'statement', 'excluding', 'joke', 'quote', 'disingenuous', 'statement', 'obtained', 'apparently', 'genuine', 'selfstated', 'schizophreniarelated', 'note', 'cannot', 'certain', 'actually', 'diagnosed', 'statement', 'diagnosed', 'appears', 'genuine', 'previous', 'indicates', 'interannotator', 'agreement', 'task', 'good', 'coppersmith', 'et', 'al', 'obtained', 'public', 'via', 'api', 'collecting', 'wish', 'focus', 'userauthored', 'content', 'exclude', 'analysis', 'retweets', 'contain', 'url', 'often', 'contain', 'text', 'author', 'lowercase', 'convert', 'nonstandard', 'character', 'including', 'emoji', 'systematic', 'ascii', 'representation', 'via', 'unidecode', 'randomlyselected', 'primarily', 'english', 'specifically', 'two', 'week', 'period', 'early', 'included', 'spritzer', 'sample', 'equal', 'chance', 'inclusion', 'pool', 'historic', 'assessed', 'language', 'tweeted', 'according', 'chromium', 'compact', 'language', 'detector', 'excluded', 'le', 'english']","['follow acquisition', 'acquisition curation', 'curation process', 'process coppersmith', 'coppersmith et', 'et al', 'al summarizing', 'summarizing major', 'major point', 'point medium', 'medium contains', 'contains frequent', 'frequent public', 'public statement', 'statement reporting', 'reporting various', 'various medical', 'medical many', 'many talk', 'talk physical', 'physical eg', 'eg cancer', 'cancer flu', 'flu also', 'also discus', 'discus illness', 'illness including', 'including variety', 'variety motivation', 'motivation share', 'share medium', 'medium offer', 'offer seek', 'seek support', 'support fight', 'fight stigma', 'stigma illness', 'illness perhaps', 'perhaps offer', 'offer explanation', 'explanation certain', 'certain behavior', 'behavior obtain', 'obtain message', 'message selfreported', 'selfreported api', 'api filtered', 'filtered via', 'via caseinsensitive', 'caseinsensitive regular', 'regular expression', 'expression require', 'require schizo', 'schizo close', 'close phonetic', 'phonetic approximation', 'approximation present', 'present expression', 'expression matched', 'matched subtypes', 'subtypes various', 'various approximation', 'approximation schizo', 'schizo skitzo', 'skitzo skitso', 'skitso schizotypal', 'schizotypal schizoid', 'schizoid etc', 'etc collect', 'collect public', 'public exclude', 'exclude message', 'message marked', 'marked private', 'private author', 'author use', 'use reported', 'reported paper', 'paper ha', 'ha approved', 'approved appropriate', 'appropriate institutional', 'institutional review', 'review board', 'board irb', 'irb selfstated', 'selfstated included', 'included study', 'study examined', 'examined human', 'human annotator', 'annotator one', 'one author', 'author verify', 'verify appeared', 'appeared genuine', 'genuine statement', 'statement excluding', 'excluding joke', 'joke quote', 'quote disingenuous', 'disingenuous statement', 'statement obtained', 'obtained apparently', 'apparently genuine', 'genuine selfstated', 'selfstated schizophreniarelated', 'schizophreniarelated note', 'note cannot', 'cannot certain', 'certain actually', 'actually diagnosed', 'diagnosed statement', 'statement diagnosed', 'diagnosed appears', 'appears genuine', 'genuine previous', 'previous indicates', 'indicates interannotator', 'interannotator agreement', 'agreement task', 'task good', 'good coppersmith', 'coppersmith et', 'et al', 'al obtained', 'obtained public', 'public via', 'via api', 'api collecting', 'collecting wish', 'wish focus', 'focus userauthored', 'userauthored content', 'content exclude', 'exclude analysis', 'analysis retweets', 'retweets contain', 'contain url', 'url often', 'often contain', 'contain text', 'text author', 'author lowercase', 'lowercase convert', 'convert nonstandard', 'nonstandard character', 'character including', 'including emoji', 'emoji systematic', 'systematic ascii', 'ascii representation', 'representation via', 'via unidecode', 'unidecode randomlyselected', 'randomlyselected primarily', 'primarily english', 'english specifically', 'specifically two', 'two week', 'week period', 'period early', 'early included', 'included spritzer', 'spritzer sample', 'sample equal', 'equal chance', 'chance inclusion', 'inclusion pool', 'pool historic', 'historic assessed', 'assessed language', 'language tweeted', 'tweeted according', 'according chromium', 'chromium compact', 'compact language', 'language detector', 'detector excluded', 'excluded le', 'le english']","['follow acquisition curation', 'acquisition curation process', 'curation process coppersmith', 'process coppersmith et', 'coppersmith et al', 'et al summarizing', 'al summarizing major', 'summarizing major point', 'major point medium', 'point medium contains', 'medium contains frequent', 'contains frequent public', 'frequent public statement', 'public statement reporting', 'statement reporting various', 'reporting various medical', 'various medical many', 'medical many talk', 'many talk physical', 'talk physical eg', 'physical eg cancer', 'eg cancer flu', 'cancer flu also', 'flu also discus', 'also discus illness', 'discus illness including', 'illness including variety', 'including variety motivation', 'variety motivation share', 'motivation share medium', 'share medium offer', 'medium offer seek', 'offer seek support', 'seek support fight', 'support fight stigma', 'fight stigma illness', 'stigma illness perhaps', 'illness perhaps offer', 'perhaps offer explanation', 'offer explanation certain', 'explanation certain behavior', 'certain behavior obtain', 'behavior obtain message', 'obtain message selfreported', 'message selfreported api', 'selfreported api filtered', 'api filtered via', 'filtered via caseinsensitive', 'via caseinsensitive regular', 'caseinsensitive regular expression', 'regular expression require', 'expression require schizo', 'require schizo close', 'schizo close phonetic', 'close phonetic approximation', 'phonetic approximation present', 'approximation present expression', 'present expression matched', 'expression matched subtypes', 'matched subtypes various', 'subtypes various approximation', 'various approximation schizo', 'approximation schizo skitzo', 'schizo skitzo skitso', 'skitzo skitso schizotypal', 'skitso schizotypal schizoid', 'schizotypal schizoid etc', 'schizoid etc collect', 'etc collect public', 'collect public exclude', 'public exclude message', 'exclude message marked', 'message marked private', 'marked private author', 'private author use', 'author use reported', 'use reported paper', 'reported paper ha', 'paper ha approved', 'ha approved appropriate', 'approved appropriate institutional', 'appropriate institutional review', 'institutional review board', 'review board irb', 'board irb selfstated', 'irb selfstated included', 'selfstated included study', 'included study examined', 'study examined human', 'examined human annotator', 'human annotator one', 'annotator one author', 'one author verify', 'author verify appeared', 'verify appeared genuine', 'appeared genuine statement', 'genuine statement excluding', 'statement excluding joke', 'excluding joke quote', 'joke quote disingenuous', 'quote disingenuous statement', 'disingenuous statement obtained', 'statement obtained apparently', 'obtained apparently genuine', 'apparently genuine selfstated', 'genuine selfstated schizophreniarelated', 'selfstated schizophreniarelated note', 'schizophreniarelated note cannot', 'note cannot certain', 'cannot certain actually', 'certain actually diagnosed', 'actually diagnosed statement', 'diagnosed statement diagnosed', 'statement diagnosed appears', 'diagnosed appears genuine', 'appears genuine previous', 'genuine previous indicates', 'previous indicates interannotator', 'indicates interannotator agreement', 'interannotator agreement task', 'agreement task good', 'task good coppersmith', 'good coppersmith et', 'coppersmith et al', 'et al obtained', 'al obtained public', 'obtained public via', 'public via api', 'via api collecting', 'api collecting wish', 'collecting wish focus', 'wish focus userauthored', 'focus userauthored content', 'userauthored content exclude', 'content exclude analysis', 'exclude analysis retweets', 'analysis retweets contain', 'retweets contain url', 'contain url often', 'url often contain', 'often contain text', 'contain text author', 'text author lowercase', 'author lowercase convert', 'lowercase convert nonstandard', 'convert nonstandard character', 'nonstandard character including', 'character including emoji', 'including emoji systematic', 'emoji systematic ascii', 'systematic ascii representation', 'ascii representation via', 'representation via unidecode', 'via unidecode randomlyselected', 'unidecode randomlyselected primarily', 'randomlyselected primarily english', 'primarily english specifically', 'english specifically two', 'specifically two week', 'two week period', 'week period early', 'period early included', 'early included spritzer', 'included spritzer sample', 'spritzer sample equal', 'sample equal chance', 'equal chance inclusion', 'chance inclusion pool', 'inclusion pool historic', 'pool historic assessed', 'historic assessed language', 'assessed language tweeted', 'language tweeted according', 'tweeted according chromium', 'according chromium compact', 'chromium compact language', 'compact language detector', 'language detector excluded', 'detector excluded le', 'excluded le english']"
https://dl.acm.org/doi/abs/10.1145/2700171.2791026,0,Privacy Note: All social media data used in this paper are publicly available. At no time did we contact or interact with a user. Given the sensitive nature of this research we took care to anonymize the data in analysis and presentation so as to minimize any inadvertent disclosure of personal information or information that may reveal cues about an individual’s online identity. Approval was obtained from the relevant institutional review boards.,privacy note all social medium data used in this paper are publicly available at no time did we contact or interact with a user given the sensitive nature of this research we took care to anonymize the data in analysis and presentation so a to minimize any inadvertent disclosure of personal information or information that may reveal cue about an individual online identity approval wa obtained from the relevant institutional review board,"['privacy', 'note', 'medium', 'paper', 'publicly', 'available', 'contact', 'interact', 'given', 'sensitive', 'nature', 'research', 'took', 'care', 'anonymize', 'analysis', 'presentation', 'minimize', 'inadvertent', 'disclosure', 'personal', 'may', 'reveal', 'cue', 'individual', 'online', 'identity', 'approval', 'obtained', 'relevant', 'institutional', 'review', 'board']","['privacy note', 'note medium', 'medium paper', 'paper publicly', 'publicly available', 'available contact', 'contact interact', 'interact given', 'given sensitive', 'sensitive nature', 'nature research', 'research took', 'took care', 'care anonymize', 'anonymize analysis', 'analysis presentation', 'presentation minimize', 'minimize inadvertent', 'inadvertent disclosure', 'disclosure personal', 'personal may', 'may reveal', 'reveal cue', 'cue individual', 'individual online', 'online identity', 'identity approval', 'approval obtained', 'obtained relevant', 'relevant institutional', 'institutional review', 'review board']","['privacy note medium', 'note medium paper', 'medium paper publicly', 'paper publicly available', 'publicly available contact', 'available contact interact', 'contact interact given', 'interact given sensitive', 'given sensitive nature', 'sensitive nature research', 'nature research took', 'research took care', 'took care anonymize', 'care anonymize analysis', 'anonymize analysis presentation', 'analysis presentation minimize', 'presentation minimize inadvertent', 'minimize inadvertent disclosure', 'inadvertent disclosure personal', 'disclosure personal may', 'personal may reveal', 'may reveal cue', 'reveal cue individual', 'cue individual online', 'individual online identity', 'online identity approval', 'identity approval obtained', 'approval obtained relevant', 'obtained relevant institutional', 'relevant institutional review', 'institutional review board']"
https://aclanthology.org/W17-3110.pdf,1,We briefly explain the data collection method here but we refer the interested reader with further questions on the methodology to Coppersmith et al. (2016) for the suicide attempt data and Coppersmith et al. (2014a) for all other conditions. The data for these analyses are Twitter posts collected via two methods. Most of the data come from users who have publicly discussed their mental health conditions. These users are frequently referred to as “self-stated diagnosis” users as they state publicly something like “I was diagnosed with schizophrenia” or “I’m so thankful to have survived my suicide attempt last year”. The data for users with a suicide attempt was supplemented by data from OurDataHelps.org a data donation site where people provide access to their public posts and fill out a short questionnaire about their mental health history. Data are then deidentified and made available to researchers addressing questions of interest to the mental health community. Donors provide consent for their data to be used in mental health research upon signup. Of the users who attempted suicide 146 came from OurDataHelps.org. Specifically we examine generalized anxiety disorder eating disorders panic attacks schizophrenia and attempted suicides. These conditions were selected based on the theory that there are important timing aspects to their symptoms – ebbing and flowing of symptoms as treatment is effective (especially schizophrenia) onset and exacerbation of symptoms by external events and stress and punctuated events in time of psychological symptoms (suicide attempts panic attacks and binging/purging behavior with eating disorders). We use the Twitter streaming API to collect a sample of users who used a series of mental health words or phrases in their tweet text (e.g. ‘schizophrenia‘ or ‘suicide attempt‘). Each tweet that uses one of these phrases is examined via regular expression to indicate that the user is talking about themselves. Finally those tweets that pass the regular expression are examined by a human to confirm (to the best of our ability) that their selfstatement of diagnosis appears to be genuine. This results in a dataset with users that have a self-stated diagnosis of generalized anxiety disorder (n = 2408) an eating disorder (749) panic attacks (263) schizophrenia (350) or someone who would go on to attempt suicide (423). Some of these users do not exhibit the sort of posting behavior required to create micropatterns (i.e. they rarely post multiple times within a 3 hour time window). We exclude these users from our analysis which is 5-9% of users for most conditions with the exception of those with a suicide attempt where a little over half the users do not exhibit this posting behavior. The resultant dataset used for analyses is: generalized anxiety disorder (n = 2271) eating disorders (687) panic attacks (247) schizophrenia (318) suicide attempts (157). In order to allow comparisons of each condition to control users we gather a random sample of 10000 Twitter users for whom at least 75% of their posts are identified by Twitter as English. All the users with a self-stated diagnoses and all members of this control population have their age and gender estimated according to Sap et al. (2014). For each user with a self-stated diagnosis we find a matched control through the following procedure: create a pool of users where the estimated gender matches and the estimated age is within the same 10-year bracket (the suggested accuracy of the age estimator). From that pool of age- and gender- matched users we select the user whose tweets start and end over the most similar timeframe. We will refer to these age- gender- and time-matched controls simply as “matched controls” throughout the rest of this paper. All tweets were publicly posted by their author (i.e. no users marked at “protected” or “private” were included). On average users had 2949 tweets. The distribution of estimated age and genders for users with each self-stated condition can be seen in Figure 1. For most conditions the population skews female though for schizophrenia the genders are roughly balanced. The average age tends to be in the early-to-mid 20s.,we briefly explain the data collection method here but we refer the interested reader with further question on the methodology to coppersmith et al for the suicide attempt data and coppersmith et al a for all other condition the data for these analysis are twitter post collected via two method most of the data come from user who have publicly discussed their mental health condition these user are frequently referred to a selfstated diagnosis user a they state publicly something like i wa diagnosed with schizophrenia or im so thankful to have survived my suicide attempt last year the data for user with a suicide attempt wa supplemented by data from ourdatahelpsorg a data donation site where people provide access to their public post and fill out a short questionnaire about their mental health history data are then deidentified and made available to researcher addressing question of interest to the mental health community donor provide consent for their data to be used in mental health research upon signup of the user who attempted suicide came from ourdatahelpsorg specifically we examine generalized anxiety disorder eating disorder panic attack schizophrenia and attempted suicide these condition were selected based on the theory that there are important timing aspect to their symptom ebbing and flowing of symptom a treatment is effective especially schizophrenia onset and exacerbation of symptom by external event and stress and punctuated event in time of psychological symptom suicide attempt panic attack and bingingpurging behavior with eating disorder we use the twitter streaming api to collect a sample of user who used a series of mental health word or phrase in their tweet text eg schizophrenia or suicide attempt each tweet that us one of these phrase is examined via regular expression to indicate that the user is talking about themselves finally those tweet that pas the regular expression are examined by a human to confirm to the best of our ability that their selfstatement of diagnosis appears to be genuine this result in a dataset with user that have a selfstated diagnosis of generalized anxiety disorder n an eating disorder panic attack schizophrenia or someone who would go on to attempt suicide some of these user do not exhibit the sort of posting behavior required to create micropatterns ie they rarely post multiple time within a hour time window we exclude these user from our analysis which is of user for most condition with the exception of those with a suicide attempt where a little over half the user do not exhibit this posting behavior the resultant dataset used for analysis is generalized anxiety disorder n eating disorder panic attack schizophrenia suicide attempt in order to allow comparison of each condition to control user we gather a random sample of twitter user for whom at least of their post are identified by twitter a english all the user with a selfstated diagnosis and all member of this control population have their age and gender estimated according to sap et al for each user with a selfstated diagnosis we find a matched control through the following procedure create a pool of user where the estimated gender match and the estimated age is within the same year bracket the suggested accuracy of the age estimator from that pool of age and gender matched user we select the user whose tweet start and end over the most similar timeframe we will refer to these age gender and timematched control simply a matched control throughout the rest of this paper all tweet were publicly posted by their author ie no user marked at protected or private were included on average user had tweet the distribution of estimated age and gender for user with each selfstated condition can be seen in figure for most condition the population skews female though for schizophrenia the gender are roughly balanced the average age tends to be in the earlytomid s,"['briefly', 'explain', 'collection', 'method', 'refer', 'interested', 'reader', 'question', 'methodology', 'coppersmith', 'et', 'al', 'attempt', 'coppersmith', 'et', 'al', 'analysis', 'via', 'two', 'method', 'come', 'publicly', 'discussed', 'frequently', 'referred', 'selfstated', 'state', 'publicly', 'something', 'like', 'diagnosed', 'im', 'thankful', 'survived', 'attempt', 'last', 'year', 'attempt', 'supplemented', 'ourdatahelpsorg', 'donation', 'site', 'people', 'provide', 'access', 'public', 'fill', 'short', 'questionnaire', 'history', 'deidentified', 'available', 'researcher', 'addressing', 'question', 'interest', 'donor', 'provide', 'consent', 'research', 'upon', 'signup', 'attempted', 'came', 'ourdatahelpsorg', 'specifically', 'examine', 'generalized', 'anxiety', 'eating', 'panic', 'attack', 'attempted', 'selected', 'based', 'theory', 'important', 'timing', 'aspect', 'symptom', 'ebbing', 'flowing', 'symptom', 'treatment', 'effective', 'especially', 'onset', 'exacerbation', 'symptom', 'external', 'event', 'stress', 'punctuated', 'event', 'psychological', 'symptom', 'attempt', 'panic', 'attack', 'bingingpurging', 'behavior', 'eating', 'use', 'streaming', 'api', 'collect', 'sample', 'series', 'phrase', 'text', 'eg', 'attempt', 'us', 'one', 'phrase', 'examined', 'via', 'regular', 'expression', 'indicate', 'talking', 'finally', 'pas', 'regular', 'expression', 'examined', 'human', 'confirm', 'best', 'ability', 'selfstatement', 'appears', 'genuine', 'result', 'selfstated', 'generalized', 'anxiety', 'n', 'eating', 'panic', 'attack', 'someone', 'would', 'go', 'attempt', 'exhibit', 'sort', 'posting', 'behavior', 'required', 'create', 'micropatterns', 'ie', 'rarely', 'multiple', 'within', 'hour', 'window', 'exclude', 'analysis', 'exception', 'attempt', 'little', 'half', 'exhibit', 'posting', 'behavior', 'resultant', 'analysis', 'generalized', 'anxiety', 'n', 'eating', 'panic', 'attack', 'attempt', 'order', 'allow', 'comparison', 'gather', 'random', 'sample', 'least', 'identified', 'english', 'selfstated', 'member', 'population', 'age', 'gender', 'estimated', 'according', 'sap', 'et', 'al', 'selfstated', 'find', 'matched', 'following', 'procedure', 'create', 'pool', 'estimated', 'gender', 'match', 'estimated', 'age', 'within', 'year', 'bracket', 'suggested', 'accuracy', 'age', 'estimator', 'pool', 'age', 'gender', 'matched', 'select', 'whose', 'start', 'end', 'similar', 'timeframe', 'refer', 'age', 'gender', 'timematched', 'simply', 'matched', 'throughout', 'rest', 'paper', 'publicly', 'posted', 'author', 'ie', 'marked', 'protected', 'private', 'included', 'average', 'distribution', 'estimated', 'age', 'gender', 'selfstated', 'seen', 'figure', 'population', 'skews', 'female', 'though', 'gender', 'roughly', 'balanced', 'average', 'age', 'tends', 'earlytomid']","['briefly explain', 'explain collection', 'collection method', 'method refer', 'refer interested', 'interested reader', 'reader question', 'question methodology', 'methodology coppersmith', 'coppersmith et', 'et al', 'al attempt', 'attempt coppersmith', 'coppersmith et', 'et al', 'al analysis', 'analysis via', 'via two', 'two method', 'method come', 'come publicly', 'publicly discussed', 'discussed frequently', 'frequently referred', 'referred selfstated', 'selfstated state', 'state publicly', 'publicly something', 'something like', 'like diagnosed', 'diagnosed im', 'im thankful', 'thankful survived', 'survived attempt', 'attempt last', 'last year', 'year attempt', 'attempt supplemented', 'supplemented ourdatahelpsorg', 'ourdatahelpsorg donation', 'donation site', 'site people', 'people provide', 'provide access', 'access public', 'public fill', 'fill short', 'short questionnaire', 'questionnaire history', 'history deidentified', 'deidentified available', 'available researcher', 'researcher addressing', 'addressing question', 'question interest', 'interest donor', 'donor provide', 'provide consent', 'consent research', 'research upon', 'upon signup', 'signup attempted', 'attempted came', 'came ourdatahelpsorg', 'ourdatahelpsorg specifically', 'specifically examine', 'examine generalized', 'generalized anxiety', 'anxiety eating', 'eating panic', 'panic attack', 'attack attempted', 'attempted selected', 'selected based', 'based theory', 'theory important', 'important timing', 'timing aspect', 'aspect symptom', 'symptom ebbing', 'ebbing flowing', 'flowing symptom', 'symptom treatment', 'treatment effective', 'effective especially', 'especially onset', 'onset exacerbation', 'exacerbation symptom', 'symptom external', 'external event', 'event stress', 'stress punctuated', 'punctuated event', 'event psychological', 'psychological symptom', 'symptom attempt', 'attempt panic', 'panic attack', 'attack bingingpurging', 'bingingpurging behavior', 'behavior eating', 'eating use', 'use streaming', 'streaming api', 'api collect', 'collect sample', 'sample series', 'series phrase', 'phrase text', 'text eg', 'eg attempt', 'attempt us', 'us one', 'one phrase', 'phrase examined', 'examined via', 'via regular', 'regular expression', 'expression indicate', 'indicate talking', 'talking finally', 'finally pas', 'pas regular', 'regular expression', 'expression examined', 'examined human', 'human confirm', 'confirm best', 'best ability', 'ability selfstatement', 'selfstatement appears', 'appears genuine', 'genuine result', 'result selfstated', 'selfstated generalized', 'generalized anxiety', 'anxiety n', 'n eating', 'eating panic', 'panic attack', 'attack someone', 'someone would', 'would go', 'go attempt', 'attempt exhibit', 'exhibit sort', 'sort posting', 'posting behavior', 'behavior required', 'required create', 'create micropatterns', 'micropatterns ie', 'ie rarely', 'rarely multiple', 'multiple within', 'within hour', 'hour window', 'window exclude', 'exclude analysis', 'analysis exception', 'exception attempt', 'attempt little', 'little half', 'half exhibit', 'exhibit posting', 'posting behavior', 'behavior resultant', 'resultant analysis', 'analysis generalized', 'generalized anxiety', 'anxiety n', 'n eating', 'eating panic', 'panic attack', 'attack attempt', 'attempt order', 'order allow', 'allow comparison', 'comparison gather', 'gather random', 'random sample', 'sample least', 'least identified', 'identified english', 'english selfstated', 'selfstated member', 'member population', 'population age', 'age gender', 'gender estimated', 'estimated according', 'according sap', 'sap et', 'et al', 'al selfstated', 'selfstated find', 'find matched', 'matched following', 'following procedure', 'procedure create', 'create pool', 'pool estimated', 'estimated gender', 'gender match', 'match estimated', 'estimated age', 'age within', 'within year', 'year bracket', 'bracket suggested', 'suggested accuracy', 'accuracy age', 'age estimator', 'estimator pool', 'pool age', 'age gender', 'gender matched', 'matched select', 'select whose', 'whose start', 'start end', 'end similar', 'similar timeframe', 'timeframe refer', 'refer age', 'age gender', 'gender timematched', 'timematched simply', 'simply matched', 'matched throughout', 'throughout rest', 'rest paper', 'paper publicly', 'publicly posted', 'posted author', 'author ie', 'ie marked', 'marked protected', 'protected private', 'private included', 'included average', 'average distribution', 'distribution estimated', 'estimated age', 'age gender', 'gender selfstated', 'selfstated seen', 'seen figure', 'figure population', 'population skews', 'skews female', 'female though', 'though gender', 'gender roughly', 'roughly balanced', 'balanced average', 'average age', 'age tends', 'tends earlytomid']","['briefly explain collection', 'explain collection method', 'collection method refer', 'method refer interested', 'refer interested reader', 'interested reader question', 'reader question methodology', 'question methodology coppersmith', 'methodology coppersmith et', 'coppersmith et al', 'et al attempt', 'al attempt coppersmith', 'attempt coppersmith et', 'coppersmith et al', 'et al analysis', 'al analysis via', 'analysis via two', 'via two method', 'two method come', 'method come publicly', 'come publicly discussed', 'publicly discussed frequently', 'discussed frequently referred', 'frequently referred selfstated', 'referred selfstated state', 'selfstated state publicly', 'state publicly something', 'publicly something like', 'something like diagnosed', 'like diagnosed im', 'diagnosed im thankful', 'im thankful survived', 'thankful survived attempt', 'survived attempt last', 'attempt last year', 'last year attempt', 'year attempt supplemented', 'attempt supplemented ourdatahelpsorg', 'supplemented ourdatahelpsorg donation', 'ourdatahelpsorg donation site', 'donation site people', 'site people provide', 'people provide access', 'provide access public', 'access public fill', 'public fill short', 'fill short questionnaire', 'short questionnaire history', 'questionnaire history deidentified', 'history deidentified available', 'deidentified available researcher', 'available researcher addressing', 'researcher addressing question', 'addressing question interest', 'question interest donor', 'interest donor provide', 'donor provide consent', 'provide consent research', 'consent research upon', 'research upon signup', 'upon signup attempted', 'signup attempted came', 'attempted came ourdatahelpsorg', 'came ourdatahelpsorg specifically', 'ourdatahelpsorg specifically examine', 'specifically examine generalized', 'examine generalized anxiety', 'generalized anxiety eating', 'anxiety eating panic', 'eating panic attack', 'panic attack attempted', 'attack attempted selected', 'attempted selected based', 'selected based theory', 'based theory important', 'theory important timing', 'important timing aspect', 'timing aspect symptom', 'aspect symptom ebbing', 'symptom ebbing flowing', 'ebbing flowing symptom', 'flowing symptom treatment', 'symptom treatment effective', 'treatment effective especially', 'effective especially onset', 'especially onset exacerbation', 'onset exacerbation symptom', 'exacerbation symptom external', 'symptom external event', 'external event stress', 'event stress punctuated', 'stress punctuated event', 'punctuated event psychological', 'event psychological symptom', 'psychological symptom attempt', 'symptom attempt panic', 'attempt panic attack', 'panic attack bingingpurging', 'attack bingingpurging behavior', 'bingingpurging behavior eating', 'behavior eating use', 'eating use streaming', 'use streaming api', 'streaming api collect', 'api collect sample', 'collect sample series', 'sample series phrase', 'series phrase text', 'phrase text eg', 'text eg attempt', 'eg attempt us', 'attempt us one', 'us one phrase', 'one phrase examined', 'phrase examined via', 'examined via regular', 'via regular expression', 'regular expression indicate', 'expression indicate talking', 'indicate talking finally', 'talking finally pas', 'finally pas regular', 'pas regular expression', 'regular expression examined', 'expression examined human', 'examined human confirm', 'human confirm best', 'confirm best ability', 'best ability selfstatement', 'ability selfstatement appears', 'selfstatement appears genuine', 'appears genuine result', 'genuine result selfstated', 'result selfstated generalized', 'selfstated generalized anxiety', 'generalized anxiety n', 'anxiety n eating', 'n eating panic', 'eating panic attack', 'panic attack someone', 'attack someone would', 'someone would go', 'would go attempt', 'go attempt exhibit', 'attempt exhibit sort', 'exhibit sort posting', 'sort posting behavior', 'posting behavior required', 'behavior required create', 'required create micropatterns', 'create micropatterns ie', 'micropatterns ie rarely', 'ie rarely multiple', 'rarely multiple within', 'multiple within hour', 'within hour window', 'hour window exclude', 'window exclude analysis', 'exclude analysis exception', 'analysis exception attempt', 'exception attempt little', 'attempt little half', 'little half exhibit', 'half exhibit posting', 'exhibit posting behavior', 'posting behavior resultant', 'behavior resultant analysis', 'resultant analysis generalized', 'analysis generalized anxiety', 'generalized anxiety n', 'anxiety n eating', 'n eating panic', 'eating panic attack', 'panic attack attempt', 'attack attempt order', 'attempt order allow', 'order allow comparison', 'allow comparison gather', 'comparison gather random', 'gather random sample', 'random sample least', 'sample least identified', 'least identified english', 'identified english selfstated', 'english selfstated member', 'selfstated member population', 'member population age', 'population age gender', 'age gender estimated', 'gender estimated according', 'estimated according sap', 'according sap et', 'sap et al', 'et al selfstated', 'al selfstated find', 'selfstated find matched', 'find matched following', 'matched following procedure', 'following procedure create', 'procedure create pool', 'create pool estimated', 'pool estimated gender', 'estimated gender match', 'gender match estimated', 'match estimated age', 'estimated age within', 'age within year', 'within year bracket', 'year bracket suggested', 'bracket suggested accuracy', 'suggested accuracy age', 'accuracy age estimator', 'age estimator pool', 'estimator pool age', 'pool age gender', 'age gender matched', 'gender matched select', 'matched select whose', 'select whose start', 'whose start end', 'start end similar', 'end similar timeframe', 'similar timeframe refer', 'timeframe refer age', 'refer age gender', 'age gender timematched', 'gender timematched simply', 'timematched simply matched', 'simply matched throughout', 'matched throughout rest', 'throughout rest paper', 'rest paper publicly', 'paper publicly posted', 'publicly posted author', 'posted author ie', 'author ie marked', 'ie marked protected', 'marked protected private', 'protected private included', 'private included average', 'included average distribution', 'average distribution estimated', 'distribution estimated age', 'estimated age gender', 'age gender selfstated', 'gender selfstated seen', 'selfstated seen figure', 'seen figure population', 'figure population skews', 'population skews female', 'skews female though', 'female though gender', 'though gender roughly', 'gender roughly balanced', 'roughly balanced average', 'balanced average age', 'average age tends', 'age tends earlytomid']"
https://dl.acm.org/doi/abs/10.1145/2998181.2998220,0,Privacy and Ethics. We leverage public data from Twitter and Reddit for our work; hence our work did not qualify for approval from our Institutional Review Board. Nevertheless we took greater care in de-identifying and paraphrasing any content we present as examples to support our investigation. Importantly our work does not make any diagnostic claims about mental illness experiences of the population we study.,privacy and ethic we leverage public data from twitter and reddit for our work hence our work did not qualify for approval from our institutional review board nevertheless we took greater care in deidentifying and paraphrasing any content we present a example to support our investigation importantly our work doe not make any diagnostic claim about mental illness experience of the population we study,"['privacy', 'ethic', 'leverage', 'public', 'reddit', 'hence', 'qualify', 'approval', 'institutional', 'review', 'board', 'nevertheless', 'took', 'greater', 'care', 'deidentifying', 'paraphrasing', 'content', 'present', 'example', 'support', 'investigation', 'importantly', 'doe', 'make', 'diagnostic', 'claim', 'illness', 'experience', 'population', 'study']","['privacy ethic', 'ethic leverage', 'leverage public', 'public reddit', 'reddit hence', 'hence qualify', 'qualify approval', 'approval institutional', 'institutional review', 'review board', 'board nevertheless', 'nevertheless took', 'took greater', 'greater care', 'care deidentifying', 'deidentifying paraphrasing', 'paraphrasing content', 'content present', 'present example', 'example support', 'support investigation', 'investigation importantly', 'importantly doe', 'doe make', 'make diagnostic', 'diagnostic claim', 'claim illness', 'illness experience', 'experience population', 'population study']","['privacy ethic leverage', 'ethic leverage public', 'leverage public reddit', 'public reddit hence', 'reddit hence qualify', 'hence qualify approval', 'qualify approval institutional', 'approval institutional review', 'institutional review board', 'review board nevertheless', 'board nevertheless took', 'nevertheless took greater', 'took greater care', 'greater care deidentifying', 'care deidentifying paraphrasing', 'deidentifying paraphrasing content', 'paraphrasing content present', 'content present example', 'present example support', 'example support investigation', 'support investigation importantly', 'investigation importantly doe', 'importantly doe make', 'doe make diagnostic', 'make diagnostic claim', 'diagnostic claim illness', 'claim illness experience', 'illness experience population', 'experience population study']"
https://www.jmir.org/2019/6/e14199/,0,The selection of the tweets and their users was based on the filtered real-time streaming support provided by the Twitter API. In the first step we selected the users who showed potential signs of depression on Twitter on the basis of the 20 most frequent words in Spanish expressed by patients suffering from depression in clinical settings. These words were jointly identified and selected by a psychologist and a family physician with clinical experience and were based on the definition and general features of depression according to the Diagnostic and Statistical Manual of Mental Disorders [42]. The list of words used and their English translations are shown in Textbox 1. During June 2018 1470000 tweets including 1 or more occurrences of the words listed in Textbox 1 were collected. From this collection of tweets and to select the users who publicly stated in the textual description associated to their profile that they suffered from depression all the profile descriptions including 1 or more occurrences of the word “depr” and all the possible derivations related to the word depression in Spanish such as “depre” “depresión” “depresivo” “depresiva” “deprimido” and “deprimida” were considered. From the 720 users who included 1 or more of these words in their description profile 90 users who stated they suffered from depression or were receiving treatment for depression were selected for the analysis. This selection was performed by a psychologist verifying that the statements were related to real expressions of depression excluding quotes jokes or fake ones. For each of these depressed Twitter users we collected all the most recent tweets from their timeline up to a maximum of about 3200 tweets. Thus a total of 189669 tweets were collected a figure that was reduced to 140946 after discarding the retweets. These 140946 tweets constituted the depressive users dataset. Examples of sentences appearing in the user profiles that were used for selecting the depressive users are: “Paciente psiquiátrico con depresión crónica” (Psychiatric patient with chronic depression; example of a profile sentence that indicates depression). “Colecciono errores traducidos a tweets depresivos y a uno que otro impulso de amor” (I gather errors translated into depressing tweets and into one or another love impulse; example of a profile sentence that does not indicate depression). Once the users with profile sentences indicating depression had been retrieved their Twitter timelines were collected. Only those users having in their timeline at least 10 tweets that suggested signs of depression were retained for further analyses. For each user the selection of these tweets was performed by manually inspecting the tweets of the user’s complete timeline in reverse temporal order starting from the most recent one to the oldest tweet of the timeline retrieved by means of the Twitter API . Finally a total number of 1000 tweets issued by the 90 depressive users suggesting signs of depression were detected and used for the analysis. This set of tweets provided us with the depressive tweets dataset which was used to analyze linguistic features of tweets showing signs of depression. It has to be mentioned that these 1000 tweets were not to be included in the depressive users dataset (see Figure 1). At the same time more than 97500000 tweets were also collected in June 2018: such tweets were gathered by listening to the public Twitter stream during this time span by only considering tweets with Spanish textual contents (as detected by Twitter language identification support). Given that Twitter requires more restrictive filters than just the language of the tweets we used a list of the most frequently used Spanish words (stopwords) to retrieve all tweets that included 1 or more of these words. The vast majority of Spanish tweets should match this criterion. A sample of 450 users who did not mention in their profile the word depression and its derivations were selected randomly from the 97500000 tweets. The complete timelines of these users were compiled (1141021 tweets) which were reduced to 712589 once retweets were removed. These 712589 tweets constituted the control dataset. To identify the language of a tweet we relied on the language automatically identified by Twitter for each tweet selecting tweets in Spanish. It has to be noted that these data can contain some tweets from unidentified depressive users.,the selection of the tweet and their user wa based on the filtered realtime streaming support provided by the twitter api in the first step we selected the user who showed potential sign of depression on twitter on the basis of the most frequent word in spanish expressed by patient suffering from depression in clinical setting these word were jointly identified and selected by a psychologist and a family physician with clinical experience and were based on the definition and general feature of depression according to the diagnostic and statistical manual of mental disorder the list of word used and their english translation are shown in textbox during june tweet including or more occurrence of the word listed in textbox were collected from this collection of tweet and to select the user who publicly stated in the textual description associated to their profile that they suffered from depression all the profile description including or more occurrence of the word depr and all the possible derivation related to the word depression in spanish such a depre depresin depresivo depresiva deprimido and deprimida were considered from the user who included or more of these word in their description profile user who stated they suffered from depression or were receiving treatment for depression were selected for the analysis this selection wa performed by a psychologist verifying that the statement were related to real expression of depression excluding quote joke or fake one for each of these depressed twitter user we collected all the most recent tweet from their timeline up to a maximum of about tweet thus a total of tweet were collected a figure that wa reduced to after discarding the retweets these tweet constituted the depressive user dataset example of sentence appearing in the user profile that were used for selecting the depressive user are paciente psiquitrico con depresin crnica psychiatric patient with chronic depression example of a profile sentence that indicates depression colecciono errores traducidos a tweet depresivos y a uno que otro impulso de amor i gather error translated into depressing tweet and into one or another love impulse example of a profile sentence that doe not indicate depression once the user with profile sentence indicating depression had been retrieved their twitter timeline were collected only those user having in their timeline at least tweet that suggested sign of depression were retained for further analysis for each user the selection of these tweet wa performed by manually inspecting the tweet of the user complete timeline in reverse temporal order starting from the most recent one to the oldest tweet of the timeline retrieved by mean of the twitter api finally a total number of tweet issued by the depressive user suggesting sign of depression were detected and used for the analysis this set of tweet provided u with the depressive tweet dataset which wa used to analyze linguistic feature of tweet showing sign of depression it ha to be mentioned that these tweet were not to be included in the depressive user dataset see figure at the same time more than tweet were also collected in june such tweet were gathered by listening to the public twitter stream during this time span by only considering tweet with spanish textual content a detected by twitter language identification support given that twitter requires more restrictive filter than just the language of the tweet we used a list of the most frequently used spanish word stopwords to retrieve all tweet that included or more of these word the vast majority of spanish tweet should match this criterion a sample of user who did not mention in their profile the word depression and it derivation were selected randomly from the tweet the complete timeline of these user were compiled tweet which were reduced to once retweets were removed these tweet constituted the control dataset to identify the language of a tweet we relied on the language automatically identified by twitter for each tweet selecting tweet in spanish it ha to be noted that these data can contain some tweet from unidentified depressive user,"['selection', 'based', 'filtered', 'realtime', 'streaming', 'support', 'provided', 'api', 'first', 'step', 'selected', 'showed', 'potential', 'sign', 'basis', 'frequent', 'spanish', 'expressed', 'patient', 'suffering', 'clinical', 'setting', 'jointly', 'identified', 'selected', 'psychologist', 'family', 'physician', 'clinical', 'experience', 'based', 'definition', 'general', 'feature', 'according', 'diagnostic', 'statistical', 'manual', 'list', 'english', 'translation', 'shown', 'textbox', 'june', 'including', 'occurrence', 'listed', 'textbox', 'collection', 'select', 'publicly', 'stated', 'textual', 'description', 'associated', 'profile', 'suffered', 'profile', 'description', 'including', 'occurrence', 'depr', 'possible', 'derivation', 'related', 'spanish', 'depre', 'depresin', 'depresivo', 'depresiva', 'deprimido', 'deprimida', 'considered', 'included', 'description', 'profile', 'stated', 'suffered', 'receiving', 'treatment', 'selected', 'analysis', 'selection', 'performed', 'psychologist', 'verifying', 'statement', 'related', 'real', 'expression', 'excluding', 'quote', 'joke', 'fake', 'one', 'depressed', 'recent', 'timeline', 'maximum', 'thus', 'total', 'figure', 'reduced', 'discarding', 'retweets', 'constituted', 'depressive', 'example', 'sentence', 'appearing', 'profile', 'selecting', 'depressive', 'paciente', 'psiquitrico', 'con', 'depresin', 'crnica', 'psychiatric', 'patient', 'chronic', 'example', 'profile', 'sentence', 'indicates', 'colecciono', 'errores', 'traducidos', 'depresivos', 'uno', 'que', 'otro', 'impulso', 'de', 'amor', 'gather', 'error', 'translated', 'depressing', 'one', 'another', 'love', 'impulse', 'example', 'profile', 'sentence', 'doe', 'indicate', 'profile', 'sentence', 'indicating', 'retrieved', 'timeline', 'timeline', 'least', 'suggested', 'sign', 'retained', 'analysis', 'selection', 'performed', 'manually', 'inspecting', 'complete', 'timeline', 'reverse', 'temporal', 'order', 'starting', 'recent', 'one', 'oldest', 'timeline', 'retrieved', 'mean', 'api', 'finally', 'total', 'number', 'issued', 'depressive', 'suggesting', 'sign', 'detected', 'analysis', 'provided', 'u', 'depressive', 'analyze', 'linguistic', 'feature', 'showing', 'sign', 'ha', 'mentioned', 'included', 'depressive', 'see', 'figure', 'also', 'june', 'gathered', 'listening', 'public', 'stream', 'span', 'considering', 'spanish', 'textual', 'content', 'detected', 'language', 'identification', 'support', 'given', 'requires', 'restrictive', 'filter', 'language', 'list', 'frequently', 'spanish', 'stopwords', 'retrieve', 'included', 'vast', 'majority', 'spanish', 'match', 'criterion', 'sample', 'mention', 'profile', 'derivation', 'selected', 'randomly', 'complete', 'timeline', 'compiled', 'reduced', 'retweets', 'removed', 'constituted', 'identify', 'language', 'relied', 'language', 'automatically', 'identified', 'selecting', 'spanish', 'ha', 'noted', 'contain', 'unidentified', 'depressive']","['selection based', 'based filtered', 'filtered realtime', 'realtime streaming', 'streaming support', 'support provided', 'provided api', 'api first', 'first step', 'step selected', 'selected showed', 'showed potential', 'potential sign', 'sign basis', 'basis frequent', 'frequent spanish', 'spanish expressed', 'expressed patient', 'patient suffering', 'suffering clinical', 'clinical setting', 'setting jointly', 'jointly identified', 'identified selected', 'selected psychologist', 'psychologist family', 'family physician', 'physician clinical', 'clinical experience', 'experience based', 'based definition', 'definition general', 'general feature', 'feature according', 'according diagnostic', 'diagnostic statistical', 'statistical manual', 'manual list', 'list english', 'english translation', 'translation shown', 'shown textbox', 'textbox june', 'june including', 'including occurrence', 'occurrence listed', 'listed textbox', 'textbox collection', 'collection select', 'select publicly', 'publicly stated', 'stated textual', 'textual description', 'description associated', 'associated profile', 'profile suffered', 'suffered profile', 'profile description', 'description including', 'including occurrence', 'occurrence depr', 'depr possible', 'possible derivation', 'derivation related', 'related spanish', 'spanish depre', 'depre depresin', 'depresin depresivo', 'depresivo depresiva', 'depresiva deprimido', 'deprimido deprimida', 'deprimida considered', 'considered included', 'included description', 'description profile', 'profile stated', 'stated suffered', 'suffered receiving', 'receiving treatment', 'treatment selected', 'selected analysis', 'analysis selection', 'selection performed', 'performed psychologist', 'psychologist verifying', 'verifying statement', 'statement related', 'related real', 'real expression', 'expression excluding', 'excluding quote', 'quote joke', 'joke fake', 'fake one', 'one depressed', 'depressed recent', 'recent timeline', 'timeline maximum', 'maximum thus', 'thus total', 'total figure', 'figure reduced', 'reduced discarding', 'discarding retweets', 'retweets constituted', 'constituted depressive', 'depressive example', 'example sentence', 'sentence appearing', 'appearing profile', 'profile selecting', 'selecting depressive', 'depressive paciente', 'paciente psiquitrico', 'psiquitrico con', 'con depresin', 'depresin crnica', 'crnica psychiatric', 'psychiatric patient', 'patient chronic', 'chronic example', 'example profile', 'profile sentence', 'sentence indicates', 'indicates colecciono', 'colecciono errores', 'errores traducidos', 'traducidos depresivos', 'depresivos uno', 'uno que', 'que otro', 'otro impulso', 'impulso de', 'de amor', 'amor gather', 'gather error', 'error translated', 'translated depressing', 'depressing one', 'one another', 'another love', 'love impulse', 'impulse example', 'example profile', 'profile sentence', 'sentence doe', 'doe indicate', 'indicate profile', 'profile sentence', 'sentence indicating', 'indicating retrieved', 'retrieved timeline', 'timeline timeline', 'timeline least', 'least suggested', 'suggested sign', 'sign retained', 'retained analysis', 'analysis selection', 'selection performed', 'performed manually', 'manually inspecting', 'inspecting complete', 'complete timeline', 'timeline reverse', 'reverse temporal', 'temporal order', 'order starting', 'starting recent', 'recent one', 'one oldest', 'oldest timeline', 'timeline retrieved', 'retrieved mean', 'mean api', 'api finally', 'finally total', 'total number', 'number issued', 'issued depressive', 'depressive suggesting', 'suggesting sign', 'sign detected', 'detected analysis', 'analysis provided', 'provided u', 'u depressive', 'depressive analyze', 'analyze linguistic', 'linguistic feature', 'feature showing', 'showing sign', 'sign ha', 'ha mentioned', 'mentioned included', 'included depressive', 'depressive see', 'see figure', 'figure also', 'also june', 'june gathered', 'gathered listening', 'listening public', 'public stream', 'stream span', 'span considering', 'considering spanish', 'spanish textual', 'textual content', 'content detected', 'detected language', 'language identification', 'identification support', 'support given', 'given requires', 'requires restrictive', 'restrictive filter', 'filter language', 'language list', 'list frequently', 'frequently spanish', 'spanish stopwords', 'stopwords retrieve', 'retrieve included', 'included vast', 'vast majority', 'majority spanish', 'spanish match', 'match criterion', 'criterion sample', 'sample mention', 'mention profile', 'profile derivation', 'derivation selected', 'selected randomly', 'randomly complete', 'complete timeline', 'timeline compiled', 'compiled reduced', 'reduced retweets', 'retweets removed', 'removed constituted', 'constituted identify', 'identify language', 'language relied', 'relied language', 'language automatically', 'automatically identified', 'identified selecting', 'selecting spanish', 'spanish ha', 'ha noted', 'noted contain', 'contain unidentified', 'unidentified depressive']","['selection based filtered', 'based filtered realtime', 'filtered realtime streaming', 'realtime streaming support', 'streaming support provided', 'support provided api', 'provided api first', 'api first step', 'first step selected', 'step selected showed', 'selected showed potential', 'showed potential sign', 'potential sign basis', 'sign basis frequent', 'basis frequent spanish', 'frequent spanish expressed', 'spanish expressed patient', 'expressed patient suffering', 'patient suffering clinical', 'suffering clinical setting', 'clinical setting jointly', 'setting jointly identified', 'jointly identified selected', 'identified selected psychologist', 'selected psychologist family', 'psychologist family physician', 'family physician clinical', 'physician clinical experience', 'clinical experience based', 'experience based definition', 'based definition general', 'definition general feature', 'general feature according', 'feature according diagnostic', 'according diagnostic statistical', 'diagnostic statistical manual', 'statistical manual list', 'manual list english', 'list english translation', 'english translation shown', 'translation shown textbox', 'shown textbox june', 'textbox june including', 'june including occurrence', 'including occurrence listed', 'occurrence listed textbox', 'listed textbox collection', 'textbox collection select', 'collection select publicly', 'select publicly stated', 'publicly stated textual', 'stated textual description', 'textual description associated', 'description associated profile', 'associated profile suffered', 'profile suffered profile', 'suffered profile description', 'profile description including', 'description including occurrence', 'including occurrence depr', 'occurrence depr possible', 'depr possible derivation', 'possible derivation related', 'derivation related spanish', 'related spanish depre', 'spanish depre depresin', 'depre depresin depresivo', 'depresin depresivo depresiva', 'depresivo depresiva deprimido', 'depresiva deprimido deprimida', 'deprimido deprimida considered', 'deprimida considered included', 'considered included description', 'included description profile', 'description profile stated', 'profile stated suffered', 'stated suffered receiving', 'suffered receiving treatment', 'receiving treatment selected', 'treatment selected analysis', 'selected analysis selection', 'analysis selection performed', 'selection performed psychologist', 'performed psychologist verifying', 'psychologist verifying statement', 'verifying statement related', 'statement related real', 'related real expression', 'real expression excluding', 'expression excluding quote', 'excluding quote joke', 'quote joke fake', 'joke fake one', 'fake one depressed', 'one depressed recent', 'depressed recent timeline', 'recent timeline maximum', 'timeline maximum thus', 'maximum thus total', 'thus total figure', 'total figure reduced', 'figure reduced discarding', 'reduced discarding retweets', 'discarding retweets constituted', 'retweets constituted depressive', 'constituted depressive example', 'depressive example sentence', 'example sentence appearing', 'sentence appearing profile', 'appearing profile selecting', 'profile selecting depressive', 'selecting depressive paciente', 'depressive paciente psiquitrico', 'paciente psiquitrico con', 'psiquitrico con depresin', 'con depresin crnica', 'depresin crnica psychiatric', 'crnica psychiatric patient', 'psychiatric patient chronic', 'patient chronic example', 'chronic example profile', 'example profile sentence', 'profile sentence indicates', 'sentence indicates colecciono', 'indicates colecciono errores', 'colecciono errores traducidos', 'errores traducidos depresivos', 'traducidos depresivos uno', 'depresivos uno que', 'uno que otro', 'que otro impulso', 'otro impulso de', 'impulso de amor', 'de amor gather', 'amor gather error', 'gather error translated', 'error translated depressing', 'translated depressing one', 'depressing one another', 'one another love', 'another love impulse', 'love impulse example', 'impulse example profile', 'example profile sentence', 'profile sentence doe', 'sentence doe indicate', 'doe indicate profile', 'indicate profile sentence', 'profile sentence indicating', 'sentence indicating retrieved', 'indicating retrieved timeline', 'retrieved timeline timeline', 'timeline timeline least', 'timeline least suggested', 'least suggested sign', 'suggested sign retained', 'sign retained analysis', 'retained analysis selection', 'analysis selection performed', 'selection performed manually', 'performed manually inspecting', 'manually inspecting complete', 'inspecting complete timeline', 'complete timeline reverse', 'timeline reverse temporal', 'reverse temporal order', 'temporal order starting', 'order starting recent', 'starting recent one', 'recent one oldest', 'one oldest timeline', 'oldest timeline retrieved', 'timeline retrieved mean', 'retrieved mean api', 'mean api finally', 'api finally total', 'finally total number', 'total number issued', 'number issued depressive', 'issued depressive suggesting', 'depressive suggesting sign', 'suggesting sign detected', 'sign detected analysis', 'detected analysis provided', 'analysis provided u', 'provided u depressive', 'u depressive analyze', 'depressive analyze linguistic', 'analyze linguistic feature', 'linguistic feature showing', 'feature showing sign', 'showing sign ha', 'sign ha mentioned', 'ha mentioned included', 'mentioned included depressive', 'included depressive see', 'depressive see figure', 'see figure also', 'figure also june', 'also june gathered', 'june gathered listening', 'gathered listening public', 'listening public stream', 'public stream span', 'stream span considering', 'span considering spanish', 'considering spanish textual', 'spanish textual content', 'textual content detected', 'content detected language', 'detected language identification', 'language identification support', 'identification support given', 'support given requires', 'given requires restrictive', 'requires restrictive filter', 'restrictive filter language', 'filter language list', 'language list frequently', 'list frequently spanish', 'frequently spanish stopwords', 'spanish stopwords retrieve', 'stopwords retrieve included', 'retrieve included vast', 'included vast majority', 'vast majority spanish', 'majority spanish match', 'spanish match criterion', 'match criterion sample', 'criterion sample mention', 'sample mention profile', 'mention profile derivation', 'profile derivation selected', 'derivation selected randomly', 'selected randomly complete', 'randomly complete timeline', 'complete timeline compiled', 'timeline compiled reduced', 'compiled reduced retweets', 'reduced retweets removed', 'retweets removed constituted', 'removed constituted identify', 'constituted identify language', 'identify language relied', 'language relied language', 'relied language automatically', 'language automatically identified', 'automatically identified selecting', 'identified selecting spanish', 'selecting spanish ha', 'spanish ha noted', 'ha noted contain', 'noted contain unidentified', 'contain unidentified depressive']"
https://aclanthology.org/W18-0608.pdf,1,Data was collected from 7 Cups of Tea an anonymous online chat-based peer support community for emotional distress1 . Users agree at signup that their data may be used for the purposes of research. All the data used for the current study was anonymous and securely stored. This research was performed in line with the ethical and privacy protocols outlined in detail in (Benton et al. 2017). Data from 7 Cups takes the form of written dialogue between users of the service and volunteers who are trained as “active listeners”. A fragment of an exchange between the user of the service (U) and the volunteer (V) might go as follows: For the analyses reported in this paper we used only text generated by users of the service not the volunteers providing peer support. Users who reported depression as their primary concern at sign up were eligible for inclusion in analyses. Our original sample was comprised of 23048 conversations involving 1937 unique users. Users were excluded from the sample if they did not indicate their culture or if they selected ‘Other’. This resulted in the exclusion of 199 and 130 users respectively. The original sample also included users identifying as Native American or American Indian. This group was excluded from analyses since the majority of the data among these users was not English. This resulted in the removal of 15 users leaving a total sample size of 1593.,data wa collected from cup of tea an anonymous online chatbased peer support community for emotional distress user agree at signup that their data may be used for the purpose of research all the data used for the current study wa anonymous and securely stored this research wa performed in line with the ethical and privacy protocol outlined in detail in benton et al data from cup take the form of written dialogue between user of the service and volunteer who are trained a active listener a fragment of an exchange between the user of the service u and the volunteer v might go a follows for the analysis reported in this paper we used only text generated by user of the service not the volunteer providing peer support user who reported depression a their primary concern at sign up were eligible for inclusion in analysis our original sample wa comprised of conversation involving unique user user were excluded from the sample if they did not indicate their culture or if they selected other this resulted in the exclusion of and user respectively the original sample also included user identifying a native american or american indian this group wa excluded from analysis since the majority of the data among these user wa not english this resulted in the removal of user leaving a total sample size of,"['cup', 'tea', 'anonymous', 'online', 'chatbased', 'peer', 'support', 'emotional', 'distress', 'agree', 'signup', 'may', 'purpose', 'research', 'current', 'study', 'anonymous', 'securely', 'stored', 'research', 'performed', 'line', 'ethical', 'privacy', 'protocol', 'outlined', 'detail', 'benton', 'et', 'al', 'cup', 'take', 'form', 'written', 'dialogue', 'service', 'volunteer', 'trained', 'active', 'listener', 'fragment', 'exchange', 'service', 'u', 'volunteer', 'v', 'might', 'go', 'follows', 'analysis', 'reported', 'paper', 'text', 'generated', 'service', 'volunteer', 'providing', 'peer', 'support', 'reported', 'primary', 'concern', 'sign', 'eligible', 'inclusion', 'analysis', 'original', 'sample', 'comprised', 'conversation', 'involving', 'unique', 'excluded', 'sample', 'indicate', 'culture', 'selected', 'resulted', 'exclusion', 'respectively', 'original', 'sample', 'also', 'included', 'identifying', 'native', 'american', 'american', 'indian', 'group', 'excluded', 'analysis', 'since', 'majority', 'among', 'english', 'resulted', 'removal', 'leaving', 'total', 'sample', 'size']","['cup tea', 'tea anonymous', 'anonymous online', 'online chatbased', 'chatbased peer', 'peer support', 'support emotional', 'emotional distress', 'distress agree', 'agree signup', 'signup may', 'may purpose', 'purpose research', 'research current', 'current study', 'study anonymous', 'anonymous securely', 'securely stored', 'stored research', 'research performed', 'performed line', 'line ethical', 'ethical privacy', 'privacy protocol', 'protocol outlined', 'outlined detail', 'detail benton', 'benton et', 'et al', 'al cup', 'cup take', 'take form', 'form written', 'written dialogue', 'dialogue service', 'service volunteer', 'volunteer trained', 'trained active', 'active listener', 'listener fragment', 'fragment exchange', 'exchange service', 'service u', 'u volunteer', 'volunteer v', 'v might', 'might go', 'go follows', 'follows analysis', 'analysis reported', 'reported paper', 'paper text', 'text generated', 'generated service', 'service volunteer', 'volunteer providing', 'providing peer', 'peer support', 'support reported', 'reported primary', 'primary concern', 'concern sign', 'sign eligible', 'eligible inclusion', 'inclusion analysis', 'analysis original', 'original sample', 'sample comprised', 'comprised conversation', 'conversation involving', 'involving unique', 'unique excluded', 'excluded sample', 'sample indicate', 'indicate culture', 'culture selected', 'selected resulted', 'resulted exclusion', 'exclusion respectively', 'respectively original', 'original sample', 'sample also', 'also included', 'included identifying', 'identifying native', 'native american', 'american american', 'american indian', 'indian group', 'group excluded', 'excluded analysis', 'analysis since', 'since majority', 'majority among', 'among english', 'english resulted', 'resulted removal', 'removal leaving', 'leaving total', 'total sample', 'sample size']","['cup tea anonymous', 'tea anonymous online', 'anonymous online chatbased', 'online chatbased peer', 'chatbased peer support', 'peer support emotional', 'support emotional distress', 'emotional distress agree', 'distress agree signup', 'agree signup may', 'signup may purpose', 'may purpose research', 'purpose research current', 'research current study', 'current study anonymous', 'study anonymous securely', 'anonymous securely stored', 'securely stored research', 'stored research performed', 'research performed line', 'performed line ethical', 'line ethical privacy', 'ethical privacy protocol', 'privacy protocol outlined', 'protocol outlined detail', 'outlined detail benton', 'detail benton et', 'benton et al', 'et al cup', 'al cup take', 'cup take form', 'take form written', 'form written dialogue', 'written dialogue service', 'dialogue service volunteer', 'service volunteer trained', 'volunteer trained active', 'trained active listener', 'active listener fragment', 'listener fragment exchange', 'fragment exchange service', 'exchange service u', 'service u volunteer', 'u volunteer v', 'volunteer v might', 'v might go', 'might go follows', 'go follows analysis', 'follows analysis reported', 'analysis reported paper', 'reported paper text', 'paper text generated', 'text generated service', 'generated service volunteer', 'service volunteer providing', 'volunteer providing peer', 'providing peer support', 'peer support reported', 'support reported primary', 'reported primary concern', 'primary concern sign', 'concern sign eligible', 'sign eligible inclusion', 'eligible inclusion analysis', 'inclusion analysis original', 'analysis original sample', 'original sample comprised', 'sample comprised conversation', 'comprised conversation involving', 'conversation involving unique', 'involving unique excluded', 'unique excluded sample', 'excluded sample indicate', 'sample indicate culture', 'indicate culture selected', 'culture selected resulted', 'selected resulted exclusion', 'resulted exclusion respectively', 'exclusion respectively original', 'respectively original sample', 'original sample also', 'sample also included', 'also included identifying', 'included identifying native', 'identifying native american', 'native american american', 'american american indian', 'american indian group', 'indian group excluded', 'group excluded analysis', 'excluded analysis since', 'analysis since majority', 'since majority among', 'majority among english', 'among english resulted', 'english resulted removal', 'resulted removal leaving', 'removal leaving total', 'leaving total sample', 'total sample size']"
https://dl.acm.org/doi/pdf/10.1145/3359169,1,All data analyzed in this study was sourced (with license and consent) from the Talklife and 7Cups platforms. Additionally to maintain user anonymity all personally identifiable information was removed from the dataset before any findings were reported. Additionally all work was approved by our institution’s Institutional Review Board.,all data analyzed in this study wa sourced with license and consent from the talklife and cup platform additionally to maintain user anonymity all personally identifiable information wa removed from the dataset before any finding were reported additionally all work wa approved by our institution institutional review board,"['analyzed', 'study', 'sourced', 'license', 'consent', 'talklife', 'cup', 'platform', 'additionally', 'maintain', 'anonymity', 'personally', 'identifiable', 'removed', 'finding', 'reported', 'additionally', 'approved', 'institution', 'institutional', 'review', 'board']","['analyzed study', 'study sourced', 'sourced license', 'license consent', 'consent talklife', 'talklife cup', 'cup platform', 'platform additionally', 'additionally maintain', 'maintain anonymity', 'anonymity personally', 'personally identifiable', 'identifiable removed', 'removed finding', 'finding reported', 'reported additionally', 'additionally approved', 'approved institution', 'institution institutional', 'institutional review', 'review board']","['analyzed study sourced', 'study sourced license', 'sourced license consent', 'license consent talklife', 'consent talklife cup', 'talklife cup platform', 'cup platform additionally', 'platform additionally maintain', 'additionally maintain anonymity', 'maintain anonymity personally', 'anonymity personally identifiable', 'personally identifiable removed', 'identifiable removed finding', 'removed finding reported', 'finding reported additionally', 'reported additionally approved', 'additionally approved institution', 'approved institution institutional', 'institution institutional review', 'institutional review board']"
https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-018-2197-z,1,Ethics approval and consent to participate Not applicable.,ethic approval and consent to participate not applicable,"['ethic', 'approval', 'consent', 'participate', 'applicable']","['ethic approval', 'approval consent', 'consent participate', 'participate applicable']","['ethic approval consent', 'approval consent participate', 'consent participate applicable']"
https://ieeexplore.ieee.org/abstract/document/8609647,0,Reddit is a multilingual Online Social Network founded in 2005 and organized in subcommunities by areas of interest called subreddits. We obtained data from the Reddit's data repository4 focusing on four subreddits where people discuss issues related to mental heath disorders: Depression (/r/depression) Suicide Watch (/r/Suicide Watch) Anxiety (/r/anxiety) and Bipolar (/r/bipolar). Our dataset is comprised of user activities (posts and comments) that took place between 2011 and 201 7. Here we focus on data from January 2017 to December 2017. In total we obtained 261511 posts and 1256669 comments from 184708 unique users. Table I shows the total number of users posts and comments per subreddit. The total number of comments in each community is at least 4.2 times larger than the number of posts which suggests a supportive behavior among users.,reddit is a multilingual online social network founded in and organized in subcommunities by area of interest called subreddits we obtained data from the reddits data repository focusing on four subreddits where people discus issue related to mental heath disorder depression rdepression suicide watch rsuicide watch anxiety ranxiety and bipolar rbipolar our dataset is comprised of user activity post and comment that took place between and here we focus on data from january to december in total we obtained post and comment from unique user table i show the total number of user post and comment per subreddit the total number of comment in each community is at least time larger than the number of post which suggests a supportive behavior among user,"['reddit', 'multilingual', 'online', 'network', 'founded', 'organized', 'subcommunities', 'area', 'interest', 'called', 'obtained', 'reddits', 'repository', 'focusing', 'four', 'people', 'discus', 'issue', 'related', 'heath', 'rdepression', 'watch', 'rsuicide', 'watch', 'anxiety', 'ranxiety', 'bipolar', 'rbipolar', 'comprised', 'activity', 'took', 'place', 'focus', 'january', 'december', 'total', 'obtained', 'unique', 'table', 'show', 'total', 'number', 'per', 'subreddit', 'total', 'number', 'least', 'larger', 'number', 'suggests', 'supportive', 'behavior', 'among']","['reddit multilingual', 'multilingual online', 'online network', 'network founded', 'founded organized', 'organized subcommunities', 'subcommunities area', 'area interest', 'interest called', 'called obtained', 'obtained reddits', 'reddits repository', 'repository focusing', 'focusing four', 'four people', 'people discus', 'discus issue', 'issue related', 'related heath', 'heath rdepression', 'rdepression watch', 'watch rsuicide', 'rsuicide watch', 'watch anxiety', 'anxiety ranxiety', 'ranxiety bipolar', 'bipolar rbipolar', 'rbipolar comprised', 'comprised activity', 'activity took', 'took place', 'place focus', 'focus january', 'january december', 'december total', 'total obtained', 'obtained unique', 'unique table', 'table show', 'show total', 'total number', 'number per', 'per subreddit', 'subreddit total', 'total number', 'number least', 'least larger', 'larger number', 'number suggests', 'suggests supportive', 'supportive behavior', 'behavior among']","['reddit multilingual online', 'multilingual online network', 'online network founded', 'network founded organized', 'founded organized subcommunities', 'organized subcommunities area', 'subcommunities area interest', 'area interest called', 'interest called obtained', 'called obtained reddits', 'obtained reddits repository', 'reddits repository focusing', 'repository focusing four', 'focusing four people', 'four people discus', 'people discus issue', 'discus issue related', 'issue related heath', 'related heath rdepression', 'heath rdepression watch', 'rdepression watch rsuicide', 'watch rsuicide watch', 'rsuicide watch anxiety', 'watch anxiety ranxiety', 'anxiety ranxiety bipolar', 'ranxiety bipolar rbipolar', 'bipolar rbipolar comprised', 'rbipolar comprised activity', 'comprised activity took', 'activity took place', 'took place focus', 'place focus january', 'focus january december', 'january december total', 'december total obtained', 'total obtained unique', 'obtained unique table', 'unique table show', 'table show total', 'show total number', 'total number per', 'number per subreddit', 'per subreddit total', 'subreddit total number', 'total number least', 'number least larger', 'least larger number', 'larger number suggests', 'number suggests supportive', 'suggests supportive behavior', 'supportive behavior among']"
