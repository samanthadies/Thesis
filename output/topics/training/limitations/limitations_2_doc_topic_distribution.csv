Link to paper,Score,Text,Cleaned,unigrams,bigrams,trigrams,topic1,topic2,topic3,topic4,topic5,topic6,topic7,topic8
https://link.springer.com/content/pdf/10.1140/epjds/s13688-017-0110-z.pdf,0,Data collection was crowdsourced using Amazon’s Mechanical Turk (MTurk) crowdwork platform. Separate surveys were created for depressed and healthy individuals. In the depressed survey participants were invited to complete a survey that involved passing a series of inclusion criteria responding to a standardized clinical depression survey answering questions related to demographics and history of depression and sharing social media history. We used the CES-D (Center for Epidemiologic Studies Depression Scale) questionnaire to screen participant depression levels []. CES-D assessment quality has been demonstrated as on-par with other depression inventories including the Beck Depression Inventory and the Kellner Symptom Questionnaire [ ]. Healthy participants were screened to ensure no history of depression and active Instagram use. See Additional file  for actual survey text. Qualified participants were asked to share their Instagram usernames and history. An app embedded in the survey allowed participants to securely log into their Instagram accounts and agree to share their data.b Upon securing consent we made a one-time collection of participants’ entire Instagram posting history. In total we collected  photographs from  Instagram users  of whom had a history of depression. We asked a different set of MTurk crowdworkers to rate the Instagram photographs collected. This new task asked participants to rate a random selection of  photos from the data we collected. Raters were asked to judge how interesting likable happy and sad each photo seemed on a continuous - scale. Each photo was rated by at least three different raters and ratings were averaged across raters. Raters were not informed that photos were from Instagram nor were they given any information about the study participants who provided the photos including mental health status. Each ratings category showed good inter-rater agreement. Only a subset of participant Instagram photos were rated (N = ). We limited ratings data to a subset because this task was time-consuming for crowdworkers and so proved a costly form of data collection. For the depressed sample ratings were only made for photos posted within a year in either direction of the date of first depression diagnosis. Within this subset for each user the nearest  posts prior to the diagnosis date were rated. For the control population the most recent  photos from each user’s date of participation in this study were rated.Several different types of information were extracted from the collected Instagram data. We used total posts per user per day as a measure of user activity. We gauged community reaction by counting the number of comments and ‘likes’ each posted photograph received. Face detection software was used to determine whether or not a photograph contained a human face as well as count the total number of faces in each photo as a proxy measure for participants’ social activity levels. Pixel-level averages were computed for Hue Saturation and Value (HSV) three color properties commonly used in image analysis. Hue describes an image’s coloring on the light spectrum (ranging from red to blue/purple). Lower hue values indicate more red and higher hue values indicate more blue. Saturation refers to the vividness of an image. Low saturation makes an image appear grey and faded. Value refers to image brightness. Lower brightness scores indicate a darker image. See Figure  for a comparison of high and low HSV values. We also checked metadata to assess whether an Instagram-provided filter was applied to alter the appearance of a photograph. Collectively these measures served as the feature set in our primary model. For the separate model fit on ratings data we used only the four ratings categories (happy sad likable interesting) as predictors.,data collection wa crowdsourced using amazon mechanical turk mturk crowdwork platform separate survey were created for depressed and healthy individual in the depressed survey participant were invited to complete a survey that involved passing a series of inclusion criterion responding to a standardized clinical depression survey answering question related to demographic and history of depression and sharing social medium history we used the cesd center for epidemiologic study depression scale questionnaire to screen participant depression level cesd assessment quality ha been demonstrated a onpar with other depression inventory including the beck depression inventory and the kellner symptom questionnaire healthy participant were screened to ensure no history of depression and active instagram use see additional file for actual survey text qualified participant were asked to share their instagram usernames and history an app embedded in the survey allowed participant to securely log into their instagram account and agree to share their datab upon securing consent we made a onetime collection of participant entire instagram posting history in total we collected photograph from instagram user of whom had a history of depression we asked a different set of mturk crowdworkers to rate the instagram photograph collected this new task asked participant to rate a random selection of photo from the data we collected raters were asked to judge how interesting likable happy and sad each photo seemed on a continuous scale each photo wa rated by at least three different raters and rating were averaged across raters raters were not informed that photo were from instagram nor were they given any information about the study participant who provided the photo including mental health status each rating category showed good interrater agreement only a subset of participant instagram photo were rated n we limited rating data to a subset because this task wa timeconsuming for crowdworkers and so proved a costly form of data collection for the depressed sample rating were only made for photo posted within a year in either direction of the date of first depression diagnosis within this subset for each user the nearest post prior to the diagnosis date were rated for the control population the most recent photo from each user date of participation in this study were ratedseveral different type of information were extracted from the collected instagram data we used total post per user per day a a measure of user activity we gauged community reaction by counting the number of comment and like each posted photograph received face detection software wa used to determine whether or not a photograph contained a human face a well a count the total number of face in each photo a a proxy measure for participant social activity level pixellevel average were computed for hue saturation and value hsv three color property commonly used in image analysis hue describes an image coloring on the light spectrum ranging from red to bluepurple lower hue value indicate more red and higher hue value indicate more blue saturation refers to the vividness of an image low saturation make an image appear grey and faded value refers to image brightness lower brightness score indicate a darker image see figure for a comparison of high and low hsv value we also checked metadata to ass whether an instagramprovided filter wa applied to alter the appearance of a photograph collectively these measure served a the feature set in our primary model for the separate model fit on rating data we used only the four rating category happy sad likable interesting a predictor,"['data', 'collection', 'wa', 'crowdsourced', 'using', 'amazon', 'mechanical', 'turk', 'mturk', 'crowdwork', 'platform', 'separate', 'survey', 'created', 'depressed', 'healthy', 'individual', 'depressed', 'survey', 'participant', 'invited', 'complete', 'survey', 'involved', 'passing', 'series', 'inclusion', 'criterion', 'responding', 'standardized', 'clinical', 'depression', 'survey', 'answering', 'question', 'related', 'demographic', 'history', 'depression', 'sharing', 'social', 'medium', 'history', 'used', 'cesd', 'center', 'epidemiologic', 'study', 'depression', 'scale', 'questionnaire', 'screen', 'participant', 'depression', 'level', 'cesd', 'assessment', 'quality', 'ha', 'demonstrated', 'onpar', 'depression', 'inventory', 'including', 'beck', 'depression', 'inventory', 'kellner', 'symptom', 'questionnaire', 'healthy', 'participant', 'screened', 'ensure', 'history', 'depression', 'active', 'instagram', 'use', 'see', 'additional', 'file', 'actual', 'survey', 'text', 'qualified', 'participant', 'asked', 'share', 'instagram', 'usernames', 'history', 'app', 'embedded', 'survey', 'allowed', 'participant', 'securely', 'log', 'instagram', 'account', 'agree', 'share', 'datab', 'upon', 'securing', 'consent', 'made', 'onetime', 'collection', 'participant', 'entire', 'instagram', 'posting', 'history', 'total', 'collected', 'photograph', 'instagram', 'user', 'history', 'depression', 'asked', 'different', 'set', 'mturk', 'crowdworkers', 'rate', 'instagram', 'photograph', 'collected', 'new', 'task', 'asked', 'participant', 'rate', 'random', 'selection', 'photo', 'data', 'collected', 'raters', 'asked', 'judge', 'interesting', 'likable', 'happy', 'sad', 'photo', 'seemed', 'continuous', 'scale', 'photo', 'wa', 'rated', 'least', 'three', 'different', 'raters', 'rating', 'averaged', 'across', 'raters', 'raters', 'informed', 'photo', 'instagram', 'given', 'information', 'study', 'participant', 'provided', 'photo', 'including', 'mental', 'health', 'status', 'rating', 'category', 'showed', 'good', 'interrater', 'agreement', 'subset', 'participant', 'instagram', 'photo', 'rated', 'n', 'limited', 'rating', 'data', 'subset', 'task', 'wa', 'timeconsuming', 'crowdworkers', 'proved', 'costly', 'form', 'data', 'collection', 'depressed', 'sample', 'rating', 'made', 'photo', 'posted', 'within', 'year', 'either', 'direction', 'date', 'first', 'depression', 'diagnosis', 'within', 'subset', 'user', 'nearest', 'post', 'prior', 'diagnosis', 'date', 'rated', 'control', 'population', 'recent', 'photo', 'user', 'date', 'participation', 'study', 'ratedseveral', 'different', 'type', 'information', 'extracted', 'collected', 'instagram', 'data', 'used', 'total', 'post', 'per', 'user', 'per', 'day', 'measure', 'user', 'activity', 'gauged', 'community', 'reaction', 'counting', 'number', 'comment', 'like', 'posted', 'photograph', 'received', 'face', 'detection', 'software', 'wa', 'used', 'determine', 'whether', 'photograph', 'contained', 'human', 'face', 'well', 'count', 'total', 'number', 'face', 'photo', 'proxy', 'measure', 'participant', 'social', 'activity', 'level', 'pixellevel', 'average', 'computed', 'hue', 'saturation', 'value', 'hsv', 'three', 'color', 'property', 'commonly', 'used', 'image', 'analysis', 'hue', 'describes', 'image', 'coloring', 'light', 'spectrum', 'ranging', 'red', 'bluepurple', 'lower', 'hue', 'value', 'indicate', 'red', 'higher', 'hue', 'value', 'indicate', 'blue', 'saturation', 'refers', 'vividness', 'image', 'low', 'saturation', 'make', 'image', 'appear', 'grey', 'faded', 'value', 'refers', 'image', 'brightness', 'lower', 'brightness', 'score', 'indicate', 'darker', 'image', 'see', 'figure', 'comparison', 'high', 'low', 'hsv', 'value', 'also', 'checked', 'metadata', 'ass', 'whether', 'instagramprovided', 'filter', 'wa', 'applied', 'alter', 'appearance', 'photograph', 'collectively', 'measure', 'served', 'feature', 'set', 'primary', 'model', 'separate', 'model', 'fit', 'rating', 'data', 'used', 'four', 'rating', 'category', 'happy', 'sad', 'likable', 'interesting', 'predictor']","['data collection', 'collection wa', 'wa crowdsourced', 'crowdsourced using', 'using amazon', 'amazon mechanical', 'mechanical turk', 'turk mturk', 'mturk crowdwork', 'crowdwork platform', 'platform separate', 'separate survey', 'survey created', 'created depressed', 'depressed healthy', 'healthy individual', 'individual depressed', 'depressed survey', 'survey participant', 'participant invited', 'invited complete', 'complete survey', 'survey involved', 'involved passing', 'passing series', 'series inclusion', 'inclusion criterion', 'criterion responding', 'responding standardized', 'standardized clinical', 'clinical depression', 'depression survey', 'survey answering', 'answering question', 'question related', 'related demographic', 'demographic history', 'history depression', 'depression sharing', 'sharing social', 'social medium', 'medium history', 'history used', 'used cesd', 'cesd center', 'center epidemiologic', 'epidemiologic study', 'study depression', 'depression scale', 'scale questionnaire', 'questionnaire screen', 'screen participant', 'participant depression', 'depression level', 'level cesd', 'cesd assessment', 'assessment quality', 'quality ha', 'ha demonstrated', 'demonstrated onpar', 'onpar depression', 'depression inventory', 'inventory including', 'including beck', 'beck depression', 'depression inventory', 'inventory kellner', 'kellner symptom', 'symptom questionnaire', 'questionnaire healthy', 'healthy participant', 'participant screened', 'screened ensure', 'ensure history', 'history depression', 'depression active', 'active instagram', 'instagram use', 'use see', 'see additional', 'additional file', 'file actual', 'actual survey', 'survey text', 'text qualified', 'qualified participant', 'participant asked', 'asked share', 'share instagram', 'instagram usernames', 'usernames history', 'history app', 'app embedded', 'embedded survey', 'survey allowed', 'allowed participant', 'participant securely', 'securely log', 'log instagram', 'instagram account', 'account agree', 'agree share', 'share datab', 'datab upon', 'upon securing', 'securing consent', 'consent made', 'made onetime', 'onetime collection', 'collection participant', 'participant entire', 'entire instagram', 'instagram posting', 'posting history', 'history total', 'total collected', 'collected photograph', 'photograph instagram', 'instagram user', 'user history', 'history depression', 'depression asked', 'asked different', 'different set', 'set mturk', 'mturk crowdworkers', 'crowdworkers rate', 'rate instagram', 'instagram photograph', 'photograph collected', 'collected new', 'new task', 'task asked', 'asked participant', 'participant rate', 'rate random', 'random selection', 'selection photo', 'photo data', 'data collected', 'collected raters', 'raters asked', 'asked judge', 'judge interesting', 'interesting likable', 'likable happy', 'happy sad', 'sad photo', 'photo seemed', 'seemed continuous', 'continuous scale', 'scale photo', 'photo wa', 'wa rated', 'rated least', 'least three', 'three different', 'different raters', 'raters rating', 'rating averaged', 'averaged across', 'across raters', 'raters raters', 'raters informed', 'informed photo', 'photo instagram', 'instagram given', 'given information', 'information study', 'study participant', 'participant provided', 'provided photo', 'photo including', 'including mental', 'mental health', 'health status', 'status rating', 'rating category', 'category showed', 'showed good', 'good interrater', 'interrater agreement', 'agreement subset', 'subset participant', 'participant instagram', 'instagram photo', 'photo rated', 'rated n', 'n limited', 'limited rating', 'rating data', 'data subset', 'subset task', 'task wa', 'wa timeconsuming', 'timeconsuming crowdworkers', 'crowdworkers proved', 'proved costly', 'costly form', 'form data', 'data collection', 'collection depressed', 'depressed sample', 'sample rating', 'rating made', 'made photo', 'photo posted', 'posted within', 'within year', 'year either', 'either direction', 'direction date', 'date first', 'first depression', 'depression diagnosis', 'diagnosis within', 'within subset', 'subset user', 'user nearest', 'nearest post', 'post prior', 'prior diagnosis', 'diagnosis date', 'date rated', 'rated control', 'control population', 'population recent', 'recent photo', 'photo user', 'user date', 'date participation', 'participation study', 'study ratedseveral', 'ratedseveral different', 'different type', 'type information', 'information extracted', 'extracted collected', 'collected instagram', 'instagram data', 'data used', 'used total', 'total post', 'post per', 'per user', 'user per', 'per day', 'day measure', 'measure user', 'user activity', 'activity gauged', 'gauged community', 'community reaction', 'reaction counting', 'counting number', 'number comment', 'comment like', 'like posted', 'posted photograph', 'photograph received', 'received face', 'face detection', 'detection software', 'software wa', 'wa used', 'used determine', 'determine whether', 'whether photograph', 'photograph contained', 'contained human', 'human face', 'face well', 'well count', 'count total', 'total number', 'number face', 'face photo', 'photo proxy', 'proxy measure', 'measure participant', 'participant social', 'social activity', 'activity level', 'level pixellevel', 'pixellevel average', 'average computed', 'computed hue', 'hue saturation', 'saturation value', 'value hsv', 'hsv three', 'three color', 'color property', 'property commonly', 'commonly used', 'used image', 'image analysis', 'analysis hue', 'hue describes', 'describes image', 'image coloring', 'coloring light', 'light spectrum', 'spectrum ranging', 'ranging red', 'red bluepurple', 'bluepurple lower', 'lower hue', 'hue value', 'value indicate', 'indicate red', 'red higher', 'higher hue', 'hue value', 'value indicate', 'indicate blue', 'blue saturation', 'saturation refers', 'refers vividness', 'vividness image', 'image low', 'low saturation', 'saturation make', 'make image', 'image appear', 'appear grey', 'grey faded', 'faded value', 'value refers', 'refers image', 'image brightness', 'brightness lower', 'lower brightness', 'brightness score', 'score indicate', 'indicate darker', 'darker image', 'image see', 'see figure', 'figure comparison', 'comparison high', 'high low', 'low hsv', 'hsv value', 'value also', 'also checked', 'checked metadata', 'metadata ass', 'ass whether', 'whether instagramprovided', 'instagramprovided filter', 'filter wa', 'wa applied', 'applied alter', 'alter appearance', 'appearance photograph', 'photograph collectively', 'collectively measure', 'measure served', 'served feature', 'feature set', 'set primary', 'primary model', 'model separate', 'separate model', 'model fit', 'fit rating', 'rating data', 'data used', 'used four', 'four rating', 'rating category', 'category happy', 'happy sad', 'sad likable', 'likable interesting', 'interesting predictor']","['data collection wa', 'collection wa crowdsourced', 'wa crowdsourced using', 'crowdsourced using amazon', 'using amazon mechanical', 'amazon mechanical turk', 'mechanical turk mturk', 'turk mturk crowdwork', 'mturk crowdwork platform', 'crowdwork platform separate', 'platform separate survey', 'separate survey created', 'survey created depressed', 'created depressed healthy', 'depressed healthy individual', 'healthy individual depressed', 'individual depressed survey', 'depressed survey participant', 'survey participant invited', 'participant invited complete', 'invited complete survey', 'complete survey involved', 'survey involved passing', 'involved passing series', 'passing series inclusion', 'series inclusion criterion', 'inclusion criterion responding', 'criterion responding standardized', 'responding standardized clinical', 'standardized clinical depression', 'clinical depression survey', 'depression survey answering', 'survey answering question', 'answering question related', 'question related demographic', 'related demographic history', 'demographic history depression', 'history depression sharing', 'depression sharing social', 'sharing social medium', 'social medium history', 'medium history used', 'history used cesd', 'used cesd center', 'cesd center epidemiologic', 'center epidemiologic study', 'epidemiologic study depression', 'study depression scale', 'depression scale questionnaire', 'scale questionnaire screen', 'questionnaire screen participant', 'screen participant depression', 'participant depression level', 'depression level cesd', 'level cesd assessment', 'cesd assessment quality', 'assessment quality ha', 'quality ha demonstrated', 'ha demonstrated onpar', 'demonstrated onpar depression', 'onpar depression inventory', 'depression inventory including', 'inventory including beck', 'including beck depression', 'beck depression inventory', 'depression inventory kellner', 'inventory kellner symptom', 'kellner symptom questionnaire', 'symptom questionnaire healthy', 'questionnaire healthy participant', 'healthy participant screened', 'participant screened ensure', 'screened ensure history', 'ensure history depression', 'history depression active', 'depression active instagram', 'active instagram use', 'instagram use see', 'use see additional', 'see additional file', 'additional file actual', 'file actual survey', 'actual survey text', 'survey text qualified', 'text qualified participant', 'qualified participant asked', 'participant asked share', 'asked share instagram', 'share instagram usernames', 'instagram usernames history', 'usernames history app', 'history app embedded', 'app embedded survey', 'embedded survey allowed', 'survey allowed participant', 'allowed participant securely', 'participant securely log', 'securely log instagram', 'log instagram account', 'instagram account agree', 'account agree share', 'agree share datab', 'share datab upon', 'datab upon securing', 'upon securing consent', 'securing consent made', 'consent made onetime', 'made onetime collection', 'onetime collection participant', 'collection participant entire', 'participant entire instagram', 'entire instagram posting', 'instagram posting history', 'posting history total', 'history total collected', 'total collected photograph', 'collected photograph instagram', 'photograph instagram user', 'instagram user history', 'user history depression', 'history depression asked', 'depression asked different', 'asked different set', 'different set mturk', 'set mturk crowdworkers', 'mturk crowdworkers rate', 'crowdworkers rate instagram', 'rate instagram photograph', 'instagram photograph collected', 'photograph collected new', 'collected new task', 'new task asked', 'task asked participant', 'asked participant rate', 'participant rate random', 'rate random selection', 'random selection photo', 'selection photo data', 'photo data collected', 'data collected raters', 'collected raters asked', 'raters asked judge', 'asked judge interesting', 'judge interesting likable', 'interesting likable happy', 'likable happy sad', 'happy sad photo', 'sad photo seemed', 'photo seemed continuous', 'seemed continuous scale', 'continuous scale photo', 'scale photo wa', 'photo wa rated', 'wa rated least', 'rated least three', 'least three different', 'three different raters', 'different raters rating', 'raters rating averaged', 'rating averaged across', 'averaged across raters', 'across raters raters', 'raters raters informed', 'raters informed photo', 'informed photo instagram', 'photo instagram given', 'instagram given information', 'given information study', 'information study participant', 'study participant provided', 'participant provided photo', 'provided photo including', 'photo including mental', 'including mental health', 'mental health status', 'health status rating', 'status rating category', 'rating category showed', 'category showed good', 'showed good interrater', 'good interrater agreement', 'interrater agreement subset', 'agreement subset participant', 'subset participant instagram', 'participant instagram photo', 'instagram photo rated', 'photo rated n', 'rated n limited', 'n limited rating', 'limited rating data', 'rating data subset', 'data subset task', 'subset task wa', 'task wa timeconsuming', 'wa timeconsuming crowdworkers', 'timeconsuming crowdworkers proved', 'crowdworkers proved costly', 'proved costly form', 'costly form data', 'form data collection', 'data collection depressed', 'collection depressed sample', 'depressed sample rating', 'sample rating made', 'rating made photo', 'made photo posted', 'photo posted within', 'posted within year', 'within year either', 'year either direction', 'either direction date', 'direction date first', 'date first depression', 'first depression diagnosis', 'depression diagnosis within', 'diagnosis within subset', 'within subset user', 'subset user nearest', 'user nearest post', 'nearest post prior', 'post prior diagnosis', 'prior diagnosis date', 'diagnosis date rated', 'date rated control', 'rated control population', 'control population recent', 'population recent photo', 'recent photo user', 'photo user date', 'user date participation', 'date participation study', 'participation study ratedseveral', 'study ratedseveral different', 'ratedseveral different type', 'different type information', 'type information extracted', 'information extracted collected', 'extracted collected instagram', 'collected instagram data', 'instagram data used', 'data used total', 'used total post', 'total post per', 'post per user', 'per user per', 'user per day', 'per day measure', 'day measure user', 'measure user activity', 'user activity gauged', 'activity gauged community', 'gauged community reaction', 'community reaction counting', 'reaction counting number', 'counting number comment', 'number comment like', 'comment like posted', 'like posted photograph', 'posted photograph received', 'photograph received face', 'received face detection', 'face detection software', 'detection software wa', 'software wa used', 'wa used determine', 'used determine whether', 'determine whether photograph', 'whether photograph contained', 'photograph contained human', 'contained human face', 'human face well', 'face well count', 'well count total', 'count total number', 'total number face', 'number face photo', 'face photo proxy', 'photo proxy measure', 'proxy measure participant', 'measure participant social', 'participant social activity', 'social activity level', 'activity level pixellevel', 'level pixellevel average', 'pixellevel average computed', 'average computed hue', 'computed hue saturation', 'hue saturation value', 'saturation value hsv', 'value hsv three', 'hsv three color', 'three color property', 'color property commonly', 'property commonly used', 'commonly used image', 'used image analysis', 'image analysis hue', 'analysis hue describes', 'hue describes image', 'describes image coloring', 'image coloring light', 'coloring light spectrum', 'light spectrum ranging', 'spectrum ranging red', 'ranging red bluepurple', 'red bluepurple lower', 'bluepurple lower hue', 'lower hue value', 'hue value indicate', 'value indicate red', 'indicate red higher', 'red higher hue', 'higher hue value', 'hue value indicate', 'value indicate blue', 'indicate blue saturation', 'blue saturation refers', 'saturation refers vividness', 'refers vividness image', 'vividness image low', 'image low saturation', 'low saturation make', 'saturation make image', 'make image appear', 'image appear grey', 'appear grey faded', 'grey faded value', 'faded value refers', 'value refers image', 'refers image brightness', 'image brightness lower', 'brightness lower brightness', 'lower brightness score', 'brightness score indicate', 'score indicate darker', 'indicate darker image', 'darker image see', 'image see figure', 'see figure comparison', 'figure comparison high', 'comparison high low', 'high low hsv', 'low hsv value', 'hsv value also', 'value also checked', 'also checked metadata', 'checked metadata ass', 'metadata ass whether', 'ass whether instagramprovided', 'whether instagramprovided filter', 'instagramprovided filter wa', 'filter wa applied', 'wa applied alter', 'applied alter appearance', 'alter appearance photograph', 'appearance photograph collectively', 'photograph collectively measure', 'collectively measure served', 'measure served feature', 'served feature set', 'feature set primary', 'set primary model', 'primary model separate', 'model separate model', 'separate model fit', 'model fit rating', 'fit rating data', 'rating data used', 'data used four', 'used four rating', 'four rating category', 'rating category happy', 'category happy sad', 'happy sad likable', 'sad likable interesting', 'likable interesting predictor']",,,,,,,,
https://dl.acm.org/doi/abs/10.1145/2858036.2858207 ,1,We split our data into two sequential time periods (t1 from Feb 11 2014 to Aug 11 2014 and t2 from Aug 12 2014 to November 11 2014). Using these two time periods we created two sets of users. Note that since Reddit does not enforce the real name rule of having exactly one account per person our reference to “users” in this paper is equivalent to “user accounts”. First we identified those users that posted on MHs during t1 but did not post on SW during t1 or t2 (i.e. users that discuss mental health topics but not on SW; hereafter “MH”). The second class included those who posted on MHs during t1 and posted in SW during t2 (i.e. users that discuss mental health topics originally not related to suicide but eventually transition to talk about suicide; hereafter “MH → SW”). Figure 1 shows a schematic description of our user class construction. Note that by focusing on users that initiate at least one post on SW or the MHs as opposed to only commenting we can focus on those frequenting the communities for support disregarding those primarily providing help through commentary. This split yielded 440 MH → SW users; which is 1.52% of the total number of 28831 accounts who posted in MHs but never on SW during either of the periods. To construct a MH cohort of equal size who did not post on SW in either period we randomly sampled a set of 440 users from the 28831 users. Note although MH users did not post on SW during our timeframe of analysis they may have done so outside the bounds of our analysis. To support our goal of characterizing differences between the MH → SW and MH users we obtained via Reddit’s API the timeline of posts and comments authored by the 880 users (the API only provides the last 1000 public posts and comments for a user). For each post we obtained their associated metadata (e.g. vote difference or score) and comments. Our final dataset contained 4731 posts and 46949 comments from the 440 MH → SW users and 8318 posts and 54086 comments from the 440 MH users. We note an important concern: individuals may post suicidal thoughts on MHs never engaging on SW and thus “corrupting” the MHs data with discussions of suicidal ideation. We argue against this possibility. (1) SW is a prominent suicide support forum and the role of this community in suicide prevention and in acting as an inoculator of vulnerable thoughts is well-recognized [31]. (2) Most MHs (e.g. r/depression) clearly specify in their guidelines that suicidal thoughts should go to SW: “It’s usually better to post anything that specifically involves suicidal thoughts or intent in /r/SuicideWatch rather than here. If you’re concerned about someone else who may be at risk for suicide please check out their talking tips and risk assessment guide.” (3) Finally discussions with the moderators of SW confirmed that active steps are taken to move all suicidal ideation related content to SW. Given these considerations we expect that few suicidal ideation posts appear on subreddits outside of SW.,we split our data into two sequential time period t from feb to aug and t from aug to november using these two time period we created two set of user note that since reddit doe not enforce the real name rule of having exactly one account per person our reference to user in this paper is equivalent to user account first we identified those user that posted on mhs during t but did not post on sw during t or t ie user that discus mental health topic but not on sw hereafter mh the second class included those who posted on mhs during t and posted in sw during t ie user that discus mental health topic originally not related to suicide but eventually transition to talk about suicide hereafter mh sw figure show a schematic description of our user class construction note that by focusing on user that initiate at least one post on sw or the mhs a opposed to only commenting we can focus on those frequenting the community for support disregarding those primarily providing help through commentary this split yielded mh sw user which is of the total number of account who posted in mhs but never on sw during either of the period to construct a mh cohort of equal size who did not post on sw in either period we randomly sampled a set of user from the user note although mh user did not post on sw during our timeframe of analysis they may have done so outside the bound of our analysis to support our goal of characterizing difference between the mh sw and mh user we obtained via reddits api the timeline of post and comment authored by the user the api only provides the last public post and comment for a user for each post we obtained their associated metadata eg vote difference or score and comment our final dataset contained post and comment from the mh sw user and post and comment from the mh user we note an important concern individual may post suicidal thought on mhs never engaging on sw and thus corrupting the mhs data with discussion of suicidal ideation we argue against this possibility sw is a prominent suicide support forum and the role of this community in suicide prevention and in acting a an inoculator of vulnerable thought is wellrecognized most mhs eg rdepression clearly specify in their guideline that suicidal thought should go to sw it usually better to post anything that specifically involves suicidal thought or intent in rsuicidewatch rather than here if youre concerned about someone else who may be at risk for suicide please check out their talking tip and risk assessment guide finally discussion with the moderator of sw confirmed that active step are taken to move all suicidal ideation related content to sw given these consideration we expect that few suicidal ideation post appear on subreddits outside of sw,"['split', 'data', 'two', 'sequential', 'time', 'period', 'feb', 'aug', 'aug', 'november', 'using', 'two', 'time', 'period', 'created', 'two', 'set', 'user', 'note', 'since', 'reddit', 'doe', 'enforce', 'real', 'name', 'rule', 'exactly', 'one', 'account', 'per', 'person', 'reference', 'user', 'paper', 'equivalent', 'user', 'account', 'first', 'identified', 'user', 'posted', 'mhs', 'post', 'sw', 'ie', 'user', 'discus', 'mental', 'health', 'topic', 'sw', 'hereafter', 'mh', 'second', 'class', 'included', 'posted', 'mhs', 'posted', 'sw', 'ie', 'user', 'discus', 'mental', 'health', 'topic', 'originally', 'related', 'suicide', 'eventually', 'transition', 'talk', 'suicide', 'hereafter', 'mh', 'sw', 'figure', 'show', 'schematic', 'description', 'user', 'class', 'construction', 'note', 'focusing', 'user', 'initiate', 'least', 'one', 'post', 'sw', 'mhs', 'opposed', 'commenting', 'focus', 'frequenting', 'community', 'support', 'disregarding', 'primarily', 'providing', 'help', 'commentary', 'split', 'yielded', 'mh', 'sw', 'user', 'total', 'number', 'account', 'posted', 'mhs', 'never', 'sw', 'either', 'period', 'construct', 'mh', 'cohort', 'equal', 'size', 'post', 'sw', 'either', 'period', 'randomly', 'sampled', 'set', 'user', 'user', 'note', 'although', 'mh', 'user', 'post', 'sw', 'timeframe', 'analysis', 'may', 'done', 'outside', 'bound', 'analysis', 'support', 'goal', 'characterizing', 'difference', 'mh', 'sw', 'mh', 'user', 'obtained', 'via', 'reddits', 'api', 'timeline', 'post', 'comment', 'authored', 'user', 'api', 'provides', 'last', 'public', 'post', 'comment', 'user', 'post', 'obtained', 'associated', 'metadata', 'eg', 'vote', 'difference', 'score', 'comment', 'final', 'dataset', 'contained', 'post', 'comment', 'mh', 'sw', 'user', 'post', 'comment', 'mh', 'user', 'note', 'important', 'concern', 'individual', 'may', 'post', 'suicidal', 'thought', 'mhs', 'never', 'engaging', 'sw', 'thus', 'corrupting', 'mhs', 'data', 'discussion', 'suicidal', 'ideation', 'argue', 'possibility', 'sw', 'prominent', 'suicide', 'support', 'forum', 'role', 'community', 'suicide', 'prevention', 'acting', 'inoculator', 'vulnerable', 'thought', 'wellrecognized', 'mhs', 'eg', 'rdepression', 'clearly', 'specify', 'guideline', 'suicidal', 'thought', 'go', 'sw', 'usually', 'better', 'post', 'anything', 'specifically', 'involves', 'suicidal', 'thought', 'intent', 'rsuicidewatch', 'rather', 'youre', 'concerned', 'someone', 'else', 'may', 'risk', 'suicide', 'please', 'check', 'talking', 'tip', 'risk', 'assessment', 'guide', 'finally', 'discussion', 'moderator', 'sw', 'confirmed', 'active', 'step', 'taken', 'move', 'suicidal', 'ideation', 'related', 'content', 'sw', 'given', 'consideration', 'expect', 'suicidal', 'ideation', 'post', 'appear', 'subreddits', 'outside', 'sw']","['split data', 'data two', 'two sequential', 'sequential time', 'time period', 'period feb', 'feb aug', 'aug aug', 'aug november', 'november using', 'using two', 'two time', 'time period', 'period created', 'created two', 'two set', 'set user', 'user note', 'note since', 'since reddit', 'reddit doe', 'doe enforce', 'enforce real', 'real name', 'name rule', 'rule exactly', 'exactly one', 'one account', 'account per', 'per person', 'person reference', 'reference user', 'user paper', 'paper equivalent', 'equivalent user', 'user account', 'account first', 'first identified', 'identified user', 'user posted', 'posted mhs', 'mhs post', 'post sw', 'sw ie', 'ie user', 'user discus', 'discus mental', 'mental health', 'health topic', 'topic sw', 'sw hereafter', 'hereafter mh', 'mh second', 'second class', 'class included', 'included posted', 'posted mhs', 'mhs posted', 'posted sw', 'sw ie', 'ie user', 'user discus', 'discus mental', 'mental health', 'health topic', 'topic originally', 'originally related', 'related suicide', 'suicide eventually', 'eventually transition', 'transition talk', 'talk suicide', 'suicide hereafter', 'hereafter mh', 'mh sw', 'sw figure', 'figure show', 'show schematic', 'schematic description', 'description user', 'user class', 'class construction', 'construction note', 'note focusing', 'focusing user', 'user initiate', 'initiate least', 'least one', 'one post', 'post sw', 'sw mhs', 'mhs opposed', 'opposed commenting', 'commenting focus', 'focus frequenting', 'frequenting community', 'community support', 'support disregarding', 'disregarding primarily', 'primarily providing', 'providing help', 'help commentary', 'commentary split', 'split yielded', 'yielded mh', 'mh sw', 'sw user', 'user total', 'total number', 'number account', 'account posted', 'posted mhs', 'mhs never', 'never sw', 'sw either', 'either period', 'period construct', 'construct mh', 'mh cohort', 'cohort equal', 'equal size', 'size post', 'post sw', 'sw either', 'either period', 'period randomly', 'randomly sampled', 'sampled set', 'set user', 'user user', 'user note', 'note although', 'although mh', 'mh user', 'user post', 'post sw', 'sw timeframe', 'timeframe analysis', 'analysis may', 'may done', 'done outside', 'outside bound', 'bound analysis', 'analysis support', 'support goal', 'goal characterizing', 'characterizing difference', 'difference mh', 'mh sw', 'sw mh', 'mh user', 'user obtained', 'obtained via', 'via reddits', 'reddits api', 'api timeline', 'timeline post', 'post comment', 'comment authored', 'authored user', 'user api', 'api provides', 'provides last', 'last public', 'public post', 'post comment', 'comment user', 'user post', 'post obtained', 'obtained associated', 'associated metadata', 'metadata eg', 'eg vote', 'vote difference', 'difference score', 'score comment', 'comment final', 'final dataset', 'dataset contained', 'contained post', 'post comment', 'comment mh', 'mh sw', 'sw user', 'user post', 'post comment', 'comment mh', 'mh user', 'user note', 'note important', 'important concern', 'concern individual', 'individual may', 'may post', 'post suicidal', 'suicidal thought', 'thought mhs', 'mhs never', 'never engaging', 'engaging sw', 'sw thus', 'thus corrupting', 'corrupting mhs', 'mhs data', 'data discussion', 'discussion suicidal', 'suicidal ideation', 'ideation argue', 'argue possibility', 'possibility sw', 'sw prominent', 'prominent suicide', 'suicide support', 'support forum', 'forum role', 'role community', 'community suicide', 'suicide prevention', 'prevention acting', 'acting inoculator', 'inoculator vulnerable', 'vulnerable thought', 'thought wellrecognized', 'wellrecognized mhs', 'mhs eg', 'eg rdepression', 'rdepression clearly', 'clearly specify', 'specify guideline', 'guideline suicidal', 'suicidal thought', 'thought go', 'go sw', 'sw usually', 'usually better', 'better post', 'post anything', 'anything specifically', 'specifically involves', 'involves suicidal', 'suicidal thought', 'thought intent', 'intent rsuicidewatch', 'rsuicidewatch rather', 'rather youre', 'youre concerned', 'concerned someone', 'someone else', 'else may', 'may risk', 'risk suicide', 'suicide please', 'please check', 'check talking', 'talking tip', 'tip risk', 'risk assessment', 'assessment guide', 'guide finally', 'finally discussion', 'discussion moderator', 'moderator sw', 'sw confirmed', 'confirmed active', 'active step', 'step taken', 'taken move', 'move suicidal', 'suicidal ideation', 'ideation related', 'related content', 'content sw', 'sw given', 'given consideration', 'consideration expect', 'expect suicidal', 'suicidal ideation', 'ideation post', 'post appear', 'appear subreddits', 'subreddits outside', 'outside sw']","['split data two', 'data two sequential', 'two sequential time', 'sequential time period', 'time period feb', 'period feb aug', 'feb aug aug', 'aug aug november', 'aug november using', 'november using two', 'using two time', 'two time period', 'time period created', 'period created two', 'created two set', 'two set user', 'set user note', 'user note since', 'note since reddit', 'since reddit doe', 'reddit doe enforce', 'doe enforce real', 'enforce real name', 'real name rule', 'name rule exactly', 'rule exactly one', 'exactly one account', 'one account per', 'account per person', 'per person reference', 'person reference user', 'reference user paper', 'user paper equivalent', 'paper equivalent user', 'equivalent user account', 'user account first', 'account first identified', 'first identified user', 'identified user posted', 'user posted mhs', 'posted mhs post', 'mhs post sw', 'post sw ie', 'sw ie user', 'ie user discus', 'user discus mental', 'discus mental health', 'mental health topic', 'health topic sw', 'topic sw hereafter', 'sw hereafter mh', 'hereafter mh second', 'mh second class', 'second class included', 'class included posted', 'included posted mhs', 'posted mhs posted', 'mhs posted sw', 'posted sw ie', 'sw ie user', 'ie user discus', 'user discus mental', 'discus mental health', 'mental health topic', 'health topic originally', 'topic originally related', 'originally related suicide', 'related suicide eventually', 'suicide eventually transition', 'eventually transition talk', 'transition talk suicide', 'talk suicide hereafter', 'suicide hereafter mh', 'hereafter mh sw', 'mh sw figure', 'sw figure show', 'figure show schematic', 'show schematic description', 'schematic description user', 'description user class', 'user class construction', 'class construction note', 'construction note focusing', 'note focusing user', 'focusing user initiate', 'user initiate least', 'initiate least one', 'least one post', 'one post sw', 'post sw mhs', 'sw mhs opposed', 'mhs opposed commenting', 'opposed commenting focus', 'commenting focus frequenting', 'focus frequenting community', 'frequenting community support', 'community support disregarding', 'support disregarding primarily', 'disregarding primarily providing', 'primarily providing help', 'providing help commentary', 'help commentary split', 'commentary split yielded', 'split yielded mh', 'yielded mh sw', 'mh sw user', 'sw user total', 'user total number', 'total number account', 'number account posted', 'account posted mhs', 'posted mhs never', 'mhs never sw', 'never sw either', 'sw either period', 'either period construct', 'period construct mh', 'construct mh cohort', 'mh cohort equal', 'cohort equal size', 'equal size post', 'size post sw', 'post sw either', 'sw either period', 'either period randomly', 'period randomly sampled', 'randomly sampled set', 'sampled set user', 'set user user', 'user user note', 'user note although', 'note although mh', 'although mh user', 'mh user post', 'user post sw', 'post sw timeframe', 'sw timeframe analysis', 'timeframe analysis may', 'analysis may done', 'may done outside', 'done outside bound', 'outside bound analysis', 'bound analysis support', 'analysis support goal', 'support goal characterizing', 'goal characterizing difference', 'characterizing difference mh', 'difference mh sw', 'mh sw mh', 'sw mh user', 'mh user obtained', 'user obtained via', 'obtained via reddits', 'via reddits api', 'reddits api timeline', 'api timeline post', 'timeline post comment', 'post comment authored', 'comment authored user', 'authored user api', 'user api provides', 'api provides last', 'provides last public', 'last public post', 'public post comment', 'post comment user', 'comment user post', 'user post obtained', 'post obtained associated', 'obtained associated metadata', 'associated metadata eg', 'metadata eg vote', 'eg vote difference', 'vote difference score', 'difference score comment', 'score comment final', 'comment final dataset', 'final dataset contained', 'dataset contained post', 'contained post comment', 'post comment mh', 'comment mh sw', 'mh sw user', 'sw user post', 'user post comment', 'post comment mh', 'comment mh user', 'mh user note', 'user note important', 'note important concern', 'important concern individual', 'concern individual may', 'individual may post', 'may post suicidal', 'post suicidal thought', 'suicidal thought mhs', 'thought mhs never', 'mhs never engaging', 'never engaging sw', 'engaging sw thus', 'sw thus corrupting', 'thus corrupting mhs', 'corrupting mhs data', 'mhs data discussion', 'data discussion suicidal', 'discussion suicidal ideation', 'suicidal ideation argue', 'ideation argue possibility', 'argue possibility sw', 'possibility sw prominent', 'sw prominent suicide', 'prominent suicide support', 'suicide support forum', 'support forum role', 'forum role community', 'role community suicide', 'community suicide prevention', 'suicide prevention acting', 'prevention acting inoculator', 'acting inoculator vulnerable', 'inoculator vulnerable thought', 'vulnerable thought wellrecognized', 'thought wellrecognized mhs', 'wellrecognized mhs eg', 'mhs eg rdepression', 'eg rdepression clearly', 'rdepression clearly specify', 'clearly specify guideline', 'specify guideline suicidal', 'guideline suicidal thought', 'suicidal thought go', 'thought go sw', 'go sw usually', 'sw usually better', 'usually better post', 'better post anything', 'post anything specifically', 'anything specifically involves', 'specifically involves suicidal', 'involves suicidal thought', 'suicidal thought intent', 'thought intent rsuicidewatch', 'intent rsuicidewatch rather', 'rsuicidewatch rather youre', 'rather youre concerned', 'youre concerned someone', 'concerned someone else', 'someone else may', 'else may risk', 'may risk suicide', 'risk suicide please', 'suicide please check', 'please check talking', 'check talking tip', 'talking tip risk', 'tip risk assessment', 'risk assessment guide', 'assessment guide finally', 'guide finally discussion', 'finally discussion moderator', 'discussion moderator sw', 'moderator sw confirmed', 'sw confirmed active', 'confirmed active step', 'active step taken', 'step taken move', 'taken move suicidal', 'move suicidal ideation', 'suicidal ideation related', 'ideation related content', 'related content sw', 'content sw given', 'sw given consideration', 'given consideration expect', 'consideration expect suicidal', 'expect suicidal ideation', 'suicidal ideation post', 'ideation post appear', 'post appear subreddits', 'appear subreddits outside', 'subreddits outside sw']",,,,,,,,
https://dl.acm.org/doi/abs/10.1145/2702613.2732733,0,We used Reddit's official API to collect posts comments on posts and associated metadata from several mental health focused subreddits. We build on the data collection methodology we used in [4]. In order to arrive at a comprehensive list of subreddits to focus on we utilized Reddit's native subreddit search feature (http://www.reddit.com/reddits). We searched for subreddits on “mental health”. Two researchers familiar with Reddit employed an initial filtering step on the search results returned so that we “seed” on high precision subreddits discussing mental health concerns. Thereafter we focused on a snowball approach to compile a second list of “related” or “similar” subreddits that are mentioned in the profile pages of the seed subreddits. Sample of subreddits (31 in all) we crawled are given in Table 1. Note all of these subreddits host public content. For the purposes of self-disclosure detection we also identified subreddits (sample listed in Table 2) as our control group (total of 12 subreddits) – meaning they are unrelated to mental health topics. For sanity check we randomly sampled a set of 200 posts from the control subreddits and two researchers familiar with Reddit manually checked their content for presence of any mental health content. We found that 97% of subreddit content in our sample were not about any mental health concern (Cohen’s Kappa for inter-rater agreement was .84). In all our dataset had 32509 posts from 23807 users in the mental health subreddits and 15383 posts from 13216 users in the control forums. For each of the unique users in the mental health forums we further collected all of their Reddit post/comment histories (last 1000 posts/comments per Reddit API limits) if their number of posts and comments in our dataset was five or more – this gave us 7248 users and 4.1M posts/commentsAutomatic detection of self-disclosure levels in posts necessitates obtaining gold standard labels on self-disclosure in essence “ground truth”. For the purpose two raters familiar with Reddit and its mental health communities in particular independently rated a small random sample (50 posts) with equal proportions from mental health and control subreddits for three levels of self-disclosure – no selfdisclosure low and high self-disclosure. These three classes of self-disclosure were chosen based on categorization by Bak et al in [10]. The raters mutually discussed their labels thereafter and thus came up with a set of rules for rating. The rules were further aligned with observations in prior work [9 10 11]. Per the rules: Posts that either reveal personal information (e.g. age location gender etc.) or divulge sensitive or vulnerable thoughts beliefs or embarrassing/confessional experiences were to be considered to be indicative of high self-disclosure. Joinson [10] characterized sensitive disclosure in terms of the extent of “revealed vulnerability”. Posts about self but not disclosing any personal or emotionally vulnerable content was to be considered of low self-disclosure. No self-disclosure posts were those which were about people or things other than the posting author and which divulged information unrelated to the self. Following these mutually agreed upon rules the previous two raters and an additional rater familiar with Reddit independently coded a larger sample of 800 posts to create a training set for the purposes of classification. The raters had good agreement in their ratings: Fleiss’ Kappa was found to be .73. However given the subjective nature of characterization of self-disclosure we considered only those posts in the training set for which we had agreement across all three raters – this gave us 627 posts. Across the three categories the coded set consisted of 38% posts of high selfdisclosure 35% posts of low self-disclosure and 27% with no self-disclosure. Table 3 gives examples of mental health post excerpts with high self-disclosure while Table 4 and 5 provide examples of low and no self-disclosure posts. Note that including non-mental health posts in the training set was essential so as to let the detector learn on posts of low and no self-disclosure and on those not mental health related.,we used reddits official api to collect post comment on post and associated metadata from several mental health focused subreddits we build on the data collection methodology we used in in order to arrive at a comprehensive list of subreddits to focus on we utilized reddits native subreddit search feature httpwwwredditcomreddits we searched for subreddits on mental health two researcher familiar with reddit employed an initial filtering step on the search result returned so that we seed on high precision subreddits discussing mental health concern thereafter we focused on a snowball approach to compile a second list of related or similar subreddits that are mentioned in the profile page of the seed subreddits sample of subreddits in all we crawled are given in table note all of these subreddits host public content for the purpose of selfdisclosure detection we also identified subreddits sample listed in table a our control group total of subreddits meaning they are unrelated to mental health topic for sanity check we randomly sampled a set of post from the control subreddits and two researcher familiar with reddit manually checked their content for presence of any mental health content we found that of subreddit content in our sample were not about any mental health concern cohens kappa for interrater agreement wa in all our dataset had post from user in the mental health subreddits and post from user in the control forum for each of the unique user in the mental health forum we further collected all of their reddit postcomment history last postscomments per reddit api limit if their number of post and comment in our dataset wa five or more this gave u user and m postscommentsautomatic detection of selfdisclosure level in post necessitates obtaining gold standard label on selfdisclosure in essence ground truth for the purpose two raters familiar with reddit and it mental health community in particular independently rated a small random sample post with equal proportion from mental health and control subreddits for three level of selfdisclosure no selfdisclosure low and high selfdisclosure these three class of selfdisclosure were chosen based on categorization by bak et al in the raters mutually discussed their label thereafter and thus came up with a set of rule for rating the rule were further aligned with observation in prior work per the rule post that either reveal personal information eg age location gender etc or divulge sensitive or vulnerable thought belief or embarrassingconfessional experience were to be considered to be indicative of high selfdisclosure joinson characterized sensitive disclosure in term of the extent of revealed vulnerability post about self but not disclosing any personal or emotionally vulnerable content wa to be considered of low selfdisclosure no selfdisclosure post were those which were about people or thing other than the posting author and which divulged information unrelated to the self following these mutually agreed upon rule the previous two raters and an additional rater familiar with reddit independently coded a larger sample of post to create a training set for the purpose of classification the raters had good agreement in their rating fleiss kappa wa found to be however given the subjective nature of characterization of selfdisclosure we considered only those post in the training set for which we had agreement across all three raters this gave u post across the three category the coded set consisted of post of high selfdisclosure post of low selfdisclosure and with no selfdisclosure table give example of mental health post excerpt with high selfdisclosure while table and provide example of low and no selfdisclosure post note that including nonmental health post in the training set wa essential so a to let the detector learn on post of low and no selfdisclosure and on those not mental health related,"['used', 'reddits', 'official', 'api', 'collect', 'post', 'comment', 'post', 'associated', 'metadata', 'several', 'mental', 'health', 'focused', 'subreddits', 'build', 'data', 'collection', 'methodology', 'used', 'order', 'arrive', 'comprehensive', 'list', 'subreddits', 'focus', 'utilized', 'reddits', 'native', 'subreddit', 'search', 'feature', 'httpwwwredditcomreddits', 'searched', 'subreddits', 'mental', 'health', 'two', 'researcher', 'familiar', 'reddit', 'employed', 'initial', 'filtering', 'step', 'search', 'result', 'returned', 'seed', 'high', 'precision', 'subreddits', 'discussing', 'mental', 'health', 'concern', 'thereafter', 'focused', 'snowball', 'approach', 'compile', 'second', 'list', 'related', 'similar', 'subreddits', 'mentioned', 'profile', 'page', 'seed', 'subreddits', 'sample', 'subreddits', 'crawled', 'given', 'table', 'note', 'subreddits', 'host', 'public', 'content', 'purpose', 'selfdisclosure', 'detection', 'also', 'identified', 'subreddits', 'sample', 'listed', 'table', 'control', 'group', 'total', 'subreddits', 'meaning', 'unrelated', 'mental', 'health', 'topic', 'sanity', 'check', 'randomly', 'sampled', 'set', 'post', 'control', 'subreddits', 'two', 'researcher', 'familiar', 'reddit', 'manually', 'checked', 'content', 'presence', 'mental', 'health', 'content', 'found', 'subreddit', 'content', 'sample', 'mental', 'health', 'concern', 'cohens', 'kappa', 'interrater', 'agreement', 'wa', 'dataset', 'post', 'user', 'mental', 'health', 'subreddits', 'post', 'user', 'control', 'forum', 'unique', 'user', 'mental', 'health', 'forum', 'collected', 'reddit', 'postcomment', 'history', 'last', 'postscomments', 'per', 'reddit', 'api', 'limit', 'number', 'post', 'comment', 'dataset', 'wa', 'five', 'gave', 'u', 'user', 'postscommentsautomatic', 'detection', 'selfdisclosure', 'level', 'post', 'necessitates', 'obtaining', 'gold', 'standard', 'label', 'selfdisclosure', 'essence', 'ground', 'truth', 'purpose', 'two', 'raters', 'familiar', 'reddit', 'mental', 'health', 'community', 'particular', 'independently', 'rated', 'small', 'random', 'sample', 'post', 'equal', 'proportion', 'mental', 'health', 'control', 'subreddits', 'three', 'level', 'selfdisclosure', 'selfdisclosure', 'low', 'high', 'selfdisclosure', 'three', 'class', 'selfdisclosure', 'chosen', 'based', 'categorization', 'bak', 'et', 'al', 'raters', 'mutually', 'discussed', 'label', 'thereafter', 'thus', 'came', 'set', 'rule', 'rating', 'rule', 'aligned', 'observation', 'prior', 'work', 'per', 'rule', 'post', 'either', 'reveal', 'personal', 'information', 'eg', 'age', 'location', 'gender', 'etc', 'divulge', 'sensitive', 'vulnerable', 'thought', 'belief', 'embarrassingconfessional', 'experience', 'considered', 'indicative', 'high', 'selfdisclosure', 'joinson', 'characterized', 'sensitive', 'disclosure', 'term', 'extent', 'revealed', 'vulnerability', 'post', 'self', 'disclosing', 'personal', 'emotionally', 'vulnerable', 'content', 'wa', 'considered', 'low', 'selfdisclosure', 'selfdisclosure', 'post', 'people', 'thing', 'posting', 'author', 'divulged', 'information', 'unrelated', 'self', 'following', 'mutually', 'agreed', 'upon', 'rule', 'previous', 'two', 'raters', 'additional', 'rater', 'familiar', 'reddit', 'independently', 'coded', 'larger', 'sample', 'post', 'create', 'training', 'set', 'purpose', 'classification', 'raters', 'good', 'agreement', 'rating', 'fleiss', 'kappa', 'wa', 'found', 'however', 'given', 'subjective', 'nature', 'characterization', 'selfdisclosure', 'considered', 'post', 'training', 'set', 'agreement', 'across', 'three', 'raters', 'gave', 'u', 'post', 'across', 'three', 'category', 'coded', 'set', 'consisted', 'post', 'high', 'selfdisclosure', 'post', 'low', 'selfdisclosure', 'selfdisclosure', 'table', 'give', 'example', 'mental', 'health', 'post', 'excerpt', 'high', 'selfdisclosure', 'table', 'provide', 'example', 'low', 'selfdisclosure', 'post', 'note', 'including', 'nonmental', 'health', 'post', 'training', 'set', 'wa', 'essential', 'let', 'detector', 'learn', 'post', 'low', 'selfdisclosure', 'mental', 'health', 'related']","['used reddits', 'reddits official', 'official api', 'api collect', 'collect post', 'post comment', 'comment post', 'post associated', 'associated metadata', 'metadata several', 'several mental', 'mental health', 'health focused', 'focused subreddits', 'subreddits build', 'build data', 'data collection', 'collection methodology', 'methodology used', 'used order', 'order arrive', 'arrive comprehensive', 'comprehensive list', 'list subreddits', 'subreddits focus', 'focus utilized', 'utilized reddits', 'reddits native', 'native subreddit', 'subreddit search', 'search feature', 'feature httpwwwredditcomreddits', 'httpwwwredditcomreddits searched', 'searched subreddits', 'subreddits mental', 'mental health', 'health two', 'two researcher', 'researcher familiar', 'familiar reddit', 'reddit employed', 'employed initial', 'initial filtering', 'filtering step', 'step search', 'search result', 'result returned', 'returned seed', 'seed high', 'high precision', 'precision subreddits', 'subreddits discussing', 'discussing mental', 'mental health', 'health concern', 'concern thereafter', 'thereafter focused', 'focused snowball', 'snowball approach', 'approach compile', 'compile second', 'second list', 'list related', 'related similar', 'similar subreddits', 'subreddits mentioned', 'mentioned profile', 'profile page', 'page seed', 'seed subreddits', 'subreddits sample', 'sample subreddits', 'subreddits crawled', 'crawled given', 'given table', 'table note', 'note subreddits', 'subreddits host', 'host public', 'public content', 'content purpose', 'purpose selfdisclosure', 'selfdisclosure detection', 'detection also', 'also identified', 'identified subreddits', 'subreddits sample', 'sample listed', 'listed table', 'table control', 'control group', 'group total', 'total subreddits', 'subreddits meaning', 'meaning unrelated', 'unrelated mental', 'mental health', 'health topic', 'topic sanity', 'sanity check', 'check randomly', 'randomly sampled', 'sampled set', 'set post', 'post control', 'control subreddits', 'subreddits two', 'two researcher', 'researcher familiar', 'familiar reddit', 'reddit manually', 'manually checked', 'checked content', 'content presence', 'presence mental', 'mental health', 'health content', 'content found', 'found subreddit', 'subreddit content', 'content sample', 'sample mental', 'mental health', 'health concern', 'concern cohens', 'cohens kappa', 'kappa interrater', 'interrater agreement', 'agreement wa', 'wa dataset', 'dataset post', 'post user', 'user mental', 'mental health', 'health subreddits', 'subreddits post', 'post user', 'user control', 'control forum', 'forum unique', 'unique user', 'user mental', 'mental health', 'health forum', 'forum collected', 'collected reddit', 'reddit postcomment', 'postcomment history', 'history last', 'last postscomments', 'postscomments per', 'per reddit', 'reddit api', 'api limit', 'limit number', 'number post', 'post comment', 'comment dataset', 'dataset wa', 'wa five', 'five gave', 'gave u', 'u user', 'user postscommentsautomatic', 'postscommentsautomatic detection', 'detection selfdisclosure', 'selfdisclosure level', 'level post', 'post necessitates', 'necessitates obtaining', 'obtaining gold', 'gold standard', 'standard label', 'label selfdisclosure', 'selfdisclosure essence', 'essence ground', 'ground truth', 'truth purpose', 'purpose two', 'two raters', 'raters familiar', 'familiar reddit', 'reddit mental', 'mental health', 'health community', 'community particular', 'particular independently', 'independently rated', 'rated small', 'small random', 'random sample', 'sample post', 'post equal', 'equal proportion', 'proportion mental', 'mental health', 'health control', 'control subreddits', 'subreddits three', 'three level', 'level selfdisclosure', 'selfdisclosure selfdisclosure', 'selfdisclosure low', 'low high', 'high selfdisclosure', 'selfdisclosure three', 'three class', 'class selfdisclosure', 'selfdisclosure chosen', 'chosen based', 'based categorization', 'categorization bak', 'bak et', 'et al', 'al raters', 'raters mutually', 'mutually discussed', 'discussed label', 'label thereafter', 'thereafter thus', 'thus came', 'came set', 'set rule', 'rule rating', 'rating rule', 'rule aligned', 'aligned observation', 'observation prior', 'prior work', 'work per', 'per rule', 'rule post', 'post either', 'either reveal', 'reveal personal', 'personal information', 'information eg', 'eg age', 'age location', 'location gender', 'gender etc', 'etc divulge', 'divulge sensitive', 'sensitive vulnerable', 'vulnerable thought', 'thought belief', 'belief embarrassingconfessional', 'embarrassingconfessional experience', 'experience considered', 'considered indicative', 'indicative high', 'high selfdisclosure', 'selfdisclosure joinson', 'joinson characterized', 'characterized sensitive', 'sensitive disclosure', 'disclosure term', 'term extent', 'extent revealed', 'revealed vulnerability', 'vulnerability post', 'post self', 'self disclosing', 'disclosing personal', 'personal emotionally', 'emotionally vulnerable', 'vulnerable content', 'content wa', 'wa considered', 'considered low', 'low selfdisclosure', 'selfdisclosure selfdisclosure', 'selfdisclosure post', 'post people', 'people thing', 'thing posting', 'posting author', 'author divulged', 'divulged information', 'information unrelated', 'unrelated self', 'self following', 'following mutually', 'mutually agreed', 'agreed upon', 'upon rule', 'rule previous', 'previous two', 'two raters', 'raters additional', 'additional rater', 'rater familiar', 'familiar reddit', 'reddit independently', 'independently coded', 'coded larger', 'larger sample', 'sample post', 'post create', 'create training', 'training set', 'set purpose', 'purpose classification', 'classification raters', 'raters good', 'good agreement', 'agreement rating', 'rating fleiss', 'fleiss kappa', 'kappa wa', 'wa found', 'found however', 'however given', 'given subjective', 'subjective nature', 'nature characterization', 'characterization selfdisclosure', 'selfdisclosure considered', 'considered post', 'post training', 'training set', 'set agreement', 'agreement across', 'across three', 'three raters', 'raters gave', 'gave u', 'u post', 'post across', 'across three', 'three category', 'category coded', 'coded set', 'set consisted', 'consisted post', 'post high', 'high selfdisclosure', 'selfdisclosure post', 'post low', 'low selfdisclosure', 'selfdisclosure selfdisclosure', 'selfdisclosure table', 'table give', 'give example', 'example mental', 'mental health', 'health post', 'post excerpt', 'excerpt high', 'high selfdisclosure', 'selfdisclosure table', 'table provide', 'provide example', 'example low', 'low selfdisclosure', 'selfdisclosure post', 'post note', 'note including', 'including nonmental', 'nonmental health', 'health post', 'post training', 'training set', 'set wa', 'wa essential', 'essential let', 'let detector', 'detector learn', 'learn post', 'post low', 'low selfdisclosure', 'selfdisclosure mental', 'mental health', 'health related']","['used reddits official', 'reddits official api', 'official api collect', 'api collect post', 'collect post comment', 'post comment post', 'comment post associated', 'post associated metadata', 'associated metadata several', 'metadata several mental', 'several mental health', 'mental health focused', 'health focused subreddits', 'focused subreddits build', 'subreddits build data', 'build data collection', 'data collection methodology', 'collection methodology used', 'methodology used order', 'used order arrive', 'order arrive comprehensive', 'arrive comprehensive list', 'comprehensive list subreddits', 'list subreddits focus', 'subreddits focus utilized', 'focus utilized reddits', 'utilized reddits native', 'reddits native subreddit', 'native subreddit search', 'subreddit search feature', 'search feature httpwwwredditcomreddits', 'feature httpwwwredditcomreddits searched', 'httpwwwredditcomreddits searched subreddits', 'searched subreddits mental', 'subreddits mental health', 'mental health two', 'health two researcher', 'two researcher familiar', 'researcher familiar reddit', 'familiar reddit employed', 'reddit employed initial', 'employed initial filtering', 'initial filtering step', 'filtering step search', 'step search result', 'search result returned', 'result returned seed', 'returned seed high', 'seed high precision', 'high precision subreddits', 'precision subreddits discussing', 'subreddits discussing mental', 'discussing mental health', 'mental health concern', 'health concern thereafter', 'concern thereafter focused', 'thereafter focused snowball', 'focused snowball approach', 'snowball approach compile', 'approach compile second', 'compile second list', 'second list related', 'list related similar', 'related similar subreddits', 'similar subreddits mentioned', 'subreddits mentioned profile', 'mentioned profile page', 'profile page seed', 'page seed subreddits', 'seed subreddits sample', 'subreddits sample subreddits', 'sample subreddits crawled', 'subreddits crawled given', 'crawled given table', 'given table note', 'table note subreddits', 'note subreddits host', 'subreddits host public', 'host public content', 'public content purpose', 'content purpose selfdisclosure', 'purpose selfdisclosure detection', 'selfdisclosure detection also', 'detection also identified', 'also identified subreddits', 'identified subreddits sample', 'subreddits sample listed', 'sample listed table', 'listed table control', 'table control group', 'control group total', 'group total subreddits', 'total subreddits meaning', 'subreddits meaning unrelated', 'meaning unrelated mental', 'unrelated mental health', 'mental health topic', 'health topic sanity', 'topic sanity check', 'sanity check randomly', 'check randomly sampled', 'randomly sampled set', 'sampled set post', 'set post control', 'post control subreddits', 'control subreddits two', 'subreddits two researcher', 'two researcher familiar', 'researcher familiar reddit', 'familiar reddit manually', 'reddit manually checked', 'manually checked content', 'checked content presence', 'content presence mental', 'presence mental health', 'mental health content', 'health content found', 'content found subreddit', 'found subreddit content', 'subreddit content sample', 'content sample mental', 'sample mental health', 'mental health concern', 'health concern cohens', 'concern cohens kappa', 'cohens kappa interrater', 'kappa interrater agreement', 'interrater agreement wa', 'agreement wa dataset', 'wa dataset post', 'dataset post user', 'post user mental', 'user mental health', 'mental health subreddits', 'health subreddits post', 'subreddits post user', 'post user control', 'user control forum', 'control forum unique', 'forum unique user', 'unique user mental', 'user mental health', 'mental health forum', 'health forum collected', 'forum collected reddit', 'collected reddit postcomment', 'reddit postcomment history', 'postcomment history last', 'history last postscomments', 'last postscomments per', 'postscomments per reddit', 'per reddit api', 'reddit api limit', 'api limit number', 'limit number post', 'number post comment', 'post comment dataset', 'comment dataset wa', 'dataset wa five', 'wa five gave', 'five gave u', 'gave u user', 'u user postscommentsautomatic', 'user postscommentsautomatic detection', 'postscommentsautomatic detection selfdisclosure', 'detection selfdisclosure level', 'selfdisclosure level post', 'level post necessitates', 'post necessitates obtaining', 'necessitates obtaining gold', 'obtaining gold standard', 'gold standard label', 'standard label selfdisclosure', 'label selfdisclosure essence', 'selfdisclosure essence ground', 'essence ground truth', 'ground truth purpose', 'truth purpose two', 'purpose two raters', 'two raters familiar', 'raters familiar reddit', 'familiar reddit mental', 'reddit mental health', 'mental health community', 'health community particular', 'community particular independently', 'particular independently rated', 'independently rated small', 'rated small random', 'small random sample', 'random sample post', 'sample post equal', 'post equal proportion', 'equal proportion mental', 'proportion mental health', 'mental health control', 'health control subreddits', 'control subreddits three', 'subreddits three level', 'three level selfdisclosure', 'level selfdisclosure selfdisclosure', 'selfdisclosure selfdisclosure low', 'selfdisclosure low high', 'low high selfdisclosure', 'high selfdisclosure three', 'selfdisclosure three class', 'three class selfdisclosure', 'class selfdisclosure chosen', 'selfdisclosure chosen based', 'chosen based categorization', 'based categorization bak', 'categorization bak et', 'bak et al', 'et al raters', 'al raters mutually', 'raters mutually discussed', 'mutually discussed label', 'discussed label thereafter', 'label thereafter thus', 'thereafter thus came', 'thus came set', 'came set rule', 'set rule rating', 'rule rating rule', 'rating rule aligned', 'rule aligned observation', 'aligned observation prior', 'observation prior work', 'prior work per', 'work per rule', 'per rule post', 'rule post either', 'post either reveal', 'either reveal personal', 'reveal personal information', 'personal information eg', 'information eg age', 'eg age location', 'age location gender', 'location gender etc', 'gender etc divulge', 'etc divulge sensitive', 'divulge sensitive vulnerable', 'sensitive vulnerable thought', 'vulnerable thought belief', 'thought belief embarrassingconfessional', 'belief embarrassingconfessional experience', 'embarrassingconfessional experience considered', 'experience considered indicative', 'considered indicative high', 'indicative high selfdisclosure', 'high selfdisclosure joinson', 'selfdisclosure joinson characterized', 'joinson characterized sensitive', 'characterized sensitive disclosure', 'sensitive disclosure term', 'disclosure term extent', 'term extent revealed', 'extent revealed vulnerability', 'revealed vulnerability post', 'vulnerability post self', 'post self disclosing', 'self disclosing personal', 'disclosing personal emotionally', 'personal emotionally vulnerable', 'emotionally vulnerable content', 'vulnerable content wa', 'content wa considered', 'wa considered low', 'considered low selfdisclosure', 'low selfdisclosure selfdisclosure', 'selfdisclosure selfdisclosure post', 'selfdisclosure post people', 'post people thing', 'people thing posting', 'thing posting author', 'posting author divulged', 'author divulged information', 'divulged information unrelated', 'information unrelated self', 'unrelated self following', 'self following mutually', 'following mutually agreed', 'mutually agreed upon', 'agreed upon rule', 'upon rule previous', 'rule previous two', 'previous two raters', 'two raters additional', 'raters additional rater', 'additional rater familiar', 'rater familiar reddit', 'familiar reddit independently', 'reddit independently coded', 'independently coded larger', 'coded larger sample', 'larger sample post', 'sample post create', 'post create training', 'create training set', 'training set purpose', 'set purpose classification', 'purpose classification raters', 'classification raters good', 'raters good agreement', 'good agreement rating', 'agreement rating fleiss', 'rating fleiss kappa', 'fleiss kappa wa', 'kappa wa found', 'wa found however', 'found however given', 'however given subjective', 'given subjective nature', 'subjective nature characterization', 'nature characterization selfdisclosure', 'characterization selfdisclosure considered', 'selfdisclosure considered post', 'considered post training', 'post training set', 'training set agreement', 'set agreement across', 'agreement across three', 'across three raters', 'three raters gave', 'raters gave u', 'gave u post', 'u post across', 'post across three', 'across three category', 'three category coded', 'category coded set', 'coded set consisted', 'set consisted post', 'consisted post high', 'post high selfdisclosure', 'high selfdisclosure post', 'selfdisclosure post low', 'post low selfdisclosure', 'low selfdisclosure selfdisclosure', 'selfdisclosure selfdisclosure table', 'selfdisclosure table give', 'table give example', 'give example mental', 'example mental health', 'mental health post', 'health post excerpt', 'post excerpt high', 'excerpt high selfdisclosure', 'high selfdisclosure table', 'selfdisclosure table provide', 'table provide example', 'provide example low', 'example low selfdisclosure', 'low selfdisclosure post', 'selfdisclosure post note', 'post note including', 'note including nonmental', 'including nonmental health', 'nonmental health post', 'health post training', 'post training set', 'training set wa', 'set wa essential', 'wa essential let', 'essential let detector', 'let detector learn', 'detector learn post', 'learn post low', 'post low selfdisclosure', 'low selfdisclosure mental', 'selfdisclosure mental health', 'mental health related']",,,,,,,,
https://dl.acm.org/doi/abs/10.1145/2702123.2702280,0,In this study we gathered information on depression levels of Twitter users and their activity histories. To do this we published a website to administer a questionnaire and disseminated information about the website over Twitter1. In contrast to De Choudhury et al. [14] who collected data from Englishspeaking users through crowdsourcing this study collected data from Japanese-speaking volunteers. This approach was used to investigate the extent to which depression risk can be estimated for a population different from the population considered by the prior research [14]. Figure 1 shows a screenshot of our website. The website collected the responses to a questionnaire to evaluate the degree of depression of the Twitter users who participated (hereinafter the participants) and to collect the histories of participants activities on Twitter. The activity histories of participants were collected through the Twitter application programming interface (API)2 and the questionnaires to determine degree of depression were completed by participants through their web browsers. Before data collection visitors to the website were presented with a written explanation of the aims of the experiment the information that would be collected and how that information would be handled. Those who consented to become participants after receiving the explanation logged into their individual Twitter accounts through the OAuth authorization process. Next participants were surveyed on gender age occupation and history of depression following which they answered a questionnaire designed to evaluate degree of depression. A message called the “kokoro score” (“kokoro” is a Japanese word meaning “heart”) determined on the basis of answers to the questionnaire and information in the collected tweets was displayed to participants after completion of the questionnaire (Fig. 2). Experiment participants were able to tweet the message displayed which made it possible to promote the website over Twitter by word-of-mouth in a type of snowball sampling. The CES-D questionnaire was used to evaluate the degree of depression [30]. In the CES-D test participants answered 20 questions on a Likert-type 4-point scale. Each answer was assigned a score of 0-3 points with the sum of the points from all answers used as the score to estimate likelihood of depression. Several standards exist by which to determine the appropriate cutoff score for identifying depression. In this research we regarded a score of 22 points or higher as indicating active depression and a score of 21 points or lower as indicating no active depression; these are the same values as used in [14] and give a cutoff score of 22. In addition answers to BDI [2] a depression scale used with characteristics similar to CESD were collected to ensure the reliability of data. For each participant scores were calculated on both scales with poor correlation regarded as indicating unreliable answers. The time taken to answer the questionnaires was also recorded and those completed in too brief a time were excluded. After each participant answered the questionnaire the activity history of that participant on Twitter was collected from Twitter by using the API. At most 3200 tweets were collected for each participant and the number of users following the participant and being followed by the participant were recorded. Tweets published after the questionnaire was taken were discarded. The website was opened to the public on 4 December 2013 at which time the authors publicized it on their Twitter accounts. Between 4 December 2013 and 8 February 2014 219 people participated in the experiment. After eliminating participants who did not tweet and participants who answered the questionnaire in fewer than 30 seconds (as previously mentioned to ensure the reliability of the questionnaire answers) 214 sets of answers remained. Only the first set of answers was used for participants who completed the questionnaire more than once. As a result data about 209 experiment participants (male: 121; female: 88) aged 16 to 55 (mean: 28.8 years; standard deviation: 8.2 years) were analyzed. The correlations between CES-D score and BDI score for these participants were high 0.87 and there were no participants with uncorrelated scores so the data for all 209 participants were used; excluded datasets are not discussed any further. Figure 3 shows the histogram of CES-D scores of 209 participants. Among the participants 81 (resp. 128) were estimated to have (resp. not have) active depression for an incidence of approximately 39%. This incidence is similar to that found by De Choudhury et al. [14] who identified depression in approximately 36% of participants. Table 1 gives statistics on the activity histories of participants.It is possible to extract various features from the activity histories of Twitter users. This section explains what kinds of features are used to estimate degree of depression and the way in which these quantities are extracted. Table 2 shows the features used in this study. A detailed explanation of each feature follows. The frequencies of words in a tweet (i.e. its bag of words) are used as a basic feature relating to the content of the tweet. Tsugawa et al. showed that the word frequencies are useful for identifying depression [37]. MeCab [20] was used to for morphological stemming and categorization of the Japanese tweet text to obtain accurate word frequencies. Particles auxiliary verbs adnominal adjectives and visual symbols were excluded for extracting content words. Words used by only one participant were also excluded resulting in a total of 84255 distinct words. However most of these words were rarely used and the distribution of word frequencies is extremely biased (see Fig. 4). Because words with a low rate of use were regarded as unlikely to be associated with depression for most users the frequencies of only the 20000 words with the highest rate of use (corresponding to 25 or more uses across all participants) were used as a feature in this study. Furthermore because the number and length of tweets differed by participant the word frequencies were normalized by the total number of words in the tweets. The topics of the tweets of each user as estimated by using a representative topic model LDA [5] were used as a second feature relating to the content of the tweets. With LDA the distribution of topics in each document is estimated from the word frequencies in each text through unsupervised learning on the assumption that the text and the words in it are generated according to a particular topic [5]. In LDA the number of topics to identify and a set of documents (as bags of words) are used as input and a topic distribution is output for each document. As mentioned in Related Work Section the topics of essays written by university students were estimated by using LDA and found to be useful in evaluating degree of depression [31]. From that study topics are expected to be a useful feature. A set of all tweets of each user was used as the user document for input in LDA and the 20000 words selected as described above were used as the words. We used LDA with collapsed Gibbs sampling [16]. As the parameters of LDA we used α = 50/K and β = 0.1 where K is the number of topics [16]. All extracted topics were used as the features. The ratio of positive words and the ratio of negative words used in the tweet text are used as the final features relating to tweet content. Users with depression are intuitively expected to use negative words more frequently than users without depression do. To categorize words a dictionary of affective words [19] which is compiled by manual evaluation of a dictionary of positive and negative words extracted according to a technique proposed in the literature [35] is used. The dictionary contains 760 positive words and 862 negative words. The user’s timing of tweets frequency of tweets average number of words retweet rate (rate of republishing other users’ tweets) mention rate (rate of directly referencing at least one other user) ratio of tweets containing a uniform resource locator (URL) number of users being followed and number of users following are used as features independent of the content of the tweet. The relative ratios of tweets posted during each hour of the day were used to characterize the timing of tweets; the number of posts per day was used as the posting frequency; and the ratio of qualifying tweets to all tweets were used for the retweet ratio mention ratio and ratio of tweets containing a URL. These features are used in prior research [14].,in this study we gathered information on depression level of twitter user and their activity history to do this we published a website to administer a questionnaire and disseminated information about the website over twitter in contrast to de choudhury et al who collected data from englishspeaking user through crowdsourcing this study collected data from japanesespeaking volunteer this approach wa used to investigate the extent to which depression risk can be estimated for a population different from the population considered by the prior research figure show a screenshot of our website the website collected the response to a questionnaire to evaluate the degree of depression of the twitter user who participated hereinafter the participant and to collect the history of participant activity on twitter the activity history of participant were collected through the twitter application programming interface api and the questionnaire to determine degree of depression were completed by participant through their web browser before data collection visitor to the website were presented with a written explanation of the aim of the experiment the information that would be collected and how that information would be handled those who consented to become participant after receiving the explanation logged into their individual twitter account through the oauth authorization process next participant were surveyed on gender age occupation and history of depression following which they answered a questionnaire designed to evaluate degree of depression a message called the kokoro score kokoro is a japanese word meaning heart determined on the basis of answer to the questionnaire and information in the collected tweet wa displayed to participant after completion of the questionnaire fig experiment participant were able to tweet the message displayed which made it possible to promote the website over twitter by wordofmouth in a type of snowball sampling the cesd questionnaire wa used to evaluate the degree of depression in the cesd test participant answered question on a likerttype point scale each answer wa assigned a score of point with the sum of the point from all answer used a the score to estimate likelihood of depression several standard exist by which to determine the appropriate cutoff score for identifying depression in this research we regarded a score of point or higher a indicating active depression and a score of point or lower a indicating no active depression these are the same value a used in and give a cutoff score of in addition answer to bdi a depression scale used with characteristic similar to cesd were collected to ensure the reliability of data for each participant score were calculated on both scale with poor correlation regarded a indicating unreliable answer the time taken to answer the questionnaire wa also recorded and those completed in too brief a time were excluded after each participant answered the questionnaire the activity history of that participant on twitter wa collected from twitter by using the api at most tweet were collected for each participant and the number of user following the participant and being followed by the participant were recorded tweet published after the questionnaire wa taken were discarded the website wa opened to the public on december at which time the author publicized it on their twitter account between december and february people participated in the experiment after eliminating participant who did not tweet and participant who answered the questionnaire in fewer than second a previously mentioned to ensure the reliability of the questionnaire answer set of answer remained only the first set of answer wa used for participant who completed the questionnaire more than once a a result data about experiment participant male female aged to mean year standard deviation year were analyzed the correlation between cesd score and bdi score for these participant were high and there were no participant with uncorrelated score so the data for all participant were used excluded datasets are not discussed any further figure show the histogram of cesd score of participant among the participant resp were estimated to have resp not have active depression for an incidence of approximately this incidence is similar to that found by de choudhury et al who identified depression in approximately of participant table give statistic on the activity history of participantsit is possible to extract various feature from the activity history of twitter user this section explains what kind of feature are used to estimate degree of depression and the way in which these quantity are extracted table show the feature used in this study a detailed explanation of each feature follows the frequency of word in a tweet ie it bag of word are used a a basic feature relating to the content of the tweet tsugawa et al showed that the word frequency are useful for identifying depression mecab wa used to for morphological stemming and categorization of the japanese tweet text to obtain accurate word frequency particle auxiliary verb adnominal adjective and visual symbol were excluded for extracting content word word used by only one participant were also excluded resulting in a total of distinct word however most of these word were rarely used and the distribution of word frequency is extremely biased see fig because word with a low rate of use were regarded a unlikely to be associated with depression for most user the frequency of only the word with the highest rate of use corresponding to or more us across all participant were used a a feature in this study furthermore because the number and length of tweet differed by participant the word frequency were normalized by the total number of word in the tweet the topic of the tweet of each user a estimated by using a representative topic model lda were used a a second feature relating to the content of the tweet with lda the distribution of topic in each document is estimated from the word frequency in each text through unsupervised learning on the assumption that the text and the word in it are generated according to a particular topic in lda the number of topic to identify and a set of document a bag of word are used a input and a topic distribution is output for each document a mentioned in related work section the topic of essay written by university student were estimated by using lda and found to be useful in evaluating degree of depression from that study topic are expected to be a useful feature a set of all tweet of each user wa used a the user document for input in lda and the word selected a described above were used a the word we used lda with collapsed gibbs sampling a the parameter of lda we used k and where k is the number of topic all extracted topic were used a the feature the ratio of positive word and the ratio of negative word used in the tweet text are used a the final feature relating to tweet content user with depression are intuitively expected to use negative word more frequently than user without depression do to categorize word a dictionary of affective word which is compiled by manual evaluation of a dictionary of positive and negative word extracted according to a technique proposed in the literature is used the dictionary contains positive word and negative word the user timing of tweet frequency of tweet average number of word retweet rate rate of republishing other user tweet mention rate rate of directly referencing at least one other user ratio of tweet containing a uniform resource locator url number of user being followed and number of user following are used a feature independent of the content of the tweet the relative ratio of tweet posted during each hour of the day were used to characterize the timing of tweet the number of post per day wa used a the posting frequency and the ratio of qualifying tweet to all tweet were used for the retweet ratio mention ratio and ratio of tweet containing a url these feature are used in prior research,"['study', 'gathered', 'information', 'depression', 'level', 'twitter', 'user', 'activity', 'history', 'published', 'website', 'administer', 'questionnaire', 'disseminated', 'information', 'website', 'twitter', 'contrast', 'de', 'choudhury', 'et', 'al', 'collected', 'data', 'englishspeaking', 'user', 'crowdsourcing', 'study', 'collected', 'data', 'japanesespeaking', 'volunteer', 'approach', 'wa', 'used', 'investigate', 'extent', 'depression', 'risk', 'estimated', 'population', 'different', 'population', 'considered', 'prior', 'research', 'figure', 'show', 'screenshot', 'website', 'website', 'collected', 'response', 'questionnaire', 'evaluate', 'degree', 'depression', 'twitter', 'user', 'participated', 'hereinafter', 'participant', 'collect', 'history', 'participant', 'activity', 'twitter', 'activity', 'history', 'participant', 'collected', 'twitter', 'application', 'programming', 'interface', 'api', 'questionnaire', 'determine', 'degree', 'depression', 'completed', 'participant', 'web', 'browser', 'data', 'collection', 'visitor', 'website', 'presented', 'written', 'explanation', 'aim', 'experiment', 'information', 'would', 'collected', 'information', 'would', 'handled', 'consented', 'become', 'participant', 'receiving', 'explanation', 'logged', 'individual', 'twitter', 'account', 'oauth', 'authorization', 'process', 'next', 'participant', 'surveyed', 'gender', 'age', 'occupation', 'history', 'depression', 'following', 'answered', 'questionnaire', 'designed', 'evaluate', 'degree', 'depression', 'message', 'called', 'kokoro', 'score', 'kokoro', 'japanese', 'word', 'meaning', 'heart', 'determined', 'basis', 'answer', 'questionnaire', 'information', 'collected', 'tweet', 'wa', 'displayed', 'participant', 'completion', 'questionnaire', 'fig', 'experiment', 'participant', 'able', 'tweet', 'message', 'displayed', 'made', 'possible', 'promote', 'website', 'twitter', 'wordofmouth', 'type', 'snowball', 'sampling', 'cesd', 'questionnaire', 'wa', 'used', 'evaluate', 'degree', 'depression', 'cesd', 'test', 'participant', 'answered', 'question', 'likerttype', 'point', 'scale', 'answer', 'wa', 'assigned', 'score', 'point', 'sum', 'point', 'answer', 'used', 'score', 'estimate', 'likelihood', 'depression', 'several', 'standard', 'exist', 'determine', 'appropriate', 'cutoff', 'score', 'identifying', 'depression', 'research', 'regarded', 'score', 'point', 'higher', 'indicating', 'active', 'depression', 'score', 'point', 'lower', 'indicating', 'active', 'depression', 'value', 'used', 'give', 'cutoff', 'score', 'addition', 'answer', 'bdi', 'depression', 'scale', 'used', 'characteristic', 'similar', 'cesd', 'collected', 'ensure', 'reliability', 'data', 'participant', 'score', 'calculated', 'scale', 'poor', 'correlation', 'regarded', 'indicating', 'unreliable', 'answer', 'time', 'taken', 'answer', 'questionnaire', 'wa', 'also', 'recorded', 'completed', 'brief', 'time', 'excluded', 'participant', 'answered', 'questionnaire', 'activity', 'history', 'participant', 'twitter', 'wa', 'collected', 'twitter', 'using', 'api', 'tweet', 'collected', 'participant', 'number', 'user', 'following', 'participant', 'followed', 'participant', 'recorded', 'tweet', 'published', 'questionnaire', 'wa', 'taken', 'discarded', 'website', 'wa', 'opened', 'public', 'december', 'time', 'author', 'publicized', 'twitter', 'account', 'december', 'february', 'people', 'participated', 'experiment', 'eliminating', 'participant', 'tweet', 'participant', 'answered', 'questionnaire', 'fewer', 'second', 'previously', 'mentioned', 'ensure', 'reliability', 'questionnaire', 'answer', 'set', 'answer', 'remained', 'first', 'set', 'answer', 'wa', 'used', 'participant', 'completed', 'questionnaire', 'result', 'data', 'experiment', 'participant', 'male', 'female', 'aged', 'mean', 'year', 'standard', 'deviation', 'year', 'analyzed', 'correlation', 'cesd', 'score', 'bdi', 'score', 'participant', 'high', 'participant', 'uncorrelated', 'score', 'data', 'participant', 'used', 'excluded', 'datasets', 'discussed', 'figure', 'show', 'histogram', 'cesd', 'score', 'participant', 'among', 'participant', 'resp', 'estimated', 'resp', 'active', 'depression', 'incidence', 'approximately', 'incidence', 'similar', 'found', 'de', 'choudhury', 'et', 'al', 'identified', 'depression', 'approximately', 'participant', 'table', 'give', 'statistic', 'activity', 'history', 'participantsit', 'possible', 'extract', 'various', 'feature', 'activity', 'history', 'twitter', 'user', 'section', 'explains', 'kind', 'feature', 'used', 'estimate', 'degree', 'depression', 'way', 'quantity', 'extracted', 'table', 'show', 'feature', 'used', 'study', 'detailed', 'explanation', 'feature', 'follows', 'frequency', 'word', 'tweet', 'ie', 'bag', 'word', 'used', 'basic', 'feature', 'relating', 'content', 'tweet', 'tsugawa', 'et', 'al', 'showed', 'word', 'frequency', 'useful', 'identifying', 'depression', 'mecab', 'wa', 'used', 'morphological', 'stemming', 'categorization', 'japanese', 'tweet', 'text', 'obtain', 'accurate', 'word', 'frequency', 'particle', 'auxiliary', 'verb', 'adnominal', 'adjective', 'visual', 'symbol', 'excluded', 'extracting', 'content', 'word', 'word', 'used', 'one', 'participant', 'also', 'excluded', 'resulting', 'total', 'distinct', 'word', 'however', 'word', 'rarely', 'used', 'distribution', 'word', 'frequency', 'extremely', 'biased', 'see', 'fig', 'word', 'low', 'rate', 'use', 'regarded', 'unlikely', 'associated', 'depression', 'user', 'frequency', 'word', 'highest', 'rate', 'use', 'corresponding', 'us', 'across', 'participant', 'used', 'feature', 'study', 'furthermore', 'number', 'length', 'tweet', 'differed', 'participant', 'word', 'frequency', 'normalized', 'total', 'number', 'word', 'tweet', 'topic', 'tweet', 'user', 'estimated', 'using', 'representative', 'topic', 'model', 'lda', 'used', 'second', 'feature', 'relating', 'content', 'tweet', 'lda', 'distribution', 'topic', 'document', 'estimated', 'word', 'frequency', 'text', 'unsupervised', 'learning', 'assumption', 'text', 'word', 'generated', 'according', 'particular', 'topic', 'lda', 'number', 'topic', 'identify', 'set', 'document', 'bag', 'word', 'used', 'input', 'topic', 'distribution', 'output', 'document', 'mentioned', 'related', 'work', 'section', 'topic', 'essay', 'written', 'university', 'student', 'estimated', 'using', 'lda', 'found', 'useful', 'evaluating', 'degree', 'depression', 'study', 'topic', 'expected', 'useful', 'feature', 'set', 'tweet', 'user', 'wa', 'used', 'user', 'document', 'input', 'lda', 'word', 'selected', 'described', 'used', 'word', 'used', 'lda', 'collapsed', 'gibbs', 'sampling', 'parameter', 'lda', 'used', 'k', 'k', 'number', 'topic', 'extracted', 'topic', 'used', 'feature', 'ratio', 'positive', 'word', 'ratio', 'negative', 'word', 'used', 'tweet', 'text', 'used', 'final', 'feature', 'relating', 'tweet', 'content', 'user', 'depression', 'intuitively', 'expected', 'use', 'negative', 'word', 'frequently', 'user', 'without', 'depression', 'categorize', 'word', 'dictionary', 'affective', 'word', 'compiled', 'manual', 'evaluation', 'dictionary', 'positive', 'negative', 'word', 'extracted', 'according', 'technique', 'proposed', 'literature', 'used', 'dictionary', 'contains', 'positive', 'word', 'negative', 'word', 'user', 'timing', 'tweet', 'frequency', 'tweet', 'average', 'number', 'word', 'retweet', 'rate', 'rate', 'republishing', 'user', 'tweet', 'mention', 'rate', 'rate', 'directly', 'referencing', 'least', 'one', 'user', 'ratio', 'tweet', 'containing', 'uniform', 'resource', 'locator', 'url', 'number', 'user', 'followed', 'number', 'user', 'following', 'used', 'feature', 'independent', 'content', 'tweet', 'relative', 'ratio', 'tweet', 'posted', 'hour', 'day', 'used', 'characterize', 'timing', 'tweet', 'number', 'post', 'per', 'day', 'wa', 'used', 'posting', 'frequency', 'ratio', 'qualifying', 'tweet', 'tweet', 'used', 'retweet', 'ratio', 'mention', 'ratio', 'ratio', 'tweet', 'containing', 'url', 'feature', 'used', 'prior', 'research']","['study gathered', 'gathered information', 'information depression', 'depression level', 'level twitter', 'twitter user', 'user activity', 'activity history', 'history published', 'published website', 'website administer', 'administer questionnaire', 'questionnaire disseminated', 'disseminated information', 'information website', 'website twitter', 'twitter contrast', 'contrast de', 'de choudhury', 'choudhury et', 'et al', 'al collected', 'collected data', 'data englishspeaking', 'englishspeaking user', 'user crowdsourcing', 'crowdsourcing study', 'study collected', 'collected data', 'data japanesespeaking', 'japanesespeaking volunteer', 'volunteer approach', 'approach wa', 'wa used', 'used investigate', 'investigate extent', 'extent depression', 'depression risk', 'risk estimated', 'estimated population', 'population different', 'different population', 'population considered', 'considered prior', 'prior research', 'research figure', 'figure show', 'show screenshot', 'screenshot website', 'website website', 'website collected', 'collected response', 'response questionnaire', 'questionnaire evaluate', 'evaluate degree', 'degree depression', 'depression twitter', 'twitter user', 'user participated', 'participated hereinafter', 'hereinafter participant', 'participant collect', 'collect history', 'history participant', 'participant activity', 'activity twitter', 'twitter activity', 'activity history', 'history participant', 'participant collected', 'collected twitter', 'twitter application', 'application programming', 'programming interface', 'interface api', 'api questionnaire', 'questionnaire determine', 'determine degree', 'degree depression', 'depression completed', 'completed participant', 'participant web', 'web browser', 'browser data', 'data collection', 'collection visitor', 'visitor website', 'website presented', 'presented written', 'written explanation', 'explanation aim', 'aim experiment', 'experiment information', 'information would', 'would collected', 'collected information', 'information would', 'would handled', 'handled consented', 'consented become', 'become participant', 'participant receiving', 'receiving explanation', 'explanation logged', 'logged individual', 'individual twitter', 'twitter account', 'account oauth', 'oauth authorization', 'authorization process', 'process next', 'next participant', 'participant surveyed', 'surveyed gender', 'gender age', 'age occupation', 'occupation history', 'history depression', 'depression following', 'following answered', 'answered questionnaire', 'questionnaire designed', 'designed evaluate', 'evaluate degree', 'degree depression', 'depression message', 'message called', 'called kokoro', 'kokoro score', 'score kokoro', 'kokoro japanese', 'japanese word', 'word meaning', 'meaning heart', 'heart determined', 'determined basis', 'basis answer', 'answer questionnaire', 'questionnaire information', 'information collected', 'collected tweet', 'tweet wa', 'wa displayed', 'displayed participant', 'participant completion', 'completion questionnaire', 'questionnaire fig', 'fig experiment', 'experiment participant', 'participant able', 'able tweet', 'tweet message', 'message displayed', 'displayed made', 'made possible', 'possible promote', 'promote website', 'website twitter', 'twitter wordofmouth', 'wordofmouth type', 'type snowball', 'snowball sampling', 'sampling cesd', 'cesd questionnaire', 'questionnaire wa', 'wa used', 'used evaluate', 'evaluate degree', 'degree depression', 'depression cesd', 'cesd test', 'test participant', 'participant answered', 'answered question', 'question likerttype', 'likerttype point', 'point scale', 'scale answer', 'answer wa', 'wa assigned', 'assigned score', 'score point', 'point sum', 'sum point', 'point answer', 'answer used', 'used score', 'score estimate', 'estimate likelihood', 'likelihood depression', 'depression several', 'several standard', 'standard exist', 'exist determine', 'determine appropriate', 'appropriate cutoff', 'cutoff score', 'score identifying', 'identifying depression', 'depression research', 'research regarded', 'regarded score', 'score point', 'point higher', 'higher indicating', 'indicating active', 'active depression', 'depression score', 'score point', 'point lower', 'lower indicating', 'indicating active', 'active depression', 'depression value', 'value used', 'used give', 'give cutoff', 'cutoff score', 'score addition', 'addition answer', 'answer bdi', 'bdi depression', 'depression scale', 'scale used', 'used characteristic', 'characteristic similar', 'similar cesd', 'cesd collected', 'collected ensure', 'ensure reliability', 'reliability data', 'data participant', 'participant score', 'score calculated', 'calculated scale', 'scale poor', 'poor correlation', 'correlation regarded', 'regarded indicating', 'indicating unreliable', 'unreliable answer', 'answer time', 'time taken', 'taken answer', 'answer questionnaire', 'questionnaire wa', 'wa also', 'also recorded', 'recorded completed', 'completed brief', 'brief time', 'time excluded', 'excluded participant', 'participant answered', 'answered questionnaire', 'questionnaire activity', 'activity history', 'history participant', 'participant twitter', 'twitter wa', 'wa collected', 'collected twitter', 'twitter using', 'using api', 'api tweet', 'tweet collected', 'collected participant', 'participant number', 'number user', 'user following', 'following participant', 'participant followed', 'followed participant', 'participant recorded', 'recorded tweet', 'tweet published', 'published questionnaire', 'questionnaire wa', 'wa taken', 'taken discarded', 'discarded website', 'website wa', 'wa opened', 'opened public', 'public december', 'december time', 'time author', 'author publicized', 'publicized twitter', 'twitter account', 'account december', 'december february', 'february people', 'people participated', 'participated experiment', 'experiment eliminating', 'eliminating participant', 'participant tweet', 'tweet participant', 'participant answered', 'answered questionnaire', 'questionnaire fewer', 'fewer second', 'second previously', 'previously mentioned', 'mentioned ensure', 'ensure reliability', 'reliability questionnaire', 'questionnaire answer', 'answer set', 'set answer', 'answer remained', 'remained first', 'first set', 'set answer', 'answer wa', 'wa used', 'used participant', 'participant completed', 'completed questionnaire', 'questionnaire result', 'result data', 'data experiment', 'experiment participant', 'participant male', 'male female', 'female aged', 'aged mean', 'mean year', 'year standard', 'standard deviation', 'deviation year', 'year analyzed', 'analyzed correlation', 'correlation cesd', 'cesd score', 'score bdi', 'bdi score', 'score participant', 'participant high', 'high participant', 'participant uncorrelated', 'uncorrelated score', 'score data', 'data participant', 'participant used', 'used excluded', 'excluded datasets', 'datasets discussed', 'discussed figure', 'figure show', 'show histogram', 'histogram cesd', 'cesd score', 'score participant', 'participant among', 'among participant', 'participant resp', 'resp estimated', 'estimated resp', 'resp active', 'active depression', 'depression incidence', 'incidence approximately', 'approximately incidence', 'incidence similar', 'similar found', 'found de', 'de choudhury', 'choudhury et', 'et al', 'al identified', 'identified depression', 'depression approximately', 'approximately participant', 'participant table', 'table give', 'give statistic', 'statistic activity', 'activity history', 'history participantsit', 'participantsit possible', 'possible extract', 'extract various', 'various feature', 'feature activity', 'activity history', 'history twitter', 'twitter user', 'user section', 'section explains', 'explains kind', 'kind feature', 'feature used', 'used estimate', 'estimate degree', 'degree depression', 'depression way', 'way quantity', 'quantity extracted', 'extracted table', 'table show', 'show feature', 'feature used', 'used study', 'study detailed', 'detailed explanation', 'explanation feature', 'feature follows', 'follows frequency', 'frequency word', 'word tweet', 'tweet ie', 'ie bag', 'bag word', 'word used', 'used basic', 'basic feature', 'feature relating', 'relating content', 'content tweet', 'tweet tsugawa', 'tsugawa et', 'et al', 'al showed', 'showed word', 'word frequency', 'frequency useful', 'useful identifying', 'identifying depression', 'depression mecab', 'mecab wa', 'wa used', 'used morphological', 'morphological stemming', 'stemming categorization', 'categorization japanese', 'japanese tweet', 'tweet text', 'text obtain', 'obtain accurate', 'accurate word', 'word frequency', 'frequency particle', 'particle auxiliary', 'auxiliary verb', 'verb adnominal', 'adnominal adjective', 'adjective visual', 'visual symbol', 'symbol excluded', 'excluded extracting', 'extracting content', 'content word', 'word word', 'word used', 'used one', 'one participant', 'participant also', 'also excluded', 'excluded resulting', 'resulting total', 'total distinct', 'distinct word', 'word however', 'however word', 'word rarely', 'rarely used', 'used distribution', 'distribution word', 'word frequency', 'frequency extremely', 'extremely biased', 'biased see', 'see fig', 'fig word', 'word low', 'low rate', 'rate use', 'use regarded', 'regarded unlikely', 'unlikely associated', 'associated depression', 'depression user', 'user frequency', 'frequency word', 'word highest', 'highest rate', 'rate use', 'use corresponding', 'corresponding us', 'us across', 'across participant', 'participant used', 'used feature', 'feature study', 'study furthermore', 'furthermore number', 'number length', 'length tweet', 'tweet differed', 'differed participant', 'participant word', 'word frequency', 'frequency normalized', 'normalized total', 'total number', 'number word', 'word tweet', 'tweet topic', 'topic tweet', 'tweet user', 'user estimated', 'estimated using', 'using representative', 'representative topic', 'topic model', 'model lda', 'lda used', 'used second', 'second feature', 'feature relating', 'relating content', 'content tweet', 'tweet lda', 'lda distribution', 'distribution topic', 'topic document', 'document estimated', 'estimated word', 'word frequency', 'frequency text', 'text unsupervised', 'unsupervised learning', 'learning assumption', 'assumption text', 'text word', 'word generated', 'generated according', 'according particular', 'particular topic', 'topic lda', 'lda number', 'number topic', 'topic identify', 'identify set', 'set document', 'document bag', 'bag word', 'word used', 'used input', 'input topic', 'topic distribution', 'distribution output', 'output document', 'document mentioned', 'mentioned related', 'related work', 'work section', 'section topic', 'topic essay', 'essay written', 'written university', 'university student', 'student estimated', 'estimated using', 'using lda', 'lda found', 'found useful', 'useful evaluating', 'evaluating degree', 'degree depression', 'depression study', 'study topic', 'topic expected', 'expected useful', 'useful feature', 'feature set', 'set tweet', 'tweet user', 'user wa', 'wa used', 'used user', 'user document', 'document input', 'input lda', 'lda word', 'word selected', 'selected described', 'described used', 'used word', 'word used', 'used lda', 'lda collapsed', 'collapsed gibbs', 'gibbs sampling', 'sampling parameter', 'parameter lda', 'lda used', 'used k', 'k k', 'k number', 'number topic', 'topic extracted', 'extracted topic', 'topic used', 'used feature', 'feature ratio', 'ratio positive', 'positive word', 'word ratio', 'ratio negative', 'negative word', 'word used', 'used tweet', 'tweet text', 'text used', 'used final', 'final feature', 'feature relating', 'relating tweet', 'tweet content', 'content user', 'user depression', 'depression intuitively', 'intuitively expected', 'expected use', 'use negative', 'negative word', 'word frequently', 'frequently user', 'user without', 'without depression', 'depression categorize', 'categorize word', 'word dictionary', 'dictionary affective', 'affective word', 'word compiled', 'compiled manual', 'manual evaluation', 'evaluation dictionary', 'dictionary positive', 'positive negative', 'negative word', 'word extracted', 'extracted according', 'according technique', 'technique proposed', 'proposed literature', 'literature used', 'used dictionary', 'dictionary contains', 'contains positive', 'positive word', 'word negative', 'negative word', 'word user', 'user timing', 'timing tweet', 'tweet frequency', 'frequency tweet', 'tweet average', 'average number', 'number word', 'word retweet', 'retweet rate', 'rate rate', 'rate republishing', 'republishing user', 'user tweet', 'tweet mention', 'mention rate', 'rate rate', 'rate directly', 'directly referencing', 'referencing least', 'least one', 'one user', 'user ratio', 'ratio tweet', 'tweet containing', 'containing uniform', 'uniform resource', 'resource locator', 'locator url', 'url number', 'number user', 'user followed', 'followed number', 'number user', 'user following', 'following used', 'used feature', 'feature independent', 'independent content', 'content tweet', 'tweet relative', 'relative ratio', 'ratio tweet', 'tweet posted', 'posted hour', 'hour day', 'day used', 'used characterize', 'characterize timing', 'timing tweet', 'tweet number', 'number post', 'post per', 'per day', 'day wa', 'wa used', 'used posting', 'posting frequency', 'frequency ratio', 'ratio qualifying', 'qualifying tweet', 'tweet tweet', 'tweet used', 'used retweet', 'retweet ratio', 'ratio mention', 'mention ratio', 'ratio ratio', 'ratio tweet', 'tweet containing', 'containing url', 'url feature', 'feature used', 'used prior', 'prior research']","['study gathered information', 'gathered information depression', 'information depression level', 'depression level twitter', 'level twitter user', 'twitter user activity', 'user activity history', 'activity history published', 'history published website', 'published website administer', 'website administer questionnaire', 'administer questionnaire disseminated', 'questionnaire disseminated information', 'disseminated information website', 'information website twitter', 'website twitter contrast', 'twitter contrast de', 'contrast de choudhury', 'de choudhury et', 'choudhury et al', 'et al collected', 'al collected data', 'collected data englishspeaking', 'data englishspeaking user', 'englishspeaking user crowdsourcing', 'user crowdsourcing study', 'crowdsourcing study collected', 'study collected data', 'collected data japanesespeaking', 'data japanesespeaking volunteer', 'japanesespeaking volunteer approach', 'volunteer approach wa', 'approach wa used', 'wa used investigate', 'used investigate extent', 'investigate extent depression', 'extent depression risk', 'depression risk estimated', 'risk estimated population', 'estimated population different', 'population different population', 'different population considered', 'population considered prior', 'considered prior research', 'prior research figure', 'research figure show', 'figure show screenshot', 'show screenshot website', 'screenshot website website', 'website website collected', 'website collected response', 'collected response questionnaire', 'response questionnaire evaluate', 'questionnaire evaluate degree', 'evaluate degree depression', 'degree depression twitter', 'depression twitter user', 'twitter user participated', 'user participated hereinafter', 'participated hereinafter participant', 'hereinafter participant collect', 'participant collect history', 'collect history participant', 'history participant activity', 'participant activity twitter', 'activity twitter activity', 'twitter activity history', 'activity history participant', 'history participant collected', 'participant collected twitter', 'collected twitter application', 'twitter application programming', 'application programming interface', 'programming interface api', 'interface api questionnaire', 'api questionnaire determine', 'questionnaire determine degree', 'determine degree depression', 'degree depression completed', 'depression completed participant', 'completed participant web', 'participant web browser', 'web browser data', 'browser data collection', 'data collection visitor', 'collection visitor website', 'visitor website presented', 'website presented written', 'presented written explanation', 'written explanation aim', 'explanation aim experiment', 'aim experiment information', 'experiment information would', 'information would collected', 'would collected information', 'collected information would', 'information would handled', 'would handled consented', 'handled consented become', 'consented become participant', 'become participant receiving', 'participant receiving explanation', 'receiving explanation logged', 'explanation logged individual', 'logged individual twitter', 'individual twitter account', 'twitter account oauth', 'account oauth authorization', 'oauth authorization process', 'authorization process next', 'process next participant', 'next participant surveyed', 'participant surveyed gender', 'surveyed gender age', 'gender age occupation', 'age occupation history', 'occupation history depression', 'history depression following', 'depression following answered', 'following answered questionnaire', 'answered questionnaire designed', 'questionnaire designed evaluate', 'designed evaluate degree', 'evaluate degree depression', 'degree depression message', 'depression message called', 'message called kokoro', 'called kokoro score', 'kokoro score kokoro', 'score kokoro japanese', 'kokoro japanese word', 'japanese word meaning', 'word meaning heart', 'meaning heart determined', 'heart determined basis', 'determined basis answer', 'basis answer questionnaire', 'answer questionnaire information', 'questionnaire information collected', 'information collected tweet', 'collected tweet wa', 'tweet wa displayed', 'wa displayed participant', 'displayed participant completion', 'participant completion questionnaire', 'completion questionnaire fig', 'questionnaire fig experiment', 'fig experiment participant', 'experiment participant able', 'participant able tweet', 'able tweet message', 'tweet message displayed', 'message displayed made', 'displayed made possible', 'made possible promote', 'possible promote website', 'promote website twitter', 'website twitter wordofmouth', 'twitter wordofmouth type', 'wordofmouth type snowball', 'type snowball sampling', 'snowball sampling cesd', 'sampling cesd questionnaire', 'cesd questionnaire wa', 'questionnaire wa used', 'wa used evaluate', 'used evaluate degree', 'evaluate degree depression', 'degree depression cesd', 'depression cesd test', 'cesd test participant', 'test participant answered', 'participant answered question', 'answered question likerttype', 'question likerttype point', 'likerttype point scale', 'point scale answer', 'scale answer wa', 'answer wa assigned', 'wa assigned score', 'assigned score point', 'score point sum', 'point sum point', 'sum point answer', 'point answer used', 'answer used score', 'used score estimate', 'score estimate likelihood', 'estimate likelihood depression', 'likelihood depression several', 'depression several standard', 'several standard exist', 'standard exist determine', 'exist determine appropriate', 'determine appropriate cutoff', 'appropriate cutoff score', 'cutoff score identifying', 'score identifying depression', 'identifying depression research', 'depression research regarded', 'research regarded score', 'regarded score point', 'score point higher', 'point higher indicating', 'higher indicating active', 'indicating active depression', 'active depression score', 'depression score point', 'score point lower', 'point lower indicating', 'lower indicating active', 'indicating active depression', 'active depression value', 'depression value used', 'value used give', 'used give cutoff', 'give cutoff score', 'cutoff score addition', 'score addition answer', 'addition answer bdi', 'answer bdi depression', 'bdi depression scale', 'depression scale used', 'scale used characteristic', 'used characteristic similar', 'characteristic similar cesd', 'similar cesd collected', 'cesd collected ensure', 'collected ensure reliability', 'ensure reliability data', 'reliability data participant', 'data participant score', 'participant score calculated', 'score calculated scale', 'calculated scale poor', 'scale poor correlation', 'poor correlation regarded', 'correlation regarded indicating', 'regarded indicating unreliable', 'indicating unreliable answer', 'unreliable answer time', 'answer time taken', 'time taken answer', 'taken answer questionnaire', 'answer questionnaire wa', 'questionnaire wa also', 'wa also recorded', 'also recorded completed', 'recorded completed brief', 'completed brief time', 'brief time excluded', 'time excluded participant', 'excluded participant answered', 'participant answered questionnaire', 'answered questionnaire activity', 'questionnaire activity history', 'activity history participant', 'history participant twitter', 'participant twitter wa', 'twitter wa collected', 'wa collected twitter', 'collected twitter using', 'twitter using api', 'using api tweet', 'api tweet collected', 'tweet collected participant', 'collected participant number', 'participant number user', 'number user following', 'user following participant', 'following participant followed', 'participant followed participant', 'followed participant recorded', 'participant recorded tweet', 'recorded tweet published', 'tweet published questionnaire', 'published questionnaire wa', 'questionnaire wa taken', 'wa taken discarded', 'taken discarded website', 'discarded website wa', 'website wa opened', 'wa opened public', 'opened public december', 'public december time', 'december time author', 'time author publicized', 'author publicized twitter', 'publicized twitter account', 'twitter account december', 'account december february', 'december february people', 'february people participated', 'people participated experiment', 'participated experiment eliminating', 'experiment eliminating participant', 'eliminating participant tweet', 'participant tweet participant', 'tweet participant answered', 'participant answered questionnaire', 'answered questionnaire fewer', 'questionnaire fewer second', 'fewer second previously', 'second previously mentioned', 'previously mentioned ensure', 'mentioned ensure reliability', 'ensure reliability questionnaire', 'reliability questionnaire answer', 'questionnaire answer set', 'answer set answer', 'set answer remained', 'answer remained first', 'remained first set', 'first set answer', 'set answer wa', 'answer wa used', 'wa used participant', 'used participant completed', 'participant completed questionnaire', 'completed questionnaire result', 'questionnaire result data', 'result data experiment', 'data experiment participant', 'experiment participant male', 'participant male female', 'male female aged', 'female aged mean', 'aged mean year', 'mean year standard', 'year standard deviation', 'standard deviation year', 'deviation year analyzed', 'year analyzed correlation', 'analyzed correlation cesd', 'correlation cesd score', 'cesd score bdi', 'score bdi score', 'bdi score participant', 'score participant high', 'participant high participant', 'high participant uncorrelated', 'participant uncorrelated score', 'uncorrelated score data', 'score data participant', 'data participant used', 'participant used excluded', 'used excluded datasets', 'excluded datasets discussed', 'datasets discussed figure', 'discussed figure show', 'figure show histogram', 'show histogram cesd', 'histogram cesd score', 'cesd score participant', 'score participant among', 'participant among participant', 'among participant resp', 'participant resp estimated', 'resp estimated resp', 'estimated resp active', 'resp active depression', 'active depression incidence', 'depression incidence approximately', 'incidence approximately incidence', 'approximately incidence similar', 'incidence similar found', 'similar found de', 'found de choudhury', 'de choudhury et', 'choudhury et al', 'et al identified', 'al identified depression', 'identified depression approximately', 'depression approximately participant', 'approximately participant table', 'participant table give', 'table give statistic', 'give statistic activity', 'statistic activity history', 'activity history participantsit', 'history participantsit possible', 'participantsit possible extract', 'possible extract various', 'extract various feature', 'various feature activity', 'feature activity history', 'activity history twitter', 'history twitter user', 'twitter user section', 'user section explains', 'section explains kind', 'explains kind feature', 'kind feature used', 'feature used estimate', 'used estimate degree', 'estimate degree depression', 'degree depression way', 'depression way quantity', 'way quantity extracted', 'quantity extracted table', 'extracted table show', 'table show feature', 'show feature used', 'feature used study', 'used study detailed', 'study detailed explanation', 'detailed explanation feature', 'explanation feature follows', 'feature follows frequency', 'follows frequency word', 'frequency word tweet', 'word tweet ie', 'tweet ie bag', 'ie bag word', 'bag word used', 'word used basic', 'used basic feature', 'basic feature relating', 'feature relating content', 'relating content tweet', 'content tweet tsugawa', 'tweet tsugawa et', 'tsugawa et al', 'et al showed', 'al showed word', 'showed word frequency', 'word frequency useful', 'frequency useful identifying', 'useful identifying depression', 'identifying depression mecab', 'depression mecab wa', 'mecab wa used', 'wa used morphological', 'used morphological stemming', 'morphological stemming categorization', 'stemming categorization japanese', 'categorization japanese tweet', 'japanese tweet text', 'tweet text obtain', 'text obtain accurate', 'obtain accurate word', 'accurate word frequency', 'word frequency particle', 'frequency particle auxiliary', 'particle auxiliary verb', 'auxiliary verb adnominal', 'verb adnominal adjective', 'adnominal adjective visual', 'adjective visual symbol', 'visual symbol excluded', 'symbol excluded extracting', 'excluded extracting content', 'extracting content word', 'content word word', 'word word used', 'word used one', 'used one participant', 'one participant also', 'participant also excluded', 'also excluded resulting', 'excluded resulting total', 'resulting total distinct', 'total distinct word', 'distinct word however', 'word however word', 'however word rarely', 'word rarely used', 'rarely used distribution', 'used distribution word', 'distribution word frequency', 'word frequency extremely', 'frequency extremely biased', 'extremely biased see', 'biased see fig', 'see fig word', 'fig word low', 'word low rate', 'low rate use', 'rate use regarded', 'use regarded unlikely', 'regarded unlikely associated', 'unlikely associated depression', 'associated depression user', 'depression user frequency', 'user frequency word', 'frequency word highest', 'word highest rate', 'highest rate use', 'rate use corresponding', 'use corresponding us', 'corresponding us across', 'us across participant', 'across participant used', 'participant used feature', 'used feature study', 'feature study furthermore', 'study furthermore number', 'furthermore number length', 'number length tweet', 'length tweet differed', 'tweet differed participant', 'differed participant word', 'participant word frequency', 'word frequency normalized', 'frequency normalized total', 'normalized total number', 'total number word', 'number word tweet', 'word tweet topic', 'tweet topic tweet', 'topic tweet user', 'tweet user estimated', 'user estimated using', 'estimated using representative', 'using representative topic', 'representative topic model', 'topic model lda', 'model lda used', 'lda used second', 'used second feature', 'second feature relating', 'feature relating content', 'relating content tweet', 'content tweet lda', 'tweet lda distribution', 'lda distribution topic', 'distribution topic document', 'topic document estimated', 'document estimated word', 'estimated word frequency', 'word frequency text', 'frequency text unsupervised', 'text unsupervised learning', 'unsupervised learning assumption', 'learning assumption text', 'assumption text word', 'text word generated', 'word generated according', 'generated according particular', 'according particular topic', 'particular topic lda', 'topic lda number', 'lda number topic', 'number topic identify', 'topic identify set', 'identify set document', 'set document bag', 'document bag word', 'bag word used', 'word used input', 'used input topic', 'input topic distribution', 'topic distribution output', 'distribution output document', 'output document mentioned', 'document mentioned related', 'mentioned related work', 'related work section', 'work section topic', 'section topic essay', 'topic essay written', 'essay written university', 'written university student', 'university student estimated', 'student estimated using', 'estimated using lda', 'using lda found', 'lda found useful', 'found useful evaluating', 'useful evaluating degree', 'evaluating degree depression', 'degree depression study', 'depression study topic', 'study topic expected', 'topic expected useful', 'expected useful feature', 'useful feature set', 'feature set tweet', 'set tweet user', 'tweet user wa', 'user wa used', 'wa used user', 'used user document', 'user document input', 'document input lda', 'input lda word', 'lda word selected', 'word selected described', 'selected described used', 'described used word', 'used word used', 'word used lda', 'used lda collapsed', 'lda collapsed gibbs', 'collapsed gibbs sampling', 'gibbs sampling parameter', 'sampling parameter lda', 'parameter lda used', 'lda used k', 'used k k', 'k k number', 'k number topic', 'number topic extracted', 'topic extracted topic', 'extracted topic used', 'topic used feature', 'used feature ratio', 'feature ratio positive', 'ratio positive word', 'positive word ratio', 'word ratio negative', 'ratio negative word', 'negative word used', 'word used tweet', 'used tweet text', 'tweet text used', 'text used final', 'used final feature', 'final feature relating', 'feature relating tweet', 'relating tweet content', 'tweet content user', 'content user depression', 'user depression intuitively', 'depression intuitively expected', 'intuitively expected use', 'expected use negative', 'use negative word', 'negative word frequently', 'word frequently user', 'frequently user without', 'user without depression', 'without depression categorize', 'depression categorize word', 'categorize word dictionary', 'word dictionary affective', 'dictionary affective word', 'affective word compiled', 'word compiled manual', 'compiled manual evaluation', 'manual evaluation dictionary', 'evaluation dictionary positive', 'dictionary positive negative', 'positive negative word', 'negative word extracted', 'word extracted according', 'extracted according technique', 'according technique proposed', 'technique proposed literature', 'proposed literature used', 'literature used dictionary', 'used dictionary contains', 'dictionary contains positive', 'contains positive word', 'positive word negative', 'word negative word', 'negative word user', 'word user timing', 'user timing tweet', 'timing tweet frequency', 'tweet frequency tweet', 'frequency tweet average', 'tweet average number', 'average number word', 'number word retweet', 'word retweet rate', 'retweet rate rate', 'rate rate republishing', 'rate republishing user', 'republishing user tweet', 'user tweet mention', 'tweet mention rate', 'mention rate rate', 'rate rate directly', 'rate directly referencing', 'directly referencing least', 'referencing least one', 'least one user', 'one user ratio', 'user ratio tweet', 'ratio tweet containing', 'tweet containing uniform', 'containing uniform resource', 'uniform resource locator', 'resource locator url', 'locator url number', 'url number user', 'number user followed', 'user followed number', 'followed number user', 'number user following', 'user following used', 'following used feature', 'used feature independent', 'feature independent content', 'independent content tweet', 'content tweet relative', 'tweet relative ratio', 'relative ratio tweet', 'ratio tweet posted', 'tweet posted hour', 'posted hour day', 'hour day used', 'day used characterize', 'used characterize timing', 'characterize timing tweet', 'timing tweet number', 'tweet number post', 'number post per', 'post per day', 'per day wa', 'day wa used', 'wa used posting', 'used posting frequency', 'posting frequency ratio', 'frequency ratio qualifying', 'ratio qualifying tweet', 'qualifying tweet tweet', 'tweet tweet used', 'tweet used retweet', 'used retweet ratio', 'retweet ratio mention', 'ratio mention ratio', 'mention ratio ratio', 'ratio ratio tweet', 'ratio tweet containing', 'tweet containing url', 'containing url feature', 'url feature used', 'feature used prior', 'used prior research']",,,,,,,,
https://www.nature.com/articles/s41598-017-12961-9,1,We extracted several categories of predictors from the Twitter posts collected. Predictor selection for both depression and PTSD was based on prior machine learning models of depression in Twitter data78 as the two conditions’ high comorbidity rates suggest their predictive signals may exhibit considerable overlap20. Depressed Twitter users have been observed to tweet less frequently than non-depressed users8 so we used total tweets per user per day as a measure of user activity. Tweet metadata was analyzed to assess average word count per tweet (here a word is defined as a set of characters surrounded by whitespace) whether or not the tweet was a retweet and whether or not the tweet was a reply to someone else’s tweet. The labMT LIWC 2007 and ANEW unigram sentiment instruments were used to quantify the happiness of tweet language37383940. The use of labMT which has shown strong prior performance in analyzing happiness on Twitter4142 is novel with respect to depression screening; ANEW and LIWC have been successfully applied in previous studies on depression and Twitter7814. LIWC was also used to compile frequency counts of various parts of speech (e.g. pronouns verbs adjectives) and semantic categories (e.g. food words familial terms profanity) as additional predictors37.Determining the best time span for analysis raises a difficult question: When and for how long does mental illness occur? Receiving a clinical diagnosis of depression or PTSD does not imply that an individual remains in a persistent state of illness and so to conduct analysis with an individual’s entire posting history as a single unit of observation is a dubious proposition. At the other extreme to take one tweet as a unit of observation runs the risk of being too granular. De Choudhury et al.8 looked at all of a given user’s tweets in a single day and aggregated those data into per-person per-day units of observation. In this report we have followed the convention of aggregated “user-days” as a primary unit of analysis rather than try to categorize a person’s entire history or analyze each individual tweet. In our own previous research however we have found that many Twitter users do not generate enough daily content to make for robust unigram sentiment analysis43. For completeness we conducted analyses using both daily and weekly units of observation. Both analyses yielded predictive models of similar strengths with the weekly model showing a slight but consistent edge in performance. We report accuracy metrics from both analyses but restrict other results to the daily-unit analysis to allow for more direct comparison with previous research. Details of weekly-unit analytical results are available in Supplementary Information section II. When reporting results we occasionally refer to observations or tweets as “depressed” e.g. “depressed tweets received fewer likes”. It would be more correct to use the phrase “tweet data from depressed participants aggregated by user-days” instead of “depressed tweets” but we chose to sacrifice a degree of technical correctness for the sake of clarity.,we extracted several category of predictor from the twitter post collected predictor selection for both depression and ptsd wa based on prior machine learning model of depression in twitter data a the two condition high comorbidity rate suggest their predictive signal may exhibit considerable overlap depressed twitter user have been observed to tweet le frequently than nondepressed user so we used total tweet per user per day a a measure of user activity tweet metadata wa analyzed to ass average word count per tweet here a word is defined a a set of character surrounded by whitespace whether or not the tweet wa a retweet and whether or not the tweet wa a reply to someone el tweet the labmt liwc and anew unigram sentiment instrument were used to quantify the happiness of tweet language the use of labmt which ha shown strong prior performance in analyzing happiness on twitter is novel with respect to depression screening anew and liwc have been successfully applied in previous study on depression and twitter liwc wa also used to compile frequency count of various part of speech eg pronoun verb adjective and semantic category eg food word familial term profanity a additional predictorsdetermining the best time span for analysis raise a difficult question when and for how long doe mental illness occur receiving a clinical diagnosis of depression or ptsd doe not imply that an individual remains in a persistent state of illness and so to conduct analysis with an individual entire posting history a a single unit of observation is a dubious proposition at the other extreme to take one tweet a a unit of observation run the risk of being too granular de choudhury et al looked at all of a given user tweet in a single day and aggregated those data into perperson perday unit of observation in this report we have followed the convention of aggregated userdays a a primary unit of analysis rather than try to categorize a person entire history or analyze each individual tweet in our own previous research however we have found that many twitter user do not generate enough daily content to make for robust unigram sentiment analysis for completeness we conducted analysis using both daily and weekly unit of observation both analysis yielded predictive model of similar strength with the weekly model showing a slight but consistent edge in performance we report accuracy metric from both analysis but restrict other result to the dailyunit analysis to allow for more direct comparison with previous research detail of weeklyunit analytical result are available in supplementary information section ii when reporting result we occasionally refer to observation or tweet a depressed eg depressed tweet received fewer like it would be more correct to use the phrase tweet data from depressed participant aggregated by userdays instead of depressed tweet but we chose to sacrifice a degree of technical correctness for the sake of clarity,"['extracted', 'several', 'category', 'predictor', 'twitter', 'post', 'collected', 'predictor', 'selection', 'depression', 'ptsd', 'wa', 'based', 'prior', 'machine', 'learning', 'model', 'depression', 'twitter', 'data', 'two', 'condition', 'high', 'comorbidity', 'rate', 'suggest', 'predictive', 'signal', 'may', 'exhibit', 'considerable', 'overlap', 'depressed', 'twitter', 'user', 'observed', 'tweet', 'le', 'frequently', 'nondepressed', 'user', 'used', 'total', 'tweet', 'per', 'user', 'per', 'day', 'measure', 'user', 'activity', 'tweet', 'metadata', 'wa', 'analyzed', 'ass', 'average', 'word', 'count', 'per', 'tweet', 'word', 'defined', 'set', 'character', 'surrounded', 'whitespace', 'whether', 'tweet', 'wa', 'retweet', 'whether', 'tweet', 'wa', 'reply', 'someone', 'el', 'tweet', 'labmt', 'liwc', 'anew', 'unigram', 'sentiment', 'instrument', 'used', 'quantify', 'happiness', 'tweet', 'language', 'use', 'labmt', 'ha', 'shown', 'strong', 'prior', 'performance', 'analyzing', 'happiness', 'twitter', 'novel', 'respect', 'depression', 'screening', 'anew', 'liwc', 'successfully', 'applied', 'previous', 'study', 'depression', 'twitter', 'liwc', 'wa', 'also', 'used', 'compile', 'frequency', 'count', 'various', 'part', 'speech', 'eg', 'pronoun', 'verb', 'adjective', 'semantic', 'category', 'eg', 'food', 'word', 'familial', 'term', 'profanity', 'additional', 'predictorsdetermining', 'best', 'time', 'span', 'analysis', 'raise', 'difficult', 'question', 'long', 'doe', 'mental', 'illness', 'occur', 'receiving', 'clinical', 'diagnosis', 'depression', 'ptsd', 'doe', 'imply', 'individual', 'remains', 'persistent', 'state', 'illness', 'conduct', 'analysis', 'individual', 'entire', 'posting', 'history', 'single', 'unit', 'observation', 'dubious', 'proposition', 'extreme', 'take', 'one', 'tweet', 'unit', 'observation', 'run', 'risk', 'granular', 'de', 'choudhury', 'et', 'al', 'looked', 'given', 'user', 'tweet', 'single', 'day', 'aggregated', 'data', 'perperson', 'perday', 'unit', 'observation', 'report', 'followed', 'convention', 'aggregated', 'userdays', 'primary', 'unit', 'analysis', 'rather', 'try', 'categorize', 'person', 'entire', 'history', 'analyze', 'individual', 'tweet', 'previous', 'research', 'however', 'found', 'many', 'twitter', 'user', 'generate', 'enough', 'daily', 'content', 'make', 'robust', 'unigram', 'sentiment', 'analysis', 'completeness', 'conducted', 'analysis', 'using', 'daily', 'weekly', 'unit', 'observation', 'analysis', 'yielded', 'predictive', 'model', 'similar', 'strength', 'weekly', 'model', 'showing', 'slight', 'consistent', 'edge', 'performance', 'report', 'accuracy', 'metric', 'analysis', 'restrict', 'result', 'dailyunit', 'analysis', 'allow', 'direct', 'comparison', 'previous', 'research', 'detail', 'weeklyunit', 'analytical', 'result', 'available', 'supplementary', 'information', 'section', 'ii', 'reporting', 'result', 'occasionally', 'refer', 'observation', 'tweet', 'depressed', 'eg', 'depressed', 'tweet', 'received', 'fewer', 'like', 'would', 'correct', 'use', 'phrase', 'tweet', 'data', 'depressed', 'participant', 'aggregated', 'userdays', 'instead', 'depressed', 'tweet', 'chose', 'sacrifice', 'degree', 'technical', 'correctness', 'sake', 'clarity']","['extracted several', 'several category', 'category predictor', 'predictor twitter', 'twitter post', 'post collected', 'collected predictor', 'predictor selection', 'selection depression', 'depression ptsd', 'ptsd wa', 'wa based', 'based prior', 'prior machine', 'machine learning', 'learning model', 'model depression', 'depression twitter', 'twitter data', 'data two', 'two condition', 'condition high', 'high comorbidity', 'comorbidity rate', 'rate suggest', 'suggest predictive', 'predictive signal', 'signal may', 'may exhibit', 'exhibit considerable', 'considerable overlap', 'overlap depressed', 'depressed twitter', 'twitter user', 'user observed', 'observed tweet', 'tweet le', 'le frequently', 'frequently nondepressed', 'nondepressed user', 'user used', 'used total', 'total tweet', 'tweet per', 'per user', 'user per', 'per day', 'day measure', 'measure user', 'user activity', 'activity tweet', 'tweet metadata', 'metadata wa', 'wa analyzed', 'analyzed ass', 'ass average', 'average word', 'word count', 'count per', 'per tweet', 'tweet word', 'word defined', 'defined set', 'set character', 'character surrounded', 'surrounded whitespace', 'whitespace whether', 'whether tweet', 'tweet wa', 'wa retweet', 'retweet whether', 'whether tweet', 'tweet wa', 'wa reply', 'reply someone', 'someone el', 'el tweet', 'tweet labmt', 'labmt liwc', 'liwc anew', 'anew unigram', 'unigram sentiment', 'sentiment instrument', 'instrument used', 'used quantify', 'quantify happiness', 'happiness tweet', 'tweet language', 'language use', 'use labmt', 'labmt ha', 'ha shown', 'shown strong', 'strong prior', 'prior performance', 'performance analyzing', 'analyzing happiness', 'happiness twitter', 'twitter novel', 'novel respect', 'respect depression', 'depression screening', 'screening anew', 'anew liwc', 'liwc successfully', 'successfully applied', 'applied previous', 'previous study', 'study depression', 'depression twitter', 'twitter liwc', 'liwc wa', 'wa also', 'also used', 'used compile', 'compile frequency', 'frequency count', 'count various', 'various part', 'part speech', 'speech eg', 'eg pronoun', 'pronoun verb', 'verb adjective', 'adjective semantic', 'semantic category', 'category eg', 'eg food', 'food word', 'word familial', 'familial term', 'term profanity', 'profanity additional', 'additional predictorsdetermining', 'predictorsdetermining best', 'best time', 'time span', 'span analysis', 'analysis raise', 'raise difficult', 'difficult question', 'question long', 'long doe', 'doe mental', 'mental illness', 'illness occur', 'occur receiving', 'receiving clinical', 'clinical diagnosis', 'diagnosis depression', 'depression ptsd', 'ptsd doe', 'doe imply', 'imply individual', 'individual remains', 'remains persistent', 'persistent state', 'state illness', 'illness conduct', 'conduct analysis', 'analysis individual', 'individual entire', 'entire posting', 'posting history', 'history single', 'single unit', 'unit observation', 'observation dubious', 'dubious proposition', 'proposition extreme', 'extreme take', 'take one', 'one tweet', 'tweet unit', 'unit observation', 'observation run', 'run risk', 'risk granular', 'granular de', 'de choudhury', 'choudhury et', 'et al', 'al looked', 'looked given', 'given user', 'user tweet', 'tweet single', 'single day', 'day aggregated', 'aggregated data', 'data perperson', 'perperson perday', 'perday unit', 'unit observation', 'observation report', 'report followed', 'followed convention', 'convention aggregated', 'aggregated userdays', 'userdays primary', 'primary unit', 'unit analysis', 'analysis rather', 'rather try', 'try categorize', 'categorize person', 'person entire', 'entire history', 'history analyze', 'analyze individual', 'individual tweet', 'tweet previous', 'previous research', 'research however', 'however found', 'found many', 'many twitter', 'twitter user', 'user generate', 'generate enough', 'enough daily', 'daily content', 'content make', 'make robust', 'robust unigram', 'unigram sentiment', 'sentiment analysis', 'analysis completeness', 'completeness conducted', 'conducted analysis', 'analysis using', 'using daily', 'daily weekly', 'weekly unit', 'unit observation', 'observation analysis', 'analysis yielded', 'yielded predictive', 'predictive model', 'model similar', 'similar strength', 'strength weekly', 'weekly model', 'model showing', 'showing slight', 'slight consistent', 'consistent edge', 'edge performance', 'performance report', 'report accuracy', 'accuracy metric', 'metric analysis', 'analysis restrict', 'restrict result', 'result dailyunit', 'dailyunit analysis', 'analysis allow', 'allow direct', 'direct comparison', 'comparison previous', 'previous research', 'research detail', 'detail weeklyunit', 'weeklyunit analytical', 'analytical result', 'result available', 'available supplementary', 'supplementary information', 'information section', 'section ii', 'ii reporting', 'reporting result', 'result occasionally', 'occasionally refer', 'refer observation', 'observation tweet', 'tweet depressed', 'depressed eg', 'eg depressed', 'depressed tweet', 'tweet received', 'received fewer', 'fewer like', 'like would', 'would correct', 'correct use', 'use phrase', 'phrase tweet', 'tweet data', 'data depressed', 'depressed participant', 'participant aggregated', 'aggregated userdays', 'userdays instead', 'instead depressed', 'depressed tweet', 'tweet chose', 'chose sacrifice', 'sacrifice degree', 'degree technical', 'technical correctness', 'correctness sake', 'sake clarity']","['extracted several category', 'several category predictor', 'category predictor twitter', 'predictor twitter post', 'twitter post collected', 'post collected predictor', 'collected predictor selection', 'predictor selection depression', 'selection depression ptsd', 'depression ptsd wa', 'ptsd wa based', 'wa based prior', 'based prior machine', 'prior machine learning', 'machine learning model', 'learning model depression', 'model depression twitter', 'depression twitter data', 'twitter data two', 'data two condition', 'two condition high', 'condition high comorbidity', 'high comorbidity rate', 'comorbidity rate suggest', 'rate suggest predictive', 'suggest predictive signal', 'predictive signal may', 'signal may exhibit', 'may exhibit considerable', 'exhibit considerable overlap', 'considerable overlap depressed', 'overlap depressed twitter', 'depressed twitter user', 'twitter user observed', 'user observed tweet', 'observed tweet le', 'tweet le frequently', 'le frequently nondepressed', 'frequently nondepressed user', 'nondepressed user used', 'user used total', 'used total tweet', 'total tweet per', 'tweet per user', 'per user per', 'user per day', 'per day measure', 'day measure user', 'measure user activity', 'user activity tweet', 'activity tweet metadata', 'tweet metadata wa', 'metadata wa analyzed', 'wa analyzed ass', 'analyzed ass average', 'ass average word', 'average word count', 'word count per', 'count per tweet', 'per tweet word', 'tweet word defined', 'word defined set', 'defined set character', 'set character surrounded', 'character surrounded whitespace', 'surrounded whitespace whether', 'whitespace whether tweet', 'whether tweet wa', 'tweet wa retweet', 'wa retweet whether', 'retweet whether tweet', 'whether tweet wa', 'tweet wa reply', 'wa reply someone', 'reply someone el', 'someone el tweet', 'el tweet labmt', 'tweet labmt liwc', 'labmt liwc anew', 'liwc anew unigram', 'anew unigram sentiment', 'unigram sentiment instrument', 'sentiment instrument used', 'instrument used quantify', 'used quantify happiness', 'quantify happiness tweet', 'happiness tweet language', 'tweet language use', 'language use labmt', 'use labmt ha', 'labmt ha shown', 'ha shown strong', 'shown strong prior', 'strong prior performance', 'prior performance analyzing', 'performance analyzing happiness', 'analyzing happiness twitter', 'happiness twitter novel', 'twitter novel respect', 'novel respect depression', 'respect depression screening', 'depression screening anew', 'screening anew liwc', 'anew liwc successfully', 'liwc successfully applied', 'successfully applied previous', 'applied previous study', 'previous study depression', 'study depression twitter', 'depression twitter liwc', 'twitter liwc wa', 'liwc wa also', 'wa also used', 'also used compile', 'used compile frequency', 'compile frequency count', 'frequency count various', 'count various part', 'various part speech', 'part speech eg', 'speech eg pronoun', 'eg pronoun verb', 'pronoun verb adjective', 'verb adjective semantic', 'adjective semantic category', 'semantic category eg', 'category eg food', 'eg food word', 'food word familial', 'word familial term', 'familial term profanity', 'term profanity additional', 'profanity additional predictorsdetermining', 'additional predictorsdetermining best', 'predictorsdetermining best time', 'best time span', 'time span analysis', 'span analysis raise', 'analysis raise difficult', 'raise difficult question', 'difficult question long', 'question long doe', 'long doe mental', 'doe mental illness', 'mental illness occur', 'illness occur receiving', 'occur receiving clinical', 'receiving clinical diagnosis', 'clinical diagnosis depression', 'diagnosis depression ptsd', 'depression ptsd doe', 'ptsd doe imply', 'doe imply individual', 'imply individual remains', 'individual remains persistent', 'remains persistent state', 'persistent state illness', 'state illness conduct', 'illness conduct analysis', 'conduct analysis individual', 'analysis individual entire', 'individual entire posting', 'entire posting history', 'posting history single', 'history single unit', 'single unit observation', 'unit observation dubious', 'observation dubious proposition', 'dubious proposition extreme', 'proposition extreme take', 'extreme take one', 'take one tweet', 'one tweet unit', 'tweet unit observation', 'unit observation run', 'observation run risk', 'run risk granular', 'risk granular de', 'granular de choudhury', 'de choudhury et', 'choudhury et al', 'et al looked', 'al looked given', 'looked given user', 'given user tweet', 'user tweet single', 'tweet single day', 'single day aggregated', 'day aggregated data', 'aggregated data perperson', 'data perperson perday', 'perperson perday unit', 'perday unit observation', 'unit observation report', 'observation report followed', 'report followed convention', 'followed convention aggregated', 'convention aggregated userdays', 'aggregated userdays primary', 'userdays primary unit', 'primary unit analysis', 'unit analysis rather', 'analysis rather try', 'rather try categorize', 'try categorize person', 'categorize person entire', 'person entire history', 'entire history analyze', 'history analyze individual', 'analyze individual tweet', 'individual tweet previous', 'tweet previous research', 'previous research however', 'research however found', 'however found many', 'found many twitter', 'many twitter user', 'twitter user generate', 'user generate enough', 'generate enough daily', 'enough daily content', 'daily content make', 'content make robust', 'make robust unigram', 'robust unigram sentiment', 'unigram sentiment analysis', 'sentiment analysis completeness', 'analysis completeness conducted', 'completeness conducted analysis', 'conducted analysis using', 'analysis using daily', 'using daily weekly', 'daily weekly unit', 'weekly unit observation', 'unit observation analysis', 'observation analysis yielded', 'analysis yielded predictive', 'yielded predictive model', 'predictive model similar', 'model similar strength', 'similar strength weekly', 'strength weekly model', 'weekly model showing', 'model showing slight', 'showing slight consistent', 'slight consistent edge', 'consistent edge performance', 'edge performance report', 'performance report accuracy', 'report accuracy metric', 'accuracy metric analysis', 'metric analysis restrict', 'analysis restrict result', 'restrict result dailyunit', 'result dailyunit analysis', 'dailyunit analysis allow', 'analysis allow direct', 'allow direct comparison', 'direct comparison previous', 'comparison previous research', 'previous research detail', 'research detail weeklyunit', 'detail weeklyunit analytical', 'weeklyunit analytical result', 'analytical result available', 'result available supplementary', 'available supplementary information', 'supplementary information section', 'information section ii', 'section ii reporting', 'ii reporting result', 'reporting result occasionally', 'result occasionally refer', 'occasionally refer observation', 'refer observation tweet', 'observation tweet depressed', 'tweet depressed eg', 'depressed eg depressed', 'eg depressed tweet', 'depressed tweet received', 'tweet received fewer', 'received fewer like', 'fewer like would', 'like would correct', 'would correct use', 'correct use phrase', 'use phrase tweet', 'phrase tweet data', 'tweet data depressed', 'data depressed participant', 'depressed participant aggregated', 'participant aggregated userdays', 'aggregated userdays instead', 'userdays instead depressed', 'instead depressed tweet', 'depressed tweet chose', 'tweet chose sacrifice', 'chose sacrifice degree', 'sacrifice degree technical', 'degree technical correctness', 'technical correctness sake', 'correctness sake clarity']",,,,,,,,
https://aclanthology.org/W14-3214.pdf,0,We used a dataset of 28749 nonclinical users who opted into a Facebook application (“MyPersonality”; Kosinski and Stillwell 2012) between June 2009 and March 2011 completed a 100-item personality questionnaire (an International Personality Item Pool (IPIP) proxy to the NEO-PI-R (Goldberg 1999) and shared access to their status updates containing at least 500 words. Users wrote on average of 4236 words (69917624 total word instances) and a subset of 16507 users provided gender and age in which 57.0% were female and the mean age was 24.8. The dataset was divided into training and testing samples. In particular the testing sample consisted of a random set of 1000 users who wrote at least 1000 words and completed the personality measure while the training set contained the 27749 remaining users.We estimated user-level degree of depression (DDep) as the average response to seven depression facet items which are nested within the larger Neuroticism item pool. For each item users indicated how accurately short phrases described themselves (e.g. “often feel blue” “dislike myself”; responses ranged from 1 = very inaccurate to 5 = very accurate). Figure 1a shows the distribution of surveyassessed DDep (standardized). The items can be seen in Table 1. Figure 2 shows the daily averages of surveyassessed DDep collapsed across years. A LOESS smoother over the daily averages illustrates a seasonal trend with depression rising over the winter months and dropping during the summer.,we used a dataset of nonclinical user who opted into a facebook application mypersonality kosinski and stillwell between june and march completed a item personality questionnaire an international personality item pool ipip proxy to the neopir goldberg and shared access to their status update containing at least word user wrote on average of word total word instance and a subset of user provided gender and age in which were female and the mean age wa the dataset wa divided into training and testing sample in particular the testing sample consisted of a random set of user who wrote at least word and completed the personality measure while the training set contained the remaining userswe estimated userlevel degree of depression ddep a the average response to seven depression facet item which are nested within the larger neuroticism item pool for each item user indicated how accurately short phrase described themselves eg often feel blue dislike myself response ranged from very inaccurate to very accurate figure a show the distribution of surveyassessed ddep standardized the item can be seen in table figure show the daily average of surveyassessed ddep collapsed across year a loess smoother over the daily average illustrates a seasonal trend with depression rising over the winter month and dropping during the summer,"['used', 'dataset', 'nonclinical', 'user', 'opted', 'facebook', 'application', 'mypersonality', 'kosinski', 'stillwell', 'june', 'march', 'completed', 'item', 'personality', 'questionnaire', 'international', 'personality', 'item', 'pool', 'ipip', 'proxy', 'neopir', 'goldberg', 'shared', 'access', 'status', 'update', 'containing', 'least', 'word', 'user', 'wrote', 'average', 'word', 'total', 'word', 'instance', 'subset', 'user', 'provided', 'gender', 'age', 'female', 'mean', 'age', 'wa', 'dataset', 'wa', 'divided', 'training', 'testing', 'sample', 'particular', 'testing', 'sample', 'consisted', 'random', 'set', 'user', 'wrote', 'least', 'word', 'completed', 'personality', 'measure', 'training', 'set', 'contained', 'remaining', 'userswe', 'estimated', 'userlevel', 'degree', 'depression', 'ddep', 'average', 'response', 'seven', 'depression', 'facet', 'item', 'nested', 'within', 'larger', 'neuroticism', 'item', 'pool', 'item', 'user', 'indicated', 'accurately', 'short', 'phrase', 'described', 'eg', 'often', 'feel', 'blue', 'dislike', 'response', 'ranged', 'inaccurate', 'accurate', 'figure', 'show', 'distribution', 'surveyassessed', 'ddep', 'standardized', 'item', 'seen', 'table', 'figure', 'show', 'daily', 'average', 'surveyassessed', 'ddep', 'collapsed', 'across', 'year', 'loess', 'smoother', 'daily', 'average', 'illustrates', 'seasonal', 'trend', 'depression', 'rising', 'winter', 'month', 'dropping', 'summer']","['used dataset', 'dataset nonclinical', 'nonclinical user', 'user opted', 'opted facebook', 'facebook application', 'application mypersonality', 'mypersonality kosinski', 'kosinski stillwell', 'stillwell june', 'june march', 'march completed', 'completed item', 'item personality', 'personality questionnaire', 'questionnaire international', 'international personality', 'personality item', 'item pool', 'pool ipip', 'ipip proxy', 'proxy neopir', 'neopir goldberg', 'goldberg shared', 'shared access', 'access status', 'status update', 'update containing', 'containing least', 'least word', 'word user', 'user wrote', 'wrote average', 'average word', 'word total', 'total word', 'word instance', 'instance subset', 'subset user', 'user provided', 'provided gender', 'gender age', 'age female', 'female mean', 'mean age', 'age wa', 'wa dataset', 'dataset wa', 'wa divided', 'divided training', 'training testing', 'testing sample', 'sample particular', 'particular testing', 'testing sample', 'sample consisted', 'consisted random', 'random set', 'set user', 'user wrote', 'wrote least', 'least word', 'word completed', 'completed personality', 'personality measure', 'measure training', 'training set', 'set contained', 'contained remaining', 'remaining userswe', 'userswe estimated', 'estimated userlevel', 'userlevel degree', 'degree depression', 'depression ddep', 'ddep average', 'average response', 'response seven', 'seven depression', 'depression facet', 'facet item', 'item nested', 'nested within', 'within larger', 'larger neuroticism', 'neuroticism item', 'item pool', 'pool item', 'item user', 'user indicated', 'indicated accurately', 'accurately short', 'short phrase', 'phrase described', 'described eg', 'eg often', 'often feel', 'feel blue', 'blue dislike', 'dislike response', 'response ranged', 'ranged inaccurate', 'inaccurate accurate', 'accurate figure', 'figure show', 'show distribution', 'distribution surveyassessed', 'surveyassessed ddep', 'ddep standardized', 'standardized item', 'item seen', 'seen table', 'table figure', 'figure show', 'show daily', 'daily average', 'average surveyassessed', 'surveyassessed ddep', 'ddep collapsed', 'collapsed across', 'across year', 'year loess', 'loess smoother', 'smoother daily', 'daily average', 'average illustrates', 'illustrates seasonal', 'seasonal trend', 'trend depression', 'depression rising', 'rising winter', 'winter month', 'month dropping', 'dropping summer']","['used dataset nonclinical', 'dataset nonclinical user', 'nonclinical user opted', 'user opted facebook', 'opted facebook application', 'facebook application mypersonality', 'application mypersonality kosinski', 'mypersonality kosinski stillwell', 'kosinski stillwell june', 'stillwell june march', 'june march completed', 'march completed item', 'completed item personality', 'item personality questionnaire', 'personality questionnaire international', 'questionnaire international personality', 'international personality item', 'personality item pool', 'item pool ipip', 'pool ipip proxy', 'ipip proxy neopir', 'proxy neopir goldberg', 'neopir goldberg shared', 'goldberg shared access', 'shared access status', 'access status update', 'status update containing', 'update containing least', 'containing least word', 'least word user', 'word user wrote', 'user wrote average', 'wrote average word', 'average word total', 'word total word', 'total word instance', 'word instance subset', 'instance subset user', 'subset user provided', 'user provided gender', 'provided gender age', 'gender age female', 'age female mean', 'female mean age', 'mean age wa', 'age wa dataset', 'wa dataset wa', 'dataset wa divided', 'wa divided training', 'divided training testing', 'training testing sample', 'testing sample particular', 'sample particular testing', 'particular testing sample', 'testing sample consisted', 'sample consisted random', 'consisted random set', 'random set user', 'set user wrote', 'user wrote least', 'wrote least word', 'least word completed', 'word completed personality', 'completed personality measure', 'personality measure training', 'measure training set', 'training set contained', 'set contained remaining', 'contained remaining userswe', 'remaining userswe estimated', 'userswe estimated userlevel', 'estimated userlevel degree', 'userlevel degree depression', 'degree depression ddep', 'depression ddep average', 'ddep average response', 'average response seven', 'response seven depression', 'seven depression facet', 'depression facet item', 'facet item nested', 'item nested within', 'nested within larger', 'within larger neuroticism', 'larger neuroticism item', 'neuroticism item pool', 'item pool item', 'pool item user', 'item user indicated', 'user indicated accurately', 'indicated accurately short', 'accurately short phrase', 'short phrase described', 'phrase described eg', 'described eg often', 'eg often feel', 'often feel blue', 'feel blue dislike', 'blue dislike response', 'dislike response ranged', 'response ranged inaccurate', 'ranged inaccurate accurate', 'inaccurate accurate figure', 'accurate figure show', 'figure show distribution', 'show distribution surveyassessed', 'distribution surveyassessed ddep', 'surveyassessed ddep standardized', 'ddep standardized item', 'standardized item seen', 'item seen table', 'seen table figure', 'table figure show', 'figure show daily', 'show daily average', 'daily average surveyassessed', 'average surveyassessed ddep', 'surveyassessed ddep collapsed', 'ddep collapsed across', 'collapsed across year', 'across year loess', 'year loess smoother', 'loess smoother daily', 'smoother daily average', 'daily average illustrates', 'average illustrates seasonal', 'illustrates seasonal trend', 'seasonal trend depression', 'trend depression rising', 'depression rising winter', 'rising winter month', 'winter month dropping', 'month dropping summer']",,,,,,,,
https://ieeexplore.ieee.org/abstract/document/6784326,0,a) CLINICAL Communities: Communities who are interested in ‘depression’ and with at least 200 posts are extracted from LiveJournal. This is identified through the ‘Search communities by interest’2 provided by LiveJournal and results in 24 communities with 38401 posts. The CLINICAL communities are grouped based on name and description of the individual community: depression bipolar self-harm attachment/separation and suicide (See Table 1 for statistics). The earliest community creation date was in 2001 thus our data set spans over 10 years. b) CONTROL communities: We constructed a CONTROL data set using five popular categories of communities in the LiveJournal Directory.3 We select communities who have at least 200 posts resulting in 23 communities with 229563 posts. This set is called CONTROL and the statistics of these 23 communities and their description are shown in Table 2.To characterize the difference between CLINICAL and CONTROL communities a variety of features are extracted: Affective features: We use the lexicon—Affective Norms for English Words (ANEW) [5]—to extract the sentiment conveyed in the content. This lexicon consists of 1034 words rated in terms of valence and arousal and is thus suitable for a quantitative estimation. The valence of ANEW words is on a scale of 1 (very unpleasant) to 9 (very pleasant). The arousal is measured on the same scale—1 (least active) to 9 (most active). A cloud visualization of ANEW words used in the blog posts made by CLINICAL and CONTROL groups is illustrated in Fig. 1. Mood tags: LiveJournal provides a mechanism for users to tag their posts from a list of 132 pre-defined mood labels.4 Thus in addition to the emotion expressed in the text of posts the mood tag produced allows us direct access to the user sentiment. A cloud visualization of moods tagged on blog posts made by CLINICAL and CONTROL communities is llustrated in Fig. 2. LIWC features: We examine the proportions of words in psycholinguistic categories as defined in the LIWC package [27]: linguistic social affective cognitive perceptual biological relativity personal concerns and spoken.5 Table 3 presents the mean of these LIWC psycholinguistic processes for the CLINICAL and CONTROL communities. Whilst similar in the use words with positive emotion people in the CLINICAL communities tend to use words with more negative emotion—as examples anxiety anger and sadness. Further they discuss more issues about health and death in comparison with the CONTROL group. On the other hand the users in the CONTROL group discuss more neutral life related topics—ingestion home and leisure words. Topics: For extracting topics latent Dirichlet allocation (LDA) [4] is used as a Bayesian probabilistic modelling framework. LDA extracts the probabilities —that is words in a topic and then assigns a topic to each word in a document. For the inference part we implemented Gibbs inference detailed in [10]. We set the number of topics to 50 run the Gibbs for 5000 samples and use the last Gibbs sample to interpret the results.,a clinical community community who are interested in depression and with at least post are extracted from livejournal this is identified through the search community by interest provided by livejournal and result in community with post the clinical community are grouped based on name and description of the individual community depression bipolar selfharm attachmentseparation and suicide see table for statistic the earliest community creation date wa in thus our data set span over year b control community we constructed a control data set using five popular category of community in the livejournal directory we select community who have at least post resulting in community with post this set is called control and the statistic of these community and their description are shown in table to characterize the difference between clinical and control community a variety of feature are extracted affective feature we use the lexiconaffective norm for english word anew to extract the sentiment conveyed in the content this lexicon consists of word rated in term of valence and arousal and is thus suitable for a quantitative estimation the valence of anew word is on a scale of very unpleasant to very pleasant the arousal is measured on the same scale least active to most active a cloud visualization of anew word used in the blog post made by clinical and control group is illustrated in fig mood tag livejournal provides a mechanism for user to tag their post from a list of predefined mood label thus in addition to the emotion expressed in the text of post the mood tag produced allows u direct access to the user sentiment a cloud visualization of mood tagged on blog post made by clinical and control community is llustrated in fig liwc feature we examine the proportion of word in psycholinguistic category a defined in the liwc package linguistic social affective cognitive perceptual biological relativity personal concern and spoken table present the mean of these liwc psycholinguistic process for the clinical and control community whilst similar in the use word with positive emotion people in the clinical community tend to use word with more negative emotionas example anxiety anger and sadness further they discus more issue about health and death in comparison with the control group on the other hand the user in the control group discus more neutral life related topicsingestion home and leisure word topic for extracting topic latent dirichlet allocation lda is used a a bayesian probabilistic modelling framework lda extract the probability that is word in a topic and then assigns a topic to each word in a document for the inference part we implemented gibbs inference detailed in we set the number of topic to run the gibbs for sample and use the last gibbs sample to interpret the result,"['clinical', 'community', 'community', 'interested', 'depression', 'least', 'post', 'extracted', 'livejournal', 'identified', 'search', 'community', 'interest', 'provided', 'livejournal', 'result', 'community', 'post', 'clinical', 'community', 'grouped', 'based', 'name', 'description', 'individual', 'community', 'depression', 'bipolar', 'selfharm', 'attachmentseparation', 'suicide', 'see', 'table', 'statistic', 'earliest', 'community', 'creation', 'date', 'wa', 'thus', 'data', 'set', 'span', 'year', 'b', 'control', 'community', 'constructed', 'control', 'data', 'set', 'using', 'five', 'popular', 'category', 'community', 'livejournal', 'directory', 'select', 'community', 'least', 'post', 'resulting', 'community', 'post', 'set', 'called', 'control', 'statistic', 'community', 'description', 'shown', 'table', 'characterize', 'difference', 'clinical', 'control', 'community', 'variety', 'feature', 'extracted', 'affective', 'feature', 'use', 'lexiconaffective', 'norm', 'english', 'word', 'anew', 'extract', 'sentiment', 'conveyed', 'content', 'lexicon', 'consists', 'word', 'rated', 'term', 'valence', 'arousal', 'thus', 'suitable', 'quantitative', 'estimation', 'valence', 'anew', 'word', 'scale', 'unpleasant', 'pleasant', 'arousal', 'measured', 'scale', 'least', 'active', 'active', 'cloud', 'visualization', 'anew', 'word', 'used', 'blog', 'post', 'made', 'clinical', 'control', 'group', 'illustrated', 'fig', 'mood', 'tag', 'livejournal', 'provides', 'mechanism', 'user', 'tag', 'post', 'list', 'predefined', 'mood', 'label', 'thus', 'addition', 'emotion', 'expressed', 'text', 'post', 'mood', 'tag', 'produced', 'allows', 'u', 'direct', 'access', 'user', 'sentiment', 'cloud', 'visualization', 'mood', 'tagged', 'blog', 'post', 'made', 'clinical', 'control', 'community', 'llustrated', 'fig', 'liwc', 'feature', 'examine', 'proportion', 'word', 'psycholinguistic', 'category', 'defined', 'liwc', 'package', 'linguistic', 'social', 'affective', 'cognitive', 'perceptual', 'biological', 'relativity', 'personal', 'concern', 'spoken', 'table', 'present', 'mean', 'liwc', 'psycholinguistic', 'process', 'clinical', 'control', 'community', 'whilst', 'similar', 'use', 'word', 'positive', 'emotion', 'people', 'clinical', 'community', 'tend', 'use', 'word', 'negative', 'emotionas', 'example', 'anxiety', 'anger', 'sadness', 'discus', 'issue', 'health', 'death', 'comparison', 'control', 'group', 'hand', 'user', 'control', 'group', 'discus', 'neutral', 'life', 'related', 'topicsingestion', 'home', 'leisure', 'word', 'topic', 'extracting', 'topic', 'latent', 'dirichlet', 'allocation', 'lda', 'used', 'bayesian', 'probabilistic', 'modelling', 'framework', 'lda', 'extract', 'probability', 'word', 'topic', 'assigns', 'topic', 'word', 'document', 'inference', 'part', 'implemented', 'gibbs', 'inference', 'detailed', 'set', 'number', 'topic', 'run', 'gibbs', 'sample', 'use', 'last', 'gibbs', 'sample', 'interpret', 'result']","['clinical community', 'community community', 'community interested', 'interested depression', 'depression least', 'least post', 'post extracted', 'extracted livejournal', 'livejournal identified', 'identified search', 'search community', 'community interest', 'interest provided', 'provided livejournal', 'livejournal result', 'result community', 'community post', 'post clinical', 'clinical community', 'community grouped', 'grouped based', 'based name', 'name description', 'description individual', 'individual community', 'community depression', 'depression bipolar', 'bipolar selfharm', 'selfharm attachmentseparation', 'attachmentseparation suicide', 'suicide see', 'see table', 'table statistic', 'statistic earliest', 'earliest community', 'community creation', 'creation date', 'date wa', 'wa thus', 'thus data', 'data set', 'set span', 'span year', 'year b', 'b control', 'control community', 'community constructed', 'constructed control', 'control data', 'data set', 'set using', 'using five', 'five popular', 'popular category', 'category community', 'community livejournal', 'livejournal directory', 'directory select', 'select community', 'community least', 'least post', 'post resulting', 'resulting community', 'community post', 'post set', 'set called', 'called control', 'control statistic', 'statistic community', 'community description', 'description shown', 'shown table', 'table characterize', 'characterize difference', 'difference clinical', 'clinical control', 'control community', 'community variety', 'variety feature', 'feature extracted', 'extracted affective', 'affective feature', 'feature use', 'use lexiconaffective', 'lexiconaffective norm', 'norm english', 'english word', 'word anew', 'anew extract', 'extract sentiment', 'sentiment conveyed', 'conveyed content', 'content lexicon', 'lexicon consists', 'consists word', 'word rated', 'rated term', 'term valence', 'valence arousal', 'arousal thus', 'thus suitable', 'suitable quantitative', 'quantitative estimation', 'estimation valence', 'valence anew', 'anew word', 'word scale', 'scale unpleasant', 'unpleasant pleasant', 'pleasant arousal', 'arousal measured', 'measured scale', 'scale least', 'least active', 'active active', 'active cloud', 'cloud visualization', 'visualization anew', 'anew word', 'word used', 'used blog', 'blog post', 'post made', 'made clinical', 'clinical control', 'control group', 'group illustrated', 'illustrated fig', 'fig mood', 'mood tag', 'tag livejournal', 'livejournal provides', 'provides mechanism', 'mechanism user', 'user tag', 'tag post', 'post list', 'list predefined', 'predefined mood', 'mood label', 'label thus', 'thus addition', 'addition emotion', 'emotion expressed', 'expressed text', 'text post', 'post mood', 'mood tag', 'tag produced', 'produced allows', 'allows u', 'u direct', 'direct access', 'access user', 'user sentiment', 'sentiment cloud', 'cloud visualization', 'visualization mood', 'mood tagged', 'tagged blog', 'blog post', 'post made', 'made clinical', 'clinical control', 'control community', 'community llustrated', 'llustrated fig', 'fig liwc', 'liwc feature', 'feature examine', 'examine proportion', 'proportion word', 'word psycholinguistic', 'psycholinguistic category', 'category defined', 'defined liwc', 'liwc package', 'package linguistic', 'linguistic social', 'social affective', 'affective cognitive', 'cognitive perceptual', 'perceptual biological', 'biological relativity', 'relativity personal', 'personal concern', 'concern spoken', 'spoken table', 'table present', 'present mean', 'mean liwc', 'liwc psycholinguistic', 'psycholinguistic process', 'process clinical', 'clinical control', 'control community', 'community whilst', 'whilst similar', 'similar use', 'use word', 'word positive', 'positive emotion', 'emotion people', 'people clinical', 'clinical community', 'community tend', 'tend use', 'use word', 'word negative', 'negative emotionas', 'emotionas example', 'example anxiety', 'anxiety anger', 'anger sadness', 'sadness discus', 'discus issue', 'issue health', 'health death', 'death comparison', 'comparison control', 'control group', 'group hand', 'hand user', 'user control', 'control group', 'group discus', 'discus neutral', 'neutral life', 'life related', 'related topicsingestion', 'topicsingestion home', 'home leisure', 'leisure word', 'word topic', 'topic extracting', 'extracting topic', 'topic latent', 'latent dirichlet', 'dirichlet allocation', 'allocation lda', 'lda used', 'used bayesian', 'bayesian probabilistic', 'probabilistic modelling', 'modelling framework', 'framework lda', 'lda extract', 'extract probability', 'probability word', 'word topic', 'topic assigns', 'assigns topic', 'topic word', 'word document', 'document inference', 'inference part', 'part implemented', 'implemented gibbs', 'gibbs inference', 'inference detailed', 'detailed set', 'set number', 'number topic', 'topic run', 'run gibbs', 'gibbs sample', 'sample use', 'use last', 'last gibbs', 'gibbs sample', 'sample interpret', 'interpret result']","['clinical community community', 'community community interested', 'community interested depression', 'interested depression least', 'depression least post', 'least post extracted', 'post extracted livejournal', 'extracted livejournal identified', 'livejournal identified search', 'identified search community', 'search community interest', 'community interest provided', 'interest provided livejournal', 'provided livejournal result', 'livejournal result community', 'result community post', 'community post clinical', 'post clinical community', 'clinical community grouped', 'community grouped based', 'grouped based name', 'based name description', 'name description individual', 'description individual community', 'individual community depression', 'community depression bipolar', 'depression bipolar selfharm', 'bipolar selfharm attachmentseparation', 'selfharm attachmentseparation suicide', 'attachmentseparation suicide see', 'suicide see table', 'see table statistic', 'table statistic earliest', 'statistic earliest community', 'earliest community creation', 'community creation date', 'creation date wa', 'date wa thus', 'wa thus data', 'thus data set', 'data set span', 'set span year', 'span year b', 'year b control', 'b control community', 'control community constructed', 'community constructed control', 'constructed control data', 'control data set', 'data set using', 'set using five', 'using five popular', 'five popular category', 'popular category community', 'category community livejournal', 'community livejournal directory', 'livejournal directory select', 'directory select community', 'select community least', 'community least post', 'least post resulting', 'post resulting community', 'resulting community post', 'community post set', 'post set called', 'set called control', 'called control statistic', 'control statistic community', 'statistic community description', 'community description shown', 'description shown table', 'shown table characterize', 'table characterize difference', 'characterize difference clinical', 'difference clinical control', 'clinical control community', 'control community variety', 'community variety feature', 'variety feature extracted', 'feature extracted affective', 'extracted affective feature', 'affective feature use', 'feature use lexiconaffective', 'use lexiconaffective norm', 'lexiconaffective norm english', 'norm english word', 'english word anew', 'word anew extract', 'anew extract sentiment', 'extract sentiment conveyed', 'sentiment conveyed content', 'conveyed content lexicon', 'content lexicon consists', 'lexicon consists word', 'consists word rated', 'word rated term', 'rated term valence', 'term valence arousal', 'valence arousal thus', 'arousal thus suitable', 'thus suitable quantitative', 'suitable quantitative estimation', 'quantitative estimation valence', 'estimation valence anew', 'valence anew word', 'anew word scale', 'word scale unpleasant', 'scale unpleasant pleasant', 'unpleasant pleasant arousal', 'pleasant arousal measured', 'arousal measured scale', 'measured scale least', 'scale least active', 'least active active', 'active active cloud', 'active cloud visualization', 'cloud visualization anew', 'visualization anew word', 'anew word used', 'word used blog', 'used blog post', 'blog post made', 'post made clinical', 'made clinical control', 'clinical control group', 'control group illustrated', 'group illustrated fig', 'illustrated fig mood', 'fig mood tag', 'mood tag livejournal', 'tag livejournal provides', 'livejournal provides mechanism', 'provides mechanism user', 'mechanism user tag', 'user tag post', 'tag post list', 'post list predefined', 'list predefined mood', 'predefined mood label', 'mood label thus', 'label thus addition', 'thus addition emotion', 'addition emotion expressed', 'emotion expressed text', 'expressed text post', 'text post mood', 'post mood tag', 'mood tag produced', 'tag produced allows', 'produced allows u', 'allows u direct', 'u direct access', 'direct access user', 'access user sentiment', 'user sentiment cloud', 'sentiment cloud visualization', 'cloud visualization mood', 'visualization mood tagged', 'mood tagged blog', 'tagged blog post', 'blog post made', 'post made clinical', 'made clinical control', 'clinical control community', 'control community llustrated', 'community llustrated fig', 'llustrated fig liwc', 'fig liwc feature', 'liwc feature examine', 'feature examine proportion', 'examine proportion word', 'proportion word psycholinguistic', 'word psycholinguistic category', 'psycholinguistic category defined', 'category defined liwc', 'defined liwc package', 'liwc package linguistic', 'package linguistic social', 'linguistic social affective', 'social affective cognitive', 'affective cognitive perceptual', 'cognitive perceptual biological', 'perceptual biological relativity', 'biological relativity personal', 'relativity personal concern', 'personal concern spoken', 'concern spoken table', 'spoken table present', 'table present mean', 'present mean liwc', 'mean liwc psycholinguistic', 'liwc psycholinguistic process', 'psycholinguistic process clinical', 'process clinical control', 'clinical control community', 'control community whilst', 'community whilst similar', 'whilst similar use', 'similar use word', 'use word positive', 'word positive emotion', 'positive emotion people', 'emotion people clinical', 'people clinical community', 'clinical community tend', 'community tend use', 'tend use word', 'use word negative', 'word negative emotionas', 'negative emotionas example', 'emotionas example anxiety', 'example anxiety anger', 'anxiety anger sadness', 'anger sadness discus', 'sadness discus issue', 'discus issue health', 'issue health death', 'health death comparison', 'death comparison control', 'comparison control group', 'control group hand', 'group hand user', 'hand user control', 'user control group', 'control group discus', 'group discus neutral', 'discus neutral life', 'neutral life related', 'life related topicsingestion', 'related topicsingestion home', 'topicsingestion home leisure', 'home leisure word', 'leisure word topic', 'word topic extracting', 'topic extracting topic', 'extracting topic latent', 'topic latent dirichlet', 'latent dirichlet allocation', 'dirichlet allocation lda', 'allocation lda used', 'lda used bayesian', 'used bayesian probabilistic', 'bayesian probabilistic modelling', 'probabilistic modelling framework', 'modelling framework lda', 'framework lda extract', 'lda extract probability', 'extract probability word', 'probability word topic', 'word topic assigns', 'topic assigns topic', 'assigns topic word', 'topic word document', 'word document inference', 'document inference part', 'inference part implemented', 'part implemented gibbs', 'implemented gibbs inference', 'gibbs inference detailed', 'inference detailed set', 'detailed set number', 'set number topic', 'number topic run', 'topic run gibbs', 'run gibbs sample', 'gibbs sample use', 'sample use last', 'use last gibbs', 'last gibbs sample', 'gibbs sample interpret', 'sample interpret result']",,,,,,,,
https://www.jmir.org/2017/7/e243/,1,A Web-based survey of Weibo users was conducted to assess the respondents’ suicide risk and emotional distress (ie depression anxiety and stress). The invitation letter to participate in this survey was widely sent out to general Weibo users by various promotion activities. For a Weibo user to be eligible for the study she or he had to be 18 years or older (by self-report). A 30 Renminbi incentive for each complete survey was provided to boost the respond rate. With the respondents’ consent their Weibo posts that were posted in the public domain during the 12 months before the survey were downloaded by calling Weibo API. The survey fulfilled the Checklist for Reporting Results of Internet E-Surveys (CHERRIES) checklist and details of the procedure have been reported in previous publications [2232]. In addition when multiple survey feedback were submitted from the same Internet protocol addresses only the first submission was used to avoid duplicate participation. In contrast to a previous study [32] this study excluded those who posted nothing throughout the 12 months but not those who posted fewer than 100 posts. Eventually data provided by 974 respondents remained for further analyses. The study has obtained ethical approvals from the Human Research Ethical Review Committee at the University of Hong Kong and the Institute Review Board of the Institute of Psychology at the Chinese Academy of Sciences. The survey measured respondents’ suicide probability score depression anxiety stress and Weibo suicide communication (WSC) as the outcome variables. In addition the respondents’ Weibo posts language features were extracted as independent variables or features for machine learning. The details of how those data were obtained are elaborated in the following subsections.,a webbased survey of weibo user wa conducted to ass the respondent suicide risk and emotional distress ie depression anxiety and stress the invitation letter to participate in this survey wa widely sent out to general weibo user by various promotion activity for a weibo user to be eligible for the study she or he had to be year or older by selfreport a renminbi incentive for each complete survey wa provided to boost the respond rate with the respondent consent their weibo post that were posted in the public domain during the month before the survey were downloaded by calling weibo api the survey fulfilled the checklist for reporting result of internet esurveys cherry checklist and detail of the procedure have been reported in previous publication in addition when multiple survey feedback were submitted from the same internet protocol address only the first submission wa used to avoid duplicate participation in contrast to a previous study this study excluded those who posted nothing throughout the month but not those who posted fewer than post eventually data provided by respondent remained for further analysis the study ha obtained ethical approval from the human research ethical review committee at the university of hong kong and the institute review board of the institute of psychology at the chinese academy of science the survey measured respondent suicide probability score depression anxiety stress and weibo suicide communication wsc a the outcome variable in addition the respondent weibo post language feature were extracted a independent variable or feature for machine learning the detail of how those data were obtained are elaborated in the following subsection,"['webbased', 'survey', 'weibo', 'user', 'wa', 'conducted', 'ass', 'respondent', 'suicide', 'risk', 'emotional', 'distress', 'ie', 'depression', 'anxiety', 'stress', 'invitation', 'letter', 'participate', 'survey', 'wa', 'widely', 'sent', 'general', 'weibo', 'user', 'various', 'promotion', 'activity', 'weibo', 'user', 'eligible', 'study', 'year', 'older', 'selfreport', 'renminbi', 'incentive', 'complete', 'survey', 'wa', 'provided', 'boost', 'respond', 'rate', 'respondent', 'consent', 'weibo', 'post', 'posted', 'public', 'domain', 'month', 'survey', 'downloaded', 'calling', 'weibo', 'api', 'survey', 'fulfilled', 'checklist', 'reporting', 'result', 'internet', 'esurveys', 'cherry', 'checklist', 'detail', 'procedure', 'reported', 'previous', 'publication', 'addition', 'multiple', 'survey', 'feedback', 'submitted', 'internet', 'protocol', 'address', 'first', 'submission', 'wa', 'used', 'avoid', 'duplicate', 'participation', 'contrast', 'previous', 'study', 'study', 'excluded', 'posted', 'nothing', 'throughout', 'month', 'posted', 'fewer', 'post', 'eventually', 'data', 'provided', 'respondent', 'remained', 'analysis', 'study', 'ha', 'obtained', 'ethical', 'approval', 'human', 'research', 'ethical', 'review', 'committee', 'university', 'hong', 'kong', 'institute', 'review', 'board', 'institute', 'psychology', 'chinese', 'academy', 'science', 'survey', 'measured', 'respondent', 'suicide', 'probability', 'score', 'depression', 'anxiety', 'stress', 'weibo', 'suicide', 'communication', 'wsc', 'outcome', 'variable', 'addition', 'respondent', 'weibo', 'post', 'language', 'feature', 'extracted', 'independent', 'variable', 'feature', 'machine', 'learning', 'detail', 'data', 'obtained', 'elaborated', 'following', 'subsection']","['webbased survey', 'survey weibo', 'weibo user', 'user wa', 'wa conducted', 'conducted ass', 'ass respondent', 'respondent suicide', 'suicide risk', 'risk emotional', 'emotional distress', 'distress ie', 'ie depression', 'depression anxiety', 'anxiety stress', 'stress invitation', 'invitation letter', 'letter participate', 'participate survey', 'survey wa', 'wa widely', 'widely sent', 'sent general', 'general weibo', 'weibo user', 'user various', 'various promotion', 'promotion activity', 'activity weibo', 'weibo user', 'user eligible', 'eligible study', 'study year', 'year older', 'older selfreport', 'selfreport renminbi', 'renminbi incentive', 'incentive complete', 'complete survey', 'survey wa', 'wa provided', 'provided boost', 'boost respond', 'respond rate', 'rate respondent', 'respondent consent', 'consent weibo', 'weibo post', 'post posted', 'posted public', 'public domain', 'domain month', 'month survey', 'survey downloaded', 'downloaded calling', 'calling weibo', 'weibo api', 'api survey', 'survey fulfilled', 'fulfilled checklist', 'checklist reporting', 'reporting result', 'result internet', 'internet esurveys', 'esurveys cherry', 'cherry checklist', 'checklist detail', 'detail procedure', 'procedure reported', 'reported previous', 'previous publication', 'publication addition', 'addition multiple', 'multiple survey', 'survey feedback', 'feedback submitted', 'submitted internet', 'internet protocol', 'protocol address', 'address first', 'first submission', 'submission wa', 'wa used', 'used avoid', 'avoid duplicate', 'duplicate participation', 'participation contrast', 'contrast previous', 'previous study', 'study study', 'study excluded', 'excluded posted', 'posted nothing', 'nothing throughout', 'throughout month', 'month posted', 'posted fewer', 'fewer post', 'post eventually', 'eventually data', 'data provided', 'provided respondent', 'respondent remained', 'remained analysis', 'analysis study', 'study ha', 'ha obtained', 'obtained ethical', 'ethical approval', 'approval human', 'human research', 'research ethical', 'ethical review', 'review committee', 'committee university', 'university hong', 'hong kong', 'kong institute', 'institute review', 'review board', 'board institute', 'institute psychology', 'psychology chinese', 'chinese academy', 'academy science', 'science survey', 'survey measured', 'measured respondent', 'respondent suicide', 'suicide probability', 'probability score', 'score depression', 'depression anxiety', 'anxiety stress', 'stress weibo', 'weibo suicide', 'suicide communication', 'communication wsc', 'wsc outcome', 'outcome variable', 'variable addition', 'addition respondent', 'respondent weibo', 'weibo post', 'post language', 'language feature', 'feature extracted', 'extracted independent', 'independent variable', 'variable feature', 'feature machine', 'machine learning', 'learning detail', 'detail data', 'data obtained', 'obtained elaborated', 'elaborated following', 'following subsection']","['webbased survey weibo', 'survey weibo user', 'weibo user wa', 'user wa conducted', 'wa conducted ass', 'conducted ass respondent', 'ass respondent suicide', 'respondent suicide risk', 'suicide risk emotional', 'risk emotional distress', 'emotional distress ie', 'distress ie depression', 'ie depression anxiety', 'depression anxiety stress', 'anxiety stress invitation', 'stress invitation letter', 'invitation letter participate', 'letter participate survey', 'participate survey wa', 'survey wa widely', 'wa widely sent', 'widely sent general', 'sent general weibo', 'general weibo user', 'weibo user various', 'user various promotion', 'various promotion activity', 'promotion activity weibo', 'activity weibo user', 'weibo user eligible', 'user eligible study', 'eligible study year', 'study year older', 'year older selfreport', 'older selfreport renminbi', 'selfreport renminbi incentive', 'renminbi incentive complete', 'incentive complete survey', 'complete survey wa', 'survey wa provided', 'wa provided boost', 'provided boost respond', 'boost respond rate', 'respond rate respondent', 'rate respondent consent', 'respondent consent weibo', 'consent weibo post', 'weibo post posted', 'post posted public', 'posted public domain', 'public domain month', 'domain month survey', 'month survey downloaded', 'survey downloaded calling', 'downloaded calling weibo', 'calling weibo api', 'weibo api survey', 'api survey fulfilled', 'survey fulfilled checklist', 'fulfilled checklist reporting', 'checklist reporting result', 'reporting result internet', 'result internet esurveys', 'internet esurveys cherry', 'esurveys cherry checklist', 'cherry checklist detail', 'checklist detail procedure', 'detail procedure reported', 'procedure reported previous', 'reported previous publication', 'previous publication addition', 'publication addition multiple', 'addition multiple survey', 'multiple survey feedback', 'survey feedback submitted', 'feedback submitted internet', 'submitted internet protocol', 'internet protocol address', 'protocol address first', 'address first submission', 'first submission wa', 'submission wa used', 'wa used avoid', 'used avoid duplicate', 'avoid duplicate participation', 'duplicate participation contrast', 'participation contrast previous', 'contrast previous study', 'previous study study', 'study study excluded', 'study excluded posted', 'excluded posted nothing', 'posted nothing throughout', 'nothing throughout month', 'throughout month posted', 'month posted fewer', 'posted fewer post', 'fewer post eventually', 'post eventually data', 'eventually data provided', 'data provided respondent', 'provided respondent remained', 'respondent remained analysis', 'remained analysis study', 'analysis study ha', 'study ha obtained', 'ha obtained ethical', 'obtained ethical approval', 'ethical approval human', 'approval human research', 'human research ethical', 'research ethical review', 'ethical review committee', 'review committee university', 'committee university hong', 'university hong kong', 'hong kong institute', 'kong institute review', 'institute review board', 'review board institute', 'board institute psychology', 'institute psychology chinese', 'psychology chinese academy', 'chinese academy science', 'academy science survey', 'science survey measured', 'survey measured respondent', 'measured respondent suicide', 'respondent suicide probability', 'suicide probability score', 'probability score depression', 'score depression anxiety', 'depression anxiety stress', 'anxiety stress weibo', 'stress weibo suicide', 'weibo suicide communication', 'suicide communication wsc', 'communication wsc outcome', 'wsc outcome variable', 'outcome variable addition', 'variable addition respondent', 'addition respondent weibo', 'respondent weibo post', 'weibo post language', 'post language feature', 'language feature extracted', 'feature extracted independent', 'extracted independent variable', 'independent variable feature', 'variable feature machine', 'feature machine learning', 'machine learning detail', 'learning detail data', 'detail data obtained', 'data obtained elaborated', 'obtained elaborated following', 'elaborated following subsection']",,,,,,,,
https://dl.acm.org/doi/abs/10.1145/3025453.3025909,1,We first obtained a list of 150 ranked major universities in the United States by crawling the US News and World Report website [48]. This list is constructed based on the Carnegie classification employed extensively by higher education researchers and using a set of 16 indicators of academic excellence defined by US News. The list includes a variety of universities spread across the US in different settings (e.g. urban rural) and with a wide range of student enrollment sizes. Figure 1(a) shows their geographic distribution. As a part of this crawl we also obtained university metadata: gender distribution of students average tuition and fees and academic calendar (semester/quarter). To obtain further information about the nature of the student body we crawled the Wikipedia pages of all of the 150 universities. From these pages we extracted the size of student enrollment type (public/private) and setting (rural/suburban/urban/city) at every institution. These definitions come from a formal categorization scheme used by the US Department of Education. The student body enrollment sizes ranged from 2255 to 97494 with 98 public and 52 private universities. 50 universities were reported to be urban 47 city 39 suburban and 13 rural. Finally we obtained information on racial diversity of the universities from a website known as Priceonomics [58]. The website calculates the Herfindahl-Hirschman Index (HHI) by combining the race/ethnicity distribution of student bodies at different universities with data given from the Department of Education. HHI ranges from 1 (the least diverse: a population of all one type) to 1/N (the most diverse) where N is the number of different racial categories being analyzed. Social Media Data of Universities Next we obtained social media data of the above universities. Specifically we focused on the social media Reddit. Why Reddit? Reddit is known to be a widely used online forum and social media site among the college student demographic [23]. Due to its forum structure it is extensively used for both content sharing as well as for obtaining feedback and information from communities of interest. Reddit harbors a variety of communities known as “subreddits” including many dedicated to specific university campuses. This allows a large sample of posts shared by students of a university to be collected in one place. Our preliminary manual inspection of university subreddits (e.g. r/gatech or r/KState) revealed that these subreddits are appropriated by students to discuss college topics (Table 1). Focusing on these public Reddit communities also does not require explicit data collection efforts to be coordinated at each of the 150 university sites. Although more students are likely to use Facebook due to its largely privately shared content it is challenging to obtain access to a large dataset of a university’s students. Next while Twitter is also widely adopted without explicit self-reported information it is challenging to identify college student accounts. Finally prior work [2 18] notes that semianonymity of Reddit enables candid self disclosure around stigmatized topics like mental health. Initial Data Acquisition. We leveraged the archive of all of Reddit data made available on Google’s BigQuery [11]. BigQuery is a cloud based managed data warehouse that allows third parties to access large publicly available dataset through simple SQL-type queries. Our queries grabbed all posts ranging between June 2011 and February 2016 available in the Reddit data archive. This included 424984 posts from 153378 unique users across all of the 146 universities with a mean of 2910.8 posts ( = 4329.6) and 1050 unique users ( = 1407) per subreddit. Filling the Gaps in Subreddit Data. The second step of our data collection process focused on identifying subreddits with insufficient data and supplementing them through additional alternative data collection. Through Reddit’s official API (https://www.reddit.com/dev/api/) we obtained the most recent number of subscribers in the 146 university subreddits (as of July 2016). Then to investigate if and to what extent some subreddits may have had unusually low data as given in step 1 we determined the median unique user to subscriber ratio in each subreddit. This allows us to capture the subreddits where the subscriber count is high however the data obtained is not sufficiently representative. For subreddits with unique user to subscriber ratio under median (.42) (73 in all) we performed a one-time data collection using the Reddit API. This gave us a set of (at most) 1000 most recent posts for each subreddit with a total of 39824 posts added to the data obtained in step 1 following de-duplication. We note that this procedure did not skew the yearly distributions of data across the subreddits: The skew (yearly rate of change) before and after data filling were 4.86 and 5.05 respectively which were found to be statistically equivalent based on a two-sample equivalence test (p = .013 p = .025) a test that uses two one-sided t-tests on the before-after yearly rates of change from both sides of a chosen difference interval [1 1].Based on the Reddit data we collected from Figure 1(b) we observe high positive correlation between a university’s size of student body (enrollment) and the number of users subscribing to the corresponding subreddit (R2 = .38; ⇢2 = .6; p<.05). For subreddits deviating from trend it would imply that the associated university’s student body was under or overrepresented on Reddit. We therefore devised a method to identify these subreddits to correct especially for underadoption bias. We first calculated the ratio between the number of subreddit subscribers to student enrollment for each subreddit and the corresponding university. If for a subreddit this ratio was less than the expected adoption of Reddit for the same demographic group (4-8% as of 20161) we assumed that Reddit was under-adopted by the students in the corresponding university. We thus removed subreddits where this ratio was <4%. This brought down our subreddits from 146 to 109. In these 109 subreddits the mean Reddit adoption was 8.6% ( =1.3) which is close to the highest adoption reported by Pew. The final dataset employed in our ensuing analyses included 446897 posts from 152834 unique users (mean posts per subreddit: 4100; mean users per subreddit: 1402). Figure 2(a) gives a distribution of the volume of crawled posts over the years. Figure 2(b) gives the final distribution of subreddits over the unique user to subscriber count ratio. Figure 2(c-d) gives distribution of the posts and unique users across the final 109 subreddits.We note it is possible that the type of students who frequent the university subreddits could be consistently different from the student body at the same university. To examine the representativeness of our university subreddit data we employed a random sample of 500 posts distributed across the subreddits and the years for manual examination of demographics. Two researchers then independently coded these posts for self-reported gender race or academic stage (undergraduate/graduate). For instance from the post “I’m a junior transfer and this will be my second semester” the researchers identified the post author to be an undergraduate whereas from “Hi all! I’m a new grad student (male 22) here the gender of the author can be inferred to be male. We found the interrater agreement to be high: Cohen’s  = .84. The relative ratios between the gender race and academic stage distributions of the coded posts and the university student body (obtained based on our methodology in the subsection “University Data”) showed significant positive correlation: The mean undergrad/grad ratio in our labeled data was 2.9 while it was 2.6 in the universities. A two-sample test of equivalence gave p-values of .016 and .011 respectively with respect to the difference interval [.4 .4]. The sex (male/female) ratio for our labeled data was 1.6 also observed to be statistically equivalent to that of the student body 1.1 (p = .02 p = .03 w.r.t. the difference interval [.5 .5]). This establishes the validity of our acquired Reddit data as a representative data source for studying mental health disclosures in university campuses.,we first obtained a list of ranked major university in the united state by crawling the u news and world report website this list is constructed based on the carnegie classification employed extensively by higher education researcher and using a set of indicator of academic excellence defined by u news the list includes a variety of university spread across the u in different setting eg urban rural and with a wide range of student enrollment size figure a show their geographic distribution a a part of this crawl we also obtained university metadata gender distribution of student average tuition and fee and academic calendar semesterquarter to obtain further information about the nature of the student body we crawled the wikipedia page of all of the university from these page we extracted the size of student enrollment type publicprivate and setting ruralsuburbanurbancity at every institution these definition come from a formal categorization scheme used by the u department of education the student body enrollment size ranged from to with public and private university university were reported to be urban city suburban and rural finally we obtained information on racial diversity of the university from a website known a priceonomics the website calculates the herfindahlhirschman index hhi by combining the raceethnicity distribution of student body at different university with data given from the department of education hhi range from the least diverse a population of all one type to n the most diverse where n is the number of different racial category being analyzed social medium data of university next we obtained social medium data of the above university specifically we focused on the social medium reddit why reddit reddit is known to be a widely used online forum and social medium site among the college student demographic due to it forum structure it is extensively used for both content sharing a well a for obtaining feedback and information from community of interest reddit harbor a variety of community known a subreddits including many dedicated to specific university campus this allows a large sample of post shared by student of a university to be collected in one place our preliminary manual inspection of university subreddits eg rgatech or rkstate revealed that these subreddits are appropriated by student to discus college topic table focusing on these public reddit community also doe not require explicit data collection effort to be coordinated at each of the university site although more student are likely to use facebook due to it largely privately shared content it is challenging to obtain access to a large dataset of a university student next while twitter is also widely adopted without explicit selfreported information it is challenging to identify college student account finally prior work note that semianonymity of reddit enables candid self disclosure around stigmatized topic like mental health initial data acquisition we leveraged the archive of all of reddit data made available on google bigquery bigquery is a cloud based managed data warehouse that allows third party to access large publicly available dataset through simple sqltype query our query grabbed all post ranging between june and february available in the reddit data archive this included post from unique user across all of the university with a mean of post and unique user per subreddit filling the gap in subreddit data the second step of our data collection process focused on identifying subreddits with insufficient data and supplementing them through additional alternative data collection through reddits official api httpswwwredditcomdevapi we obtained the most recent number of subscriber in the university subreddits a of july then to investigate if and to what extent some subreddits may have had unusually low data a given in step we determined the median unique user to subscriber ratio in each subreddit this allows u to capture the subreddits where the subscriber count is high however the data obtained is not sufficiently representative for subreddits with unique user to subscriber ratio under median in all we performed a onetime data collection using the reddit api this gave u a set of at most most recent post for each subreddit with a total of post added to the data obtained in step following deduplication we note that this procedure did not skew the yearly distribution of data across the subreddits the skew yearly rate of change before and after data filling were and respectively which were found to be statistically equivalent based on a twosample equivalence test p p a test that us two onesided ttests on the beforeafter yearly rate of change from both side of a chosen difference interval based on the reddit data we collected from figure b we observe high positive correlation between a university size of student body enrollment and the number of user subscribing to the corresponding subreddit r p for subreddits deviating from trend it would imply that the associated university student body wa under or overrepresented on reddit we therefore devised a method to identify these subreddits to correct especially for underadoption bias we first calculated the ratio between the number of subreddit subscriber to student enrollment for each subreddit and the corresponding university if for a subreddit this ratio wa le than the expected adoption of reddit for the same demographic group a of we assumed that reddit wa underadopted by the student in the corresponding university we thus removed subreddits where this ratio wa this brought down our subreddits from to in these subreddits the mean reddit adoption wa which is close to the highest adoption reported by pew the final dataset employed in our ensuing analysis included post from unique user mean post per subreddit mean user per subreddit figure a give a distribution of the volume of crawled post over the year figure b give the final distribution of subreddits over the unique user to subscriber count ratio figure cd give distribution of the post and unique user across the final subredditswe note it is possible that the type of student who frequent the university subreddits could be consistently different from the student body at the same university to examine the representativeness of our university subreddit data we employed a random sample of post distributed across the subreddits and the year for manual examination of demographic two researcher then independently coded these post for selfreported gender race or academic stage undergraduategraduate for instance from the post im a junior transfer and this will be my second semester the researcher identified the post author to be an undergraduate whereas from hi all im a new grad student male here the gender of the author can be inferred to be male we found the interrater agreement to be high cohens the relative ratio between the gender race and academic stage distribution of the coded post and the university student body obtained based on our methodology in the subsection university data showed significant positive correlation the mean undergradgrad ratio in our labeled data wa while it wa in the university a twosample test of equivalence gave pvalues of and respectively with respect to the difference interval the sex malefemale ratio for our labeled data wa also observed to be statistically equivalent to that of the student body p p wrt the difference interval this establishes the validity of our acquired reddit data a a representative data source for studying mental health disclosure in university campus,"['first', 'obtained', 'list', 'ranked', 'major', 'university', 'united', 'state', 'crawling', 'u', 'news', 'world', 'report', 'website', 'list', 'constructed', 'based', 'carnegie', 'classification', 'employed', 'extensively', 'higher', 'education', 'researcher', 'using', 'set', 'indicator', 'academic', 'excellence', 'defined', 'u', 'news', 'list', 'includes', 'variety', 'university', 'spread', 'across', 'u', 'different', 'setting', 'eg', 'urban', 'rural', 'wide', 'range', 'student', 'enrollment', 'size', 'figure', 'show', 'geographic', 'distribution', 'part', 'crawl', 'also', 'obtained', 'university', 'metadata', 'gender', 'distribution', 'student', 'average', 'tuition', 'fee', 'academic', 'calendar', 'semesterquarter', 'obtain', 'information', 'nature', 'student', 'body', 'crawled', 'wikipedia', 'page', 'university', 'page', 'extracted', 'size', 'student', 'enrollment', 'type', 'publicprivate', 'setting', 'ruralsuburbanurbancity', 'every', 'institution', 'definition', 'come', 'formal', 'categorization', 'scheme', 'used', 'u', 'department', 'education', 'student', 'body', 'enrollment', 'size', 'ranged', 'public', 'private', 'university', 'university', 'reported', 'urban', 'city', 'suburban', 'rural', 'finally', 'obtained', 'information', 'racial', 'diversity', 'university', 'website', 'known', 'priceonomics', 'website', 'calculates', 'herfindahlhirschman', 'index', 'hhi', 'combining', 'raceethnicity', 'distribution', 'student', 'body', 'different', 'university', 'data', 'given', 'department', 'education', 'hhi', 'range', 'least', 'diverse', 'population', 'one', 'type', 'n', 'diverse', 'n', 'number', 'different', 'racial', 'category', 'analyzed', 'social', 'medium', 'data', 'university', 'next', 'obtained', 'social', 'medium', 'data', 'university', 'specifically', 'focused', 'social', 'medium', 'reddit', 'reddit', 'reddit', 'known', 'widely', 'used', 'online', 'forum', 'social', 'medium', 'site', 'among', 'college', 'student', 'demographic', 'due', 'forum', 'structure', 'extensively', 'used', 'content', 'sharing', 'well', 'obtaining', 'feedback', 'information', 'community', 'interest', 'reddit', 'harbor', 'variety', 'community', 'known', 'subreddits', 'including', 'many', 'dedicated', 'specific', 'university', 'campus', 'allows', 'large', 'sample', 'post', 'shared', 'student', 'university', 'collected', 'one', 'place', 'preliminary', 'manual', 'inspection', 'university', 'subreddits', 'eg', 'rgatech', 'rkstate', 'revealed', 'subreddits', 'appropriated', 'student', 'discus', 'college', 'topic', 'table', 'focusing', 'public', 'reddit', 'community', 'also', 'doe', 'require', 'explicit', 'data', 'collection', 'effort', 'coordinated', 'university', 'site', 'although', 'student', 'likely', 'use', 'facebook', 'due', 'largely', 'privately', 'shared', 'content', 'challenging', 'obtain', 'access', 'large', 'dataset', 'university', 'student', 'next', 'twitter', 'also', 'widely', 'adopted', 'without', 'explicit', 'selfreported', 'information', 'challenging', 'identify', 'college', 'student', 'account', 'finally', 'prior', 'work', 'note', 'semianonymity', 'reddit', 'enables', 'candid', 'self', 'disclosure', 'around', 'stigmatized', 'topic', 'like', 'mental', 'health', 'initial', 'data', 'acquisition', 'leveraged', 'archive', 'reddit', 'data', 'made', 'available', 'google', 'bigquery', 'bigquery', 'cloud', 'based', 'managed', 'data', 'warehouse', 'allows', 'third', 'party', 'access', 'large', 'publicly', 'available', 'dataset', 'simple', 'sqltype', 'query', 'query', 'grabbed', 'post', 'ranging', 'june', 'february', 'available', 'reddit', 'data', 'archive', 'included', 'post', 'unique', 'user', 'across', 'university', 'mean', 'post', 'unique', 'user', 'per', 'subreddit', 'filling', 'gap', 'subreddit', 'data', 'second', 'step', 'data', 'collection', 'process', 'focused', 'identifying', 'subreddits', 'insufficient', 'data', 'supplementing', 'additional', 'alternative', 'data', 'collection', 'reddits', 'official', 'api', 'httpswwwredditcomdevapi', 'obtained', 'recent', 'number', 'subscriber', 'university', 'subreddits', 'july', 'investigate', 'extent', 'subreddits', 'may', 'unusually', 'low', 'data', 'given', 'step', 'determined', 'median', 'unique', 'user', 'subscriber', 'ratio', 'subreddit', 'allows', 'u', 'capture', 'subreddits', 'subscriber', 'count', 'high', 'however', 'data', 'obtained', 'sufficiently', 'representative', 'subreddits', 'unique', 'user', 'subscriber', 'ratio', 'median', 'performed', 'onetime', 'data', 'collection', 'using', 'reddit', 'api', 'gave', 'u', 'set', 'recent', 'post', 'subreddit', 'total', 'post', 'added', 'data', 'obtained', 'step', 'following', 'deduplication', 'note', 'procedure', 'skew', 'yearly', 'distribution', 'data', 'across', 'subreddits', 'skew', 'yearly', 'rate', 'change', 'data', 'filling', 'respectively', 'found', 'statistically', 'equivalent', 'based', 'twosample', 'equivalence', 'test', 'p', 'p', 'test', 'us', 'two', 'onesided', 'ttests', 'beforeafter', 'yearly', 'rate', 'change', 'side', 'chosen', 'difference', 'interval', 'based', 'reddit', 'data', 'collected', 'figure', 'b', 'observe', 'high', 'positive', 'correlation', 'university', 'size', 'student', 'body', 'enrollment', 'number', 'user', 'subscribing', 'corresponding', 'subreddit', 'r', 'p', 'subreddits', 'deviating', 'trend', 'would', 'imply', 'associated', 'university', 'student', 'body', 'wa', 'overrepresented', 'reddit', 'therefore', 'devised', 'method', 'identify', 'subreddits', 'correct', 'especially', 'underadoption', 'bias', 'first', 'calculated', 'ratio', 'number', 'subreddit', 'subscriber', 'student', 'enrollment', 'subreddit', 'corresponding', 'university', 'subreddit', 'ratio', 'wa', 'le', 'expected', 'adoption', 'reddit', 'demographic', 'group', 'assumed', 'reddit', 'wa', 'underadopted', 'student', 'corresponding', 'university', 'thus', 'removed', 'subreddits', 'ratio', 'wa', 'brought', 'subreddits', 'subreddits', 'mean', 'reddit', 'adoption', 'wa', 'close', 'highest', 'adoption', 'reported', 'pew', 'final', 'dataset', 'employed', 'ensuing', 'analysis', 'included', 'post', 'unique', 'user', 'mean', 'post', 'per', 'subreddit', 'mean', 'user', 'per', 'subreddit', 'figure', 'give', 'distribution', 'volume', 'crawled', 'post', 'year', 'figure', 'b', 'give', 'final', 'distribution', 'subreddits', 'unique', 'user', 'subscriber', 'count', 'ratio', 'figure', 'cd', 'give', 'distribution', 'post', 'unique', 'user', 'across', 'final', 'subredditswe', 'note', 'possible', 'type', 'student', 'frequent', 'university', 'subreddits', 'could', 'consistently', 'different', 'student', 'body', 'university', 'examine', 'representativeness', 'university', 'subreddit', 'data', 'employed', 'random', 'sample', 'post', 'distributed', 'across', 'subreddits', 'year', 'manual', 'examination', 'demographic', 'two', 'researcher', 'independently', 'coded', 'post', 'selfreported', 'gender', 'race', 'academic', 'stage', 'undergraduategraduate', 'instance', 'post', 'im', 'junior', 'transfer', 'second', 'semester', 'researcher', 'identified', 'post', 'author', 'undergraduate', 'whereas', 'hi', 'im', 'new', 'grad', 'student', 'male', 'gender', 'author', 'inferred', 'male', 'found', 'interrater', 'agreement', 'high', 'cohens', 'relative', 'ratio', 'gender', 'race', 'academic', 'stage', 'distribution', 'coded', 'post', 'university', 'student', 'body', 'obtained', 'based', 'methodology', 'subsection', 'university', 'data', 'showed', 'significant', 'positive', 'correlation', 'mean', 'undergradgrad', 'ratio', 'labeled', 'data', 'wa', 'wa', 'university', 'twosample', 'test', 'equivalence', 'gave', 'pvalues', 'respectively', 'respect', 'difference', 'interval', 'sex', 'malefemale', 'ratio', 'labeled', 'data', 'wa', 'also', 'observed', 'statistically', 'equivalent', 'student', 'body', 'p', 'p', 'wrt', 'difference', 'interval', 'establishes', 'validity', 'acquired', 'reddit', 'data', 'representative', 'data', 'source', 'studying', 'mental', 'health', 'disclosure', 'university', 'campus']","['first obtained', 'obtained list', 'list ranked', 'ranked major', 'major university', 'university united', 'united state', 'state crawling', 'crawling u', 'u news', 'news world', 'world report', 'report website', 'website list', 'list constructed', 'constructed based', 'based carnegie', 'carnegie classification', 'classification employed', 'employed extensively', 'extensively higher', 'higher education', 'education researcher', 'researcher using', 'using set', 'set indicator', 'indicator academic', 'academic excellence', 'excellence defined', 'defined u', 'u news', 'news list', 'list includes', 'includes variety', 'variety university', 'university spread', 'spread across', 'across u', 'u different', 'different setting', 'setting eg', 'eg urban', 'urban rural', 'rural wide', 'wide range', 'range student', 'student enrollment', 'enrollment size', 'size figure', 'figure show', 'show geographic', 'geographic distribution', 'distribution part', 'part crawl', 'crawl also', 'also obtained', 'obtained university', 'university metadata', 'metadata gender', 'gender distribution', 'distribution student', 'student average', 'average tuition', 'tuition fee', 'fee academic', 'academic calendar', 'calendar semesterquarter', 'semesterquarter obtain', 'obtain information', 'information nature', 'nature student', 'student body', 'body crawled', 'crawled wikipedia', 'wikipedia page', 'page university', 'university page', 'page extracted', 'extracted size', 'size student', 'student enrollment', 'enrollment type', 'type publicprivate', 'publicprivate setting', 'setting ruralsuburbanurbancity', 'ruralsuburbanurbancity every', 'every institution', 'institution definition', 'definition come', 'come formal', 'formal categorization', 'categorization scheme', 'scheme used', 'used u', 'u department', 'department education', 'education student', 'student body', 'body enrollment', 'enrollment size', 'size ranged', 'ranged public', 'public private', 'private university', 'university university', 'university reported', 'reported urban', 'urban city', 'city suburban', 'suburban rural', 'rural finally', 'finally obtained', 'obtained information', 'information racial', 'racial diversity', 'diversity university', 'university website', 'website known', 'known priceonomics', 'priceonomics website', 'website calculates', 'calculates herfindahlhirschman', 'herfindahlhirschman index', 'index hhi', 'hhi combining', 'combining raceethnicity', 'raceethnicity distribution', 'distribution student', 'student body', 'body different', 'different university', 'university data', 'data given', 'given department', 'department education', 'education hhi', 'hhi range', 'range least', 'least diverse', 'diverse population', 'population one', 'one type', 'type n', 'n diverse', 'diverse n', 'n number', 'number different', 'different racial', 'racial category', 'category analyzed', 'analyzed social', 'social medium', 'medium data', 'data university', 'university next', 'next obtained', 'obtained social', 'social medium', 'medium data', 'data university', 'university specifically', 'specifically focused', 'focused social', 'social medium', 'medium reddit', 'reddit reddit', 'reddit reddit', 'reddit known', 'known widely', 'widely used', 'used online', 'online forum', 'forum social', 'social medium', 'medium site', 'site among', 'among college', 'college student', 'student demographic', 'demographic due', 'due forum', 'forum structure', 'structure extensively', 'extensively used', 'used content', 'content sharing', 'sharing well', 'well obtaining', 'obtaining feedback', 'feedback information', 'information community', 'community interest', 'interest reddit', 'reddit harbor', 'harbor variety', 'variety community', 'community known', 'known subreddits', 'subreddits including', 'including many', 'many dedicated', 'dedicated specific', 'specific university', 'university campus', 'campus allows', 'allows large', 'large sample', 'sample post', 'post shared', 'shared student', 'student university', 'university collected', 'collected one', 'one place', 'place preliminary', 'preliminary manual', 'manual inspection', 'inspection university', 'university subreddits', 'subreddits eg', 'eg rgatech', 'rgatech rkstate', 'rkstate revealed', 'revealed subreddits', 'subreddits appropriated', 'appropriated student', 'student discus', 'discus college', 'college topic', 'topic table', 'table focusing', 'focusing public', 'public reddit', 'reddit community', 'community also', 'also doe', 'doe require', 'require explicit', 'explicit data', 'data collection', 'collection effort', 'effort coordinated', 'coordinated university', 'university site', 'site although', 'although student', 'student likely', 'likely use', 'use facebook', 'facebook due', 'due largely', 'largely privately', 'privately shared', 'shared content', 'content challenging', 'challenging obtain', 'obtain access', 'access large', 'large dataset', 'dataset university', 'university student', 'student next', 'next twitter', 'twitter also', 'also widely', 'widely adopted', 'adopted without', 'without explicit', 'explicit selfreported', 'selfreported information', 'information challenging', 'challenging identify', 'identify college', 'college student', 'student account', 'account finally', 'finally prior', 'prior work', 'work note', 'note semianonymity', 'semianonymity reddit', 'reddit enables', 'enables candid', 'candid self', 'self disclosure', 'disclosure around', 'around stigmatized', 'stigmatized topic', 'topic like', 'like mental', 'mental health', 'health initial', 'initial data', 'data acquisition', 'acquisition leveraged', 'leveraged archive', 'archive reddit', 'reddit data', 'data made', 'made available', 'available google', 'google bigquery', 'bigquery bigquery', 'bigquery cloud', 'cloud based', 'based managed', 'managed data', 'data warehouse', 'warehouse allows', 'allows third', 'third party', 'party access', 'access large', 'large publicly', 'publicly available', 'available dataset', 'dataset simple', 'simple sqltype', 'sqltype query', 'query query', 'query grabbed', 'grabbed post', 'post ranging', 'ranging june', 'june february', 'february available', 'available reddit', 'reddit data', 'data archive', 'archive included', 'included post', 'post unique', 'unique user', 'user across', 'across university', 'university mean', 'mean post', 'post unique', 'unique user', 'user per', 'per subreddit', 'subreddit filling', 'filling gap', 'gap subreddit', 'subreddit data', 'data second', 'second step', 'step data', 'data collection', 'collection process', 'process focused', 'focused identifying', 'identifying subreddits', 'subreddits insufficient', 'insufficient data', 'data supplementing', 'supplementing additional', 'additional alternative', 'alternative data', 'data collection', 'collection reddits', 'reddits official', 'official api', 'api httpswwwredditcomdevapi', 'httpswwwredditcomdevapi obtained', 'obtained recent', 'recent number', 'number subscriber', 'subscriber university', 'university subreddits', 'subreddits july', 'july investigate', 'investigate extent', 'extent subreddits', 'subreddits may', 'may unusually', 'unusually low', 'low data', 'data given', 'given step', 'step determined', 'determined median', 'median unique', 'unique user', 'user subscriber', 'subscriber ratio', 'ratio subreddit', 'subreddit allows', 'allows u', 'u capture', 'capture subreddits', 'subreddits subscriber', 'subscriber count', 'count high', 'high however', 'however data', 'data obtained', 'obtained sufficiently', 'sufficiently representative', 'representative subreddits', 'subreddits unique', 'unique user', 'user subscriber', 'subscriber ratio', 'ratio median', 'median performed', 'performed onetime', 'onetime data', 'data collection', 'collection using', 'using reddit', 'reddit api', 'api gave', 'gave u', 'u set', 'set recent', 'recent post', 'post subreddit', 'subreddit total', 'total post', 'post added', 'added data', 'data obtained', 'obtained step', 'step following', 'following deduplication', 'deduplication note', 'note procedure', 'procedure skew', 'skew yearly', 'yearly distribution', 'distribution data', 'data across', 'across subreddits', 'subreddits skew', 'skew yearly', 'yearly rate', 'rate change', 'change data', 'data filling', 'filling respectively', 'respectively found', 'found statistically', 'statistically equivalent', 'equivalent based', 'based twosample', 'twosample equivalence', 'equivalence test', 'test p', 'p p', 'p test', 'test us', 'us two', 'two onesided', 'onesided ttests', 'ttests beforeafter', 'beforeafter yearly', 'yearly rate', 'rate change', 'change side', 'side chosen', 'chosen difference', 'difference interval', 'interval based', 'based reddit', 'reddit data', 'data collected', 'collected figure', 'figure b', 'b observe', 'observe high', 'high positive', 'positive correlation', 'correlation university', 'university size', 'size student', 'student body', 'body enrollment', 'enrollment number', 'number user', 'user subscribing', 'subscribing corresponding', 'corresponding subreddit', 'subreddit r', 'r p', 'p subreddits', 'subreddits deviating', 'deviating trend', 'trend would', 'would imply', 'imply associated', 'associated university', 'university student', 'student body', 'body wa', 'wa overrepresented', 'overrepresented reddit', 'reddit therefore', 'therefore devised', 'devised method', 'method identify', 'identify subreddits', 'subreddits correct', 'correct especially', 'especially underadoption', 'underadoption bias', 'bias first', 'first calculated', 'calculated ratio', 'ratio number', 'number subreddit', 'subreddit subscriber', 'subscriber student', 'student enrollment', 'enrollment subreddit', 'subreddit corresponding', 'corresponding university', 'university subreddit', 'subreddit ratio', 'ratio wa', 'wa le', 'le expected', 'expected adoption', 'adoption reddit', 'reddit demographic', 'demographic group', 'group assumed', 'assumed reddit', 'reddit wa', 'wa underadopted', 'underadopted student', 'student corresponding', 'corresponding university', 'university thus', 'thus removed', 'removed subreddits', 'subreddits ratio', 'ratio wa', 'wa brought', 'brought subreddits', 'subreddits subreddits', 'subreddits mean', 'mean reddit', 'reddit adoption', 'adoption wa', 'wa close', 'close highest', 'highest adoption', 'adoption reported', 'reported pew', 'pew final', 'final dataset', 'dataset employed', 'employed ensuing', 'ensuing analysis', 'analysis included', 'included post', 'post unique', 'unique user', 'user mean', 'mean post', 'post per', 'per subreddit', 'subreddit mean', 'mean user', 'user per', 'per subreddit', 'subreddit figure', 'figure give', 'give distribution', 'distribution volume', 'volume crawled', 'crawled post', 'post year', 'year figure', 'figure b', 'b give', 'give final', 'final distribution', 'distribution subreddits', 'subreddits unique', 'unique user', 'user subscriber', 'subscriber count', 'count ratio', 'ratio figure', 'figure cd', 'cd give', 'give distribution', 'distribution post', 'post unique', 'unique user', 'user across', 'across final', 'final subredditswe', 'subredditswe note', 'note possible', 'possible type', 'type student', 'student frequent', 'frequent university', 'university subreddits', 'subreddits could', 'could consistently', 'consistently different', 'different student', 'student body', 'body university', 'university examine', 'examine representativeness', 'representativeness university', 'university subreddit', 'subreddit data', 'data employed', 'employed random', 'random sample', 'sample post', 'post distributed', 'distributed across', 'across subreddits', 'subreddits year', 'year manual', 'manual examination', 'examination demographic', 'demographic two', 'two researcher', 'researcher independently', 'independently coded', 'coded post', 'post selfreported', 'selfreported gender', 'gender race', 'race academic', 'academic stage', 'stage undergraduategraduate', 'undergraduategraduate instance', 'instance post', 'post im', 'im junior', 'junior transfer', 'transfer second', 'second semester', 'semester researcher', 'researcher identified', 'identified post', 'post author', 'author undergraduate', 'undergraduate whereas', 'whereas hi', 'hi im', 'im new', 'new grad', 'grad student', 'student male', 'male gender', 'gender author', 'author inferred', 'inferred male', 'male found', 'found interrater', 'interrater agreement', 'agreement high', 'high cohens', 'cohens relative', 'relative ratio', 'ratio gender', 'gender race', 'race academic', 'academic stage', 'stage distribution', 'distribution coded', 'coded post', 'post university', 'university student', 'student body', 'body obtained', 'obtained based', 'based methodology', 'methodology subsection', 'subsection university', 'university data', 'data showed', 'showed significant', 'significant positive', 'positive correlation', 'correlation mean', 'mean undergradgrad', 'undergradgrad ratio', 'ratio labeled', 'labeled data', 'data wa', 'wa wa', 'wa university', 'university twosample', 'twosample test', 'test equivalence', 'equivalence gave', 'gave pvalues', 'pvalues respectively', 'respectively respect', 'respect difference', 'difference interval', 'interval sex', 'sex malefemale', 'malefemale ratio', 'ratio labeled', 'labeled data', 'data wa', 'wa also', 'also observed', 'observed statistically', 'statistically equivalent', 'equivalent student', 'student body', 'body p', 'p p', 'p wrt', 'wrt difference', 'difference interval', 'interval establishes', 'establishes validity', 'validity acquired', 'acquired reddit', 'reddit data', 'data representative', 'representative data', 'data source', 'source studying', 'studying mental', 'mental health', 'health disclosure', 'disclosure university', 'university campus']","['first obtained list', 'obtained list ranked', 'list ranked major', 'ranked major university', 'major university united', 'university united state', 'united state crawling', 'state crawling u', 'crawling u news', 'u news world', 'news world report', 'world report website', 'report website list', 'website list constructed', 'list constructed based', 'constructed based carnegie', 'based carnegie classification', 'carnegie classification employed', 'classification employed extensively', 'employed extensively higher', 'extensively higher education', 'higher education researcher', 'education researcher using', 'researcher using set', 'using set indicator', 'set indicator academic', 'indicator academic excellence', 'academic excellence defined', 'excellence defined u', 'defined u news', 'u news list', 'news list includes', 'list includes variety', 'includes variety university', 'variety university spread', 'university spread across', 'spread across u', 'across u different', 'u different setting', 'different setting eg', 'setting eg urban', 'eg urban rural', 'urban rural wide', 'rural wide range', 'wide range student', 'range student enrollment', 'student enrollment size', 'enrollment size figure', 'size figure show', 'figure show geographic', 'show geographic distribution', 'geographic distribution part', 'distribution part crawl', 'part crawl also', 'crawl also obtained', 'also obtained university', 'obtained university metadata', 'university metadata gender', 'metadata gender distribution', 'gender distribution student', 'distribution student average', 'student average tuition', 'average tuition fee', 'tuition fee academic', 'fee academic calendar', 'academic calendar semesterquarter', 'calendar semesterquarter obtain', 'semesterquarter obtain information', 'obtain information nature', 'information nature student', 'nature student body', 'student body crawled', 'body crawled wikipedia', 'crawled wikipedia page', 'wikipedia page university', 'page university page', 'university page extracted', 'page extracted size', 'extracted size student', 'size student enrollment', 'student enrollment type', 'enrollment type publicprivate', 'type publicprivate setting', 'publicprivate setting ruralsuburbanurbancity', 'setting ruralsuburbanurbancity every', 'ruralsuburbanurbancity every institution', 'every institution definition', 'institution definition come', 'definition come formal', 'come formal categorization', 'formal categorization scheme', 'categorization scheme used', 'scheme used u', 'used u department', 'u department education', 'department education student', 'education student body', 'student body enrollment', 'body enrollment size', 'enrollment size ranged', 'size ranged public', 'ranged public private', 'public private university', 'private university university', 'university university reported', 'university reported urban', 'reported urban city', 'urban city suburban', 'city suburban rural', 'suburban rural finally', 'rural finally obtained', 'finally obtained information', 'obtained information racial', 'information racial diversity', 'racial diversity university', 'diversity university website', 'university website known', 'website known priceonomics', 'known priceonomics website', 'priceonomics website calculates', 'website calculates herfindahlhirschman', 'calculates herfindahlhirschman index', 'herfindahlhirschman index hhi', 'index hhi combining', 'hhi combining raceethnicity', 'combining raceethnicity distribution', 'raceethnicity distribution student', 'distribution student body', 'student body different', 'body different university', 'different university data', 'university data given', 'data given department', 'given department education', 'department education hhi', 'education hhi range', 'hhi range least', 'range least diverse', 'least diverse population', 'diverse population one', 'population one type', 'one type n', 'type n diverse', 'n diverse n', 'diverse n number', 'n number different', 'number different racial', 'different racial category', 'racial category analyzed', 'category analyzed social', 'analyzed social medium', 'social medium data', 'medium data university', 'data university next', 'university next obtained', 'next obtained social', 'obtained social medium', 'social medium data', 'medium data university', 'data university specifically', 'university specifically focused', 'specifically focused social', 'focused social medium', 'social medium reddit', 'medium reddit reddit', 'reddit reddit reddit', 'reddit reddit known', 'reddit known widely', 'known widely used', 'widely used online', 'used online forum', 'online forum social', 'forum social medium', 'social medium site', 'medium site among', 'site among college', 'among college student', 'college student demographic', 'student demographic due', 'demographic due forum', 'due forum structure', 'forum structure extensively', 'structure extensively used', 'extensively used content', 'used content sharing', 'content sharing well', 'sharing well obtaining', 'well obtaining feedback', 'obtaining feedback information', 'feedback information community', 'information community interest', 'community interest reddit', 'interest reddit harbor', 'reddit harbor variety', 'harbor variety community', 'variety community known', 'community known subreddits', 'known subreddits including', 'subreddits including many', 'including many dedicated', 'many dedicated specific', 'dedicated specific university', 'specific university campus', 'university campus allows', 'campus allows large', 'allows large sample', 'large sample post', 'sample post shared', 'post shared student', 'shared student university', 'student university collected', 'university collected one', 'collected one place', 'one place preliminary', 'place preliminary manual', 'preliminary manual inspection', 'manual inspection university', 'inspection university subreddits', 'university subreddits eg', 'subreddits eg rgatech', 'eg rgatech rkstate', 'rgatech rkstate revealed', 'rkstate revealed subreddits', 'revealed subreddits appropriated', 'subreddits appropriated student', 'appropriated student discus', 'student discus college', 'discus college topic', 'college topic table', 'topic table focusing', 'table focusing public', 'focusing public reddit', 'public reddit community', 'reddit community also', 'community also doe', 'also doe require', 'doe require explicit', 'require explicit data', 'explicit data collection', 'data collection effort', 'collection effort coordinated', 'effort coordinated university', 'coordinated university site', 'university site although', 'site although student', 'although student likely', 'student likely use', 'likely use facebook', 'use facebook due', 'facebook due largely', 'due largely privately', 'largely privately shared', 'privately shared content', 'shared content challenging', 'content challenging obtain', 'challenging obtain access', 'obtain access large', 'access large dataset', 'large dataset university', 'dataset university student', 'university student next', 'student next twitter', 'next twitter also', 'twitter also widely', 'also widely adopted', 'widely adopted without', 'adopted without explicit', 'without explicit selfreported', 'explicit selfreported information', 'selfreported information challenging', 'information challenging identify', 'challenging identify college', 'identify college student', 'college student account', 'student account finally', 'account finally prior', 'finally prior work', 'prior work note', 'work note semianonymity', 'note semianonymity reddit', 'semianonymity reddit enables', 'reddit enables candid', 'enables candid self', 'candid self disclosure', 'self disclosure around', 'disclosure around stigmatized', 'around stigmatized topic', 'stigmatized topic like', 'topic like mental', 'like mental health', 'mental health initial', 'health initial data', 'initial data acquisition', 'data acquisition leveraged', 'acquisition leveraged archive', 'leveraged archive reddit', 'archive reddit data', 'reddit data made', 'data made available', 'made available google', 'available google bigquery', 'google bigquery bigquery', 'bigquery bigquery cloud', 'bigquery cloud based', 'cloud based managed', 'based managed data', 'managed data warehouse', 'data warehouse allows', 'warehouse allows third', 'allows third party', 'third party access', 'party access large', 'access large publicly', 'large publicly available', 'publicly available dataset', 'available dataset simple', 'dataset simple sqltype', 'simple sqltype query', 'sqltype query query', 'query query grabbed', 'query grabbed post', 'grabbed post ranging', 'post ranging june', 'ranging june february', 'june february available', 'february available reddit', 'available reddit data', 'reddit data archive', 'data archive included', 'archive included post', 'included post unique', 'post unique user', 'unique user across', 'user across university', 'across university mean', 'university mean post', 'mean post unique', 'post unique user', 'unique user per', 'user per subreddit', 'per subreddit filling', 'subreddit filling gap', 'filling gap subreddit', 'gap subreddit data', 'subreddit data second', 'data second step', 'second step data', 'step data collection', 'data collection process', 'collection process focused', 'process focused identifying', 'focused identifying subreddits', 'identifying subreddits insufficient', 'subreddits insufficient data', 'insufficient data supplementing', 'data supplementing additional', 'supplementing additional alternative', 'additional alternative data', 'alternative data collection', 'data collection reddits', 'collection reddits official', 'reddits official api', 'official api httpswwwredditcomdevapi', 'api httpswwwredditcomdevapi obtained', 'httpswwwredditcomdevapi obtained recent', 'obtained recent number', 'recent number subscriber', 'number subscriber university', 'subscriber university subreddits', 'university subreddits july', 'subreddits july investigate', 'july investigate extent', 'investigate extent subreddits', 'extent subreddits may', 'subreddits may unusually', 'may unusually low', 'unusually low data', 'low data given', 'data given step', 'given step determined', 'step determined median', 'determined median unique', 'median unique user', 'unique user subscriber', 'user subscriber ratio', 'subscriber ratio subreddit', 'ratio subreddit allows', 'subreddit allows u', 'allows u capture', 'u capture subreddits', 'capture subreddits subscriber', 'subreddits subscriber count', 'subscriber count high', 'count high however', 'high however data', 'however data obtained', 'data obtained sufficiently', 'obtained sufficiently representative', 'sufficiently representative subreddits', 'representative subreddits unique', 'subreddits unique user', 'unique user subscriber', 'user subscriber ratio', 'subscriber ratio median', 'ratio median performed', 'median performed onetime', 'performed onetime data', 'onetime data collection', 'data collection using', 'collection using reddit', 'using reddit api', 'reddit api gave', 'api gave u', 'gave u set', 'u set recent', 'set recent post', 'recent post subreddit', 'post subreddit total', 'subreddit total post', 'total post added', 'post added data', 'added data obtained', 'data obtained step', 'obtained step following', 'step following deduplication', 'following deduplication note', 'deduplication note procedure', 'note procedure skew', 'procedure skew yearly', 'skew yearly distribution', 'yearly distribution data', 'distribution data across', 'data across subreddits', 'across subreddits skew', 'subreddits skew yearly', 'skew yearly rate', 'yearly rate change', 'rate change data', 'change data filling', 'data filling respectively', 'filling respectively found', 'respectively found statistically', 'found statistically equivalent', 'statistically equivalent based', 'equivalent based twosample', 'based twosample equivalence', 'twosample equivalence test', 'equivalence test p', 'test p p', 'p p test', 'p test us', 'test us two', 'us two onesided', 'two onesided ttests', 'onesided ttests beforeafter', 'ttests beforeafter yearly', 'beforeafter yearly rate', 'yearly rate change', 'rate change side', 'change side chosen', 'side chosen difference', 'chosen difference interval', 'difference interval based', 'interval based reddit', 'based reddit data', 'reddit data collected', 'data collected figure', 'collected figure b', 'figure b observe', 'b observe high', 'observe high positive', 'high positive correlation', 'positive correlation university', 'correlation university size', 'university size student', 'size student body', 'student body enrollment', 'body enrollment number', 'enrollment number user', 'number user subscribing', 'user subscribing corresponding', 'subscribing corresponding subreddit', 'corresponding subreddit r', 'subreddit r p', 'r p subreddits', 'p subreddits deviating', 'subreddits deviating trend', 'deviating trend would', 'trend would imply', 'would imply associated', 'imply associated university', 'associated university student', 'university student body', 'student body wa', 'body wa overrepresented', 'wa overrepresented reddit', 'overrepresented reddit therefore', 'reddit therefore devised', 'therefore devised method', 'devised method identify', 'method identify subreddits', 'identify subreddits correct', 'subreddits correct especially', 'correct especially underadoption', 'especially underadoption bias', 'underadoption bias first', 'bias first calculated', 'first calculated ratio', 'calculated ratio number', 'ratio number subreddit', 'number subreddit subscriber', 'subreddit subscriber student', 'subscriber student enrollment', 'student enrollment subreddit', 'enrollment subreddit corresponding', 'subreddit corresponding university', 'corresponding university subreddit', 'university subreddit ratio', 'subreddit ratio wa', 'ratio wa le', 'wa le expected', 'le expected adoption', 'expected adoption reddit', 'adoption reddit demographic', 'reddit demographic group', 'demographic group assumed', 'group assumed reddit', 'assumed reddit wa', 'reddit wa underadopted', 'wa underadopted student', 'underadopted student corresponding', 'student corresponding university', 'corresponding university thus', 'university thus removed', 'thus removed subreddits', 'removed subreddits ratio', 'subreddits ratio wa', 'ratio wa brought', 'wa brought subreddits', 'brought subreddits subreddits', 'subreddits subreddits mean', 'subreddits mean reddit', 'mean reddit adoption', 'reddit adoption wa', 'adoption wa close', 'wa close highest', 'close highest adoption', 'highest adoption reported', 'adoption reported pew', 'reported pew final', 'pew final dataset', 'final dataset employed', 'dataset employed ensuing', 'employed ensuing analysis', 'ensuing analysis included', 'analysis included post', 'included post unique', 'post unique user', 'unique user mean', 'user mean post', 'mean post per', 'post per subreddit', 'per subreddit mean', 'subreddit mean user', 'mean user per', 'user per subreddit', 'per subreddit figure', 'subreddit figure give', 'figure give distribution', 'give distribution volume', 'distribution volume crawled', 'volume crawled post', 'crawled post year', 'post year figure', 'year figure b', 'figure b give', 'b give final', 'give final distribution', 'final distribution subreddits', 'distribution subreddits unique', 'subreddits unique user', 'unique user subscriber', 'user subscriber count', 'subscriber count ratio', 'count ratio figure', 'ratio figure cd', 'figure cd give', 'cd give distribution', 'give distribution post', 'distribution post unique', 'post unique user', 'unique user across', 'user across final', 'across final subredditswe', 'final subredditswe note', 'subredditswe note possible', 'note possible type', 'possible type student', 'type student frequent', 'student frequent university', 'frequent university subreddits', 'university subreddits could', 'subreddits could consistently', 'could consistently different', 'consistently different student', 'different student body', 'student body university', 'body university examine', 'university examine representativeness', 'examine representativeness university', 'representativeness university subreddit', 'university subreddit data', 'subreddit data employed', 'data employed random', 'employed random sample', 'random sample post', 'sample post distributed', 'post distributed across', 'distributed across subreddits', 'across subreddits year', 'subreddits year manual', 'year manual examination', 'manual examination demographic', 'examination demographic two', 'demographic two researcher', 'two researcher independently', 'researcher independently coded', 'independently coded post', 'coded post selfreported', 'post selfreported gender', 'selfreported gender race', 'gender race academic', 'race academic stage', 'academic stage undergraduategraduate', 'stage undergraduategraduate instance', 'undergraduategraduate instance post', 'instance post im', 'post im junior', 'im junior transfer', 'junior transfer second', 'transfer second semester', 'second semester researcher', 'semester researcher identified', 'researcher identified post', 'identified post author', 'post author undergraduate', 'author undergraduate whereas', 'undergraduate whereas hi', 'whereas hi im', 'hi im new', 'im new grad', 'new grad student', 'grad student male', 'student male gender', 'male gender author', 'gender author inferred', 'author inferred male', 'inferred male found', 'male found interrater', 'found interrater agreement', 'interrater agreement high', 'agreement high cohens', 'high cohens relative', 'cohens relative ratio', 'relative ratio gender', 'ratio gender race', 'gender race academic', 'race academic stage', 'academic stage distribution', 'stage distribution coded', 'distribution coded post', 'coded post university', 'post university student', 'university student body', 'student body obtained', 'body obtained based', 'obtained based methodology', 'based methodology subsection', 'methodology subsection university', 'subsection university data', 'university data showed', 'data showed significant', 'showed significant positive', 'significant positive correlation', 'positive correlation mean', 'correlation mean undergradgrad', 'mean undergradgrad ratio', 'undergradgrad ratio labeled', 'ratio labeled data', 'labeled data wa', 'data wa wa', 'wa wa university', 'wa university twosample', 'university twosample test', 'twosample test equivalence', 'test equivalence gave', 'equivalence gave pvalues', 'gave pvalues respectively', 'pvalues respectively respect', 'respectively respect difference', 'respect difference interval', 'difference interval sex', 'interval sex malefemale', 'sex malefemale ratio', 'malefemale ratio labeled', 'ratio labeled data', 'labeled data wa', 'data wa also', 'wa also observed', 'also observed statistically', 'observed statistically equivalent', 'statistically equivalent student', 'equivalent student body', 'student body p', 'body p p', 'p p wrt', 'p wrt difference', 'wrt difference interval', 'difference interval establishes', 'interval establishes validity', 'establishes validity acquired', 'validity acquired reddit', 'acquired reddit data', 'reddit data representative', 'data representative data', 'representative data source', 'data source studying', 'source studying mental', 'studying mental health', 'mental health disclosure', 'health disclosure university', 'disclosure university campus']",,,,,,,,
https://ieeexplore.ieee.org/abstract/document/7752434,0,To train our models we require information from two different types of users: patients and non-patients. Therefore we employed a combined - manual effort and keyword matching - data collection approach to efficiently collect data for these users. For the collection of patients we manually collect the community portals relevant to both mental disorders. 2 From these portals' followers list we select the self-reported users who explicitly state in their profile description that they suffer from a mental illness; i.e. for a given user we are checking if his/her profile contains any keyword related to a target disorder (e.g. “borderline” “bpd” “bipolar”). Non-patients are referred to as random active Twitter users who are not explicitly stating that they are suffering from Bipolar disorder (hereinafter referred to as “BD”) or Borderline Personality Disorder (hereinafter referred to as “BPD”). To obtain these users we randomly sampled Twitter IDs. Thereafter we proceeded to download the tweets from the selected IDs. After the users have been identified we manually label them into one of two categories: 1) Patient: a person who is suffering from a mental disorder 2) Not-related: any user who we don't consider to be a patient. Lastly after having obtained the final list of patients we retrieve their tweets. These steps are applied for the collection of both BPD and BD patient datasets.In this work we are focused on two main type of features (linguistic and behavioral). TF-IDF is adopted to model the linguist features of patients and Pattern of Life Features (PLF) adopted from the work of Coppersmith et al. [1] is used to model the behavioral style of patients. TF-IDF Features To capture the frequent and representative words used by the patients TF-IDF is applied on the unigram and bigrams collected from all the patients' tweets. Pattern of Life Features (PLF) These features reveal the emotional patterns and behavioral tendency of users by measuring polarity emotion and social interactions. In order to fully compose the PLF we combined the following list of features: Age and Gender: Twitter does not publicly provide information about the age and gender of its users mainly due to privacy concerns so we adopted the work of Sap et al. [5] to fill in this information. Polarity Features: The Sentiment140 API 3 was used to label each tweet as either positive negative or neutral. The polarity is furthermore transformed into five different values to capture the affective traits of each user: 1) Positive Ratio: the percentage of positive tweets 2) Negative Ratio: the percentage of negative tweets 3) Positive Combo: captures the mania and hypomania traits of patients which is determined by the number of continuous positive posts appearing more than x amount of times within a period of time in minutes T. 4) Negative Combos: captures the depression traits of patients and is determined by the number of continuous negative posts appearing more than x amount of times within a period of time in minutes T. 5) Flips Ratio: quantifies the emotional unstableness and is determined by counting how frequently two continuous tweets with different polarity (either positive to negative or negative to positive) appear together within a period of time in minutes T. In our work x is set to 2 and T is set to 30 minutes. Social Features: These features can demonstrate how users are behaving with respect to their environment. The following are the social features designed for each user: 1) Tweeting Frequency; the frequency of daily posts; 2) Mention Ratio: the percentage of posts which contain at least one mention of another user; 3) Frequent Mentions: the number of Twitter users mentioned more than three times which is a measurement of how many close friends a particular user may have; 4) Unique Mentions: the number of unique users mentioned which is a measure of the width of a user's social network.,to train our model we require information from two different type of user patient and nonpatients therefore we employed a combined manual effort and keyword matching data collection approach to efficiently collect data for these user for the collection of patient we manually collect the community portal relevant to both mental disorder from these portal follower list we select the selfreported user who explicitly state in their profile description that they suffer from a mental illness ie for a given user we are checking if hisher profile contains any keyword related to a target disorder eg borderline bpd bipolar nonpatients are referred to a random active twitter user who are not explicitly stating that they are suffering from bipolar disorder hereinafter referred to a bd or borderline personality disorder hereinafter referred to a bpd to obtain these user we randomly sampled twitter id thereafter we proceeded to download the tweet from the selected id after the user have been identified we manually label them into one of two category patient a person who is suffering from a mental disorder notrelated any user who we dont consider to be a patient lastly after having obtained the final list of patient we retrieve their tweet these step are applied for the collection of both bpd and bd patient datasetsin this work we are focused on two main type of feature linguistic and behavioral tfidf is adopted to model the linguist feature of patient and pattern of life feature plf adopted from the work of coppersmith et al is used to model the behavioral style of patient tfidf feature to capture the frequent and representative word used by the patient tfidf is applied on the unigram and bigram collected from all the patient tweet pattern of life feature plf these feature reveal the emotional pattern and behavioral tendency of user by measuring polarity emotion and social interaction in order to fully compose the plf we combined the following list of feature age and gender twitter doe not publicly provide information about the age and gender of it user mainly due to privacy concern so we adopted the work of sap et al to fill in this information polarity feature the sentiment api wa used to label each tweet a either positive negative or neutral the polarity is furthermore transformed into five different value to capture the affective trait of each user positive ratio the percentage of positive tweet negative ratio the percentage of negative tweet positive combo capture the mania and hypomania trait of patient which is determined by the number of continuous positive post appearing more than x amount of time within a period of time in minute t negative combo capture the depression trait of patient and is determined by the number of continuous negative post appearing more than x amount of time within a period of time in minute t flip ratio quantifies the emotional unstableness and is determined by counting how frequently two continuous tweet with different polarity either positive to negative or negative to positive appear together within a period of time in minute t in our work x is set to and t is set to minute social feature these feature can demonstrate how user are behaving with respect to their environment the following are the social feature designed for each user tweeting frequency the frequency of daily post mention ratio the percentage of post which contain at least one mention of another user frequent mention the number of twitter user mentioned more than three time which is a measurement of how many close friend a particular user may have unique mention the number of unique user mentioned which is a measure of the width of a user social network,"['train', 'model', 'require', 'information', 'two', 'different', 'type', 'user', 'patient', 'nonpatients', 'therefore', 'employed', 'combined', 'manual', 'effort', 'keyword', 'matching', 'data', 'collection', 'approach', 'efficiently', 'collect', 'data', 'user', 'collection', 'patient', 'manually', 'collect', 'community', 'portal', 'relevant', 'mental', 'disorder', 'portal', 'follower', 'list', 'select', 'selfreported', 'user', 'explicitly', 'state', 'profile', 'description', 'suffer', 'mental', 'illness', 'ie', 'given', 'user', 'checking', 'hisher', 'profile', 'contains', 'keyword', 'related', 'target', 'disorder', 'eg', 'borderline', 'bpd', 'bipolar', 'nonpatients', 'referred', 'random', 'active', 'twitter', 'user', 'explicitly', 'stating', 'suffering', 'bipolar', 'disorder', 'hereinafter', 'referred', 'bd', 'borderline', 'personality', 'disorder', 'hereinafter', 'referred', 'bpd', 'obtain', 'user', 'randomly', 'sampled', 'twitter', 'id', 'thereafter', 'proceeded', 'download', 'tweet', 'selected', 'id', 'user', 'identified', 'manually', 'label', 'one', 'two', 'category', 'patient', 'person', 'suffering', 'mental', 'disorder', 'notrelated', 'user', 'dont', 'consider', 'patient', 'lastly', 'obtained', 'final', 'list', 'patient', 'retrieve', 'tweet', 'step', 'applied', 'collection', 'bpd', 'bd', 'patient', 'datasetsin', 'work', 'focused', 'two', 'main', 'type', 'feature', 'linguistic', 'behavioral', 'tfidf', 'adopted', 'model', 'linguist', 'feature', 'patient', 'pattern', 'life', 'feature', 'plf', 'adopted', 'work', 'coppersmith', 'et', 'al', 'used', 'model', 'behavioral', 'style', 'patient', 'tfidf', 'feature', 'capture', 'frequent', 'representative', 'word', 'used', 'patient', 'tfidf', 'applied', 'unigram', 'bigram', 'collected', 'patient', 'tweet', 'pattern', 'life', 'feature', 'plf', 'feature', 'reveal', 'emotional', 'pattern', 'behavioral', 'tendency', 'user', 'measuring', 'polarity', 'emotion', 'social', 'interaction', 'order', 'fully', 'compose', 'plf', 'combined', 'following', 'list', 'feature', 'age', 'gender', 'twitter', 'doe', 'publicly', 'provide', 'information', 'age', 'gender', 'user', 'mainly', 'due', 'privacy', 'concern', 'adopted', 'work', 'sap', 'et', 'al', 'fill', 'information', 'polarity', 'feature', 'sentiment', 'api', 'wa', 'used', 'label', 'tweet', 'either', 'positive', 'negative', 'neutral', 'polarity', 'furthermore', 'transformed', 'five', 'different', 'value', 'capture', 'affective', 'trait', 'user', 'positive', 'ratio', 'percentage', 'positive', 'tweet', 'negative', 'ratio', 'percentage', 'negative', 'tweet', 'positive', 'combo', 'capture', 'mania', 'hypomania', 'trait', 'patient', 'determined', 'number', 'continuous', 'positive', 'post', 'appearing', 'x', 'amount', 'time', 'within', 'period', 'time', 'minute', 'negative', 'combo', 'capture', 'depression', 'trait', 'patient', 'determined', 'number', 'continuous', 'negative', 'post', 'appearing', 'x', 'amount', 'time', 'within', 'period', 'time', 'minute', 'flip', 'ratio', 'quantifies', 'emotional', 'unstableness', 'determined', 'counting', 'frequently', 'two', 'continuous', 'tweet', 'different', 'polarity', 'either', 'positive', 'negative', 'negative', 'positive', 'appear', 'together', 'within', 'period', 'time', 'minute', 'work', 'x', 'set', 'set', 'minute', 'social', 'feature', 'feature', 'demonstrate', 'user', 'behaving', 'respect', 'environment', 'following', 'social', 'feature', 'designed', 'user', 'tweeting', 'frequency', 'frequency', 'daily', 'post', 'mention', 'ratio', 'percentage', 'post', 'contain', 'least', 'one', 'mention', 'another', 'user', 'frequent', 'mention', 'number', 'twitter', 'user', 'mentioned', 'three', 'time', 'measurement', 'many', 'close', 'friend', 'particular', 'user', 'may', 'unique', 'mention', 'number', 'unique', 'user', 'mentioned', 'measure', 'width', 'user', 'social', 'network']","['train model', 'model require', 'require information', 'information two', 'two different', 'different type', 'type user', 'user patient', 'patient nonpatients', 'nonpatients therefore', 'therefore employed', 'employed combined', 'combined manual', 'manual effort', 'effort keyword', 'keyword matching', 'matching data', 'data collection', 'collection approach', 'approach efficiently', 'efficiently collect', 'collect data', 'data user', 'user collection', 'collection patient', 'patient manually', 'manually collect', 'collect community', 'community portal', 'portal relevant', 'relevant mental', 'mental disorder', 'disorder portal', 'portal follower', 'follower list', 'list select', 'select selfreported', 'selfreported user', 'user explicitly', 'explicitly state', 'state profile', 'profile description', 'description suffer', 'suffer mental', 'mental illness', 'illness ie', 'ie given', 'given user', 'user checking', 'checking hisher', 'hisher profile', 'profile contains', 'contains keyword', 'keyword related', 'related target', 'target disorder', 'disorder eg', 'eg borderline', 'borderline bpd', 'bpd bipolar', 'bipolar nonpatients', 'nonpatients referred', 'referred random', 'random active', 'active twitter', 'twitter user', 'user explicitly', 'explicitly stating', 'stating suffering', 'suffering bipolar', 'bipolar disorder', 'disorder hereinafter', 'hereinafter referred', 'referred bd', 'bd borderline', 'borderline personality', 'personality disorder', 'disorder hereinafter', 'hereinafter referred', 'referred bpd', 'bpd obtain', 'obtain user', 'user randomly', 'randomly sampled', 'sampled twitter', 'twitter id', 'id thereafter', 'thereafter proceeded', 'proceeded download', 'download tweet', 'tweet selected', 'selected id', 'id user', 'user identified', 'identified manually', 'manually label', 'label one', 'one two', 'two category', 'category patient', 'patient person', 'person suffering', 'suffering mental', 'mental disorder', 'disorder notrelated', 'notrelated user', 'user dont', 'dont consider', 'consider patient', 'patient lastly', 'lastly obtained', 'obtained final', 'final list', 'list patient', 'patient retrieve', 'retrieve tweet', 'tweet step', 'step applied', 'applied collection', 'collection bpd', 'bpd bd', 'bd patient', 'patient datasetsin', 'datasetsin work', 'work focused', 'focused two', 'two main', 'main type', 'type feature', 'feature linguistic', 'linguistic behavioral', 'behavioral tfidf', 'tfidf adopted', 'adopted model', 'model linguist', 'linguist feature', 'feature patient', 'patient pattern', 'pattern life', 'life feature', 'feature plf', 'plf adopted', 'adopted work', 'work coppersmith', 'coppersmith et', 'et al', 'al used', 'used model', 'model behavioral', 'behavioral style', 'style patient', 'patient tfidf', 'tfidf feature', 'feature capture', 'capture frequent', 'frequent representative', 'representative word', 'word used', 'used patient', 'patient tfidf', 'tfidf applied', 'applied unigram', 'unigram bigram', 'bigram collected', 'collected patient', 'patient tweet', 'tweet pattern', 'pattern life', 'life feature', 'feature plf', 'plf feature', 'feature reveal', 'reveal emotional', 'emotional pattern', 'pattern behavioral', 'behavioral tendency', 'tendency user', 'user measuring', 'measuring polarity', 'polarity emotion', 'emotion social', 'social interaction', 'interaction order', 'order fully', 'fully compose', 'compose plf', 'plf combined', 'combined following', 'following list', 'list feature', 'feature age', 'age gender', 'gender twitter', 'twitter doe', 'doe publicly', 'publicly provide', 'provide information', 'information age', 'age gender', 'gender user', 'user mainly', 'mainly due', 'due privacy', 'privacy concern', 'concern adopted', 'adopted work', 'work sap', 'sap et', 'et al', 'al fill', 'fill information', 'information polarity', 'polarity feature', 'feature sentiment', 'sentiment api', 'api wa', 'wa used', 'used label', 'label tweet', 'tweet either', 'either positive', 'positive negative', 'negative neutral', 'neutral polarity', 'polarity furthermore', 'furthermore transformed', 'transformed five', 'five different', 'different value', 'value capture', 'capture affective', 'affective trait', 'trait user', 'user positive', 'positive ratio', 'ratio percentage', 'percentage positive', 'positive tweet', 'tweet negative', 'negative ratio', 'ratio percentage', 'percentage negative', 'negative tweet', 'tweet positive', 'positive combo', 'combo capture', 'capture mania', 'mania hypomania', 'hypomania trait', 'trait patient', 'patient determined', 'determined number', 'number continuous', 'continuous positive', 'positive post', 'post appearing', 'appearing x', 'x amount', 'amount time', 'time within', 'within period', 'period time', 'time minute', 'minute negative', 'negative combo', 'combo capture', 'capture depression', 'depression trait', 'trait patient', 'patient determined', 'determined number', 'number continuous', 'continuous negative', 'negative post', 'post appearing', 'appearing x', 'x amount', 'amount time', 'time within', 'within period', 'period time', 'time minute', 'minute flip', 'flip ratio', 'ratio quantifies', 'quantifies emotional', 'emotional unstableness', 'unstableness determined', 'determined counting', 'counting frequently', 'frequently two', 'two continuous', 'continuous tweet', 'tweet different', 'different polarity', 'polarity either', 'either positive', 'positive negative', 'negative negative', 'negative positive', 'positive appear', 'appear together', 'together within', 'within period', 'period time', 'time minute', 'minute work', 'work x', 'x set', 'set set', 'set minute', 'minute social', 'social feature', 'feature feature', 'feature demonstrate', 'demonstrate user', 'user behaving', 'behaving respect', 'respect environment', 'environment following', 'following social', 'social feature', 'feature designed', 'designed user', 'user tweeting', 'tweeting frequency', 'frequency frequency', 'frequency daily', 'daily post', 'post mention', 'mention ratio', 'ratio percentage', 'percentage post', 'post contain', 'contain least', 'least one', 'one mention', 'mention another', 'another user', 'user frequent', 'frequent mention', 'mention number', 'number twitter', 'twitter user', 'user mentioned', 'mentioned three', 'three time', 'time measurement', 'measurement many', 'many close', 'close friend', 'friend particular', 'particular user', 'user may', 'may unique', 'unique mention', 'mention number', 'number unique', 'unique user', 'user mentioned', 'mentioned measure', 'measure width', 'width user', 'user social', 'social network']","['train model require', 'model require information', 'require information two', 'information two different', 'two different type', 'different type user', 'type user patient', 'user patient nonpatients', 'patient nonpatients therefore', 'nonpatients therefore employed', 'therefore employed combined', 'employed combined manual', 'combined manual effort', 'manual effort keyword', 'effort keyword matching', 'keyword matching data', 'matching data collection', 'data collection approach', 'collection approach efficiently', 'approach efficiently collect', 'efficiently collect data', 'collect data user', 'data user collection', 'user collection patient', 'collection patient manually', 'patient manually collect', 'manually collect community', 'collect community portal', 'community portal relevant', 'portal relevant mental', 'relevant mental disorder', 'mental disorder portal', 'disorder portal follower', 'portal follower list', 'follower list select', 'list select selfreported', 'select selfreported user', 'selfreported user explicitly', 'user explicitly state', 'explicitly state profile', 'state profile description', 'profile description suffer', 'description suffer mental', 'suffer mental illness', 'mental illness ie', 'illness ie given', 'ie given user', 'given user checking', 'user checking hisher', 'checking hisher profile', 'hisher profile contains', 'profile contains keyword', 'contains keyword related', 'keyword related target', 'related target disorder', 'target disorder eg', 'disorder eg borderline', 'eg borderline bpd', 'borderline bpd bipolar', 'bpd bipolar nonpatients', 'bipolar nonpatients referred', 'nonpatients referred random', 'referred random active', 'random active twitter', 'active twitter user', 'twitter user explicitly', 'user explicitly stating', 'explicitly stating suffering', 'stating suffering bipolar', 'suffering bipolar disorder', 'bipolar disorder hereinafter', 'disorder hereinafter referred', 'hereinafter referred bd', 'referred bd borderline', 'bd borderline personality', 'borderline personality disorder', 'personality disorder hereinafter', 'disorder hereinafter referred', 'hereinafter referred bpd', 'referred bpd obtain', 'bpd obtain user', 'obtain user randomly', 'user randomly sampled', 'randomly sampled twitter', 'sampled twitter id', 'twitter id thereafter', 'id thereafter proceeded', 'thereafter proceeded download', 'proceeded download tweet', 'download tweet selected', 'tweet selected id', 'selected id user', 'id user identified', 'user identified manually', 'identified manually label', 'manually label one', 'label one two', 'one two category', 'two category patient', 'category patient person', 'patient person suffering', 'person suffering mental', 'suffering mental disorder', 'mental disorder notrelated', 'disorder notrelated user', 'notrelated user dont', 'user dont consider', 'dont consider patient', 'consider patient lastly', 'patient lastly obtained', 'lastly obtained final', 'obtained final list', 'final list patient', 'list patient retrieve', 'patient retrieve tweet', 'retrieve tweet step', 'tweet step applied', 'step applied collection', 'applied collection bpd', 'collection bpd bd', 'bpd bd patient', 'bd patient datasetsin', 'patient datasetsin work', 'datasetsin work focused', 'work focused two', 'focused two main', 'two main type', 'main type feature', 'type feature linguistic', 'feature linguistic behavioral', 'linguistic behavioral tfidf', 'behavioral tfidf adopted', 'tfidf adopted model', 'adopted model linguist', 'model linguist feature', 'linguist feature patient', 'feature patient pattern', 'patient pattern life', 'pattern life feature', 'life feature plf', 'feature plf adopted', 'plf adopted work', 'adopted work coppersmith', 'work coppersmith et', 'coppersmith et al', 'et al used', 'al used model', 'used model behavioral', 'model behavioral style', 'behavioral style patient', 'style patient tfidf', 'patient tfidf feature', 'tfidf feature capture', 'feature capture frequent', 'capture frequent representative', 'frequent representative word', 'representative word used', 'word used patient', 'used patient tfidf', 'patient tfidf applied', 'tfidf applied unigram', 'applied unigram bigram', 'unigram bigram collected', 'bigram collected patient', 'collected patient tweet', 'patient tweet pattern', 'tweet pattern life', 'pattern life feature', 'life feature plf', 'feature plf feature', 'plf feature reveal', 'feature reveal emotional', 'reveal emotional pattern', 'emotional pattern behavioral', 'pattern behavioral tendency', 'behavioral tendency user', 'tendency user measuring', 'user measuring polarity', 'measuring polarity emotion', 'polarity emotion social', 'emotion social interaction', 'social interaction order', 'interaction order fully', 'order fully compose', 'fully compose plf', 'compose plf combined', 'plf combined following', 'combined following list', 'following list feature', 'list feature age', 'feature age gender', 'age gender twitter', 'gender twitter doe', 'twitter doe publicly', 'doe publicly provide', 'publicly provide information', 'provide information age', 'information age gender', 'age gender user', 'gender user mainly', 'user mainly due', 'mainly due privacy', 'due privacy concern', 'privacy concern adopted', 'concern adopted work', 'adopted work sap', 'work sap et', 'sap et al', 'et al fill', 'al fill information', 'fill information polarity', 'information polarity feature', 'polarity feature sentiment', 'feature sentiment api', 'sentiment api wa', 'api wa used', 'wa used label', 'used label tweet', 'label tweet either', 'tweet either positive', 'either positive negative', 'positive negative neutral', 'negative neutral polarity', 'neutral polarity furthermore', 'polarity furthermore transformed', 'furthermore transformed five', 'transformed five different', 'five different value', 'different value capture', 'value capture affective', 'capture affective trait', 'affective trait user', 'trait user positive', 'user positive ratio', 'positive ratio percentage', 'ratio percentage positive', 'percentage positive tweet', 'positive tweet negative', 'tweet negative ratio', 'negative ratio percentage', 'ratio percentage negative', 'percentage negative tweet', 'negative tweet positive', 'tweet positive combo', 'positive combo capture', 'combo capture mania', 'capture mania hypomania', 'mania hypomania trait', 'hypomania trait patient', 'trait patient determined', 'patient determined number', 'determined number continuous', 'number continuous positive', 'continuous positive post', 'positive post appearing', 'post appearing x', 'appearing x amount', 'x amount time', 'amount time within', 'time within period', 'within period time', 'period time minute', 'time minute negative', 'minute negative combo', 'negative combo capture', 'combo capture depression', 'capture depression trait', 'depression trait patient', 'trait patient determined', 'patient determined number', 'determined number continuous', 'number continuous negative', 'continuous negative post', 'negative post appearing', 'post appearing x', 'appearing x amount', 'x amount time', 'amount time within', 'time within period', 'within period time', 'period time minute', 'time minute flip', 'minute flip ratio', 'flip ratio quantifies', 'ratio quantifies emotional', 'quantifies emotional unstableness', 'emotional unstableness determined', 'unstableness determined counting', 'determined counting frequently', 'counting frequently two', 'frequently two continuous', 'two continuous tweet', 'continuous tweet different', 'tweet different polarity', 'different polarity either', 'polarity either positive', 'either positive negative', 'positive negative negative', 'negative negative positive', 'negative positive appear', 'positive appear together', 'appear together within', 'together within period', 'within period time', 'period time minute', 'time minute work', 'minute work x', 'work x set', 'x set set', 'set set minute', 'set minute social', 'minute social feature', 'social feature feature', 'feature feature demonstrate', 'feature demonstrate user', 'demonstrate user behaving', 'user behaving respect', 'behaving respect environment', 'respect environment following', 'environment following social', 'following social feature', 'social feature designed', 'feature designed user', 'designed user tweeting', 'user tweeting frequency', 'tweeting frequency frequency', 'frequency frequency daily', 'frequency daily post', 'daily post mention', 'post mention ratio', 'mention ratio percentage', 'ratio percentage post', 'percentage post contain', 'post contain least', 'contain least one', 'least one mention', 'one mention another', 'mention another user', 'another user frequent', 'user frequent mention', 'frequent mention number', 'mention number twitter', 'number twitter user', 'twitter user mentioned', 'user mentioned three', 'mentioned three time', 'three time measurement', 'time measurement many', 'measurement many close', 'many close friend', 'close friend particular', 'friend particular user', 'particular user may', 'user may unique', 'may unique mention', 'unique mention number', 'mention number unique', 'number unique user', 'unique user mentioned', 'user mentioned measure', 'mentioned measure width', 'measure width user', 'width user social', 'user social network']",,,,,,,,
https://www.nature.com/articles/s41598-020-68764-y,1,We developed six binary classification models each of which categorizes a user’ specific post into one of the following subreddits: r/depression r/Anxiety r/bipolar r/BPD r/schizophrenia and r/autism. Our conjecture is that a user who suffers from a specific mental problem writes a post on the corresponding subreddit that deals with the problem. A user can write posts across multiple subreddits if he/she suffers from multiple mental health problems e.g. a user suffering from both depression and anxiety. However if the model is trained with the posts of users who have multiple symptoms like a prior study10 the classification model may suffer from noisy data. Therefore we developed six independent binary classification models for each symptom to improve the performance. By developing six independent models for each mental disorder each of which uses data where users suffer from only one particular mental problem we were able to accurately identify a user’s potential mental state. For example to develop a model for detecting depression we labeled the posts written by users who upload posts only in the r/depression as the depression class; the opposite class is referred to as the non-depression class. To address a class-imbalance issue for the collected data we applied the synthetic minority over-sampling technique (SMOTE) algorithm19. We divided our dataset into training (80%) and testing (20%) sets. Then XGBoost and convolutional neural network (CNN) were employed. Morover we excluded the posts of users who wrote posts across multiple subreddits in learning phase. To quantitatively represent each post we converted the words in the training set to numerical representations (Fig. 2). For the XGBoost classifier we used the TF-IDF vectorizer in the sckit-learn package20 to convert words into n-dimensional vectors. In the case of the CNN classifier we applied word-embedding procedures from the pre-processed texts using the word2vec API of Python Package Gensim21. The word vectors were pre-trained with the training dataset collected for the current study with continuous bag-of-words representation (CBOW) models while the size of window was set to five. Note that by using the pre-trained word2vec model for representing each post for each subreddit a language style used by users who write posts in a subreddit can be trained for the specific subreddit. An overview of the proposed CNN-based model is presented in Fig. 2. The model architecture is organized by the sequence of layers that includes an embedding layer convolutional layer max-pooling layer dense layers and the output. Fig. 2 illustrates how a post is trained in the given model. The first layer of the model is an embedding layer that represents the word embeddings of a pre-processed post with 20 dimensions and its weight is initialized by the pre-trained word2vec. Second a convolutional layer with input of word vectors has 128 filters and each filter size is five. In addition we applied a dropout rate of 0.25 to prevent over-fitting issues. The next layer is a max-pooling layer which takes the maximum values within the CNN filters and its dimension is 128. The output of the max-pooling layer is passed through two fully connected (dense) layers and the final output is the probability of the classification through the sigmoid activation function which ranges from 0 to 1. For training the neural network we used both the binary cross-entropy loss function and Adam optimizer22 with a learning rate of 0.001. Our model was trained through 50 epochs and the batch size was set to 64.,we developed six binary classification model each of which categorizes a user specific post into one of the following subreddits rdepression ranxiety rbipolar rbpd rschizophrenia and rautism our conjecture is that a user who suffers from a specific mental problem writes a post on the corresponding subreddit that deal with the problem a user can write post across multiple subreddits if heshe suffers from multiple mental health problem eg a user suffering from both depression and anxiety however if the model is trained with the post of user who have multiple symptom like a prior study the classification model may suffer from noisy data therefore we developed six independent binary classification model for each symptom to improve the performance by developing six independent model for each mental disorder each of which us data where user suffer from only one particular mental problem we were able to accurately identify a user potential mental state for example to develop a model for detecting depression we labeled the post written by user who upload post only in the rdepression a the depression class the opposite class is referred to a the nondepression class to address a classimbalance issue for the collected data we applied the synthetic minority oversampling technique smote algorithm we divided our dataset into training and testing set then xgboost and convolutional neural network cnn were employed morover we excluded the post of user who wrote post across multiple subreddits in learning phase to quantitatively represent each post we converted the word in the training set to numerical representation fig for the xgboost classifier we used the tfidf vectorizer in the sckitlearn package to convert word into ndimensional vector in the case of the cnn classifier we applied wordembedding procedure from the preprocessed text using the wordvec api of python package gensim the word vector were pretrained with the training dataset collected for the current study with continuous bagofwords representation cbow model while the size of window wa set to five note that by using the pretrained wordvec model for representing each post for each subreddit a language style used by user who write post in a subreddit can be trained for the specific subreddit an overview of the proposed cnnbased model is presented in fig the model architecture is organized by the sequence of layer that includes an embedding layer convolutional layer maxpooling layer dense layer and the output fig illustrates how a post is trained in the given model the first layer of the model is an embedding layer that represents the word embeddings of a preprocessed post with dimension and it weight is initialized by the pretrained wordvec second a convolutional layer with input of word vector ha filter and each filter size is five in addition we applied a dropout rate of to prevent overfitting issue the next layer is a maxpooling layer which take the maximum value within the cnn filter and it dimension is the output of the maxpooling layer is passed through two fully connected dense layer and the final output is the probability of the classification through the sigmoid activation function which range from to for training the neural network we used both the binary crossentropy loss function and adam optimizer with a learning rate of our model wa trained through epoch and the batch size wa set to,"['developed', 'six', 'binary', 'classification', 'model', 'categorizes', 'user', 'specific', 'post', 'one', 'following', 'subreddits', 'rdepression', 'ranxiety', 'rbipolar', 'rbpd', 'rschizophrenia', 'rautism', 'conjecture', 'user', 'suffers', 'specific', 'mental', 'problem', 'writes', 'post', 'corresponding', 'subreddit', 'deal', 'problem', 'user', 'write', 'post', 'across', 'multiple', 'subreddits', 'heshe', 'suffers', 'multiple', 'mental', 'health', 'problem', 'eg', 'user', 'suffering', 'depression', 'anxiety', 'however', 'model', 'trained', 'post', 'user', 'multiple', 'symptom', 'like', 'prior', 'study', 'classification', 'model', 'may', 'suffer', 'noisy', 'data', 'therefore', 'developed', 'six', 'independent', 'binary', 'classification', 'model', 'symptom', 'improve', 'performance', 'developing', 'six', 'independent', 'model', 'mental', 'disorder', 'us', 'data', 'user', 'suffer', 'one', 'particular', 'mental', 'problem', 'able', 'accurately', 'identify', 'user', 'potential', 'mental', 'state', 'example', 'develop', 'model', 'detecting', 'depression', 'labeled', 'post', 'written', 'user', 'upload', 'post', 'rdepression', 'depression', 'class', 'opposite', 'class', 'referred', 'nondepression', 'class', 'address', 'classimbalance', 'issue', 'collected', 'data', 'applied', 'synthetic', 'minority', 'oversampling', 'technique', 'smote', 'algorithm', 'divided', 'dataset', 'training', 'testing', 'set', 'xgboost', 'convolutional', 'neural', 'network', 'cnn', 'employed', 'morover', 'excluded', 'post', 'user', 'wrote', 'post', 'across', 'multiple', 'subreddits', 'learning', 'phase', 'quantitatively', 'represent', 'post', 'converted', 'word', 'training', 'set', 'numerical', 'representation', 'fig', 'xgboost', 'classifier', 'used', 'tfidf', 'vectorizer', 'sckitlearn', 'package', 'convert', 'word', 'ndimensional', 'vector', 'case', 'cnn', 'classifier', 'applied', 'wordembedding', 'procedure', 'preprocessed', 'text', 'using', 'wordvec', 'api', 'python', 'package', 'gensim', 'word', 'vector', 'pretrained', 'training', 'dataset', 'collected', 'current', 'study', 'continuous', 'bagofwords', 'representation', 'cbow', 'model', 'size', 'window', 'wa', 'set', 'five', 'note', 'using', 'pretrained', 'wordvec', 'model', 'representing', 'post', 'subreddit', 'language', 'style', 'used', 'user', 'write', 'post', 'subreddit', 'trained', 'specific', 'subreddit', 'overview', 'proposed', 'cnnbased', 'model', 'presented', 'fig', 'model', 'architecture', 'organized', 'sequence', 'layer', 'includes', 'embedding', 'layer', 'convolutional', 'layer', 'maxpooling', 'layer', 'dense', 'layer', 'output', 'fig', 'illustrates', 'post', 'trained', 'given', 'model', 'first', 'layer', 'model', 'embedding', 'layer', 'represents', 'word', 'embeddings', 'preprocessed', 'post', 'dimension', 'weight', 'initialized', 'pretrained', 'wordvec', 'second', 'convolutional', 'layer', 'input', 'word', 'vector', 'ha', 'filter', 'filter', 'size', 'five', 'addition', 'applied', 'dropout', 'rate', 'prevent', 'overfitting', 'issue', 'next', 'layer', 'maxpooling', 'layer', 'take', 'maximum', 'value', 'within', 'cnn', 'filter', 'dimension', 'output', 'maxpooling', 'layer', 'passed', 'two', 'fully', 'connected', 'dense', 'layer', 'final', 'output', 'probability', 'classification', 'sigmoid', 'activation', 'function', 'range', 'training', 'neural', 'network', 'used', 'binary', 'crossentropy', 'loss', 'function', 'adam', 'optimizer', 'learning', 'rate', 'model', 'wa', 'trained', 'epoch', 'batch', 'size', 'wa', 'set']","['developed six', 'six binary', 'binary classification', 'classification model', 'model categorizes', 'categorizes user', 'user specific', 'specific post', 'post one', 'one following', 'following subreddits', 'subreddits rdepression', 'rdepression ranxiety', 'ranxiety rbipolar', 'rbipolar rbpd', 'rbpd rschizophrenia', 'rschizophrenia rautism', 'rautism conjecture', 'conjecture user', 'user suffers', 'suffers specific', 'specific mental', 'mental problem', 'problem writes', 'writes post', 'post corresponding', 'corresponding subreddit', 'subreddit deal', 'deal problem', 'problem user', 'user write', 'write post', 'post across', 'across multiple', 'multiple subreddits', 'subreddits heshe', 'heshe suffers', 'suffers multiple', 'multiple mental', 'mental health', 'health problem', 'problem eg', 'eg user', 'user suffering', 'suffering depression', 'depression anxiety', 'anxiety however', 'however model', 'model trained', 'trained post', 'post user', 'user multiple', 'multiple symptom', 'symptom like', 'like prior', 'prior study', 'study classification', 'classification model', 'model may', 'may suffer', 'suffer noisy', 'noisy data', 'data therefore', 'therefore developed', 'developed six', 'six independent', 'independent binary', 'binary classification', 'classification model', 'model symptom', 'symptom improve', 'improve performance', 'performance developing', 'developing six', 'six independent', 'independent model', 'model mental', 'mental disorder', 'disorder us', 'us data', 'data user', 'user suffer', 'suffer one', 'one particular', 'particular mental', 'mental problem', 'problem able', 'able accurately', 'accurately identify', 'identify user', 'user potential', 'potential mental', 'mental state', 'state example', 'example develop', 'develop model', 'model detecting', 'detecting depression', 'depression labeled', 'labeled post', 'post written', 'written user', 'user upload', 'upload post', 'post rdepression', 'rdepression depression', 'depression class', 'class opposite', 'opposite class', 'class referred', 'referred nondepression', 'nondepression class', 'class address', 'address classimbalance', 'classimbalance issue', 'issue collected', 'collected data', 'data applied', 'applied synthetic', 'synthetic minority', 'minority oversampling', 'oversampling technique', 'technique smote', 'smote algorithm', 'algorithm divided', 'divided dataset', 'dataset training', 'training testing', 'testing set', 'set xgboost', 'xgboost convolutional', 'convolutional neural', 'neural network', 'network cnn', 'cnn employed', 'employed morover', 'morover excluded', 'excluded post', 'post user', 'user wrote', 'wrote post', 'post across', 'across multiple', 'multiple subreddits', 'subreddits learning', 'learning phase', 'phase quantitatively', 'quantitatively represent', 'represent post', 'post converted', 'converted word', 'word training', 'training set', 'set numerical', 'numerical representation', 'representation fig', 'fig xgboost', 'xgboost classifier', 'classifier used', 'used tfidf', 'tfidf vectorizer', 'vectorizer sckitlearn', 'sckitlearn package', 'package convert', 'convert word', 'word ndimensional', 'ndimensional vector', 'vector case', 'case cnn', 'cnn classifier', 'classifier applied', 'applied wordembedding', 'wordembedding procedure', 'procedure preprocessed', 'preprocessed text', 'text using', 'using wordvec', 'wordvec api', 'api python', 'python package', 'package gensim', 'gensim word', 'word vector', 'vector pretrained', 'pretrained training', 'training dataset', 'dataset collected', 'collected current', 'current study', 'study continuous', 'continuous bagofwords', 'bagofwords representation', 'representation cbow', 'cbow model', 'model size', 'size window', 'window wa', 'wa set', 'set five', 'five note', 'note using', 'using pretrained', 'pretrained wordvec', 'wordvec model', 'model representing', 'representing post', 'post subreddit', 'subreddit language', 'language style', 'style used', 'used user', 'user write', 'write post', 'post subreddit', 'subreddit trained', 'trained specific', 'specific subreddit', 'subreddit overview', 'overview proposed', 'proposed cnnbased', 'cnnbased model', 'model presented', 'presented fig', 'fig model', 'model architecture', 'architecture organized', 'organized sequence', 'sequence layer', 'layer includes', 'includes embedding', 'embedding layer', 'layer convolutional', 'convolutional layer', 'layer maxpooling', 'maxpooling layer', 'layer dense', 'dense layer', 'layer output', 'output fig', 'fig illustrates', 'illustrates post', 'post trained', 'trained given', 'given model', 'model first', 'first layer', 'layer model', 'model embedding', 'embedding layer', 'layer represents', 'represents word', 'word embeddings', 'embeddings preprocessed', 'preprocessed post', 'post dimension', 'dimension weight', 'weight initialized', 'initialized pretrained', 'pretrained wordvec', 'wordvec second', 'second convolutional', 'convolutional layer', 'layer input', 'input word', 'word vector', 'vector ha', 'ha filter', 'filter filter', 'filter size', 'size five', 'five addition', 'addition applied', 'applied dropout', 'dropout rate', 'rate prevent', 'prevent overfitting', 'overfitting issue', 'issue next', 'next layer', 'layer maxpooling', 'maxpooling layer', 'layer take', 'take maximum', 'maximum value', 'value within', 'within cnn', 'cnn filter', 'filter dimension', 'dimension output', 'output maxpooling', 'maxpooling layer', 'layer passed', 'passed two', 'two fully', 'fully connected', 'connected dense', 'dense layer', 'layer final', 'final output', 'output probability', 'probability classification', 'classification sigmoid', 'sigmoid activation', 'activation function', 'function range', 'range training', 'training neural', 'neural network', 'network used', 'used binary', 'binary crossentropy', 'crossentropy loss', 'loss function', 'function adam', 'adam optimizer', 'optimizer learning', 'learning rate', 'rate model', 'model wa', 'wa trained', 'trained epoch', 'epoch batch', 'batch size', 'size wa', 'wa set']","['developed six binary', 'six binary classification', 'binary classification model', 'classification model categorizes', 'model categorizes user', 'categorizes user specific', 'user specific post', 'specific post one', 'post one following', 'one following subreddits', 'following subreddits rdepression', 'subreddits rdepression ranxiety', 'rdepression ranxiety rbipolar', 'ranxiety rbipolar rbpd', 'rbipolar rbpd rschizophrenia', 'rbpd rschizophrenia rautism', 'rschizophrenia rautism conjecture', 'rautism conjecture user', 'conjecture user suffers', 'user suffers specific', 'suffers specific mental', 'specific mental problem', 'mental problem writes', 'problem writes post', 'writes post corresponding', 'post corresponding subreddit', 'corresponding subreddit deal', 'subreddit deal problem', 'deal problem user', 'problem user write', 'user write post', 'write post across', 'post across multiple', 'across multiple subreddits', 'multiple subreddits heshe', 'subreddits heshe suffers', 'heshe suffers multiple', 'suffers multiple mental', 'multiple mental health', 'mental health problem', 'health problem eg', 'problem eg user', 'eg user suffering', 'user suffering depression', 'suffering depression anxiety', 'depression anxiety however', 'anxiety however model', 'however model trained', 'model trained post', 'trained post user', 'post user multiple', 'user multiple symptom', 'multiple symptom like', 'symptom like prior', 'like prior study', 'prior study classification', 'study classification model', 'classification model may', 'model may suffer', 'may suffer noisy', 'suffer noisy data', 'noisy data therefore', 'data therefore developed', 'therefore developed six', 'developed six independent', 'six independent binary', 'independent binary classification', 'binary classification model', 'classification model symptom', 'model symptom improve', 'symptom improve performance', 'improve performance developing', 'performance developing six', 'developing six independent', 'six independent model', 'independent model mental', 'model mental disorder', 'mental disorder us', 'disorder us data', 'us data user', 'data user suffer', 'user suffer one', 'suffer one particular', 'one particular mental', 'particular mental problem', 'mental problem able', 'problem able accurately', 'able accurately identify', 'accurately identify user', 'identify user potential', 'user potential mental', 'potential mental state', 'mental state example', 'state example develop', 'example develop model', 'develop model detecting', 'model detecting depression', 'detecting depression labeled', 'depression labeled post', 'labeled post written', 'post written user', 'written user upload', 'user upload post', 'upload post rdepression', 'post rdepression depression', 'rdepression depression class', 'depression class opposite', 'class opposite class', 'opposite class referred', 'class referred nondepression', 'referred nondepression class', 'nondepression class address', 'class address classimbalance', 'address classimbalance issue', 'classimbalance issue collected', 'issue collected data', 'collected data applied', 'data applied synthetic', 'applied synthetic minority', 'synthetic minority oversampling', 'minority oversampling technique', 'oversampling technique smote', 'technique smote algorithm', 'smote algorithm divided', 'algorithm divided dataset', 'divided dataset training', 'dataset training testing', 'training testing set', 'testing set xgboost', 'set xgboost convolutional', 'xgboost convolutional neural', 'convolutional neural network', 'neural network cnn', 'network cnn employed', 'cnn employed morover', 'employed morover excluded', 'morover excluded post', 'excluded post user', 'post user wrote', 'user wrote post', 'wrote post across', 'post across multiple', 'across multiple subreddits', 'multiple subreddits learning', 'subreddits learning phase', 'learning phase quantitatively', 'phase quantitatively represent', 'quantitatively represent post', 'represent post converted', 'post converted word', 'converted word training', 'word training set', 'training set numerical', 'set numerical representation', 'numerical representation fig', 'representation fig xgboost', 'fig xgboost classifier', 'xgboost classifier used', 'classifier used tfidf', 'used tfidf vectorizer', 'tfidf vectorizer sckitlearn', 'vectorizer sckitlearn package', 'sckitlearn package convert', 'package convert word', 'convert word ndimensional', 'word ndimensional vector', 'ndimensional vector case', 'vector case cnn', 'case cnn classifier', 'cnn classifier applied', 'classifier applied wordembedding', 'applied wordembedding procedure', 'wordembedding procedure preprocessed', 'procedure preprocessed text', 'preprocessed text using', 'text using wordvec', 'using wordvec api', 'wordvec api python', 'api python package', 'python package gensim', 'package gensim word', 'gensim word vector', 'word vector pretrained', 'vector pretrained training', 'pretrained training dataset', 'training dataset collected', 'dataset collected current', 'collected current study', 'current study continuous', 'study continuous bagofwords', 'continuous bagofwords representation', 'bagofwords representation cbow', 'representation cbow model', 'cbow model size', 'model size window', 'size window wa', 'window wa set', 'wa set five', 'set five note', 'five note using', 'note using pretrained', 'using pretrained wordvec', 'pretrained wordvec model', 'wordvec model representing', 'model representing post', 'representing post subreddit', 'post subreddit language', 'subreddit language style', 'language style used', 'style used user', 'used user write', 'user write post', 'write post subreddit', 'post subreddit trained', 'subreddit trained specific', 'trained specific subreddit', 'specific subreddit overview', 'subreddit overview proposed', 'overview proposed cnnbased', 'proposed cnnbased model', 'cnnbased model presented', 'model presented fig', 'presented fig model', 'fig model architecture', 'model architecture organized', 'architecture organized sequence', 'organized sequence layer', 'sequence layer includes', 'layer includes embedding', 'includes embedding layer', 'embedding layer convolutional', 'layer convolutional layer', 'convolutional layer maxpooling', 'layer maxpooling layer', 'maxpooling layer dense', 'layer dense layer', 'dense layer output', 'layer output fig', 'output fig illustrates', 'fig illustrates post', 'illustrates post trained', 'post trained given', 'trained given model', 'given model first', 'model first layer', 'first layer model', 'layer model embedding', 'model embedding layer', 'embedding layer represents', 'layer represents word', 'represents word embeddings', 'word embeddings preprocessed', 'embeddings preprocessed post', 'preprocessed post dimension', 'post dimension weight', 'dimension weight initialized', 'weight initialized pretrained', 'initialized pretrained wordvec', 'pretrained wordvec second', 'wordvec second convolutional', 'second convolutional layer', 'convolutional layer input', 'layer input word', 'input word vector', 'word vector ha', 'vector ha filter', 'ha filter filter', 'filter filter size', 'filter size five', 'size five addition', 'five addition applied', 'addition applied dropout', 'applied dropout rate', 'dropout rate prevent', 'rate prevent overfitting', 'prevent overfitting issue', 'overfitting issue next', 'issue next layer', 'next layer maxpooling', 'layer maxpooling layer', 'maxpooling layer take', 'layer take maximum', 'take maximum value', 'maximum value within', 'value within cnn', 'within cnn filter', 'cnn filter dimension', 'filter dimension output', 'dimension output maxpooling', 'output maxpooling layer', 'maxpooling layer passed', 'layer passed two', 'passed two fully', 'two fully connected', 'fully connected dense', 'connected dense layer', 'dense layer final', 'layer final output', 'final output probability', 'output probability classification', 'probability classification sigmoid', 'classification sigmoid activation', 'sigmoid activation function', 'activation function range', 'function range training', 'range training neural', 'training neural network', 'neural network used', 'network used binary', 'used binary crossentropy', 'binary crossentropy loss', 'crossentropy loss function', 'loss function adam', 'function adam optimizer', 'adam optimizer learning', 'optimizer learning rate', 'learning rate model', 'rate model wa', 'model wa trained', 'wa trained epoch', 'trained epoch batch', 'epoch batch size', 'batch size wa', 'size wa set']",,,,,,,,
https://aclanthology.org/W19-3013.pdf,1,We build on prior work on supervised models for mental health inference over social media data. We focus on two mental health conditions — depression and PTSD — and develop classifiers with the self-reported datasets created for CLPysch 2015 (Mitchell et al. 2015; Coppersmith et al. 2015b). These labeled datasets derive from users that have publicly disclosed on Twitter a diagnosis of depression (327 users) or PTSD (246 users) with an equal number of randomly selected demographically-matched (with respect to age and gender) users as controls. For each user the associated metadata and posting history was also collected — up to the 3000 most recent tweets per limitations of the Twitter API. The participants of the task proposed a host of methods ranging from rule-based systems to various supervised models (Pedersen 2015; PreotiucPietro et al. 2015; Coppersmith et al. 2015b). More recently the neural user-level classifier proposed by Amir et al. (2017) showed not only good performance on this task but also the ability to capture implicit similarities between users affected by the same diseases thus opening the door to more interpretable analyses2 . Hence we adopt their model for this analysis.We constructed a cohort for our analysis by randomly selecting a sample of Twitter users and processing it with the aforementioned demographic inference pipeline. After discarding accounts from users located outside the United States we obtained a cohort of 48K Twitter users with the demographic composition shown in Figure 1. Some demographic groups are over-represented (e.g. young adults) while others are grossly underrepresented (e.g. teenagers) which illustrates the need for methodologies that can take these disparities into account. We then processed the cohort through the mental-health classifiers to estimate the prevalence of depression and PTSD and examine how these illnesses manifest across the population. The analysis revealed that 30.2% of the cohort members are likely to suffer from depression 30.8% from PTSD and 20% from both. We observe a significant overlap between people affected by depression and PTSD which is not surprising given that the comorbidity of these disorders is wellknown with approximately half of people with PTSD also having a diagnosis of major depressive disorder (Flory and Yehuda 2015). How do these conditions affect different parts of the population? To answer this question we looked at the affected users and measured how the demographics of individual sub-populations differ from those of the cohort as a whole. Figures 2 and 3 show the estimates for depression PTSD and both controlled for the cohort demographics. We observe large generational differences — PTSD seems to be more prevalent among older people whereas depression affects predominantly younger people. We also observe that in all cases Women are more susceptible than Men and Blacks and Hispanics are more likely to be affected than Whites. This may represent a bias in the underlying data used to construct the classifiers or a difference in how social media is used by different demographic groups. For example models that were trained with a majority of data from White users maybe oversensitive to specific dialects used by other communities.,we build on prior work on supervised model for mental health inference over social medium data we focus on two mental health condition depression and ptsd and develop classifier with the selfreported datasets created for clpysch mitchell et al coppersmith et al b these labeled datasets derive from user that have publicly disclosed on twitter a diagnosis of depression user or ptsd user with an equal number of randomly selected demographicallymatched with respect to age and gender user a control for each user the associated metadata and posting history wa also collected up to the most recent tweet per limitation of the twitter api the participant of the task proposed a host of method ranging from rulebased system to various supervised model pedersen preotiucpietro et al coppersmith et al b more recently the neural userlevel classifier proposed by amir et al showed not only good performance on this task but also the ability to capture implicit similarity between user affected by the same disease thus opening the door to more interpretable analysis hence we adopt their model for this analysiswe constructed a cohort for our analysis by randomly selecting a sample of twitter user and processing it with the aforementioned demographic inference pipeline after discarding account from user located outside the united state we obtained a cohort of k twitter user with the demographic composition shown in figure some demographic group are overrepresented eg young adult while others are grossly underrepresented eg teenager which illustrates the need for methodology that can take these disparity into account we then processed the cohort through the mentalhealth classifier to estimate the prevalence of depression and ptsd and examine how these illness manifest across the population the analysis revealed that of the cohort member are likely to suffer from depression from ptsd and from both we observe a significant overlap between people affected by depression and ptsd which is not surprising given that the comorbidity of these disorder is wellknown with approximately half of people with ptsd also having a diagnosis of major depressive disorder flory and yehuda how do these condition affect different part of the population to answer this question we looked at the affected user and measured how the demographic of individual subpopulation differ from those of the cohort a a whole figure and show the estimate for depression ptsd and both controlled for the cohort demographic we observe large generational difference ptsd seems to be more prevalent among older people whereas depression affect predominantly younger people we also observe that in all case woman are more susceptible than men and black and hispanic are more likely to be affected than white this may represent a bias in the underlying data used to construct the classifier or a difference in how social medium is used by different demographic group for example model that were trained with a majority of data from white user maybe oversensitive to specific dialect used by other community,"['build', 'prior', 'work', 'supervised', 'model', 'mental', 'health', 'inference', 'social', 'medium', 'data', 'focus', 'two', 'mental', 'health', 'condition', 'depression', 'ptsd', 'develop', 'classifier', 'selfreported', 'datasets', 'created', 'clpysch', 'mitchell', 'et', 'al', 'coppersmith', 'et', 'al', 'b', 'labeled', 'datasets', 'derive', 'user', 'publicly', 'disclosed', 'twitter', 'diagnosis', 'depression', 'user', 'ptsd', 'user', 'equal', 'number', 'randomly', 'selected', 'demographicallymatched', 'respect', 'age', 'gender', 'user', 'control', 'user', 'associated', 'metadata', 'posting', 'history', 'wa', 'also', 'collected', 'recent', 'tweet', 'per', 'limitation', 'twitter', 'api', 'participant', 'task', 'proposed', 'host', 'method', 'ranging', 'rulebased', 'system', 'various', 'supervised', 'model', 'pedersen', 'preotiucpietro', 'et', 'al', 'coppersmith', 'et', 'al', 'b', 'recently', 'neural', 'userlevel', 'classifier', 'proposed', 'amir', 'et', 'al', 'showed', 'good', 'performance', 'task', 'also', 'ability', 'capture', 'implicit', 'similarity', 'user', 'affected', 'disease', 'thus', 'opening', 'door', 'interpretable', 'analysis', 'hence', 'adopt', 'model', 'analysiswe', 'constructed', 'cohort', 'analysis', 'randomly', 'selecting', 'sample', 'twitter', 'user', 'processing', 'aforementioned', 'demographic', 'inference', 'pipeline', 'discarding', 'account', 'user', 'located', 'outside', 'united', 'state', 'obtained', 'cohort', 'k', 'twitter', 'user', 'demographic', 'composition', 'shown', 'figure', 'demographic', 'group', 'overrepresented', 'eg', 'young', 'adult', 'others', 'grossly', 'underrepresented', 'eg', 'teenager', 'illustrates', 'need', 'methodology', 'take', 'disparity', 'account', 'processed', 'cohort', 'mentalhealth', 'classifier', 'estimate', 'prevalence', 'depression', 'ptsd', 'examine', 'illness', 'manifest', 'across', 'population', 'analysis', 'revealed', 'cohort', 'member', 'likely', 'suffer', 'depression', 'ptsd', 'observe', 'significant', 'overlap', 'people', 'affected', 'depression', 'ptsd', 'surprising', 'given', 'comorbidity', 'disorder', 'wellknown', 'approximately', 'half', 'people', 'ptsd', 'also', 'diagnosis', 'major', 'depressive', 'disorder', 'flory', 'yehuda', 'condition', 'affect', 'different', 'part', 'population', 'answer', 'question', 'looked', 'affected', 'user', 'measured', 'demographic', 'individual', 'subpopulation', 'differ', 'cohort', 'whole', 'figure', 'show', 'estimate', 'depression', 'ptsd', 'controlled', 'cohort', 'demographic', 'observe', 'large', 'generational', 'difference', 'ptsd', 'seems', 'prevalent', 'among', 'older', 'people', 'whereas', 'depression', 'affect', 'predominantly', 'younger', 'people', 'also', 'observe', 'case', 'woman', 'susceptible', 'men', 'black', 'hispanic', 'likely', 'affected', 'white', 'may', 'represent', 'bias', 'underlying', 'data', 'used', 'construct', 'classifier', 'difference', 'social', 'medium', 'used', 'different', 'demographic', 'group', 'example', 'model', 'trained', 'majority', 'data', 'white', 'user', 'maybe', 'oversensitive', 'specific', 'dialect', 'used', 'community']","['build prior', 'prior work', 'work supervised', 'supervised model', 'model mental', 'mental health', 'health inference', 'inference social', 'social medium', 'medium data', 'data focus', 'focus two', 'two mental', 'mental health', 'health condition', 'condition depression', 'depression ptsd', 'ptsd develop', 'develop classifier', 'classifier selfreported', 'selfreported datasets', 'datasets created', 'created clpysch', 'clpysch mitchell', 'mitchell et', 'et al', 'al coppersmith', 'coppersmith et', 'et al', 'al b', 'b labeled', 'labeled datasets', 'datasets derive', 'derive user', 'user publicly', 'publicly disclosed', 'disclosed twitter', 'twitter diagnosis', 'diagnosis depression', 'depression user', 'user ptsd', 'ptsd user', 'user equal', 'equal number', 'number randomly', 'randomly selected', 'selected demographicallymatched', 'demographicallymatched respect', 'respect age', 'age gender', 'gender user', 'user control', 'control user', 'user associated', 'associated metadata', 'metadata posting', 'posting history', 'history wa', 'wa also', 'also collected', 'collected recent', 'recent tweet', 'tweet per', 'per limitation', 'limitation twitter', 'twitter api', 'api participant', 'participant task', 'task proposed', 'proposed host', 'host method', 'method ranging', 'ranging rulebased', 'rulebased system', 'system various', 'various supervised', 'supervised model', 'model pedersen', 'pedersen preotiucpietro', 'preotiucpietro et', 'et al', 'al coppersmith', 'coppersmith et', 'et al', 'al b', 'b recently', 'recently neural', 'neural userlevel', 'userlevel classifier', 'classifier proposed', 'proposed amir', 'amir et', 'et al', 'al showed', 'showed good', 'good performance', 'performance task', 'task also', 'also ability', 'ability capture', 'capture implicit', 'implicit similarity', 'similarity user', 'user affected', 'affected disease', 'disease thus', 'thus opening', 'opening door', 'door interpretable', 'interpretable analysis', 'analysis hence', 'hence adopt', 'adopt model', 'model analysiswe', 'analysiswe constructed', 'constructed cohort', 'cohort analysis', 'analysis randomly', 'randomly selecting', 'selecting sample', 'sample twitter', 'twitter user', 'user processing', 'processing aforementioned', 'aforementioned demographic', 'demographic inference', 'inference pipeline', 'pipeline discarding', 'discarding account', 'account user', 'user located', 'located outside', 'outside united', 'united state', 'state obtained', 'obtained cohort', 'cohort k', 'k twitter', 'twitter user', 'user demographic', 'demographic composition', 'composition shown', 'shown figure', 'figure demographic', 'demographic group', 'group overrepresented', 'overrepresented eg', 'eg young', 'young adult', 'adult others', 'others grossly', 'grossly underrepresented', 'underrepresented eg', 'eg teenager', 'teenager illustrates', 'illustrates need', 'need methodology', 'methodology take', 'take disparity', 'disparity account', 'account processed', 'processed cohort', 'cohort mentalhealth', 'mentalhealth classifier', 'classifier estimate', 'estimate prevalence', 'prevalence depression', 'depression ptsd', 'ptsd examine', 'examine illness', 'illness manifest', 'manifest across', 'across population', 'population analysis', 'analysis revealed', 'revealed cohort', 'cohort member', 'member likely', 'likely suffer', 'suffer depression', 'depression ptsd', 'ptsd observe', 'observe significant', 'significant overlap', 'overlap people', 'people affected', 'affected depression', 'depression ptsd', 'ptsd surprising', 'surprising given', 'given comorbidity', 'comorbidity disorder', 'disorder wellknown', 'wellknown approximately', 'approximately half', 'half people', 'people ptsd', 'ptsd also', 'also diagnosis', 'diagnosis major', 'major depressive', 'depressive disorder', 'disorder flory', 'flory yehuda', 'yehuda condition', 'condition affect', 'affect different', 'different part', 'part population', 'population answer', 'answer question', 'question looked', 'looked affected', 'affected user', 'user measured', 'measured demographic', 'demographic individual', 'individual subpopulation', 'subpopulation differ', 'differ cohort', 'cohort whole', 'whole figure', 'figure show', 'show estimate', 'estimate depression', 'depression ptsd', 'ptsd controlled', 'controlled cohort', 'cohort demographic', 'demographic observe', 'observe large', 'large generational', 'generational difference', 'difference ptsd', 'ptsd seems', 'seems prevalent', 'prevalent among', 'among older', 'older people', 'people whereas', 'whereas depression', 'depression affect', 'affect predominantly', 'predominantly younger', 'younger people', 'people also', 'also observe', 'observe case', 'case woman', 'woman susceptible', 'susceptible men', 'men black', 'black hispanic', 'hispanic likely', 'likely affected', 'affected white', 'white may', 'may represent', 'represent bias', 'bias underlying', 'underlying data', 'data used', 'used construct', 'construct classifier', 'classifier difference', 'difference social', 'social medium', 'medium used', 'used different', 'different demographic', 'demographic group', 'group example', 'example model', 'model trained', 'trained majority', 'majority data', 'data white', 'white user', 'user maybe', 'maybe oversensitive', 'oversensitive specific', 'specific dialect', 'dialect used', 'used community']","['build prior work', 'prior work supervised', 'work supervised model', 'supervised model mental', 'model mental health', 'mental health inference', 'health inference social', 'inference social medium', 'social medium data', 'medium data focus', 'data focus two', 'focus two mental', 'two mental health', 'mental health condition', 'health condition depression', 'condition depression ptsd', 'depression ptsd develop', 'ptsd develop classifier', 'develop classifier selfreported', 'classifier selfreported datasets', 'selfreported datasets created', 'datasets created clpysch', 'created clpysch mitchell', 'clpysch mitchell et', 'mitchell et al', 'et al coppersmith', 'al coppersmith et', 'coppersmith et al', 'et al b', 'al b labeled', 'b labeled datasets', 'labeled datasets derive', 'datasets derive user', 'derive user publicly', 'user publicly disclosed', 'publicly disclosed twitter', 'disclosed twitter diagnosis', 'twitter diagnosis depression', 'diagnosis depression user', 'depression user ptsd', 'user ptsd user', 'ptsd user equal', 'user equal number', 'equal number randomly', 'number randomly selected', 'randomly selected demographicallymatched', 'selected demographicallymatched respect', 'demographicallymatched respect age', 'respect age gender', 'age gender user', 'gender user control', 'user control user', 'control user associated', 'user associated metadata', 'associated metadata posting', 'metadata posting history', 'posting history wa', 'history wa also', 'wa also collected', 'also collected recent', 'collected recent tweet', 'recent tweet per', 'tweet per limitation', 'per limitation twitter', 'limitation twitter api', 'twitter api participant', 'api participant task', 'participant task proposed', 'task proposed host', 'proposed host method', 'host method ranging', 'method ranging rulebased', 'ranging rulebased system', 'rulebased system various', 'system various supervised', 'various supervised model', 'supervised model pedersen', 'model pedersen preotiucpietro', 'pedersen preotiucpietro et', 'preotiucpietro et al', 'et al coppersmith', 'al coppersmith et', 'coppersmith et al', 'et al b', 'al b recently', 'b recently neural', 'recently neural userlevel', 'neural userlevel classifier', 'userlevel classifier proposed', 'classifier proposed amir', 'proposed amir et', 'amir et al', 'et al showed', 'al showed good', 'showed good performance', 'good performance task', 'performance task also', 'task also ability', 'also ability capture', 'ability capture implicit', 'capture implicit similarity', 'implicit similarity user', 'similarity user affected', 'user affected disease', 'affected disease thus', 'disease thus opening', 'thus opening door', 'opening door interpretable', 'door interpretable analysis', 'interpretable analysis hence', 'analysis hence adopt', 'hence adopt model', 'adopt model analysiswe', 'model analysiswe constructed', 'analysiswe constructed cohort', 'constructed cohort analysis', 'cohort analysis randomly', 'analysis randomly selecting', 'randomly selecting sample', 'selecting sample twitter', 'sample twitter user', 'twitter user processing', 'user processing aforementioned', 'processing aforementioned demographic', 'aforementioned demographic inference', 'demographic inference pipeline', 'inference pipeline discarding', 'pipeline discarding account', 'discarding account user', 'account user located', 'user located outside', 'located outside united', 'outside united state', 'united state obtained', 'state obtained cohort', 'obtained cohort k', 'cohort k twitter', 'k twitter user', 'twitter user demographic', 'user demographic composition', 'demographic composition shown', 'composition shown figure', 'shown figure demographic', 'figure demographic group', 'demographic group overrepresented', 'group overrepresented eg', 'overrepresented eg young', 'eg young adult', 'young adult others', 'adult others grossly', 'others grossly underrepresented', 'grossly underrepresented eg', 'underrepresented eg teenager', 'eg teenager illustrates', 'teenager illustrates need', 'illustrates need methodology', 'need methodology take', 'methodology take disparity', 'take disparity account', 'disparity account processed', 'account processed cohort', 'processed cohort mentalhealth', 'cohort mentalhealth classifier', 'mentalhealth classifier estimate', 'classifier estimate prevalence', 'estimate prevalence depression', 'prevalence depression ptsd', 'depression ptsd examine', 'ptsd examine illness', 'examine illness manifest', 'illness manifest across', 'manifest across population', 'across population analysis', 'population analysis revealed', 'analysis revealed cohort', 'revealed cohort member', 'cohort member likely', 'member likely suffer', 'likely suffer depression', 'suffer depression ptsd', 'depression ptsd observe', 'ptsd observe significant', 'observe significant overlap', 'significant overlap people', 'overlap people affected', 'people affected depression', 'affected depression ptsd', 'depression ptsd surprising', 'ptsd surprising given', 'surprising given comorbidity', 'given comorbidity disorder', 'comorbidity disorder wellknown', 'disorder wellknown approximately', 'wellknown approximately half', 'approximately half people', 'half people ptsd', 'people ptsd also', 'ptsd also diagnosis', 'also diagnosis major', 'diagnosis major depressive', 'major depressive disorder', 'depressive disorder flory', 'disorder flory yehuda', 'flory yehuda condition', 'yehuda condition affect', 'condition affect different', 'affect different part', 'different part population', 'part population answer', 'population answer question', 'answer question looked', 'question looked affected', 'looked affected user', 'affected user measured', 'user measured demographic', 'measured demographic individual', 'demographic individual subpopulation', 'individual subpopulation differ', 'subpopulation differ cohort', 'differ cohort whole', 'cohort whole figure', 'whole figure show', 'figure show estimate', 'show estimate depression', 'estimate depression ptsd', 'depression ptsd controlled', 'ptsd controlled cohort', 'controlled cohort demographic', 'cohort demographic observe', 'demographic observe large', 'observe large generational', 'large generational difference', 'generational difference ptsd', 'difference ptsd seems', 'ptsd seems prevalent', 'seems prevalent among', 'prevalent among older', 'among older people', 'older people whereas', 'people whereas depression', 'whereas depression affect', 'depression affect predominantly', 'affect predominantly younger', 'predominantly younger people', 'younger people also', 'people also observe', 'also observe case', 'observe case woman', 'case woman susceptible', 'woman susceptible men', 'susceptible men black', 'men black hispanic', 'black hispanic likely', 'hispanic likely affected', 'likely affected white', 'affected white may', 'white may represent', 'may represent bias', 'represent bias underlying', 'bias underlying data', 'underlying data used', 'data used construct', 'used construct classifier', 'construct classifier difference', 'classifier difference social', 'difference social medium', 'social medium used', 'medium used different', 'used different demographic', 'different demographic group', 'demographic group example', 'group example model', 'example model trained', 'model trained majority', 'trained majority data', 'majority data white', 'data white user', 'white user maybe', 'user maybe oversensitive', 'maybe oversensitive specific', 'oversensitive specific dialect', 'specific dialect used', 'dialect used community']",,,,,,,,
https://link.springer.com/chapter/10.1007/978-3-319-67186-4_6,0,We analyze two datasets: (1) user communities on Reddit and (2) journals from a mental health journalling mobile app. We omit the name of the app for privacy and we refer to it as the “journalling app”. Reddit is a social media platform that was originally used for sharing and rating content such as news documentaries and music. Users post in and subscribe to self-organized communities known as subreddits; subscribing to a subreddit allows a user to view all posts from that subreddit. An advantage of analyzing Reddit data is that the subreddits are labelled according to their topics. Utilizing curated lists from volunteer Reddit users we crawled all subreddits related to mental health as well as all subreddits linked by these communities. The second dataset consists of anonymized journal posts from a mobile app designed to help people track their moods and share them anonymously if they desire. For each journal post the app requires the user to label the journal post with at least one mood selected from a pre-populated list including “happy” “sad” etc. We obtained all journals and the associated moods written between January 2016 and January 2017. This amounts to over 1.2 million journals written by approximately 75000 users. Figure 1 plots the number of journals posted over time. Most of the journals were written in the first half of 2016 although we inspected topic distributions per month and did not find seasonal effects. Towards the beginning of 2016 many new users registered on the app and eventually stopped using it. Like weight-loss and productivity apps we believe this influx is tied to users looking to improve their habits as a New Year’s resolution. Each journal can be set to be private or public (visible to all other users of the app). Roughly one third of all journals are public. Figure 2 plots the number of users on the y-axis versus the percentage of journals they posted publicly. Most users are either mostly private or mostly public. Most journals are relatively short just like Twitter posts that are at most 140 characters. The average length of a journal with text in it is 128 characters; there are roughly 100000 journal that have no text only a mood label. We observed that private users tend to write journals that are slightly but statistically significantly longer than those written by public users by approximately 10 characters. Figure 3 shows the distribution of journal lengths where the spikes correspond to 0 length (mood only) 200 characters (the default limit set by the app) and 300 characters (set as the maximum for visualization purposes). Users of the app can optionally enter their location age and gender. While most users did not enter this information we found that those who revealed their location are mostly from North America those who revealed their gender are predominantly female and those who revealed their age have an average age of 25.The goal of this analysis is to understand public mental health by mining social media. We want to identify common topics discussed publicly (Reddit plus public journals from the journalling app) and privately (private journals). For the Reddit dataset we simply count the number of subscribers in each subreddit related to mental health to discover popular topics and issues. Recall that each subreddit is labelled with its topic so topic modelling is not necessary. On the other hand for the journalling app each journal post is labelled with a mood but not with a topic. Below we describe our methodology for assigning topics to journals.,we analyze two datasets user community on reddit and journal from a mental health journalling mobile app we omit the name of the app for privacy and we refer to it a the journalling app reddit is a social medium platform that wa originally used for sharing and rating content such a news documentary and music user post in and subscribe to selforganized community known a subreddits subscribing to a subreddit allows a user to view all post from that subreddit an advantage of analyzing reddit data is that the subreddits are labelled according to their topic utilizing curated list from volunteer reddit user we crawled all subreddits related to mental health a well a all subreddits linked by these community the second dataset consists of anonymized journal post from a mobile app designed to help people track their mood and share them anonymously if they desire for each journal post the app requires the user to label the journal post with at least one mood selected from a prepopulated list including happy sad etc we obtained all journal and the associated mood written between january and january this amount to over million journal written by approximately user figure plot the number of journal posted over time most of the journal were written in the first half of although we inspected topic distribution per month and did not find seasonal effect towards the beginning of many new user registered on the app and eventually stopped using it like weightloss and productivity apps we believe this influx is tied to user looking to improve their habit a a new year resolution each journal can be set to be private or public visible to all other user of the app roughly one third of all journal are public figure plot the number of user on the yaxis versus the percentage of journal they posted publicly most user are either mostly private or mostly public most journal are relatively short just like twitter post that are at most character the average length of a journal with text in it is character there are roughly journal that have no text only a mood label we observed that private user tend to write journal that are slightly but statistically significantly longer than those written by public user by approximately character figure show the distribution of journal length where the spike correspond to length mood only character the default limit set by the app and character set a the maximum for visualization purpose user of the app can optionally enter their location age and gender while most user did not enter this information we found that those who revealed their location are mostly from north america those who revealed their gender are predominantly female and those who revealed their age have an average age of the goal of this analysis is to understand public mental health by mining social medium we want to identify common topic discussed publicly reddit plus public journal from the journalling app and privately private journal for the reddit dataset we simply count the number of subscriber in each subreddit related to mental health to discover popular topic and issue recall that each subreddit is labelled with it topic so topic modelling is not necessary on the other hand for the journalling app each journal post is labelled with a mood but not with a topic below we describe our methodology for assigning topic to journal,"['analyze', 'two', 'datasets', 'user', 'community', 'reddit', 'journal', 'mental', 'health', 'journalling', 'mobile', 'app', 'omit', 'name', 'app', 'privacy', 'refer', 'journalling', 'app', 'reddit', 'social', 'medium', 'platform', 'wa', 'originally', 'used', 'sharing', 'rating', 'content', 'news', 'documentary', 'music', 'user', 'post', 'subscribe', 'selforganized', 'community', 'known', 'subreddits', 'subscribing', 'subreddit', 'allows', 'user', 'view', 'post', 'subreddit', 'advantage', 'analyzing', 'reddit', 'data', 'subreddits', 'labelled', 'according', 'topic', 'utilizing', 'curated', 'list', 'volunteer', 'reddit', 'user', 'crawled', 'subreddits', 'related', 'mental', 'health', 'well', 'subreddits', 'linked', 'community', 'second', 'dataset', 'consists', 'anonymized', 'journal', 'post', 'mobile', 'app', 'designed', 'help', 'people', 'track', 'mood', 'share', 'anonymously', 'desire', 'journal', 'post', 'app', 'requires', 'user', 'label', 'journal', 'post', 'least', 'one', 'mood', 'selected', 'prepopulated', 'list', 'including', 'happy', 'sad', 'etc', 'obtained', 'journal', 'associated', 'mood', 'written', 'january', 'january', 'amount', 'million', 'journal', 'written', 'approximately', 'user', 'figure', 'plot', 'number', 'journal', 'posted', 'time', 'journal', 'written', 'first', 'half', 'although', 'inspected', 'topic', 'distribution', 'per', 'month', 'find', 'seasonal', 'effect', 'towards', 'beginning', 'many', 'new', 'user', 'registered', 'app', 'eventually', 'stopped', 'using', 'like', 'weightloss', 'productivity', 'apps', 'believe', 'influx', 'tied', 'user', 'looking', 'improve', 'habit', 'new', 'year', 'resolution', 'journal', 'set', 'private', 'public', 'visible', 'user', 'app', 'roughly', 'one', 'third', 'journal', 'public', 'figure', 'plot', 'number', 'user', 'yaxis', 'versus', 'percentage', 'journal', 'posted', 'publicly', 'user', 'either', 'mostly', 'private', 'mostly', 'public', 'journal', 'relatively', 'short', 'like', 'twitter', 'post', 'character', 'average', 'length', 'journal', 'text', 'character', 'roughly', 'journal', 'text', 'mood', 'label', 'observed', 'private', 'user', 'tend', 'write', 'journal', 'slightly', 'statistically', 'significantly', 'longer', 'written', 'public', 'user', 'approximately', 'character', 'figure', 'show', 'distribution', 'journal', 'length', 'spike', 'correspond', 'length', 'mood', 'character', 'default', 'limit', 'set', 'app', 'character', 'set', 'maximum', 'visualization', 'purpose', 'user', 'app', 'optionally', 'enter', 'location', 'age', 'gender', 'user', 'enter', 'information', 'found', 'revealed', 'location', 'mostly', 'north', 'america', 'revealed', 'gender', 'predominantly', 'female', 'revealed', 'age', 'average', 'age', 'goal', 'analysis', 'understand', 'public', 'mental', 'health', 'mining', 'social', 'medium', 'want', 'identify', 'common', 'topic', 'discussed', 'publicly', 'reddit', 'plus', 'public', 'journal', 'journalling', 'app', 'privately', 'private', 'journal', 'reddit', 'dataset', 'simply', 'count', 'number', 'subscriber', 'subreddit', 'related', 'mental', 'health', 'discover', 'popular', 'topic', 'issue', 'recall', 'subreddit', 'labelled', 'topic', 'topic', 'modelling', 'necessary', 'hand', 'journalling', 'app', 'journal', 'post', 'labelled', 'mood', 'topic', 'describe', 'methodology', 'assigning', 'topic', 'journal']","['analyze two', 'two datasets', 'datasets user', 'user community', 'community reddit', 'reddit journal', 'journal mental', 'mental health', 'health journalling', 'journalling mobile', 'mobile app', 'app omit', 'omit name', 'name app', 'app privacy', 'privacy refer', 'refer journalling', 'journalling app', 'app reddit', 'reddit social', 'social medium', 'medium platform', 'platform wa', 'wa originally', 'originally used', 'used sharing', 'sharing rating', 'rating content', 'content news', 'news documentary', 'documentary music', 'music user', 'user post', 'post subscribe', 'subscribe selforganized', 'selforganized community', 'community known', 'known subreddits', 'subreddits subscribing', 'subscribing subreddit', 'subreddit allows', 'allows user', 'user view', 'view post', 'post subreddit', 'subreddit advantage', 'advantage analyzing', 'analyzing reddit', 'reddit data', 'data subreddits', 'subreddits labelled', 'labelled according', 'according topic', 'topic utilizing', 'utilizing curated', 'curated list', 'list volunteer', 'volunteer reddit', 'reddit user', 'user crawled', 'crawled subreddits', 'subreddits related', 'related mental', 'mental health', 'health well', 'well subreddits', 'subreddits linked', 'linked community', 'community second', 'second dataset', 'dataset consists', 'consists anonymized', 'anonymized journal', 'journal post', 'post mobile', 'mobile app', 'app designed', 'designed help', 'help people', 'people track', 'track mood', 'mood share', 'share anonymously', 'anonymously desire', 'desire journal', 'journal post', 'post app', 'app requires', 'requires user', 'user label', 'label journal', 'journal post', 'post least', 'least one', 'one mood', 'mood selected', 'selected prepopulated', 'prepopulated list', 'list including', 'including happy', 'happy sad', 'sad etc', 'etc obtained', 'obtained journal', 'journal associated', 'associated mood', 'mood written', 'written january', 'january january', 'january amount', 'amount million', 'million journal', 'journal written', 'written approximately', 'approximately user', 'user figure', 'figure plot', 'plot number', 'number journal', 'journal posted', 'posted time', 'time journal', 'journal written', 'written first', 'first half', 'half although', 'although inspected', 'inspected topic', 'topic distribution', 'distribution per', 'per month', 'month find', 'find seasonal', 'seasonal effect', 'effect towards', 'towards beginning', 'beginning many', 'many new', 'new user', 'user registered', 'registered app', 'app eventually', 'eventually stopped', 'stopped using', 'using like', 'like weightloss', 'weightloss productivity', 'productivity apps', 'apps believe', 'believe influx', 'influx tied', 'tied user', 'user looking', 'looking improve', 'improve habit', 'habit new', 'new year', 'year resolution', 'resolution journal', 'journal set', 'set private', 'private public', 'public visible', 'visible user', 'user app', 'app roughly', 'roughly one', 'one third', 'third journal', 'journal public', 'public figure', 'figure plot', 'plot number', 'number user', 'user yaxis', 'yaxis versus', 'versus percentage', 'percentage journal', 'journal posted', 'posted publicly', 'publicly user', 'user either', 'either mostly', 'mostly private', 'private mostly', 'mostly public', 'public journal', 'journal relatively', 'relatively short', 'short like', 'like twitter', 'twitter post', 'post character', 'character average', 'average length', 'length journal', 'journal text', 'text character', 'character roughly', 'roughly journal', 'journal text', 'text mood', 'mood label', 'label observed', 'observed private', 'private user', 'user tend', 'tend write', 'write journal', 'journal slightly', 'slightly statistically', 'statistically significantly', 'significantly longer', 'longer written', 'written public', 'public user', 'user approximately', 'approximately character', 'character figure', 'figure show', 'show distribution', 'distribution journal', 'journal length', 'length spike', 'spike correspond', 'correspond length', 'length mood', 'mood character', 'character default', 'default limit', 'limit set', 'set app', 'app character', 'character set', 'set maximum', 'maximum visualization', 'visualization purpose', 'purpose user', 'user app', 'app optionally', 'optionally enter', 'enter location', 'location age', 'age gender', 'gender user', 'user enter', 'enter information', 'information found', 'found revealed', 'revealed location', 'location mostly', 'mostly north', 'north america', 'america revealed', 'revealed gender', 'gender predominantly', 'predominantly female', 'female revealed', 'revealed age', 'age average', 'average age', 'age goal', 'goal analysis', 'analysis understand', 'understand public', 'public mental', 'mental health', 'health mining', 'mining social', 'social medium', 'medium want', 'want identify', 'identify common', 'common topic', 'topic discussed', 'discussed publicly', 'publicly reddit', 'reddit plus', 'plus public', 'public journal', 'journal journalling', 'journalling app', 'app privately', 'privately private', 'private journal', 'journal reddit', 'reddit dataset', 'dataset simply', 'simply count', 'count number', 'number subscriber', 'subscriber subreddit', 'subreddit related', 'related mental', 'mental health', 'health discover', 'discover popular', 'popular topic', 'topic issue', 'issue recall', 'recall subreddit', 'subreddit labelled', 'labelled topic', 'topic topic', 'topic modelling', 'modelling necessary', 'necessary hand', 'hand journalling', 'journalling app', 'app journal', 'journal post', 'post labelled', 'labelled mood', 'mood topic', 'topic describe', 'describe methodology', 'methodology assigning', 'assigning topic', 'topic journal']","['analyze two datasets', 'two datasets user', 'datasets user community', 'user community reddit', 'community reddit journal', 'reddit journal mental', 'journal mental health', 'mental health journalling', 'health journalling mobile', 'journalling mobile app', 'mobile app omit', 'app omit name', 'omit name app', 'name app privacy', 'app privacy refer', 'privacy refer journalling', 'refer journalling app', 'journalling app reddit', 'app reddit social', 'reddit social medium', 'social medium platform', 'medium platform wa', 'platform wa originally', 'wa originally used', 'originally used sharing', 'used sharing rating', 'sharing rating content', 'rating content news', 'content news documentary', 'news documentary music', 'documentary music user', 'music user post', 'user post subscribe', 'post subscribe selforganized', 'subscribe selforganized community', 'selforganized community known', 'community known subreddits', 'known subreddits subscribing', 'subreddits subscribing subreddit', 'subscribing subreddit allows', 'subreddit allows user', 'allows user view', 'user view post', 'view post subreddit', 'post subreddit advantage', 'subreddit advantage analyzing', 'advantage analyzing reddit', 'analyzing reddit data', 'reddit data subreddits', 'data subreddits labelled', 'subreddits labelled according', 'labelled according topic', 'according topic utilizing', 'topic utilizing curated', 'utilizing curated list', 'curated list volunteer', 'list volunteer reddit', 'volunteer reddit user', 'reddit user crawled', 'user crawled subreddits', 'crawled subreddits related', 'subreddits related mental', 'related mental health', 'mental health well', 'health well subreddits', 'well subreddits linked', 'subreddits linked community', 'linked community second', 'community second dataset', 'second dataset consists', 'dataset consists anonymized', 'consists anonymized journal', 'anonymized journal post', 'journal post mobile', 'post mobile app', 'mobile app designed', 'app designed help', 'designed help people', 'help people track', 'people track mood', 'track mood share', 'mood share anonymously', 'share anonymously desire', 'anonymously desire journal', 'desire journal post', 'journal post app', 'post app requires', 'app requires user', 'requires user label', 'user label journal', 'label journal post', 'journal post least', 'post least one', 'least one mood', 'one mood selected', 'mood selected prepopulated', 'selected prepopulated list', 'prepopulated list including', 'list including happy', 'including happy sad', 'happy sad etc', 'sad etc obtained', 'etc obtained journal', 'obtained journal associated', 'journal associated mood', 'associated mood written', 'mood written january', 'written january january', 'january january amount', 'january amount million', 'amount million journal', 'million journal written', 'journal written approximately', 'written approximately user', 'approximately user figure', 'user figure plot', 'figure plot number', 'plot number journal', 'number journal posted', 'journal posted time', 'posted time journal', 'time journal written', 'journal written first', 'written first half', 'first half although', 'half although inspected', 'although inspected topic', 'inspected topic distribution', 'topic distribution per', 'distribution per month', 'per month find', 'month find seasonal', 'find seasonal effect', 'seasonal effect towards', 'effect towards beginning', 'towards beginning many', 'beginning many new', 'many new user', 'new user registered', 'user registered app', 'registered app eventually', 'app eventually stopped', 'eventually stopped using', 'stopped using like', 'using like weightloss', 'like weightloss productivity', 'weightloss productivity apps', 'productivity apps believe', 'apps believe influx', 'believe influx tied', 'influx tied user', 'tied user looking', 'user looking improve', 'looking improve habit', 'improve habit new', 'habit new year', 'new year resolution', 'year resolution journal', 'resolution journal set', 'journal set private', 'set private public', 'private public visible', 'public visible user', 'visible user app', 'user app roughly', 'app roughly one', 'roughly one third', 'one third journal', 'third journal public', 'journal public figure', 'public figure plot', 'figure plot number', 'plot number user', 'number user yaxis', 'user yaxis versus', 'yaxis versus percentage', 'versus percentage journal', 'percentage journal posted', 'journal posted publicly', 'posted publicly user', 'publicly user either', 'user either mostly', 'either mostly private', 'mostly private mostly', 'private mostly public', 'mostly public journal', 'public journal relatively', 'journal relatively short', 'relatively short like', 'short like twitter', 'like twitter post', 'twitter post character', 'post character average', 'character average length', 'average length journal', 'length journal text', 'journal text character', 'text character roughly', 'character roughly journal', 'roughly journal text', 'journal text mood', 'text mood label', 'mood label observed', 'label observed private', 'observed private user', 'private user tend', 'user tend write', 'tend write journal', 'write journal slightly', 'journal slightly statistically', 'slightly statistically significantly', 'statistically significantly longer', 'significantly longer written', 'longer written public', 'written public user', 'public user approximately', 'user approximately character', 'approximately character figure', 'character figure show', 'figure show distribution', 'show distribution journal', 'distribution journal length', 'journal length spike', 'length spike correspond', 'spike correspond length', 'correspond length mood', 'length mood character', 'mood character default', 'character default limit', 'default limit set', 'limit set app', 'set app character', 'app character set', 'character set maximum', 'set maximum visualization', 'maximum visualization purpose', 'visualization purpose user', 'purpose user app', 'user app optionally', 'app optionally enter', 'optionally enter location', 'enter location age', 'location age gender', 'age gender user', 'gender user enter', 'user enter information', 'enter information found', 'information found revealed', 'found revealed location', 'revealed location mostly', 'location mostly north', 'mostly north america', 'north america revealed', 'america revealed gender', 'revealed gender predominantly', 'gender predominantly female', 'predominantly female revealed', 'female revealed age', 'revealed age average', 'age average age', 'average age goal', 'age goal analysis', 'goal analysis understand', 'analysis understand public', 'understand public mental', 'public mental health', 'mental health mining', 'health mining social', 'mining social medium', 'social medium want', 'medium want identify', 'want identify common', 'identify common topic', 'common topic discussed', 'topic discussed publicly', 'discussed publicly reddit', 'publicly reddit plus', 'reddit plus public', 'plus public journal', 'public journal journalling', 'journal journalling app', 'journalling app privately', 'app privately private', 'privately private journal', 'private journal reddit', 'journal reddit dataset', 'reddit dataset simply', 'dataset simply count', 'simply count number', 'count number subscriber', 'number subscriber subreddit', 'subscriber subreddit related', 'subreddit related mental', 'related mental health', 'mental health discover', 'health discover popular', 'discover popular topic', 'popular topic issue', 'topic issue recall', 'issue recall subreddit', 'recall subreddit labelled', 'subreddit labelled topic', 'labelled topic topic', 'topic topic modelling', 'topic modelling necessary', 'modelling necessary hand', 'necessary hand journalling', 'hand journalling app', 'journalling app journal', 'app journal post', 'journal post labelled', 'post labelled mood', 'labelled mood topic', 'mood topic describe', 'topic describe methodology', 'describe methodology assigning', 'methodology assigning topic', 'assigning topic journal']",,,,,,,,
https://dl.acm.org/doi/abs/10.1145/2556288.2557214,1,A key challenge of this research was to identify the different health conditions on which people seek and share information via search engines and Twitter respectively. We identified four broad categories of conditions based on their severity and types: (1) symptoms of major diseases (2) benign explanations (non-life-threatening illnesses) (3) serious illnesses and (4) disabilities. We also characterized each condition by the degree of perceived social stigma provided by third-party judges. Our final list contained 165 conditions.,a key challenge of this research wa to identify the different health condition on which people seek and share information via search engine and twitter respectively we identified four broad category of condition based on their severity and type symptom of major disease benign explanation nonlifethreatening illness serious illness and disability we also characterized each condition by the degree of perceived social stigma provided by thirdparty judge our final list contained condition,"['key', 'challenge', 'research', 'wa', 'identify', 'different', 'health', 'condition', 'people', 'seek', 'share', 'information', 'via', 'search', 'engine', 'twitter', 'respectively', 'identified', 'four', 'broad', 'category', 'condition', 'based', 'severity', 'type', 'symptom', 'major', 'disease', 'benign', 'explanation', 'nonlifethreatening', 'illness', 'serious', 'illness', 'disability', 'also', 'characterized', 'condition', 'degree', 'perceived', 'social', 'stigma', 'provided', 'thirdparty', 'judge', 'final', 'list', 'contained', 'condition']","['key challenge', 'challenge research', 'research wa', 'wa identify', 'identify different', 'different health', 'health condition', 'condition people', 'people seek', 'seek share', 'share information', 'information via', 'via search', 'search engine', 'engine twitter', 'twitter respectively', 'respectively identified', 'identified four', 'four broad', 'broad category', 'category condition', 'condition based', 'based severity', 'severity type', 'type symptom', 'symptom major', 'major disease', 'disease benign', 'benign explanation', 'explanation nonlifethreatening', 'nonlifethreatening illness', 'illness serious', 'serious illness', 'illness disability', 'disability also', 'also characterized', 'characterized condition', 'condition degree', 'degree perceived', 'perceived social', 'social stigma', 'stigma provided', 'provided thirdparty', 'thirdparty judge', 'judge final', 'final list', 'list contained', 'contained condition']","['key challenge research', 'challenge research wa', 'research wa identify', 'wa identify different', 'identify different health', 'different health condition', 'health condition people', 'condition people seek', 'people seek share', 'seek share information', 'share information via', 'information via search', 'via search engine', 'search engine twitter', 'engine twitter respectively', 'twitter respectively identified', 'respectively identified four', 'identified four broad', 'four broad category', 'broad category condition', 'category condition based', 'condition based severity', 'based severity type', 'severity type symptom', 'type symptom major', 'symptom major disease', 'major disease benign', 'disease benign explanation', 'benign explanation nonlifethreatening', 'explanation nonlifethreatening illness', 'nonlifethreatening illness serious', 'illness serious illness', 'serious illness disability', 'illness disability also', 'disability also characterized', 'also characterized condition', 'characterized condition degree', 'condition degree perceived', 'degree perceived social', 'perceived social stigma', 'social stigma provided', 'stigma provided thirdparty', 'provided thirdparty judge', 'thirdparty judge final', 'judge final list', 'final list contained', 'list contained condition']",,,,,,,,
https://www.aaai.org/ocs/index.php/ICWSM/ICWSM14/paper/viewPaper/8075,0,reddit is a social news website where registered users submit content in the form of links or text posts. Users also known as “redditors” can then vote each submission “up” or “down” to rank the post and determine its position or prominence on the site’s pages. These two attributes associated with a post are referred to as “upvotes” and “downvotes”. Redditors can also comment on posts and respond back in a conversation tree of comments. Content entries that is the posts are organized by areas of interest or sub-communities called “subreddits” such as politics programming or science. As of 2013 reddit’s official statistics included 56 billion page views 731 million unique visitors 40855032 posts and 404603286 comments (http://blog.reddit.com/2013/ 12/top-posts-of-2013-stats-and-snoo-years.html). We used of reddit’s official API (http://www.reddit.com/ dev /api) to collect posts comments and associated metadata from several mental health subreddits: specifically using a Python wrapper PRAW (https://praw.readthedocs.org/en/ latest/index.html). The subreddits we crawled were: alcoholism anxiety bipolarreddit depression mentalhealth MMFB (Make Me Feel Better) socialanxiety SuicideWatch. All of these subreddits host public content. In order to arrive at a comprehensive list of subreddits to focus on we utilized reddit’s native subreddit search feature (http://www.reddit.com/reddits) and searched for subreddits on “mental health”. Two researchers familiar with reddit employed an initial filtering step on the search results returned so that we focus on high precision subreddits discussing mental health concerns and issues. Thereafter we focused on a snowball approach in which starting with a few seed subreddits (mentalhealth depression) we compiled a second list of “related” or “similar” subreddits that are listed in the profile pages of the seed subreddits. Following a second filtering step we arrived at the list of subreddits listed above. For each of these subreddits we obtained daily crawls of their posts in the New category. Corresponding to each post we collected information on the title of the post the body or textual content id timestamp when the post was made author id and the number of upvotes and downvotes it obtained. Since posts gather comments over a period of time following the time of sharing we crawled all of the comments per post that were shared over a three day period after the post was made. Qualitative examinations of the subreddits of interest revealed that 90% or more of the comments to any post were typically made in a three day window following the time the post is made—hence the choice. The crawl of the subreddits used in this paper We present some descriptive statistics of our crawled data. Our dataset contained 20411 posts with at least one comment and 97661 comments in all with 27102 unique users who made posts comments or both. A set of 7823 users (28.79%) were found to write both at least one post and comment. CDF of the user distribution over posts and comments is given in Figure 1. The figure shows the expected heavy tail trend observed in several social phenomena. Also see Figure 2 for the distribution of comments over time following post share. It illustrates the quick responsivity culture in the communities we study (peak at 3 hours). Some of the additional statistics of our dataset are given in Table 1. Further example titles of a few,reddit is a social news website where registered user submit content in the form of link or text post user also known a redditors can then vote each submission up or down to rank the post and determine it position or prominence on the site page these two attribute associated with a post are referred to a upvotes and downvotes redditors can also comment on post and respond back in a conversation tree of comment content entry that is the post are organized by area of interest or subcommunities called subreddits such a politics programming or science a of reddits official statistic included billion page view million unique visitor post and comment httpblogredditcom toppostsofstatsandsnooyearshtml we used of reddits official api httpwwwredditcom dev api to collect post comment and associated metadata from several mental health subreddits specifically using a python wrapper praw httpsprawreadthedocsorgen latestindexhtml the subreddits we crawled were alcoholism anxiety bipolarreddit depression mentalhealth mmfb make me feel better socialanxiety suicidewatch all of these subreddits host public content in order to arrive at a comprehensive list of subreddits to focus on we utilized reddits native subreddit search feature httpwwwredditcomreddits and searched for subreddits on mental health two researcher familiar with reddit employed an initial filtering step on the search result returned so that we focus on high precision subreddits discussing mental health concern and issue thereafter we focused on a snowball approach in which starting with a few seed subreddits mentalhealth depression we compiled a second list of related or similar subreddits that are listed in the profile page of the seed subreddits following a second filtering step we arrived at the list of subreddits listed above for each of these subreddits we obtained daily crawl of their post in the new category corresponding to each post we collected information on the title of the post the body or textual content id timestamp when the post wa made author id and the number of upvotes and downvotes it obtained since post gather comment over a period of time following the time of sharing we crawled all of the comment per post that were shared over a three day period after the post wa made qualitative examination of the subreddits of interest revealed that or more of the comment to any post were typically made in a three day window following the time the post is madehence the choice the crawl of the subreddits used in this paper we present some descriptive statistic of our crawled data our dataset contained post with at least one comment and comment in all with unique user who made post comment or both a set of user were found to write both at least one post and comment cdf of the user distribution over post and comment is given in figure the figure show the expected heavy tail trend observed in several social phenomenon also see figure for the distribution of comment over time following post share it illustrates the quick responsivity culture in the community we study peak at hour some of the additional statistic of our dataset are given in table further example title of a few,"['reddit', 'social', 'news', 'website', 'registered', 'user', 'submit', 'content', 'form', 'link', 'text', 'post', 'user', 'also', 'known', 'redditors', 'vote', 'submission', 'rank', 'post', 'determine', 'position', 'prominence', 'site', 'page', 'two', 'attribute', 'associated', 'post', 'referred', 'upvotes', 'downvotes', 'redditors', 'also', 'comment', 'post', 'respond', 'back', 'conversation', 'tree', 'comment', 'content', 'entry', 'post', 'organized', 'area', 'interest', 'subcommunities', 'called', 'subreddits', 'politics', 'programming', 'science', 'reddits', 'official', 'statistic', 'included', 'billion', 'page', 'view', 'million', 'unique', 'visitor', 'post', 'comment', 'httpblogredditcom', 'toppostsofstatsandsnooyearshtml', 'used', 'reddits', 'official', 'api', 'httpwwwredditcom', 'dev', 'api', 'collect', 'post', 'comment', 'associated', 'metadata', 'several', 'mental', 'health', 'subreddits', 'specifically', 'using', 'python', 'wrapper', 'praw', 'httpsprawreadthedocsorgen', 'latestindexhtml', 'subreddits', 'crawled', 'alcoholism', 'anxiety', 'bipolarreddit', 'depression', 'mentalhealth', 'mmfb', 'make', 'feel', 'better', 'socialanxiety', 'suicidewatch', 'subreddits', 'host', 'public', 'content', 'order', 'arrive', 'comprehensive', 'list', 'subreddits', 'focus', 'utilized', 'reddits', 'native', 'subreddit', 'search', 'feature', 'httpwwwredditcomreddits', 'searched', 'subreddits', 'mental', 'health', 'two', 'researcher', 'familiar', 'reddit', 'employed', 'initial', 'filtering', 'step', 'search', 'result', 'returned', 'focus', 'high', 'precision', 'subreddits', 'discussing', 'mental', 'health', 'concern', 'issue', 'thereafter', 'focused', 'snowball', 'approach', 'starting', 'seed', 'subreddits', 'mentalhealth', 'depression', 'compiled', 'second', 'list', 'related', 'similar', 'subreddits', 'listed', 'profile', 'page', 'seed', 'subreddits', 'following', 'second', 'filtering', 'step', 'arrived', 'list', 'subreddits', 'listed', 'subreddits', 'obtained', 'daily', 'crawl', 'post', 'new', 'category', 'corresponding', 'post', 'collected', 'information', 'title', 'post', 'body', 'textual', 'content', 'id', 'timestamp', 'post', 'wa', 'made', 'author', 'id', 'number', 'upvotes', 'downvotes', 'obtained', 'since', 'post', 'gather', 'comment', 'period', 'time', 'following', 'time', 'sharing', 'crawled', 'comment', 'per', 'post', 'shared', 'three', 'day', 'period', 'post', 'wa', 'made', 'qualitative', 'examination', 'subreddits', 'interest', 'revealed', 'comment', 'post', 'typically', 'made', 'three', 'day', 'window', 'following', 'time', 'post', 'madehence', 'choice', 'crawl', 'subreddits', 'used', 'paper', 'present', 'descriptive', 'statistic', 'crawled', 'data', 'dataset', 'contained', 'post', 'least', 'one', 'comment', 'comment', 'unique', 'user', 'made', 'post', 'comment', 'set', 'user', 'found', 'write', 'least', 'one', 'post', 'comment', 'cdf', 'user', 'distribution', 'post', 'comment', 'given', 'figure', 'figure', 'show', 'expected', 'heavy', 'tail', 'trend', 'observed', 'several', 'social', 'phenomenon', 'also', 'see', 'figure', 'distribution', 'comment', 'time', 'following', 'post', 'share', 'illustrates', 'quick', 'responsivity', 'culture', 'community', 'study', 'peak', 'hour', 'additional', 'statistic', 'dataset', 'given', 'table', 'example', 'title']","['reddit social', 'social news', 'news website', 'website registered', 'registered user', 'user submit', 'submit content', 'content form', 'form link', 'link text', 'text post', 'post user', 'user also', 'also known', 'known redditors', 'redditors vote', 'vote submission', 'submission rank', 'rank post', 'post determine', 'determine position', 'position prominence', 'prominence site', 'site page', 'page two', 'two attribute', 'attribute associated', 'associated post', 'post referred', 'referred upvotes', 'upvotes downvotes', 'downvotes redditors', 'redditors also', 'also comment', 'comment post', 'post respond', 'respond back', 'back conversation', 'conversation tree', 'tree comment', 'comment content', 'content entry', 'entry post', 'post organized', 'organized area', 'area interest', 'interest subcommunities', 'subcommunities called', 'called subreddits', 'subreddits politics', 'politics programming', 'programming science', 'science reddits', 'reddits official', 'official statistic', 'statistic included', 'included billion', 'billion page', 'page view', 'view million', 'million unique', 'unique visitor', 'visitor post', 'post comment', 'comment httpblogredditcom', 'httpblogredditcom toppostsofstatsandsnooyearshtml', 'toppostsofstatsandsnooyearshtml used', 'used reddits', 'reddits official', 'official api', 'api httpwwwredditcom', 'httpwwwredditcom dev', 'dev api', 'api collect', 'collect post', 'post comment', 'comment associated', 'associated metadata', 'metadata several', 'several mental', 'mental health', 'health subreddits', 'subreddits specifically', 'specifically using', 'using python', 'python wrapper', 'wrapper praw', 'praw httpsprawreadthedocsorgen', 'httpsprawreadthedocsorgen latestindexhtml', 'latestindexhtml subreddits', 'subreddits crawled', 'crawled alcoholism', 'alcoholism anxiety', 'anxiety bipolarreddit', 'bipolarreddit depression', 'depression mentalhealth', 'mentalhealth mmfb', 'mmfb make', 'make feel', 'feel better', 'better socialanxiety', 'socialanxiety suicidewatch', 'suicidewatch subreddits', 'subreddits host', 'host public', 'public content', 'content order', 'order arrive', 'arrive comprehensive', 'comprehensive list', 'list subreddits', 'subreddits focus', 'focus utilized', 'utilized reddits', 'reddits native', 'native subreddit', 'subreddit search', 'search feature', 'feature httpwwwredditcomreddits', 'httpwwwredditcomreddits searched', 'searched subreddits', 'subreddits mental', 'mental health', 'health two', 'two researcher', 'researcher familiar', 'familiar reddit', 'reddit employed', 'employed initial', 'initial filtering', 'filtering step', 'step search', 'search result', 'result returned', 'returned focus', 'focus high', 'high precision', 'precision subreddits', 'subreddits discussing', 'discussing mental', 'mental health', 'health concern', 'concern issue', 'issue thereafter', 'thereafter focused', 'focused snowball', 'snowball approach', 'approach starting', 'starting seed', 'seed subreddits', 'subreddits mentalhealth', 'mentalhealth depression', 'depression compiled', 'compiled second', 'second list', 'list related', 'related similar', 'similar subreddits', 'subreddits listed', 'listed profile', 'profile page', 'page seed', 'seed subreddits', 'subreddits following', 'following second', 'second filtering', 'filtering step', 'step arrived', 'arrived list', 'list subreddits', 'subreddits listed', 'listed subreddits', 'subreddits obtained', 'obtained daily', 'daily crawl', 'crawl post', 'post new', 'new category', 'category corresponding', 'corresponding post', 'post collected', 'collected information', 'information title', 'title post', 'post body', 'body textual', 'textual content', 'content id', 'id timestamp', 'timestamp post', 'post wa', 'wa made', 'made author', 'author id', 'id number', 'number upvotes', 'upvotes downvotes', 'downvotes obtained', 'obtained since', 'since post', 'post gather', 'gather comment', 'comment period', 'period time', 'time following', 'following time', 'time sharing', 'sharing crawled', 'crawled comment', 'comment per', 'per post', 'post shared', 'shared three', 'three day', 'day period', 'period post', 'post wa', 'wa made', 'made qualitative', 'qualitative examination', 'examination subreddits', 'subreddits interest', 'interest revealed', 'revealed comment', 'comment post', 'post typically', 'typically made', 'made three', 'three day', 'day window', 'window following', 'following time', 'time post', 'post madehence', 'madehence choice', 'choice crawl', 'crawl subreddits', 'subreddits used', 'used paper', 'paper present', 'present descriptive', 'descriptive statistic', 'statistic crawled', 'crawled data', 'data dataset', 'dataset contained', 'contained post', 'post least', 'least one', 'one comment', 'comment comment', 'comment unique', 'unique user', 'user made', 'made post', 'post comment', 'comment set', 'set user', 'user found', 'found write', 'write least', 'least one', 'one post', 'post comment', 'comment cdf', 'cdf user', 'user distribution', 'distribution post', 'post comment', 'comment given', 'given figure', 'figure figure', 'figure show', 'show expected', 'expected heavy', 'heavy tail', 'tail trend', 'trend observed', 'observed several', 'several social', 'social phenomenon', 'phenomenon also', 'also see', 'see figure', 'figure distribution', 'distribution comment', 'comment time', 'time following', 'following post', 'post share', 'share illustrates', 'illustrates quick', 'quick responsivity', 'responsivity culture', 'culture community', 'community study', 'study peak', 'peak hour', 'hour additional', 'additional statistic', 'statistic dataset', 'dataset given', 'given table', 'table example', 'example title']","['reddit social news', 'social news website', 'news website registered', 'website registered user', 'registered user submit', 'user submit content', 'submit content form', 'content form link', 'form link text', 'link text post', 'text post user', 'post user also', 'user also known', 'also known redditors', 'known redditors vote', 'redditors vote submission', 'vote submission rank', 'submission rank post', 'rank post determine', 'post determine position', 'determine position prominence', 'position prominence site', 'prominence site page', 'site page two', 'page two attribute', 'two attribute associated', 'attribute associated post', 'associated post referred', 'post referred upvotes', 'referred upvotes downvotes', 'upvotes downvotes redditors', 'downvotes redditors also', 'redditors also comment', 'also comment post', 'comment post respond', 'post respond back', 'respond back conversation', 'back conversation tree', 'conversation tree comment', 'tree comment content', 'comment content entry', 'content entry post', 'entry post organized', 'post organized area', 'organized area interest', 'area interest subcommunities', 'interest subcommunities called', 'subcommunities called subreddits', 'called subreddits politics', 'subreddits politics programming', 'politics programming science', 'programming science reddits', 'science reddits official', 'reddits official statistic', 'official statistic included', 'statistic included billion', 'included billion page', 'billion page view', 'page view million', 'view million unique', 'million unique visitor', 'unique visitor post', 'visitor post comment', 'post comment httpblogredditcom', 'comment httpblogredditcom toppostsofstatsandsnooyearshtml', 'httpblogredditcom toppostsofstatsandsnooyearshtml used', 'toppostsofstatsandsnooyearshtml used reddits', 'used reddits official', 'reddits official api', 'official api httpwwwredditcom', 'api httpwwwredditcom dev', 'httpwwwredditcom dev api', 'dev api collect', 'api collect post', 'collect post comment', 'post comment associated', 'comment associated metadata', 'associated metadata several', 'metadata several mental', 'several mental health', 'mental health subreddits', 'health subreddits specifically', 'subreddits specifically using', 'specifically using python', 'using python wrapper', 'python wrapper praw', 'wrapper praw httpsprawreadthedocsorgen', 'praw httpsprawreadthedocsorgen latestindexhtml', 'httpsprawreadthedocsorgen latestindexhtml subreddits', 'latestindexhtml subreddits crawled', 'subreddits crawled alcoholism', 'crawled alcoholism anxiety', 'alcoholism anxiety bipolarreddit', 'anxiety bipolarreddit depression', 'bipolarreddit depression mentalhealth', 'depression mentalhealth mmfb', 'mentalhealth mmfb make', 'mmfb make feel', 'make feel better', 'feel better socialanxiety', 'better socialanxiety suicidewatch', 'socialanxiety suicidewatch subreddits', 'suicidewatch subreddits host', 'subreddits host public', 'host public content', 'public content order', 'content order arrive', 'order arrive comprehensive', 'arrive comprehensive list', 'comprehensive list subreddits', 'list subreddits focus', 'subreddits focus utilized', 'focus utilized reddits', 'utilized reddits native', 'reddits native subreddit', 'native subreddit search', 'subreddit search feature', 'search feature httpwwwredditcomreddits', 'feature httpwwwredditcomreddits searched', 'httpwwwredditcomreddits searched subreddits', 'searched subreddits mental', 'subreddits mental health', 'mental health two', 'health two researcher', 'two researcher familiar', 'researcher familiar reddit', 'familiar reddit employed', 'reddit employed initial', 'employed initial filtering', 'initial filtering step', 'filtering step search', 'step search result', 'search result returned', 'result returned focus', 'returned focus high', 'focus high precision', 'high precision subreddits', 'precision subreddits discussing', 'subreddits discussing mental', 'discussing mental health', 'mental health concern', 'health concern issue', 'concern issue thereafter', 'issue thereafter focused', 'thereafter focused snowball', 'focused snowball approach', 'snowball approach starting', 'approach starting seed', 'starting seed subreddits', 'seed subreddits mentalhealth', 'subreddits mentalhealth depression', 'mentalhealth depression compiled', 'depression compiled second', 'compiled second list', 'second list related', 'list related similar', 'related similar subreddits', 'similar subreddits listed', 'subreddits listed profile', 'listed profile page', 'profile page seed', 'page seed subreddits', 'seed subreddits following', 'subreddits following second', 'following second filtering', 'second filtering step', 'filtering step arrived', 'step arrived list', 'arrived list subreddits', 'list subreddits listed', 'subreddits listed subreddits', 'listed subreddits obtained', 'subreddits obtained daily', 'obtained daily crawl', 'daily crawl post', 'crawl post new', 'post new category', 'new category corresponding', 'category corresponding post', 'corresponding post collected', 'post collected information', 'collected information title', 'information title post', 'title post body', 'post body textual', 'body textual content', 'textual content id', 'content id timestamp', 'id timestamp post', 'timestamp post wa', 'post wa made', 'wa made author', 'made author id', 'author id number', 'id number upvotes', 'number upvotes downvotes', 'upvotes downvotes obtained', 'downvotes obtained since', 'obtained since post', 'since post gather', 'post gather comment', 'gather comment period', 'comment period time', 'period time following', 'time following time', 'following time sharing', 'time sharing crawled', 'sharing crawled comment', 'crawled comment per', 'comment per post', 'per post shared', 'post shared three', 'shared three day', 'three day period', 'day period post', 'period post wa', 'post wa made', 'wa made qualitative', 'made qualitative examination', 'qualitative examination subreddits', 'examination subreddits interest', 'subreddits interest revealed', 'interest revealed comment', 'revealed comment post', 'comment post typically', 'post typically made', 'typically made three', 'made three day', 'three day window', 'day window following', 'window following time', 'following time post', 'time post madehence', 'post madehence choice', 'madehence choice crawl', 'choice crawl subreddits', 'crawl subreddits used', 'subreddits used paper', 'used paper present', 'paper present descriptive', 'present descriptive statistic', 'descriptive statistic crawled', 'statistic crawled data', 'crawled data dataset', 'data dataset contained', 'dataset contained post', 'contained post least', 'post least one', 'least one comment', 'one comment comment', 'comment comment unique', 'comment unique user', 'unique user made', 'user made post', 'made post comment', 'post comment set', 'comment set user', 'set user found', 'user found write', 'found write least', 'write least one', 'least one post', 'one post comment', 'post comment cdf', 'comment cdf user', 'cdf user distribution', 'user distribution post', 'distribution post comment', 'post comment given', 'comment given figure', 'given figure figure', 'figure figure show', 'figure show expected', 'show expected heavy', 'expected heavy tail', 'heavy tail trend', 'tail trend observed', 'trend observed several', 'observed several social', 'several social phenomenon', 'social phenomenon also', 'phenomenon also see', 'also see figure', 'see figure distribution', 'figure distribution comment', 'distribution comment time', 'comment time following', 'time following post', 'following post share', 'post share illustrates', 'share illustrates quick', 'illustrates quick responsivity', 'quick responsivity culture', 'responsivity culture community', 'culture community study', 'community study peak', 'study peak hour', 'peak hour additional', 'hour additional statistic', 'additional statistic dataset', 'statistic dataset given', 'dataset given table', 'given table example', 'table example title']",,,,,,,,
https://dl.acm.org/doi/abs/10.1145/3025453.3025932,1,We acknowledge that there are some limitations to our work as the analysis and the inferences obtained are purely data driven and relied on public posts shared on Instagram around mental health challenges. Specifically to obtain disclosures of mental health issues we utilized tags attached to posts. We presume self-selection biases in users who make public posts and link them to different mental health hashtags. We caution against applying our methods to arbitrary contexts. Moreover although users might be voluntarily relating themselves to one of the mental health disorder categories it is unclear to what extent this constitutes an online identity construction activity. Importantly it is challenging to assess the gravity of a given user’s health condition using these posts or images alone or more specifically if they are actually experiencing a clinical mental health concern. On a related note although the tags we employed for obtaining our mental health data were verified through consultation with a licensed psychiatrist we do not claim our methods reveal symptoms or diagnostic markers of mental illness in individuals. Therefore the methods we developed in this paper were not evaluated for their effectiveness in discovering mental health concerns but rather as a principled and quantifiable way to understand the nature of mental health disclosures shared on social media. Putting it together our findings should not be interpreted to be diagnostic claims about one’s mental health. To do so we advocate for collaboration between clinicians and HCI researchers along with voluntarily consenting patients. This constitutes one of our future research directions. Finally qualitative methods would lend a deeper understanding of the motivations behind appropriating a public social media outlet for vulnerable and sensitive exchange. We also emphasize that the analyzed visual and linguistic patterns on Instagram are not the only patterns that can help study selfdisclosure. Indeed current advancements in machine learning approaches like deep learning [36] have created a new thread of research in image classification where image classification problems once difficult to solve can now be solved very efficiently. We believe such methods can be incorporated to study mental health imagery shared on social media,we acknowledge that there are some limitation to our work a the analysis and the inference obtained are purely data driven and relied on public post shared on instagram around mental health challenge specifically to obtain disclosure of mental health issue we utilized tag attached to post we presume selfselection bias in user who make public post and link them to different mental health hashtags we caution against applying our method to arbitrary context moreover although user might be voluntarily relating themselves to one of the mental health disorder category it is unclear to what extent this constitutes an online identity construction activity importantly it is challenging to ass the gravity of a given user health condition using these post or image alone or more specifically if they are actually experiencing a clinical mental health concern on a related note although the tag we employed for obtaining our mental health data were verified through consultation with a licensed psychiatrist we do not claim our method reveal symptom or diagnostic marker of mental illness in individual therefore the method we developed in this paper were not evaluated for their effectiveness in discovering mental health concern but rather a a principled and quantifiable way to understand the nature of mental health disclosure shared on social medium putting it together our finding should not be interpreted to be diagnostic claim about one mental health to do so we advocate for collaboration between clinician and hci researcher along with voluntarily consenting patient this constitutes one of our future research direction finally qualitative method would lend a deeper understanding of the motivation behind appropriating a public social medium outlet for vulnerable and sensitive exchange we also emphasize that the analyzed visual and linguistic pattern on instagram are not the only pattern that can help study selfdisclosure indeed current advancement in machine learning approach like deep learning have created a new thread of research in image classification where image classification problem once difficult to solve can now be solved very efficiently we believe such method can be incorporated to study mental health imagery shared on social medium,"['acknowledge', 'limitation', 'work', 'analysis', 'inference', 'obtained', 'purely', 'data', 'driven', 'relied', 'public', 'post', 'shared', 'instagram', 'around', 'mental', 'health', 'challenge', 'specifically', 'obtain', 'disclosure', 'mental', 'health', 'issue', 'utilized', 'tag', 'attached', 'post', 'presume', 'selfselection', 'bias', 'user', 'make', 'public', 'post', 'link', 'different', 'mental', 'health', 'hashtags', 'caution', 'applying', 'method', 'arbitrary', 'context', 'moreover', 'although', 'user', 'might', 'voluntarily', 'relating', 'one', 'mental', 'health', 'disorder', 'category', 'unclear', 'extent', 'constitutes', 'online', 'identity', 'construction', 'activity', 'importantly', 'challenging', 'ass', 'gravity', 'given', 'user', 'health', 'condition', 'using', 'post', 'image', 'alone', 'specifically', 'actually', 'experiencing', 'clinical', 'mental', 'health', 'concern', 'related', 'note', 'although', 'tag', 'employed', 'obtaining', 'mental', 'health', 'data', 'verified', 'consultation', 'licensed', 'psychiatrist', 'claim', 'method', 'reveal', 'symptom', 'diagnostic', 'marker', 'mental', 'illness', 'individual', 'therefore', 'method', 'developed', 'paper', 'evaluated', 'effectiveness', 'discovering', 'mental', 'health', 'concern', 'rather', 'principled', 'quantifiable', 'way', 'understand', 'nature', 'mental', 'health', 'disclosure', 'shared', 'social', 'medium', 'putting', 'together', 'finding', 'interpreted', 'diagnostic', 'claim', 'one', 'mental', 'health', 'advocate', 'collaboration', 'clinician', 'hci', 'researcher', 'along', 'voluntarily', 'consenting', 'patient', 'constitutes', 'one', 'future', 'research', 'direction', 'finally', 'qualitative', 'method', 'would', 'lend', 'deeper', 'understanding', 'motivation', 'behind', 'appropriating', 'public', 'social', 'medium', 'outlet', 'vulnerable', 'sensitive', 'exchange', 'also', 'emphasize', 'analyzed', 'visual', 'linguistic', 'pattern', 'instagram', 'pattern', 'help', 'study', 'selfdisclosure', 'indeed', 'current', 'advancement', 'machine', 'learning', 'approach', 'like', 'deep', 'learning', 'created', 'new', 'thread', 'research', 'image', 'classification', 'image', 'classification', 'problem', 'difficult', 'solve', 'solved', 'efficiently', 'believe', 'method', 'incorporated', 'study', 'mental', 'health', 'imagery', 'shared', 'social', 'medium']","['acknowledge limitation', 'limitation work', 'work analysis', 'analysis inference', 'inference obtained', 'obtained purely', 'purely data', 'data driven', 'driven relied', 'relied public', 'public post', 'post shared', 'shared instagram', 'instagram around', 'around mental', 'mental health', 'health challenge', 'challenge specifically', 'specifically obtain', 'obtain disclosure', 'disclosure mental', 'mental health', 'health issue', 'issue utilized', 'utilized tag', 'tag attached', 'attached post', 'post presume', 'presume selfselection', 'selfselection bias', 'bias user', 'user make', 'make public', 'public post', 'post link', 'link different', 'different mental', 'mental health', 'health hashtags', 'hashtags caution', 'caution applying', 'applying method', 'method arbitrary', 'arbitrary context', 'context moreover', 'moreover although', 'although user', 'user might', 'might voluntarily', 'voluntarily relating', 'relating one', 'one mental', 'mental health', 'health disorder', 'disorder category', 'category unclear', 'unclear extent', 'extent constitutes', 'constitutes online', 'online identity', 'identity construction', 'construction activity', 'activity importantly', 'importantly challenging', 'challenging ass', 'ass gravity', 'gravity given', 'given user', 'user health', 'health condition', 'condition using', 'using post', 'post image', 'image alone', 'alone specifically', 'specifically actually', 'actually experiencing', 'experiencing clinical', 'clinical mental', 'mental health', 'health concern', 'concern related', 'related note', 'note although', 'although tag', 'tag employed', 'employed obtaining', 'obtaining mental', 'mental health', 'health data', 'data verified', 'verified consultation', 'consultation licensed', 'licensed psychiatrist', 'psychiatrist claim', 'claim method', 'method reveal', 'reveal symptom', 'symptom diagnostic', 'diagnostic marker', 'marker mental', 'mental illness', 'illness individual', 'individual therefore', 'therefore method', 'method developed', 'developed paper', 'paper evaluated', 'evaluated effectiveness', 'effectiveness discovering', 'discovering mental', 'mental health', 'health concern', 'concern rather', 'rather principled', 'principled quantifiable', 'quantifiable way', 'way understand', 'understand nature', 'nature mental', 'mental health', 'health disclosure', 'disclosure shared', 'shared social', 'social medium', 'medium putting', 'putting together', 'together finding', 'finding interpreted', 'interpreted diagnostic', 'diagnostic claim', 'claim one', 'one mental', 'mental health', 'health advocate', 'advocate collaboration', 'collaboration clinician', 'clinician hci', 'hci researcher', 'researcher along', 'along voluntarily', 'voluntarily consenting', 'consenting patient', 'patient constitutes', 'constitutes one', 'one future', 'future research', 'research direction', 'direction finally', 'finally qualitative', 'qualitative method', 'method would', 'would lend', 'lend deeper', 'deeper understanding', 'understanding motivation', 'motivation behind', 'behind appropriating', 'appropriating public', 'public social', 'social medium', 'medium outlet', 'outlet vulnerable', 'vulnerable sensitive', 'sensitive exchange', 'exchange also', 'also emphasize', 'emphasize analyzed', 'analyzed visual', 'visual linguistic', 'linguistic pattern', 'pattern instagram', 'instagram pattern', 'pattern help', 'help study', 'study selfdisclosure', 'selfdisclosure indeed', 'indeed current', 'current advancement', 'advancement machine', 'machine learning', 'learning approach', 'approach like', 'like deep', 'deep learning', 'learning created', 'created new', 'new thread', 'thread research', 'research image', 'image classification', 'classification image', 'image classification', 'classification problem', 'problem difficult', 'difficult solve', 'solve solved', 'solved efficiently', 'efficiently believe', 'believe method', 'method incorporated', 'incorporated study', 'study mental', 'mental health', 'health imagery', 'imagery shared', 'shared social', 'social medium']","['acknowledge limitation work', 'limitation work analysis', 'work analysis inference', 'analysis inference obtained', 'inference obtained purely', 'obtained purely data', 'purely data driven', 'data driven relied', 'driven relied public', 'relied public post', 'public post shared', 'post shared instagram', 'shared instagram around', 'instagram around mental', 'around mental health', 'mental health challenge', 'health challenge specifically', 'challenge specifically obtain', 'specifically obtain disclosure', 'obtain disclosure mental', 'disclosure mental health', 'mental health issue', 'health issue utilized', 'issue utilized tag', 'utilized tag attached', 'tag attached post', 'attached post presume', 'post presume selfselection', 'presume selfselection bias', 'selfselection bias user', 'bias user make', 'user make public', 'make public post', 'public post link', 'post link different', 'link different mental', 'different mental health', 'mental health hashtags', 'health hashtags caution', 'hashtags caution applying', 'caution applying method', 'applying method arbitrary', 'method arbitrary context', 'arbitrary context moreover', 'context moreover although', 'moreover although user', 'although user might', 'user might voluntarily', 'might voluntarily relating', 'voluntarily relating one', 'relating one mental', 'one mental health', 'mental health disorder', 'health disorder category', 'disorder category unclear', 'category unclear extent', 'unclear extent constitutes', 'extent constitutes online', 'constitutes online identity', 'online identity construction', 'identity construction activity', 'construction activity importantly', 'activity importantly challenging', 'importantly challenging ass', 'challenging ass gravity', 'ass gravity given', 'gravity given user', 'given user health', 'user health condition', 'health condition using', 'condition using post', 'using post image', 'post image alone', 'image alone specifically', 'alone specifically actually', 'specifically actually experiencing', 'actually experiencing clinical', 'experiencing clinical mental', 'clinical mental health', 'mental health concern', 'health concern related', 'concern related note', 'related note although', 'note although tag', 'although tag employed', 'tag employed obtaining', 'employed obtaining mental', 'obtaining mental health', 'mental health data', 'health data verified', 'data verified consultation', 'verified consultation licensed', 'consultation licensed psychiatrist', 'licensed psychiatrist claim', 'psychiatrist claim method', 'claim method reveal', 'method reveal symptom', 'reveal symptom diagnostic', 'symptom diagnostic marker', 'diagnostic marker mental', 'marker mental illness', 'mental illness individual', 'illness individual therefore', 'individual therefore method', 'therefore method developed', 'method developed paper', 'developed paper evaluated', 'paper evaluated effectiveness', 'evaluated effectiveness discovering', 'effectiveness discovering mental', 'discovering mental health', 'mental health concern', 'health concern rather', 'concern rather principled', 'rather principled quantifiable', 'principled quantifiable way', 'quantifiable way understand', 'way understand nature', 'understand nature mental', 'nature mental health', 'mental health disclosure', 'health disclosure shared', 'disclosure shared social', 'shared social medium', 'social medium putting', 'medium putting together', 'putting together finding', 'together finding interpreted', 'finding interpreted diagnostic', 'interpreted diagnostic claim', 'diagnostic claim one', 'claim one mental', 'one mental health', 'mental health advocate', 'health advocate collaboration', 'advocate collaboration clinician', 'collaboration clinician hci', 'clinician hci researcher', 'hci researcher along', 'researcher along voluntarily', 'along voluntarily consenting', 'voluntarily consenting patient', 'consenting patient constitutes', 'patient constitutes one', 'constitutes one future', 'one future research', 'future research direction', 'research direction finally', 'direction finally qualitative', 'finally qualitative method', 'qualitative method would', 'method would lend', 'would lend deeper', 'lend deeper understanding', 'deeper understanding motivation', 'understanding motivation behind', 'motivation behind appropriating', 'behind appropriating public', 'appropriating public social', 'public social medium', 'social medium outlet', 'medium outlet vulnerable', 'outlet vulnerable sensitive', 'vulnerable sensitive exchange', 'sensitive exchange also', 'exchange also emphasize', 'also emphasize analyzed', 'emphasize analyzed visual', 'analyzed visual linguistic', 'visual linguistic pattern', 'linguistic pattern instagram', 'pattern instagram pattern', 'instagram pattern help', 'pattern help study', 'help study selfdisclosure', 'study selfdisclosure indeed', 'selfdisclosure indeed current', 'indeed current advancement', 'current advancement machine', 'advancement machine learning', 'machine learning approach', 'learning approach like', 'approach like deep', 'like deep learning', 'deep learning created', 'learning created new', 'created new thread', 'new thread research', 'thread research image', 'research image classification', 'image classification image', 'classification image classification', 'image classification problem', 'classification problem difficult', 'problem difficult solve', 'difficult solve solved', 'solve solved efficiently', 'solved efficiently believe', 'efficiently believe method', 'believe method incorporated', 'method incorporated study', 'incorporated study mental', 'study mental health', 'mental health imagery', 'health imagery shared', 'imagery shared social', 'shared social medium']",,,,,,,,
https://www.sciencedirect.com/science/article/pii/S0747563215300996,0,Tweets about depression were collected by Simply Measured a company that specializes in social media measurement and analytics (Simply Measured 2014). Simply Measured has access to the Twitter “firehose” (or full volume of tweets) via Gnip a licensed company that can retrieve the full Twitter data stream. All tweets in the English language that contained at least either “depressed” “#depressed” “depression” or “#depression” were collected between April 11 and May 4 2014. We scanned a random sample of the tweets to identify common phrases that included our keywords of interest but were not about mental health. In SAS version 9.3 (SAS Institute Inc. Cary NC) we used the index function which searches a character expression (in this case the text of the tweet) for a specific string of characters to locate and remove such tweets from our sample. We removed tweets that included the following terms regardless of capitalization: “Great Depression” “economic depression” “during the depression” “depression era” “tropical depression” and “depressed real estate”. The popularity and influence of the Tweeters was described using the distribution of followers and Klout Scores. While number of followers is a measure of popularity Klout Score is a measure of influence. Klout Scores range from 0 to 100 with a higher score indicating higher influence. Klout Score is calculated based on an algorithm that considers over 400 signals from eight different online networks. Examples of signals include the amount of retweets a person generates in relation to the amount of tweets shared and the amount of engagement a user drives from unique individuals (e.g. lots of retweets from different individuals as opposed to lots of retweets from one person) (Klout Inc. 2014).Using the SAS surveyselect procedure we selected a simple random sample of 2000 tweets (that were not direct @replies) from the total volume of depression-related tweets. Two members of the research team each with graduate level degrees (i.e. Ph.D. and M.P.H) and more than 10 years of experience in mental health research scanned approximately 300 random tweets in order to determine their most common themes and generate a codebook. We defined themes as topics that occur and reoccur (Ryan & Bernard 2003). Tweets were coded for presence of the following themes: 1) Tweeter discloses feelings of depression; 2) Tweet is a supportive or helpful message about depression; 3) Tweeter discloses feeling school or work-related pressures related to depression; 4) Tweeter engages in substance use to deal with depression; and 5) Tweeter discloses self-harm or suicidal thoughts. Tweets could be assigned as many themes as were pertinent. For tweets where the user indicated that he or she was feeling depressed those that appeared trivial (i.e. not concerning) were identified. These were tweets where the depression terms were used casually or in a humorous manner or referenced depression caused by trivial things such as being depressed after finishing a good book seeing a concert or watching a sad movie. In addition we ascertained the source of the tweet by viewing the Tweeter's profile picture and studying their Twitter handle name. The source was then coded into one of the three following categories: clinician/therapist health-focused handle (e.g. health/government organization handle focused on healthy lifestyle etc.) or regular person or other (handle did not fall into the above categories). Using this codebook the 2000 randomly sampled tweets were coded in teams of two trained student research interns who coded the tweets together discussing each tweet and coming to an agreement on the final assigned codes. A sample of 150 tweets was also coded by a senior team member (Ph.D. clinician) with extensive mental health research experience. Inter-coder reliability for each theme was as follows: 1) Tweeter discloses feelings of depression: percent agreement 85% kappa 0.67; 2) Tweet is a supportive or helpful message about depression: percent agreement 85% kappa 0.70; 3) Tweeter discloses feeling school or work-related pressures related to depression: percent agreement 98% kappa 0.72; 4) Tweeter engages in substance use to deal with depression: percent agreement 100% kappa 1.0; 5) Tweeter discloses self-harm or suicidal thoughts: percent agreement 98% kappa 0.56; 6) trivial disclosures of depression: percent agreement 90% kappa 0.70; 7) source of Tweet: percent agreement 91% kappa 0.51. Because both prevalence of and kappa for diminished ability to think/concentrate were low we chose not to report on this code.Demographics Pro was used to infer the demographic characteristics of the individuals who disclosed feeling depressed in the tweets that were examined in the present study (Demographics Pro for Twitter 2014). The demographic characteristics examined include: age gender race/ethnicity marital status income occupation and location of the Tweeter. In order to assess for patterns in Twitter interests the most likely Twitter handles that are being followed by the Tweeters were also provided. Demographics Pro uses a series of proprietary algorithms to estimate or infer likely demographic characteristics of Twitter handles based on Twitter behavior/usage. Their predictions rely on multiple data signals from networks (signals imparted by the nature and strength of ties between individuals on Twitter) consumption (consumption of information on Twitter revealed by accounts followed and real-world consumption revealed by Twitter usage) and language (words and phrased used in tweets and bios). Demographics Pro has used their methodology to profile some 300 million Twitter users to date and requires confidence of 95% or above to make an estimate of a single demographic characteristic. For example if 10000 predictions are made 9500 would need to be correct in order to accept the methodology used to make the prediction. The success of the Demographics Pro analytic predictions relies on the relatively low covariance of multiple amplified signals. Iterative evaluation testing the methodologies on training sets of established samples of Twitter users with verified demographics allows the calibration of balance between depth of coverage (the number of demographic predictions made) and required accuracy. The size of these established samples of Twitter users with verified demographics varies from 10000 to 200000 people depending on the specific demographic characteristic to be inferred. For comparison purposes inferred demographic characteristics across a sample of 20000 randomly selected English-language Twitter users in the U.S. and Canada were also provided by Demographics Pro. We used Pearson chi square tests to compare the inferred characteristics of Tweeters from our sample who expressed feelings of depression versus the typical Twitter user. P < .05 was considered statistically significant.,tweet about depression were collected by simply measured a company that specializes in social medium measurement and analytics simply measured simply measured ha access to the twitter firehose or full volume of tweet via gnip a licensed company that can retrieve the full twitter data stream all tweet in the english language that contained at least either depressed depressed depression or depression were collected between april and may we scanned a random sample of the tweet to identify common phrase that included our keywords of interest but were not about mental health in sa version sa institute inc cary nc we used the index function which search a character expression in this case the text of the tweet for a specific string of character to locate and remove such tweet from our sample we removed tweet that included the following term regardless of capitalization great depression economic depression during the depression depression era tropical depression and depressed real estate the popularity and influence of the tweeter wa described using the distribution of follower and klout score while number of follower is a measure of popularity klout score is a measure of influence klout score range from to with a higher score indicating higher influence klout score is calculated based on an algorithm that considers over signal from eight different online network example of signal include the amount of retweets a person generates in relation to the amount of tweet shared and the amount of engagement a user drive from unique individual eg lot of retweets from different individual a opposed to lot of retweets from one person klout inc using the sa surveyselect procedure we selected a simple random sample of tweet that were not direct reply from the total volume of depressionrelated tweet two member of the research team each with graduate level degree ie phd and mph and more than year of experience in mental health research scanned approximately random tweet in order to determine their most common theme and generate a codebook we defined theme a topic that occur and reoccur ryan bernard tweet were coded for presence of the following theme tweeter discloses feeling of depression tweet is a supportive or helpful message about depression tweeter discloses feeling school or workrelated pressure related to depression tweeter engages in substance use to deal with depression and tweeter discloses selfharm or suicidal thought tweet could be assigned a many theme a were pertinent for tweet where the user indicated that he or she wa feeling depressed those that appeared trivial ie not concerning were identified these were tweet where the depression term were used casually or in a humorous manner or referenced depression caused by trivial thing such a being depressed after finishing a good book seeing a concert or watching a sad movie in addition we ascertained the source of the tweet by viewing the tweeter profile picture and studying their twitter handle name the source wa then coded into one of the three following category cliniciantherapist healthfocused handle eg healthgovernment organization handle focused on healthy lifestyle etc or regular person or other handle did not fall into the above category using this codebook the randomly sampled tweet were coded in team of two trained student research intern who coded the tweet together discussing each tweet and coming to an agreement on the final assigned code a sample of tweet wa also coded by a senior team member phd clinician with extensive mental health research experience intercoder reliability for each theme wa a follows tweeter discloses feeling of depression percent agreement kappa tweet is a supportive or helpful message about depression percent agreement kappa tweeter discloses feeling school or workrelated pressure related to depression percent agreement kappa tweeter engages in substance use to deal with depression percent agreement kappa tweeter discloses selfharm or suicidal thought percent agreement kappa trivial disclosure of depression percent agreement kappa source of tweet percent agreement kappa because both prevalence of and kappa for diminished ability to thinkconcentrate were low we chose not to report on this codedemographics pro wa used to infer the demographic characteristic of the individual who disclosed feeling depressed in the tweet that were examined in the present study demographic pro for twitter the demographic characteristic examined include age gender raceethnicity marital status income occupation and location of the tweeter in order to ass for pattern in twitter interest the most likely twitter handle that are being followed by the tweeter were also provided demographic pro us a series of proprietary algorithm to estimate or infer likely demographic characteristic of twitter handle based on twitter behaviorusage their prediction rely on multiple data signal from network signal imparted by the nature and strength of tie between individual on twitter consumption consumption of information on twitter revealed by account followed and realworld consumption revealed by twitter usage and language word and phrased used in tweet and bios demographic pro ha used their methodology to profile some million twitter user to date and requires confidence of or above to make an estimate of a single demographic characteristic for example if prediction are made would need to be correct in order to accept the methodology used to make the prediction the success of the demographic pro analytic prediction relies on the relatively low covariance of multiple amplified signal iterative evaluation testing the methodology on training set of established sample of twitter user with verified demographic allows the calibration of balance between depth of coverage the number of demographic prediction made and required accuracy the size of these established sample of twitter user with verified demographic varies from to people depending on the specific demographic characteristic to be inferred for comparison purpose inferred demographic characteristic across a sample of randomly selected englishlanguage twitter user in the u and canada were also provided by demographic pro we used pearson chi square test to compare the inferred characteristic of tweeter from our sample who expressed feeling of depression versus the typical twitter user p wa considered statistically significant,"['tweet', 'depression', 'collected', 'simply', 'measured', 'company', 'specializes', 'social', 'medium', 'measurement', 'analytics', 'simply', 'measured', 'simply', 'measured', 'ha', 'access', 'twitter', 'firehose', 'full', 'volume', 'tweet', 'via', 'gnip', 'licensed', 'company', 'retrieve', 'full', 'twitter', 'data', 'stream', 'tweet', 'english', 'language', 'contained', 'least', 'either', 'depressed', 'depressed', 'depression', 'depression', 'collected', 'april', 'may', 'scanned', 'random', 'sample', 'tweet', 'identify', 'common', 'phrase', 'included', 'keywords', 'interest', 'mental', 'health', 'sa', 'version', 'sa', 'institute', 'inc', 'cary', 'nc', 'used', 'index', 'function', 'search', 'character', 'expression', 'case', 'text', 'tweet', 'specific', 'string', 'character', 'locate', 'remove', 'tweet', 'sample', 'removed', 'tweet', 'included', 'following', 'term', 'regardless', 'capitalization', 'great', 'depression', 'economic', 'depression', 'depression', 'depression', 'era', 'tropical', 'depression', 'depressed', 'real', 'estate', 'popularity', 'influence', 'tweeter', 'wa', 'described', 'using', 'distribution', 'follower', 'klout', 'score', 'number', 'follower', 'measure', 'popularity', 'klout', 'score', 'measure', 'influence', 'klout', 'score', 'range', 'higher', 'score', 'indicating', 'higher', 'influence', 'klout', 'score', 'calculated', 'based', 'algorithm', 'considers', 'signal', 'eight', 'different', 'online', 'network', 'example', 'signal', 'include', 'amount', 'retweets', 'person', 'generates', 'relation', 'amount', 'tweet', 'shared', 'amount', 'engagement', 'user', 'drive', 'unique', 'individual', 'eg', 'lot', 'retweets', 'different', 'individual', 'opposed', 'lot', 'retweets', 'one', 'person', 'klout', 'inc', 'using', 'sa', 'surveyselect', 'procedure', 'selected', 'simple', 'random', 'sample', 'tweet', 'direct', 'reply', 'total', 'volume', 'depressionrelated', 'tweet', 'two', 'member', 'research', 'team', 'graduate', 'level', 'degree', 'ie', 'phd', 'mph', 'year', 'experience', 'mental', 'health', 'research', 'scanned', 'approximately', 'random', 'tweet', 'order', 'determine', 'common', 'theme', 'generate', 'codebook', 'defined', 'theme', 'topic', 'occur', 'reoccur', 'ryan', 'bernard', 'tweet', 'coded', 'presence', 'following', 'theme', 'tweeter', 'discloses', 'feeling', 'depression', 'tweet', 'supportive', 'helpful', 'message', 'depression', 'tweeter', 'discloses', 'feeling', 'school', 'workrelated', 'pressure', 'related', 'depression', 'tweeter', 'engages', 'substance', 'use', 'deal', 'depression', 'tweeter', 'discloses', 'selfharm', 'suicidal', 'thought', 'tweet', 'could', 'assigned', 'many', 'theme', 'pertinent', 'tweet', 'user', 'indicated', 'wa', 'feeling', 'depressed', 'appeared', 'trivial', 'ie', 'concerning', 'identified', 'tweet', 'depression', 'term', 'used', 'casually', 'humorous', 'manner', 'referenced', 'depression', 'caused', 'trivial', 'thing', 'depressed', 'finishing', 'good', 'book', 'seeing', 'concert', 'watching', 'sad', 'movie', 'addition', 'ascertained', 'source', 'tweet', 'viewing', 'tweeter', 'profile', 'picture', 'studying', 'twitter', 'handle', 'name', 'source', 'wa', 'coded', 'one', 'three', 'following', 'category', 'cliniciantherapist', 'healthfocused', 'handle', 'eg', 'healthgovernment', 'organization', 'handle', 'focused', 'healthy', 'lifestyle', 'etc', 'regular', 'person', 'handle', 'fall', 'category', 'using', 'codebook', 'randomly', 'sampled', 'tweet', 'coded', 'team', 'two', 'trained', 'student', 'research', 'intern', 'coded', 'tweet', 'together', 'discussing', 'tweet', 'coming', 'agreement', 'final', 'assigned', 'code', 'sample', 'tweet', 'wa', 'also', 'coded', 'senior', 'team', 'member', 'phd', 'clinician', 'extensive', 'mental', 'health', 'research', 'experience', 'intercoder', 'reliability', 'theme', 'wa', 'follows', 'tweeter', 'discloses', 'feeling', 'depression', 'percent', 'agreement', 'kappa', 'tweet', 'supportive', 'helpful', 'message', 'depression', 'percent', 'agreement', 'kappa', 'tweeter', 'discloses', 'feeling', 'school', 'workrelated', 'pressure', 'related', 'depression', 'percent', 'agreement', 'kappa', 'tweeter', 'engages', 'substance', 'use', 'deal', 'depression', 'percent', 'agreement', 'kappa', 'tweeter', 'discloses', 'selfharm', 'suicidal', 'thought', 'percent', 'agreement', 'kappa', 'trivial', 'disclosure', 'depression', 'percent', 'agreement', 'kappa', 'source', 'tweet', 'percent', 'agreement', 'kappa', 'prevalence', 'kappa', 'diminished', 'ability', 'thinkconcentrate', 'low', 'chose', 'report', 'codedemographics', 'pro', 'wa', 'used', 'infer', 'demographic', 'characteristic', 'individual', 'disclosed', 'feeling', 'depressed', 'tweet', 'examined', 'present', 'study', 'demographic', 'pro', 'twitter', 'demographic', 'characteristic', 'examined', 'include', 'age', 'gender', 'raceethnicity', 'marital', 'status', 'income', 'occupation', 'location', 'tweeter', 'order', 'ass', 'pattern', 'twitter', 'interest', 'likely', 'twitter', 'handle', 'followed', 'tweeter', 'also', 'provided', 'demographic', 'pro', 'us', 'series', 'proprietary', 'algorithm', 'estimate', 'infer', 'likely', 'demographic', 'characteristic', 'twitter', 'handle', 'based', 'twitter', 'behaviorusage', 'prediction', 'rely', 'multiple', 'data', 'signal', 'network', 'signal', 'imparted', 'nature', 'strength', 'tie', 'individual', 'twitter', 'consumption', 'consumption', 'information', 'twitter', 'revealed', 'account', 'followed', 'realworld', 'consumption', 'revealed', 'twitter', 'usage', 'language', 'word', 'phrased', 'used', 'tweet', 'bios', 'demographic', 'pro', 'ha', 'used', 'methodology', 'profile', 'million', 'twitter', 'user', 'date', 'requires', 'confidence', 'make', 'estimate', 'single', 'demographic', 'characteristic', 'example', 'prediction', 'made', 'would', 'need', 'correct', 'order', 'accept', 'methodology', 'used', 'make', 'prediction', 'success', 'demographic', 'pro', 'analytic', 'prediction', 'relies', 'relatively', 'low', 'covariance', 'multiple', 'amplified', 'signal', 'iterative', 'evaluation', 'testing', 'methodology', 'training', 'set', 'established', 'sample', 'twitter', 'user', 'verified', 'demographic', 'allows', 'calibration', 'balance', 'depth', 'coverage', 'number', 'demographic', 'prediction', 'made', 'required', 'accuracy', 'size', 'established', 'sample', 'twitter', 'user', 'verified', 'demographic', 'varies', 'people', 'depending', 'specific', 'demographic', 'characteristic', 'inferred', 'comparison', 'purpose', 'inferred', 'demographic', 'characteristic', 'across', 'sample', 'randomly', 'selected', 'englishlanguage', 'twitter', 'user', 'u', 'canada', 'also', 'provided', 'demographic', 'pro', 'used', 'pearson', 'chi', 'square', 'test', 'compare', 'inferred', 'characteristic', 'tweeter', 'sample', 'expressed', 'feeling', 'depression', 'versus', 'typical', 'twitter', 'user', 'p', 'wa', 'considered', 'statistically', 'significant']","['tweet depression', 'depression collected', 'collected simply', 'simply measured', 'measured company', 'company specializes', 'specializes social', 'social medium', 'medium measurement', 'measurement analytics', 'analytics simply', 'simply measured', 'measured simply', 'simply measured', 'measured ha', 'ha access', 'access twitter', 'twitter firehose', 'firehose full', 'full volume', 'volume tweet', 'tweet via', 'via gnip', 'gnip licensed', 'licensed company', 'company retrieve', 'retrieve full', 'full twitter', 'twitter data', 'data stream', 'stream tweet', 'tweet english', 'english language', 'language contained', 'contained least', 'least either', 'either depressed', 'depressed depressed', 'depressed depression', 'depression depression', 'depression collected', 'collected april', 'april may', 'may scanned', 'scanned random', 'random sample', 'sample tweet', 'tweet identify', 'identify common', 'common phrase', 'phrase included', 'included keywords', 'keywords interest', 'interest mental', 'mental health', 'health sa', 'sa version', 'version sa', 'sa institute', 'institute inc', 'inc cary', 'cary nc', 'nc used', 'used index', 'index function', 'function search', 'search character', 'character expression', 'expression case', 'case text', 'text tweet', 'tweet specific', 'specific string', 'string character', 'character locate', 'locate remove', 'remove tweet', 'tweet sample', 'sample removed', 'removed tweet', 'tweet included', 'included following', 'following term', 'term regardless', 'regardless capitalization', 'capitalization great', 'great depression', 'depression economic', 'economic depression', 'depression depression', 'depression depression', 'depression era', 'era tropical', 'tropical depression', 'depression depressed', 'depressed real', 'real estate', 'estate popularity', 'popularity influence', 'influence tweeter', 'tweeter wa', 'wa described', 'described using', 'using distribution', 'distribution follower', 'follower klout', 'klout score', 'score number', 'number follower', 'follower measure', 'measure popularity', 'popularity klout', 'klout score', 'score measure', 'measure influence', 'influence klout', 'klout score', 'score range', 'range higher', 'higher score', 'score indicating', 'indicating higher', 'higher influence', 'influence klout', 'klout score', 'score calculated', 'calculated based', 'based algorithm', 'algorithm considers', 'considers signal', 'signal eight', 'eight different', 'different online', 'online network', 'network example', 'example signal', 'signal include', 'include amount', 'amount retweets', 'retweets person', 'person generates', 'generates relation', 'relation amount', 'amount tweet', 'tweet shared', 'shared amount', 'amount engagement', 'engagement user', 'user drive', 'drive unique', 'unique individual', 'individual eg', 'eg lot', 'lot retweets', 'retweets different', 'different individual', 'individual opposed', 'opposed lot', 'lot retweets', 'retweets one', 'one person', 'person klout', 'klout inc', 'inc using', 'using sa', 'sa surveyselect', 'surveyselect procedure', 'procedure selected', 'selected simple', 'simple random', 'random sample', 'sample tweet', 'tweet direct', 'direct reply', 'reply total', 'total volume', 'volume depressionrelated', 'depressionrelated tweet', 'tweet two', 'two member', 'member research', 'research team', 'team graduate', 'graduate level', 'level degree', 'degree ie', 'ie phd', 'phd mph', 'mph year', 'year experience', 'experience mental', 'mental health', 'health research', 'research scanned', 'scanned approximately', 'approximately random', 'random tweet', 'tweet order', 'order determine', 'determine common', 'common theme', 'theme generate', 'generate codebook', 'codebook defined', 'defined theme', 'theme topic', 'topic occur', 'occur reoccur', 'reoccur ryan', 'ryan bernard', 'bernard tweet', 'tweet coded', 'coded presence', 'presence following', 'following theme', 'theme tweeter', 'tweeter discloses', 'discloses feeling', 'feeling depression', 'depression tweet', 'tweet supportive', 'supportive helpful', 'helpful message', 'message depression', 'depression tweeter', 'tweeter discloses', 'discloses feeling', 'feeling school', 'school workrelated', 'workrelated pressure', 'pressure related', 'related depression', 'depression tweeter', 'tweeter engages', 'engages substance', 'substance use', 'use deal', 'deal depression', 'depression tweeter', 'tweeter discloses', 'discloses selfharm', 'selfharm suicidal', 'suicidal thought', 'thought tweet', 'tweet could', 'could assigned', 'assigned many', 'many theme', 'theme pertinent', 'pertinent tweet', 'tweet user', 'user indicated', 'indicated wa', 'wa feeling', 'feeling depressed', 'depressed appeared', 'appeared trivial', 'trivial ie', 'ie concerning', 'concerning identified', 'identified tweet', 'tweet depression', 'depression term', 'term used', 'used casually', 'casually humorous', 'humorous manner', 'manner referenced', 'referenced depression', 'depression caused', 'caused trivial', 'trivial thing', 'thing depressed', 'depressed finishing', 'finishing good', 'good book', 'book seeing', 'seeing concert', 'concert watching', 'watching sad', 'sad movie', 'movie addition', 'addition ascertained', 'ascertained source', 'source tweet', 'tweet viewing', 'viewing tweeter', 'tweeter profile', 'profile picture', 'picture studying', 'studying twitter', 'twitter handle', 'handle name', 'name source', 'source wa', 'wa coded', 'coded one', 'one three', 'three following', 'following category', 'category cliniciantherapist', 'cliniciantherapist healthfocused', 'healthfocused handle', 'handle eg', 'eg healthgovernment', 'healthgovernment organization', 'organization handle', 'handle focused', 'focused healthy', 'healthy lifestyle', 'lifestyle etc', 'etc regular', 'regular person', 'person handle', 'handle fall', 'fall category', 'category using', 'using codebook', 'codebook randomly', 'randomly sampled', 'sampled tweet', 'tweet coded', 'coded team', 'team two', 'two trained', 'trained student', 'student research', 'research intern', 'intern coded', 'coded tweet', 'tweet together', 'together discussing', 'discussing tweet', 'tweet coming', 'coming agreement', 'agreement final', 'final assigned', 'assigned code', 'code sample', 'sample tweet', 'tweet wa', 'wa also', 'also coded', 'coded senior', 'senior team', 'team member', 'member phd', 'phd clinician', 'clinician extensive', 'extensive mental', 'mental health', 'health research', 'research experience', 'experience intercoder', 'intercoder reliability', 'reliability theme', 'theme wa', 'wa follows', 'follows tweeter', 'tweeter discloses', 'discloses feeling', 'feeling depression', 'depression percent', 'percent agreement', 'agreement kappa', 'kappa tweet', 'tweet supportive', 'supportive helpful', 'helpful message', 'message depression', 'depression percent', 'percent agreement', 'agreement kappa', 'kappa tweeter', 'tweeter discloses', 'discloses feeling', 'feeling school', 'school workrelated', 'workrelated pressure', 'pressure related', 'related depression', 'depression percent', 'percent agreement', 'agreement kappa', 'kappa tweeter', 'tweeter engages', 'engages substance', 'substance use', 'use deal', 'deal depression', 'depression percent', 'percent agreement', 'agreement kappa', 'kappa tweeter', 'tweeter discloses', 'discloses selfharm', 'selfharm suicidal', 'suicidal thought', 'thought percent', 'percent agreement', 'agreement kappa', 'kappa trivial', 'trivial disclosure', 'disclosure depression', 'depression percent', 'percent agreement', 'agreement kappa', 'kappa source', 'source tweet', 'tweet percent', 'percent agreement', 'agreement kappa', 'kappa prevalence', 'prevalence kappa', 'kappa diminished', 'diminished ability', 'ability thinkconcentrate', 'thinkconcentrate low', 'low chose', 'chose report', 'report codedemographics', 'codedemographics pro', 'pro wa', 'wa used', 'used infer', 'infer demographic', 'demographic characteristic', 'characteristic individual', 'individual disclosed', 'disclosed feeling', 'feeling depressed', 'depressed tweet', 'tweet examined', 'examined present', 'present study', 'study demographic', 'demographic pro', 'pro twitter', 'twitter demographic', 'demographic characteristic', 'characteristic examined', 'examined include', 'include age', 'age gender', 'gender raceethnicity', 'raceethnicity marital', 'marital status', 'status income', 'income occupation', 'occupation location', 'location tweeter', 'tweeter order', 'order ass', 'ass pattern', 'pattern twitter', 'twitter interest', 'interest likely', 'likely twitter', 'twitter handle', 'handle followed', 'followed tweeter', 'tweeter also', 'also provided', 'provided demographic', 'demographic pro', 'pro us', 'us series', 'series proprietary', 'proprietary algorithm', 'algorithm estimate', 'estimate infer', 'infer likely', 'likely demographic', 'demographic characteristic', 'characteristic twitter', 'twitter handle', 'handle based', 'based twitter', 'twitter behaviorusage', 'behaviorusage prediction', 'prediction rely', 'rely multiple', 'multiple data', 'data signal', 'signal network', 'network signal', 'signal imparted', 'imparted nature', 'nature strength', 'strength tie', 'tie individual', 'individual twitter', 'twitter consumption', 'consumption consumption', 'consumption information', 'information twitter', 'twitter revealed', 'revealed account', 'account followed', 'followed realworld', 'realworld consumption', 'consumption revealed', 'revealed twitter', 'twitter usage', 'usage language', 'language word', 'word phrased', 'phrased used', 'used tweet', 'tweet bios', 'bios demographic', 'demographic pro', 'pro ha', 'ha used', 'used methodology', 'methodology profile', 'profile million', 'million twitter', 'twitter user', 'user date', 'date requires', 'requires confidence', 'confidence make', 'make estimate', 'estimate single', 'single demographic', 'demographic characteristic', 'characteristic example', 'example prediction', 'prediction made', 'made would', 'would need', 'need correct', 'correct order', 'order accept', 'accept methodology', 'methodology used', 'used make', 'make prediction', 'prediction success', 'success demographic', 'demographic pro', 'pro analytic', 'analytic prediction', 'prediction relies', 'relies relatively', 'relatively low', 'low covariance', 'covariance multiple', 'multiple amplified', 'amplified signal', 'signal iterative', 'iterative evaluation', 'evaluation testing', 'testing methodology', 'methodology training', 'training set', 'set established', 'established sample', 'sample twitter', 'twitter user', 'user verified', 'verified demographic', 'demographic allows', 'allows calibration', 'calibration balance', 'balance depth', 'depth coverage', 'coverage number', 'number demographic', 'demographic prediction', 'prediction made', 'made required', 'required accuracy', 'accuracy size', 'size established', 'established sample', 'sample twitter', 'twitter user', 'user verified', 'verified demographic', 'demographic varies', 'varies people', 'people depending', 'depending specific', 'specific demographic', 'demographic characteristic', 'characteristic inferred', 'inferred comparison', 'comparison purpose', 'purpose inferred', 'inferred demographic', 'demographic characteristic', 'characteristic across', 'across sample', 'sample randomly', 'randomly selected', 'selected englishlanguage', 'englishlanguage twitter', 'twitter user', 'user u', 'u canada', 'canada also', 'also provided', 'provided demographic', 'demographic pro', 'pro used', 'used pearson', 'pearson chi', 'chi square', 'square test', 'test compare', 'compare inferred', 'inferred characteristic', 'characteristic tweeter', 'tweeter sample', 'sample expressed', 'expressed feeling', 'feeling depression', 'depression versus', 'versus typical', 'typical twitter', 'twitter user', 'user p', 'p wa', 'wa considered', 'considered statistically', 'statistically significant']","['tweet depression collected', 'depression collected simply', 'collected simply measured', 'simply measured company', 'measured company specializes', 'company specializes social', 'specializes social medium', 'social medium measurement', 'medium measurement analytics', 'measurement analytics simply', 'analytics simply measured', 'simply measured simply', 'measured simply measured', 'simply measured ha', 'measured ha access', 'ha access twitter', 'access twitter firehose', 'twitter firehose full', 'firehose full volume', 'full volume tweet', 'volume tweet via', 'tweet via gnip', 'via gnip licensed', 'gnip licensed company', 'licensed company retrieve', 'company retrieve full', 'retrieve full twitter', 'full twitter data', 'twitter data stream', 'data stream tweet', 'stream tweet english', 'tweet english language', 'english language contained', 'language contained least', 'contained least either', 'least either depressed', 'either depressed depressed', 'depressed depressed depression', 'depressed depression depression', 'depression depression collected', 'depression collected april', 'collected april may', 'april may scanned', 'may scanned random', 'scanned random sample', 'random sample tweet', 'sample tweet identify', 'tweet identify common', 'identify common phrase', 'common phrase included', 'phrase included keywords', 'included keywords interest', 'keywords interest mental', 'interest mental health', 'mental health sa', 'health sa version', 'sa version sa', 'version sa institute', 'sa institute inc', 'institute inc cary', 'inc cary nc', 'cary nc used', 'nc used index', 'used index function', 'index function search', 'function search character', 'search character expression', 'character expression case', 'expression case text', 'case text tweet', 'text tweet specific', 'tweet specific string', 'specific string character', 'string character locate', 'character locate remove', 'locate remove tweet', 'remove tweet sample', 'tweet sample removed', 'sample removed tweet', 'removed tweet included', 'tweet included following', 'included following term', 'following term regardless', 'term regardless capitalization', 'regardless capitalization great', 'capitalization great depression', 'great depression economic', 'depression economic depression', 'economic depression depression', 'depression depression depression', 'depression depression era', 'depression era tropical', 'era tropical depression', 'tropical depression depressed', 'depression depressed real', 'depressed real estate', 'real estate popularity', 'estate popularity influence', 'popularity influence tweeter', 'influence tweeter wa', 'tweeter wa described', 'wa described using', 'described using distribution', 'using distribution follower', 'distribution follower klout', 'follower klout score', 'klout score number', 'score number follower', 'number follower measure', 'follower measure popularity', 'measure popularity klout', 'popularity klout score', 'klout score measure', 'score measure influence', 'measure influence klout', 'influence klout score', 'klout score range', 'score range higher', 'range higher score', 'higher score indicating', 'score indicating higher', 'indicating higher influence', 'higher influence klout', 'influence klout score', 'klout score calculated', 'score calculated based', 'calculated based algorithm', 'based algorithm considers', 'algorithm considers signal', 'considers signal eight', 'signal eight different', 'eight different online', 'different online network', 'online network example', 'network example signal', 'example signal include', 'signal include amount', 'include amount retweets', 'amount retweets person', 'retweets person generates', 'person generates relation', 'generates relation amount', 'relation amount tweet', 'amount tweet shared', 'tweet shared amount', 'shared amount engagement', 'amount engagement user', 'engagement user drive', 'user drive unique', 'drive unique individual', 'unique individual eg', 'individual eg lot', 'eg lot retweets', 'lot retweets different', 'retweets different individual', 'different individual opposed', 'individual opposed lot', 'opposed lot retweets', 'lot retweets one', 'retweets one person', 'one person klout', 'person klout inc', 'klout inc using', 'inc using sa', 'using sa surveyselect', 'sa surveyselect procedure', 'surveyselect procedure selected', 'procedure selected simple', 'selected simple random', 'simple random sample', 'random sample tweet', 'sample tweet direct', 'tweet direct reply', 'direct reply total', 'reply total volume', 'total volume depressionrelated', 'volume depressionrelated tweet', 'depressionrelated tweet two', 'tweet two member', 'two member research', 'member research team', 'research team graduate', 'team graduate level', 'graduate level degree', 'level degree ie', 'degree ie phd', 'ie phd mph', 'phd mph year', 'mph year experience', 'year experience mental', 'experience mental health', 'mental health research', 'health research scanned', 'research scanned approximately', 'scanned approximately random', 'approximately random tweet', 'random tweet order', 'tweet order determine', 'order determine common', 'determine common theme', 'common theme generate', 'theme generate codebook', 'generate codebook defined', 'codebook defined theme', 'defined theme topic', 'theme topic occur', 'topic occur reoccur', 'occur reoccur ryan', 'reoccur ryan bernard', 'ryan bernard tweet', 'bernard tweet coded', 'tweet coded presence', 'coded presence following', 'presence following theme', 'following theme tweeter', 'theme tweeter discloses', 'tweeter discloses feeling', 'discloses feeling depression', 'feeling depression tweet', 'depression tweet supportive', 'tweet supportive helpful', 'supportive helpful message', 'helpful message depression', 'message depression tweeter', 'depression tweeter discloses', 'tweeter discloses feeling', 'discloses feeling school', 'feeling school workrelated', 'school workrelated pressure', 'workrelated pressure related', 'pressure related depression', 'related depression tweeter', 'depression tweeter engages', 'tweeter engages substance', 'engages substance use', 'substance use deal', 'use deal depression', 'deal depression tweeter', 'depression tweeter discloses', 'tweeter discloses selfharm', 'discloses selfharm suicidal', 'selfharm suicidal thought', 'suicidal thought tweet', 'thought tweet could', 'tweet could assigned', 'could assigned many', 'assigned many theme', 'many theme pertinent', 'theme pertinent tweet', 'pertinent tweet user', 'tweet user indicated', 'user indicated wa', 'indicated wa feeling', 'wa feeling depressed', 'feeling depressed appeared', 'depressed appeared trivial', 'appeared trivial ie', 'trivial ie concerning', 'ie concerning identified', 'concerning identified tweet', 'identified tweet depression', 'tweet depression term', 'depression term used', 'term used casually', 'used casually humorous', 'casually humorous manner', 'humorous manner referenced', 'manner referenced depression', 'referenced depression caused', 'depression caused trivial', 'caused trivial thing', 'trivial thing depressed', 'thing depressed finishing', 'depressed finishing good', 'finishing good book', 'good book seeing', 'book seeing concert', 'seeing concert watching', 'concert watching sad', 'watching sad movie', 'sad movie addition', 'movie addition ascertained', 'addition ascertained source', 'ascertained source tweet', 'source tweet viewing', 'tweet viewing tweeter', 'viewing tweeter profile', 'tweeter profile picture', 'profile picture studying', 'picture studying twitter', 'studying twitter handle', 'twitter handle name', 'handle name source', 'name source wa', 'source wa coded', 'wa coded one', 'coded one three', 'one three following', 'three following category', 'following category cliniciantherapist', 'category cliniciantherapist healthfocused', 'cliniciantherapist healthfocused handle', 'healthfocused handle eg', 'handle eg healthgovernment', 'eg healthgovernment organization', 'healthgovernment organization handle', 'organization handle focused', 'handle focused healthy', 'focused healthy lifestyle', 'healthy lifestyle etc', 'lifestyle etc regular', 'etc regular person', 'regular person handle', 'person handle fall', 'handle fall category', 'fall category using', 'category using codebook', 'using codebook randomly', 'codebook randomly sampled', 'randomly sampled tweet', 'sampled tweet coded', 'tweet coded team', 'coded team two', 'team two trained', 'two trained student', 'trained student research', 'student research intern', 'research intern coded', 'intern coded tweet', 'coded tweet together', 'tweet together discussing', 'together discussing tweet', 'discussing tweet coming', 'tweet coming agreement', 'coming agreement final', 'agreement final assigned', 'final assigned code', 'assigned code sample', 'code sample tweet', 'sample tweet wa', 'tweet wa also', 'wa also coded', 'also coded senior', 'coded senior team', 'senior team member', 'team member phd', 'member phd clinician', 'phd clinician extensive', 'clinician extensive mental', 'extensive mental health', 'mental health research', 'health research experience', 'research experience intercoder', 'experience intercoder reliability', 'intercoder reliability theme', 'reliability theme wa', 'theme wa follows', 'wa follows tweeter', 'follows tweeter discloses', 'tweeter discloses feeling', 'discloses feeling depression', 'feeling depression percent', 'depression percent agreement', 'percent agreement kappa', 'agreement kappa tweet', 'kappa tweet supportive', 'tweet supportive helpful', 'supportive helpful message', 'helpful message depression', 'message depression percent', 'depression percent agreement', 'percent agreement kappa', 'agreement kappa tweeter', 'kappa tweeter discloses', 'tweeter discloses feeling', 'discloses feeling school', 'feeling school workrelated', 'school workrelated pressure', 'workrelated pressure related', 'pressure related depression', 'related depression percent', 'depression percent agreement', 'percent agreement kappa', 'agreement kappa tweeter', 'kappa tweeter engages', 'tweeter engages substance', 'engages substance use', 'substance use deal', 'use deal depression', 'deal depression percent', 'depression percent agreement', 'percent agreement kappa', 'agreement kappa tweeter', 'kappa tweeter discloses', 'tweeter discloses selfharm', 'discloses selfharm suicidal', 'selfharm suicidal thought', 'suicidal thought percent', 'thought percent agreement', 'percent agreement kappa', 'agreement kappa trivial', 'kappa trivial disclosure', 'trivial disclosure depression', 'disclosure depression percent', 'depression percent agreement', 'percent agreement kappa', 'agreement kappa source', 'kappa source tweet', 'source tweet percent', 'tweet percent agreement', 'percent agreement kappa', 'agreement kappa prevalence', 'kappa prevalence kappa', 'prevalence kappa diminished', 'kappa diminished ability', 'diminished ability thinkconcentrate', 'ability thinkconcentrate low', 'thinkconcentrate low chose', 'low chose report', 'chose report codedemographics', 'report codedemographics pro', 'codedemographics pro wa', 'pro wa used', 'wa used infer', 'used infer demographic', 'infer demographic characteristic', 'demographic characteristic individual', 'characteristic individual disclosed', 'individual disclosed feeling', 'disclosed feeling depressed', 'feeling depressed tweet', 'depressed tweet examined', 'tweet examined present', 'examined present study', 'present study demographic', 'study demographic pro', 'demographic pro twitter', 'pro twitter demographic', 'twitter demographic characteristic', 'demographic characteristic examined', 'characteristic examined include', 'examined include age', 'include age gender', 'age gender raceethnicity', 'gender raceethnicity marital', 'raceethnicity marital status', 'marital status income', 'status income occupation', 'income occupation location', 'occupation location tweeter', 'location tweeter order', 'tweeter order ass', 'order ass pattern', 'ass pattern twitter', 'pattern twitter interest', 'twitter interest likely', 'interest likely twitter', 'likely twitter handle', 'twitter handle followed', 'handle followed tweeter', 'followed tweeter also', 'tweeter also provided', 'also provided demographic', 'provided demographic pro', 'demographic pro us', 'pro us series', 'us series proprietary', 'series proprietary algorithm', 'proprietary algorithm estimate', 'algorithm estimate infer', 'estimate infer likely', 'infer likely demographic', 'likely demographic characteristic', 'demographic characteristic twitter', 'characteristic twitter handle', 'twitter handle based', 'handle based twitter', 'based twitter behaviorusage', 'twitter behaviorusage prediction', 'behaviorusage prediction rely', 'prediction rely multiple', 'rely multiple data', 'multiple data signal', 'data signal network', 'signal network signal', 'network signal imparted', 'signal imparted nature', 'imparted nature strength', 'nature strength tie', 'strength tie individual', 'tie individual twitter', 'individual twitter consumption', 'twitter consumption consumption', 'consumption consumption information', 'consumption information twitter', 'information twitter revealed', 'twitter revealed account', 'revealed account followed', 'account followed realworld', 'followed realworld consumption', 'realworld consumption revealed', 'consumption revealed twitter', 'revealed twitter usage', 'twitter usage language', 'usage language word', 'language word phrased', 'word phrased used', 'phrased used tweet', 'used tweet bios', 'tweet bios demographic', 'bios demographic pro', 'demographic pro ha', 'pro ha used', 'ha used methodology', 'used methodology profile', 'methodology profile million', 'profile million twitter', 'million twitter user', 'twitter user date', 'user date requires', 'date requires confidence', 'requires confidence make', 'confidence make estimate', 'make estimate single', 'estimate single demographic', 'single demographic characteristic', 'demographic characteristic example', 'characteristic example prediction', 'example prediction made', 'prediction made would', 'made would need', 'would need correct', 'need correct order', 'correct order accept', 'order accept methodology', 'accept methodology used', 'methodology used make', 'used make prediction', 'make prediction success', 'prediction success demographic', 'success demographic pro', 'demographic pro analytic', 'pro analytic prediction', 'analytic prediction relies', 'prediction relies relatively', 'relies relatively low', 'relatively low covariance', 'low covariance multiple', 'covariance multiple amplified', 'multiple amplified signal', 'amplified signal iterative', 'signal iterative evaluation', 'iterative evaluation testing', 'evaluation testing methodology', 'testing methodology training', 'methodology training set', 'training set established', 'set established sample', 'established sample twitter', 'sample twitter user', 'twitter user verified', 'user verified demographic', 'verified demographic allows', 'demographic allows calibration', 'allows calibration balance', 'calibration balance depth', 'balance depth coverage', 'depth coverage number', 'coverage number demographic', 'number demographic prediction', 'demographic prediction made', 'prediction made required', 'made required accuracy', 'required accuracy size', 'accuracy size established', 'size established sample', 'established sample twitter', 'sample twitter user', 'twitter user verified', 'user verified demographic', 'verified demographic varies', 'demographic varies people', 'varies people depending', 'people depending specific', 'depending specific demographic', 'specific demographic characteristic', 'demographic characteristic inferred', 'characteristic inferred comparison', 'inferred comparison purpose', 'comparison purpose inferred', 'purpose inferred demographic', 'inferred demographic characteristic', 'demographic characteristic across', 'characteristic across sample', 'across sample randomly', 'sample randomly selected', 'randomly selected englishlanguage', 'selected englishlanguage twitter', 'englishlanguage twitter user', 'twitter user u', 'user u canada', 'u canada also', 'canada also provided', 'also provided demographic', 'provided demographic pro', 'demographic pro used', 'pro used pearson', 'used pearson chi', 'pearson chi square', 'chi square test', 'square test compare', 'test compare inferred', 'compare inferred characteristic', 'inferred characteristic tweeter', 'characteristic tweeter sample', 'tweeter sample expressed', 'sample expressed feeling', 'expressed feeling depression', 'feeling depression versus', 'depression versus typical', 'versus typical twitter', 'typical twitter user', 'twitter user p', 'user p wa', 'p wa considered', 'wa considered statistically', 'considered statistically significant']",,,,,,,,
https://aclanthology.org/W15-1202.pdf,1,We follow the data acquisition and curation process of Coppersmith et al. (2014a) summarizing the major points here: Social media such as Twitter contains frequent public statements by users reporting diagnoses for various medical conditions. Many talk about physical health conditions (e.g. cancer flu) but some also discuss mental illness including schizophrenia. There are a variety of motivations for users to share this information on social media: to offer or seek support to fight the stigma of mental illness or perhaps to offer an explanation for certain behaviors.4 We obtain messages with these self-reported diagnoses using the Twitter API and filtered via (caseinsensitive) regular expression to require “schizo” or a close phonetic approximation to be present; our expression matched “schizophrenia” its subtypes and various approximations: “schizo” “skitzo” “skitso” “schizotypal” “schizoid” etc. All data we collect are public posts made between 2008 and 2015 and exclude any message marked as ‘private’ by the author. All use of the data reported in this paper has been approved by the appropriate Institutional Review Board (IRB). Each self-stated diagnosis included in this study was examined by a human annotator (one of the authors) to verify that it appeared to be a genuine statement of a schizophrenia diagnosis excluding jokes quotes or disingenuous statements. We obtained 174 users with an apparently genuine selfstated diagnosis of a schizophrenia-related condition. Note that we cannot be certain that the Twitter user was actually diagnosed with schizophrenia only that their statement of being diagnosed appears to be genuine. Previous work indicates that interannotator agreement for this task is good: κ = 0.77 (Coppersmith et al. 2014a). For each user we obtained a set of their public Twitter posts via the Twitter API collecting up to 3200 tweets.5 As we wish to focus on user-authored content we exclude from analysis all retweets and any tweets that contain a URL (which often contain text that the user did not author). We lowercase all words and convert any non-standard characters (including emoji) to a systematic ASCII representation via Unidecode.6 For our community controls we used randomlyselected Twitter users who primarily tweet in English. Specifically during a two week period in early 2014 each Twitter user who was included in Twitter’s 1% “spritzer” sample had an equal chance for inclusion in our pool of community controls. We then collected some of their historic tweets and assessed the language(s) they tweeted in according to the Chromium Compact Language Detector.7 Users were excluded from our community controls if their tweets were less than 75% English.8We use a balanced dataset here for our analysis (an equal number of schizophrenia users and community controls). This 50/50 split makes the machine learning and analysis easier and will allow us to focus more on emergent linguistics that are related to schizophrenia than if we had examined a dataset more representative of the population (more like 1/99). Moreover we have not factored in the cost of false negatives or false positives (how should the consequences of misclassifying a schizophrenia user as non-schizophrenic be weighed against the consequences of misclassifying a non-schizophrenic user as schizophrenic?). All our classification results should be taken as validation that the differences in language we observe are relevant to schizophrenia but only one step towards applying something derived from this technology in a real world scenario.Often people suffering from mental illness have a diagnosis for more than one disorder and schizophrenia is no exception. Of our 174 users with a genuine self-statement of diagnosis of a schizophrenia-related condition 41 also state a diagnosis of at least one other mental illness (30%) while 15 of those state that they have a diagnosis of more than one other mental illness (11%). The vast majority of these concomitances are with bipolar (25 users) followed by depression (14) post traumatic stress disorder (8) and generalized anxiety disorder (6). These comorbidity rates are notably lower than the generally accepted prevalence rates which may be due to one of several factors. First we rely on stated diagnoses to calculate comorbidity and the users may not be stating each of their diagnosed conditions either because they have not been diagnosed as such or they choose to identify most strongly with the stated diagnosed conditions or they simply ran out of space (given Twitter’s 140-character limit). Second we are analyzing Twitter users which consists of only a subset of the population and the users that choose to state publicly on Twitter their schizophrenia diagnosis may not be an accurate representation of the population of schizophrenia sufferers. The noted concomitance of schizophrenia and bipolar disorder is frequently labeled as “schizoaffective disorder with a bipolar subtype” with some recent research indicating shared impairments in functional connectivity across patients with schizophrenia and bipolar disorders (Meda et al. 2012). It is worth keeping in mind throughout this paper that we examine all subtypes of schizophrenia together here and further in-depth analysis between subtypes is warranted.,we follow the data acquisition and curation process of coppersmith et al a summarizing the major point here social medium such a twitter contains frequent public statement by user reporting diagnosis for various medical condition many talk about physical health condition eg cancer flu but some also discus mental illness including schizophrenia there are a variety of motivation for user to share this information on social medium to offer or seek support to fight the stigma of mental illness or perhaps to offer an explanation for certain behavior we obtain message with these selfreported diagnosis using the twitter api and filtered via caseinsensitive regular expression to require schizo or a close phonetic approximation to be present our expression matched schizophrenia it subtypes and various approximation schizo skitzo skitso schizotypal schizoid etc all data we collect are public post made between and and exclude any message marked a private by the author all use of the data reported in this paper ha been approved by the appropriate institutional review board irb each selfstated diagnosis included in this study wa examined by a human annotator one of the author to verify that it appeared to be a genuine statement of a schizophrenia diagnosis excluding joke quote or disingenuous statement we obtained user with an apparently genuine selfstated diagnosis of a schizophreniarelated condition note that we cannot be certain that the twitter user wa actually diagnosed with schizophrenia only that their statement of being diagnosed appears to be genuine previous work indicates that interannotator agreement for this task is good coppersmith et al a for each user we obtained a set of their public twitter post via the twitter api collecting up to tweet a we wish to focus on userauthored content we exclude from analysis all retweets and any tweet that contain a url which often contain text that the user did not author we lowercase all word and convert any nonstandard character including emoji to a systematic ascii representation via unidecode for our community control we used randomlyselected twitter user who primarily tweet in english specifically during a two week period in early each twitter user who wa included in twitter spritzer sample had an equal chance for inclusion in our pool of community control we then collected some of their historic tweet and assessed the language they tweeted in according to the chromium compact language detector user were excluded from our community control if their tweet were le than englishwe use a balanced dataset here for our analysis an equal number of schizophrenia user and community control this split make the machine learning and analysis easier and will allow u to focus more on emergent linguistics that are related to schizophrenia than if we had examined a dataset more representative of the population more like moreover we have not factored in the cost of false negative or false positive how should the consequence of misclassifying a schizophrenia user a nonschizophrenic be weighed against the consequence of misclassifying a nonschizophrenic user a schizophrenic all our classification result should be taken a validation that the difference in language we observe are relevant to schizophrenia but only one step towards applying something derived from this technology in a real world scenariooften people suffering from mental illness have a diagnosis for more than one disorder and schizophrenia is no exception of our user with a genuine selfstatement of diagnosis of a schizophreniarelated condition also state a diagnosis of at least one other mental illness while of those state that they have a diagnosis of more than one other mental illness the vast majority of these concomitance are with bipolar user followed by depression post traumatic stress disorder and generalized anxiety disorder these comorbidity rate are notably lower than the generally accepted prevalence rate which may be due to one of several factor first we rely on stated diagnosis to calculate comorbidity and the user may not be stating each of their diagnosed condition either because they have not been diagnosed a such or they choose to identify most strongly with the stated diagnosed condition or they simply ran out of space given twitter character limit second we are analyzing twitter user which consists of only a subset of the population and the user that choose to state publicly on twitter their schizophrenia diagnosis may not be an accurate representation of the population of schizophrenia sufferer the noted concomitance of schizophrenia and bipolar disorder is frequently labeled a schizoaffective disorder with a bipolar subtype with some recent research indicating shared impairment in functional connectivity across patient with schizophrenia and bipolar disorder meda et al it is worth keeping in mind throughout this paper that we examine all subtypes of schizophrenia together here and further indepth analysis between subtypes is warranted,"['follow', 'data', 'acquisition', 'curation', 'process', 'coppersmith', 'et', 'al', 'summarizing', 'major', 'point', 'social', 'medium', 'twitter', 'contains', 'frequent', 'public', 'statement', 'user', 'reporting', 'diagnosis', 'various', 'medical', 'condition', 'many', 'talk', 'physical', 'health', 'condition', 'eg', 'cancer', 'flu', 'also', 'discus', 'mental', 'illness', 'including', 'schizophrenia', 'variety', 'motivation', 'user', 'share', 'information', 'social', 'medium', 'offer', 'seek', 'support', 'fight', 'stigma', 'mental', 'illness', 'perhaps', 'offer', 'explanation', 'certain', 'behavior', 'obtain', 'message', 'selfreported', 'diagnosis', 'using', 'twitter', 'api', 'filtered', 'via', 'caseinsensitive', 'regular', 'expression', 'require', 'schizo', 'close', 'phonetic', 'approximation', 'present', 'expression', 'matched', 'schizophrenia', 'subtypes', 'various', 'approximation', 'schizo', 'skitzo', 'skitso', 'schizotypal', 'schizoid', 'etc', 'data', 'collect', 'public', 'post', 'made', 'exclude', 'message', 'marked', 'private', 'author', 'use', 'data', 'reported', 'paper', 'ha', 'approved', 'appropriate', 'institutional', 'review', 'board', 'irb', 'selfstated', 'diagnosis', 'included', 'study', 'wa', 'examined', 'human', 'annotator', 'one', 'author', 'verify', 'appeared', 'genuine', 'statement', 'schizophrenia', 'diagnosis', 'excluding', 'joke', 'quote', 'disingenuous', 'statement', 'obtained', 'user', 'apparently', 'genuine', 'selfstated', 'diagnosis', 'schizophreniarelated', 'condition', 'note', 'cannot', 'certain', 'twitter', 'user', 'wa', 'actually', 'diagnosed', 'schizophrenia', 'statement', 'diagnosed', 'appears', 'genuine', 'previous', 'work', 'indicates', 'interannotator', 'agreement', 'task', 'good', 'coppersmith', 'et', 'al', 'user', 'obtained', 'set', 'public', 'twitter', 'post', 'via', 'twitter', 'api', 'collecting', 'tweet', 'wish', 'focus', 'userauthored', 'content', 'exclude', 'analysis', 'retweets', 'tweet', 'contain', 'url', 'often', 'contain', 'text', 'user', 'author', 'lowercase', 'word', 'convert', 'nonstandard', 'character', 'including', 'emoji', 'systematic', 'ascii', 'representation', 'via', 'unidecode', 'community', 'control', 'used', 'randomlyselected', 'twitter', 'user', 'primarily', 'tweet', 'english', 'specifically', 'two', 'week', 'period', 'early', 'twitter', 'user', 'wa', 'included', 'twitter', 'spritzer', 'sample', 'equal', 'chance', 'inclusion', 'pool', 'community', 'control', 'collected', 'historic', 'tweet', 'assessed', 'language', 'tweeted', 'according', 'chromium', 'compact', 'language', 'detector', 'user', 'excluded', 'community', 'control', 'tweet', 'le', 'englishwe', 'use', 'balanced', 'dataset', 'analysis', 'equal', 'number', 'schizophrenia', 'user', 'community', 'control', 'split', 'make', 'machine', 'learning', 'analysis', 'easier', 'allow', 'u', 'focus', 'emergent', 'linguistics', 'related', 'schizophrenia', 'examined', 'dataset', 'representative', 'population', 'like', 'moreover', 'factored', 'cost', 'false', 'negative', 'false', 'positive', 'consequence', 'misclassifying', 'schizophrenia', 'user', 'nonschizophrenic', 'weighed', 'consequence', 'misclassifying', 'nonschizophrenic', 'user', 'schizophrenic', 'classification', 'result', 'taken', 'validation', 'difference', 'language', 'observe', 'relevant', 'schizophrenia', 'one', 'step', 'towards', 'applying', 'something', 'derived', 'technology', 'real', 'world', 'scenariooften', 'people', 'suffering', 'mental', 'illness', 'diagnosis', 'one', 'disorder', 'schizophrenia', 'exception', 'user', 'genuine', 'selfstatement', 'diagnosis', 'schizophreniarelated', 'condition', 'also', 'state', 'diagnosis', 'least', 'one', 'mental', 'illness', 'state', 'diagnosis', 'one', 'mental', 'illness', 'vast', 'majority', 'concomitance', 'bipolar', 'user', 'followed', 'depression', 'post', 'traumatic', 'stress', 'disorder', 'generalized', 'anxiety', 'disorder', 'comorbidity', 'rate', 'notably', 'lower', 'generally', 'accepted', 'prevalence', 'rate', 'may', 'due', 'one', 'several', 'factor', 'first', 'rely', 'stated', 'diagnosis', 'calculate', 'comorbidity', 'user', 'may', 'stating', 'diagnosed', 'condition', 'either', 'diagnosed', 'choose', 'identify', 'strongly', 'stated', 'diagnosed', 'condition', 'simply', 'ran', 'space', 'given', 'twitter', 'character', 'limit', 'second', 'analyzing', 'twitter', 'user', 'consists', 'subset', 'population', 'user', 'choose', 'state', 'publicly', 'twitter', 'schizophrenia', 'diagnosis', 'may', 'accurate', 'representation', 'population', 'schizophrenia', 'sufferer', 'noted', 'concomitance', 'schizophrenia', 'bipolar', 'disorder', 'frequently', 'labeled', 'schizoaffective', 'disorder', 'bipolar', 'subtype', 'recent', 'research', 'indicating', 'shared', 'impairment', 'functional', 'connectivity', 'across', 'patient', 'schizophrenia', 'bipolar', 'disorder', 'meda', 'et', 'al', 'worth', 'keeping', 'mind', 'throughout', 'paper', 'examine', 'subtypes', 'schizophrenia', 'together', 'indepth', 'analysis', 'subtypes', 'warranted']","['follow data', 'data acquisition', 'acquisition curation', 'curation process', 'process coppersmith', 'coppersmith et', 'et al', 'al summarizing', 'summarizing major', 'major point', 'point social', 'social medium', 'medium twitter', 'twitter contains', 'contains frequent', 'frequent public', 'public statement', 'statement user', 'user reporting', 'reporting diagnosis', 'diagnosis various', 'various medical', 'medical condition', 'condition many', 'many talk', 'talk physical', 'physical health', 'health condition', 'condition eg', 'eg cancer', 'cancer flu', 'flu also', 'also discus', 'discus mental', 'mental illness', 'illness including', 'including schizophrenia', 'schizophrenia variety', 'variety motivation', 'motivation user', 'user share', 'share information', 'information social', 'social medium', 'medium offer', 'offer seek', 'seek support', 'support fight', 'fight stigma', 'stigma mental', 'mental illness', 'illness perhaps', 'perhaps offer', 'offer explanation', 'explanation certain', 'certain behavior', 'behavior obtain', 'obtain message', 'message selfreported', 'selfreported diagnosis', 'diagnosis using', 'using twitter', 'twitter api', 'api filtered', 'filtered via', 'via caseinsensitive', 'caseinsensitive regular', 'regular expression', 'expression require', 'require schizo', 'schizo close', 'close phonetic', 'phonetic approximation', 'approximation present', 'present expression', 'expression matched', 'matched schizophrenia', 'schizophrenia subtypes', 'subtypes various', 'various approximation', 'approximation schizo', 'schizo skitzo', 'skitzo skitso', 'skitso schizotypal', 'schizotypal schizoid', 'schizoid etc', 'etc data', 'data collect', 'collect public', 'public post', 'post made', 'made exclude', 'exclude message', 'message marked', 'marked private', 'private author', 'author use', 'use data', 'data reported', 'reported paper', 'paper ha', 'ha approved', 'approved appropriate', 'appropriate institutional', 'institutional review', 'review board', 'board irb', 'irb selfstated', 'selfstated diagnosis', 'diagnosis included', 'included study', 'study wa', 'wa examined', 'examined human', 'human annotator', 'annotator one', 'one author', 'author verify', 'verify appeared', 'appeared genuine', 'genuine statement', 'statement schizophrenia', 'schizophrenia diagnosis', 'diagnosis excluding', 'excluding joke', 'joke quote', 'quote disingenuous', 'disingenuous statement', 'statement obtained', 'obtained user', 'user apparently', 'apparently genuine', 'genuine selfstated', 'selfstated diagnosis', 'diagnosis schizophreniarelated', 'schizophreniarelated condition', 'condition note', 'note cannot', 'cannot certain', 'certain twitter', 'twitter user', 'user wa', 'wa actually', 'actually diagnosed', 'diagnosed schizophrenia', 'schizophrenia statement', 'statement diagnosed', 'diagnosed appears', 'appears genuine', 'genuine previous', 'previous work', 'work indicates', 'indicates interannotator', 'interannotator agreement', 'agreement task', 'task good', 'good coppersmith', 'coppersmith et', 'et al', 'al user', 'user obtained', 'obtained set', 'set public', 'public twitter', 'twitter post', 'post via', 'via twitter', 'twitter api', 'api collecting', 'collecting tweet', 'tweet wish', 'wish focus', 'focus userauthored', 'userauthored content', 'content exclude', 'exclude analysis', 'analysis retweets', 'retweets tweet', 'tweet contain', 'contain url', 'url often', 'often contain', 'contain text', 'text user', 'user author', 'author lowercase', 'lowercase word', 'word convert', 'convert nonstandard', 'nonstandard character', 'character including', 'including emoji', 'emoji systematic', 'systematic ascii', 'ascii representation', 'representation via', 'via unidecode', 'unidecode community', 'community control', 'control used', 'used randomlyselected', 'randomlyselected twitter', 'twitter user', 'user primarily', 'primarily tweet', 'tweet english', 'english specifically', 'specifically two', 'two week', 'week period', 'period early', 'early twitter', 'twitter user', 'user wa', 'wa included', 'included twitter', 'twitter spritzer', 'spritzer sample', 'sample equal', 'equal chance', 'chance inclusion', 'inclusion pool', 'pool community', 'community control', 'control collected', 'collected historic', 'historic tweet', 'tweet assessed', 'assessed language', 'language tweeted', 'tweeted according', 'according chromium', 'chromium compact', 'compact language', 'language detector', 'detector user', 'user excluded', 'excluded community', 'community control', 'control tweet', 'tweet le', 'le englishwe', 'englishwe use', 'use balanced', 'balanced dataset', 'dataset analysis', 'analysis equal', 'equal number', 'number schizophrenia', 'schizophrenia user', 'user community', 'community control', 'control split', 'split make', 'make machine', 'machine learning', 'learning analysis', 'analysis easier', 'easier allow', 'allow u', 'u focus', 'focus emergent', 'emergent linguistics', 'linguistics related', 'related schizophrenia', 'schizophrenia examined', 'examined dataset', 'dataset representative', 'representative population', 'population like', 'like moreover', 'moreover factored', 'factored cost', 'cost false', 'false negative', 'negative false', 'false positive', 'positive consequence', 'consequence misclassifying', 'misclassifying schizophrenia', 'schizophrenia user', 'user nonschizophrenic', 'nonschizophrenic weighed', 'weighed consequence', 'consequence misclassifying', 'misclassifying nonschizophrenic', 'nonschizophrenic user', 'user schizophrenic', 'schizophrenic classification', 'classification result', 'result taken', 'taken validation', 'validation difference', 'difference language', 'language observe', 'observe relevant', 'relevant schizophrenia', 'schizophrenia one', 'one step', 'step towards', 'towards applying', 'applying something', 'something derived', 'derived technology', 'technology real', 'real world', 'world scenariooften', 'scenariooften people', 'people suffering', 'suffering mental', 'mental illness', 'illness diagnosis', 'diagnosis one', 'one disorder', 'disorder schizophrenia', 'schizophrenia exception', 'exception user', 'user genuine', 'genuine selfstatement', 'selfstatement diagnosis', 'diagnosis schizophreniarelated', 'schizophreniarelated condition', 'condition also', 'also state', 'state diagnosis', 'diagnosis least', 'least one', 'one mental', 'mental illness', 'illness state', 'state diagnosis', 'diagnosis one', 'one mental', 'mental illness', 'illness vast', 'vast majority', 'majority concomitance', 'concomitance bipolar', 'bipolar user', 'user followed', 'followed depression', 'depression post', 'post traumatic', 'traumatic stress', 'stress disorder', 'disorder generalized', 'generalized anxiety', 'anxiety disorder', 'disorder comorbidity', 'comorbidity rate', 'rate notably', 'notably lower', 'lower generally', 'generally accepted', 'accepted prevalence', 'prevalence rate', 'rate may', 'may due', 'due one', 'one several', 'several factor', 'factor first', 'first rely', 'rely stated', 'stated diagnosis', 'diagnosis calculate', 'calculate comorbidity', 'comorbidity user', 'user may', 'may stating', 'stating diagnosed', 'diagnosed condition', 'condition either', 'either diagnosed', 'diagnosed choose', 'choose identify', 'identify strongly', 'strongly stated', 'stated diagnosed', 'diagnosed condition', 'condition simply', 'simply ran', 'ran space', 'space given', 'given twitter', 'twitter character', 'character limit', 'limit second', 'second analyzing', 'analyzing twitter', 'twitter user', 'user consists', 'consists subset', 'subset population', 'population user', 'user choose', 'choose state', 'state publicly', 'publicly twitter', 'twitter schizophrenia', 'schizophrenia diagnosis', 'diagnosis may', 'may accurate', 'accurate representation', 'representation population', 'population schizophrenia', 'schizophrenia sufferer', 'sufferer noted', 'noted concomitance', 'concomitance schizophrenia', 'schizophrenia bipolar', 'bipolar disorder', 'disorder frequently', 'frequently labeled', 'labeled schizoaffective', 'schizoaffective disorder', 'disorder bipolar', 'bipolar subtype', 'subtype recent', 'recent research', 'research indicating', 'indicating shared', 'shared impairment', 'impairment functional', 'functional connectivity', 'connectivity across', 'across patient', 'patient schizophrenia', 'schizophrenia bipolar', 'bipolar disorder', 'disorder meda', 'meda et', 'et al', 'al worth', 'worth keeping', 'keeping mind', 'mind throughout', 'throughout paper', 'paper examine', 'examine subtypes', 'subtypes schizophrenia', 'schizophrenia together', 'together indepth', 'indepth analysis', 'analysis subtypes', 'subtypes warranted']","['follow data acquisition', 'data acquisition curation', 'acquisition curation process', 'curation process coppersmith', 'process coppersmith et', 'coppersmith et al', 'et al summarizing', 'al summarizing major', 'summarizing major point', 'major point social', 'point social medium', 'social medium twitter', 'medium twitter contains', 'twitter contains frequent', 'contains frequent public', 'frequent public statement', 'public statement user', 'statement user reporting', 'user reporting diagnosis', 'reporting diagnosis various', 'diagnosis various medical', 'various medical condition', 'medical condition many', 'condition many talk', 'many talk physical', 'talk physical health', 'physical health condition', 'health condition eg', 'condition eg cancer', 'eg cancer flu', 'cancer flu also', 'flu also discus', 'also discus mental', 'discus mental illness', 'mental illness including', 'illness including schizophrenia', 'including schizophrenia variety', 'schizophrenia variety motivation', 'variety motivation user', 'motivation user share', 'user share information', 'share information social', 'information social medium', 'social medium offer', 'medium offer seek', 'offer seek support', 'seek support fight', 'support fight stigma', 'fight stigma mental', 'stigma mental illness', 'mental illness perhaps', 'illness perhaps offer', 'perhaps offer explanation', 'offer explanation certain', 'explanation certain behavior', 'certain behavior obtain', 'behavior obtain message', 'obtain message selfreported', 'message selfreported diagnosis', 'selfreported diagnosis using', 'diagnosis using twitter', 'using twitter api', 'twitter api filtered', 'api filtered via', 'filtered via caseinsensitive', 'via caseinsensitive regular', 'caseinsensitive regular expression', 'regular expression require', 'expression require schizo', 'require schizo close', 'schizo close phonetic', 'close phonetic approximation', 'phonetic approximation present', 'approximation present expression', 'present expression matched', 'expression matched schizophrenia', 'matched schizophrenia subtypes', 'schizophrenia subtypes various', 'subtypes various approximation', 'various approximation schizo', 'approximation schizo skitzo', 'schizo skitzo skitso', 'skitzo skitso schizotypal', 'skitso schizotypal schizoid', 'schizotypal schizoid etc', 'schizoid etc data', 'etc data collect', 'data collect public', 'collect public post', 'public post made', 'post made exclude', 'made exclude message', 'exclude message marked', 'message marked private', 'marked private author', 'private author use', 'author use data', 'use data reported', 'data reported paper', 'reported paper ha', 'paper ha approved', 'ha approved appropriate', 'approved appropriate institutional', 'appropriate institutional review', 'institutional review board', 'review board irb', 'board irb selfstated', 'irb selfstated diagnosis', 'selfstated diagnosis included', 'diagnosis included study', 'included study wa', 'study wa examined', 'wa examined human', 'examined human annotator', 'human annotator one', 'annotator one author', 'one author verify', 'author verify appeared', 'verify appeared genuine', 'appeared genuine statement', 'genuine statement schizophrenia', 'statement schizophrenia diagnosis', 'schizophrenia diagnosis excluding', 'diagnosis excluding joke', 'excluding joke quote', 'joke quote disingenuous', 'quote disingenuous statement', 'disingenuous statement obtained', 'statement obtained user', 'obtained user apparently', 'user apparently genuine', 'apparently genuine selfstated', 'genuine selfstated diagnosis', 'selfstated diagnosis schizophreniarelated', 'diagnosis schizophreniarelated condition', 'schizophreniarelated condition note', 'condition note cannot', 'note cannot certain', 'cannot certain twitter', 'certain twitter user', 'twitter user wa', 'user wa actually', 'wa actually diagnosed', 'actually diagnosed schizophrenia', 'diagnosed schizophrenia statement', 'schizophrenia statement diagnosed', 'statement diagnosed appears', 'diagnosed appears genuine', 'appears genuine previous', 'genuine previous work', 'previous work indicates', 'work indicates interannotator', 'indicates interannotator agreement', 'interannotator agreement task', 'agreement task good', 'task good coppersmith', 'good coppersmith et', 'coppersmith et al', 'et al user', 'al user obtained', 'user obtained set', 'obtained set public', 'set public twitter', 'public twitter post', 'twitter post via', 'post via twitter', 'via twitter api', 'twitter api collecting', 'api collecting tweet', 'collecting tweet wish', 'tweet wish focus', 'wish focus userauthored', 'focus userauthored content', 'userauthored content exclude', 'content exclude analysis', 'exclude analysis retweets', 'analysis retweets tweet', 'retweets tweet contain', 'tweet contain url', 'contain url often', 'url often contain', 'often contain text', 'contain text user', 'text user author', 'user author lowercase', 'author lowercase word', 'lowercase word convert', 'word convert nonstandard', 'convert nonstandard character', 'nonstandard character including', 'character including emoji', 'including emoji systematic', 'emoji systematic ascii', 'systematic ascii representation', 'ascii representation via', 'representation via unidecode', 'via unidecode community', 'unidecode community control', 'community control used', 'control used randomlyselected', 'used randomlyselected twitter', 'randomlyselected twitter user', 'twitter user primarily', 'user primarily tweet', 'primarily tweet english', 'tweet english specifically', 'english specifically two', 'specifically two week', 'two week period', 'week period early', 'period early twitter', 'early twitter user', 'twitter user wa', 'user wa included', 'wa included twitter', 'included twitter spritzer', 'twitter spritzer sample', 'spritzer sample equal', 'sample equal chance', 'equal chance inclusion', 'chance inclusion pool', 'inclusion pool community', 'pool community control', 'community control collected', 'control collected historic', 'collected historic tweet', 'historic tweet assessed', 'tweet assessed language', 'assessed language tweeted', 'language tweeted according', 'tweeted according chromium', 'according chromium compact', 'chromium compact language', 'compact language detector', 'language detector user', 'detector user excluded', 'user excluded community', 'excluded community control', 'community control tweet', 'control tweet le', 'tweet le englishwe', 'le englishwe use', 'englishwe use balanced', 'use balanced dataset', 'balanced dataset analysis', 'dataset analysis equal', 'analysis equal number', 'equal number schizophrenia', 'number schizophrenia user', 'schizophrenia user community', 'user community control', 'community control split', 'control split make', 'split make machine', 'make machine learning', 'machine learning analysis', 'learning analysis easier', 'analysis easier allow', 'easier allow u', 'allow u focus', 'u focus emergent', 'focus emergent linguistics', 'emergent linguistics related', 'linguistics related schizophrenia', 'related schizophrenia examined', 'schizophrenia examined dataset', 'examined dataset representative', 'dataset representative population', 'representative population like', 'population like moreover', 'like moreover factored', 'moreover factored cost', 'factored cost false', 'cost false negative', 'false negative false', 'negative false positive', 'false positive consequence', 'positive consequence misclassifying', 'consequence misclassifying schizophrenia', 'misclassifying schizophrenia user', 'schizophrenia user nonschizophrenic', 'user nonschizophrenic weighed', 'nonschizophrenic weighed consequence', 'weighed consequence misclassifying', 'consequence misclassifying nonschizophrenic', 'misclassifying nonschizophrenic user', 'nonschizophrenic user schizophrenic', 'user schizophrenic classification', 'schizophrenic classification result', 'classification result taken', 'result taken validation', 'taken validation difference', 'validation difference language', 'difference language observe', 'language observe relevant', 'observe relevant schizophrenia', 'relevant schizophrenia one', 'schizophrenia one step', 'one step towards', 'step towards applying', 'towards applying something', 'applying something derived', 'something derived technology', 'derived technology real', 'technology real world', 'real world scenariooften', 'world scenariooften people', 'scenariooften people suffering', 'people suffering mental', 'suffering mental illness', 'mental illness diagnosis', 'illness diagnosis one', 'diagnosis one disorder', 'one disorder schizophrenia', 'disorder schizophrenia exception', 'schizophrenia exception user', 'exception user genuine', 'user genuine selfstatement', 'genuine selfstatement diagnosis', 'selfstatement diagnosis schizophreniarelated', 'diagnosis schizophreniarelated condition', 'schizophreniarelated condition also', 'condition also state', 'also state diagnosis', 'state diagnosis least', 'diagnosis least one', 'least one mental', 'one mental illness', 'mental illness state', 'illness state diagnosis', 'state diagnosis one', 'diagnosis one mental', 'one mental illness', 'mental illness vast', 'illness vast majority', 'vast majority concomitance', 'majority concomitance bipolar', 'concomitance bipolar user', 'bipolar user followed', 'user followed depression', 'followed depression post', 'depression post traumatic', 'post traumatic stress', 'traumatic stress disorder', 'stress disorder generalized', 'disorder generalized anxiety', 'generalized anxiety disorder', 'anxiety disorder comorbidity', 'disorder comorbidity rate', 'comorbidity rate notably', 'rate notably lower', 'notably lower generally', 'lower generally accepted', 'generally accepted prevalence', 'accepted prevalence rate', 'prevalence rate may', 'rate may due', 'may due one', 'due one several', 'one several factor', 'several factor first', 'factor first rely', 'first rely stated', 'rely stated diagnosis', 'stated diagnosis calculate', 'diagnosis calculate comorbidity', 'calculate comorbidity user', 'comorbidity user may', 'user may stating', 'may stating diagnosed', 'stating diagnosed condition', 'diagnosed condition either', 'condition either diagnosed', 'either diagnosed choose', 'diagnosed choose identify', 'choose identify strongly', 'identify strongly stated', 'strongly stated diagnosed', 'stated diagnosed condition', 'diagnosed condition simply', 'condition simply ran', 'simply ran space', 'ran space given', 'space given twitter', 'given twitter character', 'twitter character limit', 'character limit second', 'limit second analyzing', 'second analyzing twitter', 'analyzing twitter user', 'twitter user consists', 'user consists subset', 'consists subset population', 'subset population user', 'population user choose', 'user choose state', 'choose state publicly', 'state publicly twitter', 'publicly twitter schizophrenia', 'twitter schizophrenia diagnosis', 'schizophrenia diagnosis may', 'diagnosis may accurate', 'may accurate representation', 'accurate representation population', 'representation population schizophrenia', 'population schizophrenia sufferer', 'schizophrenia sufferer noted', 'sufferer noted concomitance', 'noted concomitance schizophrenia', 'concomitance schizophrenia bipolar', 'schizophrenia bipolar disorder', 'bipolar disorder frequently', 'disorder frequently labeled', 'frequently labeled schizoaffective', 'labeled schizoaffective disorder', 'schizoaffective disorder bipolar', 'disorder bipolar subtype', 'bipolar subtype recent', 'subtype recent research', 'recent research indicating', 'research indicating shared', 'indicating shared impairment', 'shared impairment functional', 'impairment functional connectivity', 'functional connectivity across', 'connectivity across patient', 'across patient schizophrenia', 'patient schizophrenia bipolar', 'schizophrenia bipolar disorder', 'bipolar disorder meda', 'disorder meda et', 'meda et al', 'et al worth', 'al worth keeping', 'worth keeping mind', 'keeping mind throughout', 'mind throughout paper', 'throughout paper examine', 'paper examine subtypes', 'examine subtypes schizophrenia', 'subtypes schizophrenia together', 'schizophrenia together indepth', 'together indepth analysis', 'indepth analysis subtypes', 'analysis subtypes warranted']",,,,,,,,
https://dl.acm.org/doi/abs/10.1145/2700171.2791026,1,Next we compiled a list of reported celebrity suicides which fell within the time range of our Reddit data. Defining who is a “celebrity” is nontrivial so we refer to the Wikipedia page listing celebrity suicides7 as a way to measure who has sufficient celebrity status for inclusion. We obtained 10 reported celebrity suicides in the same period as our Reddit data; their names and reported suicides are shown in Table 2. We measure the prominence of a celebrity’s death by measuring the change in Wikipedia page views for the celebrity’s Wikipedia page. Wikipedia provides daily page view statistics for each page.8 We compare the number of page-views in the two weeks prior to their death with the two weeks following their death in terms of z-score (Figure 1). Here z-scores are computed by converting the page views to standard normal variable with 0-mean and standard deviation of 1. For 9/10 of the cases we see a notable spike in number of views showing that the suicides of these individuals were well-known enough to be viewable on such a macro scale and for examining the presence of Werther Effect in social media. We note two aspects related to the above analysis and which will be used through the rest of this paper. First since we are focusing on different types of data sources—Wikipedia and Reddit we use z-score conversion as a normalization technique for the Wikipedia page views and Reddit’s SW posting activity volume. Further the above observation in Wikipedia data and the analyses that ensue focus on observing changes over a two week window preceding and succeeding a celebrity suicide; this choice is motivated by our initial analyses and from the literature on Werther Effect [17].,next we compiled a list of reported celebrity suicide which fell within the time range of our reddit data defining who is a celebrity is nontrivial so we refer to the wikipedia page listing celebrity suicide a a way to measure who ha sufficient celebrity status for inclusion we obtained reported celebrity suicide in the same period a our reddit data their name and reported suicide are shown in table we measure the prominence of a celebrity death by measuring the change in wikipedia page view for the celebrity wikipedia page wikipedia provides daily page view statistic for each page we compare the number of pageviews in the two week prior to their death with the two week following their death in term of zscore figure here zscores are computed by converting the page view to standard normal variable with mean and standard deviation of for of the case we see a notable spike in number of view showing that the suicide of these individual were wellknown enough to be viewable on such a macro scale and for examining the presence of werther effect in social medium we note two aspect related to the above analysis and which will be used through the rest of this paper first since we are focusing on different type of data sourceswikipedia and reddit we use zscore conversion a a normalization technique for the wikipedia page view and reddits sw posting activity volume further the above observation in wikipedia data and the analysis that ensue focus on observing change over a two week window preceding and succeeding a celebrity suicide this choice is motivated by our initial analysis and from the literature on werther effect,"['next', 'compiled', 'list', 'reported', 'celebrity', 'suicide', 'fell', 'within', 'time', 'range', 'reddit', 'data', 'defining', 'celebrity', 'nontrivial', 'refer', 'wikipedia', 'page', 'listing', 'celebrity', 'suicide', 'way', 'measure', 'ha', 'sufficient', 'celebrity', 'status', 'inclusion', 'obtained', 'reported', 'celebrity', 'suicide', 'period', 'reddit', 'data', 'name', 'reported', 'suicide', 'shown', 'table', 'measure', 'prominence', 'celebrity', 'death', 'measuring', 'change', 'wikipedia', 'page', 'view', 'celebrity', 'wikipedia', 'page', 'wikipedia', 'provides', 'daily', 'page', 'view', 'statistic', 'page', 'compare', 'number', 'pageviews', 'two', 'week', 'prior', 'death', 'two', 'week', 'following', 'death', 'term', 'zscore', 'figure', 'zscores', 'computed', 'converting', 'page', 'view', 'standard', 'normal', 'variable', 'mean', 'standard', 'deviation', 'case', 'see', 'notable', 'spike', 'number', 'view', 'showing', 'suicide', 'individual', 'wellknown', 'enough', 'viewable', 'macro', 'scale', 'examining', 'presence', 'werther', 'effect', 'social', 'medium', 'note', 'two', 'aspect', 'related', 'analysis', 'used', 'rest', 'paper', 'first', 'since', 'focusing', 'different', 'type', 'data', 'sourceswikipedia', 'reddit', 'use', 'zscore', 'conversion', 'normalization', 'technique', 'wikipedia', 'page', 'view', 'reddits', 'sw', 'posting', 'activity', 'volume', 'observation', 'wikipedia', 'data', 'analysis', 'ensue', 'focus', 'observing', 'change', 'two', 'week', 'window', 'preceding', 'succeeding', 'celebrity', 'suicide', 'choice', 'motivated', 'initial', 'analysis', 'literature', 'werther', 'effect']","['next compiled', 'compiled list', 'list reported', 'reported celebrity', 'celebrity suicide', 'suicide fell', 'fell within', 'within time', 'time range', 'range reddit', 'reddit data', 'data defining', 'defining celebrity', 'celebrity nontrivial', 'nontrivial refer', 'refer wikipedia', 'wikipedia page', 'page listing', 'listing celebrity', 'celebrity suicide', 'suicide way', 'way measure', 'measure ha', 'ha sufficient', 'sufficient celebrity', 'celebrity status', 'status inclusion', 'inclusion obtained', 'obtained reported', 'reported celebrity', 'celebrity suicide', 'suicide period', 'period reddit', 'reddit data', 'data name', 'name reported', 'reported suicide', 'suicide shown', 'shown table', 'table measure', 'measure prominence', 'prominence celebrity', 'celebrity death', 'death measuring', 'measuring change', 'change wikipedia', 'wikipedia page', 'page view', 'view celebrity', 'celebrity wikipedia', 'wikipedia page', 'page wikipedia', 'wikipedia provides', 'provides daily', 'daily page', 'page view', 'view statistic', 'statistic page', 'page compare', 'compare number', 'number pageviews', 'pageviews two', 'two week', 'week prior', 'prior death', 'death two', 'two week', 'week following', 'following death', 'death term', 'term zscore', 'zscore figure', 'figure zscores', 'zscores computed', 'computed converting', 'converting page', 'page view', 'view standard', 'standard normal', 'normal variable', 'variable mean', 'mean standard', 'standard deviation', 'deviation case', 'case see', 'see notable', 'notable spike', 'spike number', 'number view', 'view showing', 'showing suicide', 'suicide individual', 'individual wellknown', 'wellknown enough', 'enough viewable', 'viewable macro', 'macro scale', 'scale examining', 'examining presence', 'presence werther', 'werther effect', 'effect social', 'social medium', 'medium note', 'note two', 'two aspect', 'aspect related', 'related analysis', 'analysis used', 'used rest', 'rest paper', 'paper first', 'first since', 'since focusing', 'focusing different', 'different type', 'type data', 'data sourceswikipedia', 'sourceswikipedia reddit', 'reddit use', 'use zscore', 'zscore conversion', 'conversion normalization', 'normalization technique', 'technique wikipedia', 'wikipedia page', 'page view', 'view reddits', 'reddits sw', 'sw posting', 'posting activity', 'activity volume', 'volume observation', 'observation wikipedia', 'wikipedia data', 'data analysis', 'analysis ensue', 'ensue focus', 'focus observing', 'observing change', 'change two', 'two week', 'week window', 'window preceding', 'preceding succeeding', 'succeeding celebrity', 'celebrity suicide', 'suicide choice', 'choice motivated', 'motivated initial', 'initial analysis', 'analysis literature', 'literature werther', 'werther effect']","['next compiled list', 'compiled list reported', 'list reported celebrity', 'reported celebrity suicide', 'celebrity suicide fell', 'suicide fell within', 'fell within time', 'within time range', 'time range reddit', 'range reddit data', 'reddit data defining', 'data defining celebrity', 'defining celebrity nontrivial', 'celebrity nontrivial refer', 'nontrivial refer wikipedia', 'refer wikipedia page', 'wikipedia page listing', 'page listing celebrity', 'listing celebrity suicide', 'celebrity suicide way', 'suicide way measure', 'way measure ha', 'measure ha sufficient', 'ha sufficient celebrity', 'sufficient celebrity status', 'celebrity status inclusion', 'status inclusion obtained', 'inclusion obtained reported', 'obtained reported celebrity', 'reported celebrity suicide', 'celebrity suicide period', 'suicide period reddit', 'period reddit data', 'reddit data name', 'data name reported', 'name reported suicide', 'reported suicide shown', 'suicide shown table', 'shown table measure', 'table measure prominence', 'measure prominence celebrity', 'prominence celebrity death', 'celebrity death measuring', 'death measuring change', 'measuring change wikipedia', 'change wikipedia page', 'wikipedia page view', 'page view celebrity', 'view celebrity wikipedia', 'celebrity wikipedia page', 'wikipedia page wikipedia', 'page wikipedia provides', 'wikipedia provides daily', 'provides daily page', 'daily page view', 'page view statistic', 'view statistic page', 'statistic page compare', 'page compare number', 'compare number pageviews', 'number pageviews two', 'pageviews two week', 'two week prior', 'week prior death', 'prior death two', 'death two week', 'two week following', 'week following death', 'following death term', 'death term zscore', 'term zscore figure', 'zscore figure zscores', 'figure zscores computed', 'zscores computed converting', 'computed converting page', 'converting page view', 'page view standard', 'view standard normal', 'standard normal variable', 'normal variable mean', 'variable mean standard', 'mean standard deviation', 'standard deviation case', 'deviation case see', 'case see notable', 'see notable spike', 'notable spike number', 'spike number view', 'number view showing', 'view showing suicide', 'showing suicide individual', 'suicide individual wellknown', 'individual wellknown enough', 'wellknown enough viewable', 'enough viewable macro', 'viewable macro scale', 'macro scale examining', 'scale examining presence', 'examining presence werther', 'presence werther effect', 'werther effect social', 'effect social medium', 'social medium note', 'medium note two', 'note two aspect', 'two aspect related', 'aspect related analysis', 'related analysis used', 'analysis used rest', 'used rest paper', 'rest paper first', 'paper first since', 'first since focusing', 'since focusing different', 'focusing different type', 'different type data', 'type data sourceswikipedia', 'data sourceswikipedia reddit', 'sourceswikipedia reddit use', 'reddit use zscore', 'use zscore conversion', 'zscore conversion normalization', 'conversion normalization technique', 'normalization technique wikipedia', 'technique wikipedia page', 'wikipedia page view', 'page view reddits', 'view reddits sw', 'reddits sw posting', 'sw posting activity', 'posting activity volume', 'activity volume observation', 'volume observation wikipedia', 'observation wikipedia data', 'wikipedia data analysis', 'data analysis ensue', 'analysis ensue focus', 'ensue focus observing', 'focus observing change', 'observing change two', 'change two week', 'two week window', 'week window preceding', 'window preceding succeeding', 'preceding succeeding celebrity', 'succeeding celebrity suicide', 'celebrity suicide choice', 'suicide choice motivated', 'choice motivated initial', 'motivated initial analysis', 'initial analysis literature', 'analysis literature werther', 'literature werther effect']",,,,,,,,
https://aclanthology.org/W17-3110.pdf,1,All of the following analysis is subject to a few caveats emergent from the data and how the data were collected. The users with mental health conditions are all found data of one sort or another so there are some inherent biases. We prefer to express these biases rather than add complexity by attempting to cleverly correct for them. Many of these users talk publicly about their mental health which given the stigma and discrimination they face is likely a distinct subpopulation of those with mental health conditions. It is possible that users with a psychological disorder or suicide history who did not publicly disclose this information could have been included in the control group for analyses which may have the effect of artificially lowering the estimated power of any emergent differences. Users who donated data through OurDataHelps.org are likely biased differently with over representation of altruism since they are willing to do things for the public good without any obvious self gain. Another consideration is that all users who reported a suicide attempt within our dataset survived. There is a possibility that characteristic differences also exist between individuals who do and do not die by a suicide attempt. Note that this research was conducted on English-speaking social media users. The content of social media post micropatterns for psychological disorders and suicidality could differ between cultural contexts due to differences in cross-cultural expressions of mental illness (Chentsova-Dutton et al. 2007). These are active Twitter users which imparts a demographic skew compared to the rest of the world (in particular these users skew young). We see more females in our user populations than the rough gender balance observed for general Twitter users (Greenwood et al. 2016). The language data itself is meant for public consumption and may reflect how the authors wish to be perceived and not what one would get from a more traditional journal study of internal and private thoughts and feelings. Finally we include users who had a concomittant or comorbid mental health condition. Thus a small number of users appear in more than one category.,all of the following analysis is subject to a few caveat emergent from the data and how the data were collected the user with mental health condition are all found data of one sort or another so there are some inherent bias we prefer to express these bias rather than add complexity by attempting to cleverly correct for them many of these user talk publicly about their mental health which given the stigma and discrimination they face is likely a distinct subpopulation of those with mental health condition it is possible that user with a psychological disorder or suicide history who did not publicly disclose this information could have been included in the control group for analysis which may have the effect of artificially lowering the estimated power of any emergent difference user who donated data through ourdatahelpsorg are likely biased differently with over representation of altruism since they are willing to do thing for the public good without any obvious self gain another consideration is that all user who reported a suicide attempt within our dataset survived there is a possibility that characteristic difference also exist between individual who do and do not die by a suicide attempt note that this research wa conducted on englishspeaking social medium user the content of social medium post micropatterns for psychological disorder and suicidality could differ between cultural context due to difference in crosscultural expression of mental illness chentsovadutton et al these are active twitter user which imparts a demographic skew compared to the rest of the world in particular these user skew young we see more female in our user population than the rough gender balance observed for general twitter user greenwood et al the language data itself is meant for public consumption and may reflect how the author wish to be perceived and not what one would get from a more traditional journal study of internal and private thought and feeling finally we include user who had a concomittant or comorbid mental health condition thus a small number of user appear in more than one category,"['following', 'analysis', 'subject', 'caveat', 'emergent', 'data', 'data', 'collected', 'user', 'mental', 'health', 'condition', 'found', 'data', 'one', 'sort', 'another', 'inherent', 'bias', 'prefer', 'express', 'bias', 'rather', 'add', 'complexity', 'attempting', 'cleverly', 'correct', 'many', 'user', 'talk', 'publicly', 'mental', 'health', 'given', 'stigma', 'discrimination', 'face', 'likely', 'distinct', 'subpopulation', 'mental', 'health', 'condition', 'possible', 'user', 'psychological', 'disorder', 'suicide', 'history', 'publicly', 'disclose', 'information', 'could', 'included', 'control', 'group', 'analysis', 'may', 'effect', 'artificially', 'lowering', 'estimated', 'power', 'emergent', 'difference', 'user', 'donated', 'data', 'ourdatahelpsorg', 'likely', 'biased', 'differently', 'representation', 'altruism', 'since', 'willing', 'thing', 'public', 'good', 'without', 'obvious', 'self', 'gain', 'another', 'consideration', 'user', 'reported', 'suicide', 'attempt', 'within', 'dataset', 'survived', 'possibility', 'characteristic', 'difference', 'also', 'exist', 'individual', 'die', 'suicide', 'attempt', 'note', 'research', 'wa', 'conducted', 'englishspeaking', 'social', 'medium', 'user', 'content', 'social', 'medium', 'post', 'micropatterns', 'psychological', 'disorder', 'suicidality', 'could', 'differ', 'cultural', 'context', 'due', 'difference', 'crosscultural', 'expression', 'mental', 'illness', 'chentsovadutton', 'et', 'al', 'active', 'twitter', 'user', 'imparts', 'demographic', 'skew', 'compared', 'rest', 'world', 'particular', 'user', 'skew', 'young', 'see', 'female', 'user', 'population', 'rough', 'gender', 'balance', 'observed', 'general', 'twitter', 'user', 'greenwood', 'et', 'al', 'language', 'data', 'meant', 'public', 'consumption', 'may', 'reflect', 'author', 'wish', 'perceived', 'one', 'would', 'get', 'traditional', 'journal', 'study', 'internal', 'private', 'thought', 'feeling', 'finally', 'include', 'user', 'concomittant', 'comorbid', 'mental', 'health', 'condition', 'thus', 'small', 'number', 'user', 'appear', 'one', 'category']","['following analysis', 'analysis subject', 'subject caveat', 'caveat emergent', 'emergent data', 'data data', 'data collected', 'collected user', 'user mental', 'mental health', 'health condition', 'condition found', 'found data', 'data one', 'one sort', 'sort another', 'another inherent', 'inherent bias', 'bias prefer', 'prefer express', 'express bias', 'bias rather', 'rather add', 'add complexity', 'complexity attempting', 'attempting cleverly', 'cleverly correct', 'correct many', 'many user', 'user talk', 'talk publicly', 'publicly mental', 'mental health', 'health given', 'given stigma', 'stigma discrimination', 'discrimination face', 'face likely', 'likely distinct', 'distinct subpopulation', 'subpopulation mental', 'mental health', 'health condition', 'condition possible', 'possible user', 'user psychological', 'psychological disorder', 'disorder suicide', 'suicide history', 'history publicly', 'publicly disclose', 'disclose information', 'information could', 'could included', 'included control', 'control group', 'group analysis', 'analysis may', 'may effect', 'effect artificially', 'artificially lowering', 'lowering estimated', 'estimated power', 'power emergent', 'emergent difference', 'difference user', 'user donated', 'donated data', 'data ourdatahelpsorg', 'ourdatahelpsorg likely', 'likely biased', 'biased differently', 'differently representation', 'representation altruism', 'altruism since', 'since willing', 'willing thing', 'thing public', 'public good', 'good without', 'without obvious', 'obvious self', 'self gain', 'gain another', 'another consideration', 'consideration user', 'user reported', 'reported suicide', 'suicide attempt', 'attempt within', 'within dataset', 'dataset survived', 'survived possibility', 'possibility characteristic', 'characteristic difference', 'difference also', 'also exist', 'exist individual', 'individual die', 'die suicide', 'suicide attempt', 'attempt note', 'note research', 'research wa', 'wa conducted', 'conducted englishspeaking', 'englishspeaking social', 'social medium', 'medium user', 'user content', 'content social', 'social medium', 'medium post', 'post micropatterns', 'micropatterns psychological', 'psychological disorder', 'disorder suicidality', 'suicidality could', 'could differ', 'differ cultural', 'cultural context', 'context due', 'due difference', 'difference crosscultural', 'crosscultural expression', 'expression mental', 'mental illness', 'illness chentsovadutton', 'chentsovadutton et', 'et al', 'al active', 'active twitter', 'twitter user', 'user imparts', 'imparts demographic', 'demographic skew', 'skew compared', 'compared rest', 'rest world', 'world particular', 'particular user', 'user skew', 'skew young', 'young see', 'see female', 'female user', 'user population', 'population rough', 'rough gender', 'gender balance', 'balance observed', 'observed general', 'general twitter', 'twitter user', 'user greenwood', 'greenwood et', 'et al', 'al language', 'language data', 'data meant', 'meant public', 'public consumption', 'consumption may', 'may reflect', 'reflect author', 'author wish', 'wish perceived', 'perceived one', 'one would', 'would get', 'get traditional', 'traditional journal', 'journal study', 'study internal', 'internal private', 'private thought', 'thought feeling', 'feeling finally', 'finally include', 'include user', 'user concomittant', 'concomittant comorbid', 'comorbid mental', 'mental health', 'health condition', 'condition thus', 'thus small', 'small number', 'number user', 'user appear', 'appear one', 'one category']","['following analysis subject', 'analysis subject caveat', 'subject caveat emergent', 'caveat emergent data', 'emergent data data', 'data data collected', 'data collected user', 'collected user mental', 'user mental health', 'mental health condition', 'health condition found', 'condition found data', 'found data one', 'data one sort', 'one sort another', 'sort another inherent', 'another inherent bias', 'inherent bias prefer', 'bias prefer express', 'prefer express bias', 'express bias rather', 'bias rather add', 'rather add complexity', 'add complexity attempting', 'complexity attempting cleverly', 'attempting cleverly correct', 'cleverly correct many', 'correct many user', 'many user talk', 'user talk publicly', 'talk publicly mental', 'publicly mental health', 'mental health given', 'health given stigma', 'given stigma discrimination', 'stigma discrimination face', 'discrimination face likely', 'face likely distinct', 'likely distinct subpopulation', 'distinct subpopulation mental', 'subpopulation mental health', 'mental health condition', 'health condition possible', 'condition possible user', 'possible user psychological', 'user psychological disorder', 'psychological disorder suicide', 'disorder suicide history', 'suicide history publicly', 'history publicly disclose', 'publicly disclose information', 'disclose information could', 'information could included', 'could included control', 'included control group', 'control group analysis', 'group analysis may', 'analysis may effect', 'may effect artificially', 'effect artificially lowering', 'artificially lowering estimated', 'lowering estimated power', 'estimated power emergent', 'power emergent difference', 'emergent difference user', 'difference user donated', 'user donated data', 'donated data ourdatahelpsorg', 'data ourdatahelpsorg likely', 'ourdatahelpsorg likely biased', 'likely biased differently', 'biased differently representation', 'differently representation altruism', 'representation altruism since', 'altruism since willing', 'since willing thing', 'willing thing public', 'thing public good', 'public good without', 'good without obvious', 'without obvious self', 'obvious self gain', 'self gain another', 'gain another consideration', 'another consideration user', 'consideration user reported', 'user reported suicide', 'reported suicide attempt', 'suicide attempt within', 'attempt within dataset', 'within dataset survived', 'dataset survived possibility', 'survived possibility characteristic', 'possibility characteristic difference', 'characteristic difference also', 'difference also exist', 'also exist individual', 'exist individual die', 'individual die suicide', 'die suicide attempt', 'suicide attempt note', 'attempt note research', 'note research wa', 'research wa conducted', 'wa conducted englishspeaking', 'conducted englishspeaking social', 'englishspeaking social medium', 'social medium user', 'medium user content', 'user content social', 'content social medium', 'social medium post', 'medium post micropatterns', 'post micropatterns psychological', 'micropatterns psychological disorder', 'psychological disorder suicidality', 'disorder suicidality could', 'suicidality could differ', 'could differ cultural', 'differ cultural context', 'cultural context due', 'context due difference', 'due difference crosscultural', 'difference crosscultural expression', 'crosscultural expression mental', 'expression mental illness', 'mental illness chentsovadutton', 'illness chentsovadutton et', 'chentsovadutton et al', 'et al active', 'al active twitter', 'active twitter user', 'twitter user imparts', 'user imparts demographic', 'imparts demographic skew', 'demographic skew compared', 'skew compared rest', 'compared rest world', 'rest world particular', 'world particular user', 'particular user skew', 'user skew young', 'skew young see', 'young see female', 'see female user', 'female user population', 'user population rough', 'population rough gender', 'rough gender balance', 'gender balance observed', 'balance observed general', 'observed general twitter', 'general twitter user', 'twitter user greenwood', 'user greenwood et', 'greenwood et al', 'et al language', 'al language data', 'language data meant', 'data meant public', 'meant public consumption', 'public consumption may', 'consumption may reflect', 'may reflect author', 'reflect author wish', 'author wish perceived', 'wish perceived one', 'perceived one would', 'one would get', 'would get traditional', 'get traditional journal', 'traditional journal study', 'journal study internal', 'study internal private', 'internal private thought', 'private thought feeling', 'thought feeling finally', 'feeling finally include', 'finally include user', 'include user concomittant', 'user concomittant comorbid', 'concomittant comorbid mental', 'comorbid mental health', 'mental health condition', 'health condition thus', 'condition thus small', 'thus small number', 'small number user', 'number user appear', 'user appear one', 'appear one category']",,,,,,,,
https://dl.acm.org/doi/abs/10.1145/2998181.2998220,1,We note that the populations of the four countries are widely different along with their overall reported internet penetration rates6 . Hence we devise a subsampling strategy to filter users belonging to one of the four countries from the set of users in the candidate disclosure and the control datasets with inferrable country information. First for population based subsampling we use the inverse of the population ranks of the countries4 as the respective rates of sampling. Then we use the internet penetration percentages of the countries5 to randomly sample that fraction of users from the population subsampled sets. In this manner across both the datasets we obtained 211132 Twitter users from the US 61816 users from the UK 10808 from IN and 5769 from ZA.Next we also note that it is possible that our candidate control dataset includes users who engage in mental illness in their posts however did not use any of the keyphrases from Table 1. To eliminate such users like above we compare the language used in the Twitter posts of these users with that of the Reddit mental health posts. However in this case we are interested in the users whose language is most distinct (or least similar) from that used in the Reddit content. Hence our final control dataset is obtained by filtering for those users whose language model based similarity is less than the median similarity across all control user vectors (238860 users; median distance=.38; σ = .125). See Figure 1(b) for a distribution of the cosine cosine similarities. We will refer to this dataset as CTL users (ref. Figure 2 for the approach).,we note that the population of the four country are widely different along with their overall reported internet penetration rate hence we devise a subsampling strategy to filter user belonging to one of the four country from the set of user in the candidate disclosure and the control datasets with inferrable country information first for population based subsampling we use the inverse of the population rank of the country a the respective rate of sampling then we use the internet penetration percentage of the country to randomly sample that fraction of user from the population subsampled set in this manner across both the datasets we obtained twitter user from the u user from the uk from in and from zanext we also note that it is possible that our candidate control dataset includes user who engage in mental illness in their post however did not use any of the keyphrases from table to eliminate such user like above we compare the language used in the twitter post of these user with that of the reddit mental health post however in this case we are interested in the user whose language is most distinct or least similar from that used in the reddit content hence our final control dataset is obtained by filtering for those user whose language model based similarity is le than the median similarity across all control user vector user median distance see figure b for a distribution of the cosine cosine similarity we will refer to this dataset a ctl user ref figure for the approach,"['note', 'population', 'four', 'country', 'widely', 'different', 'along', 'overall', 'reported', 'internet', 'penetration', 'rate', 'hence', 'devise', 'subsampling', 'strategy', 'filter', 'user', 'belonging', 'one', 'four', 'country', 'set', 'user', 'candidate', 'disclosure', 'control', 'datasets', 'inferrable', 'country', 'information', 'first', 'population', 'based', 'subsampling', 'use', 'inverse', 'population', 'rank', 'country', 'respective', 'rate', 'sampling', 'use', 'internet', 'penetration', 'percentage', 'country', 'randomly', 'sample', 'fraction', 'user', 'population', 'subsampled', 'set', 'manner', 'across', 'datasets', 'obtained', 'twitter', 'user', 'u', 'user', 'uk', 'zanext', 'also', 'note', 'possible', 'candidate', 'control', 'dataset', 'includes', 'user', 'engage', 'mental', 'illness', 'post', 'however', 'use', 'keyphrases', 'table', 'eliminate', 'user', 'like', 'compare', 'language', 'used', 'twitter', 'post', 'user', 'reddit', 'mental', 'health', 'post', 'however', 'case', 'interested', 'user', 'whose', 'language', 'distinct', 'least', 'similar', 'used', 'reddit', 'content', 'hence', 'final', 'control', 'dataset', 'obtained', 'filtering', 'user', 'whose', 'language', 'model', 'based', 'similarity', 'le', 'median', 'similarity', 'across', 'control', 'user', 'vector', 'user', 'median', 'distance', 'see', 'figure', 'b', 'distribution', 'cosine', 'cosine', 'similarity', 'refer', 'dataset', 'ctl', 'user', 'ref', 'figure', 'approach']","['note population', 'population four', 'four country', 'country widely', 'widely different', 'different along', 'along overall', 'overall reported', 'reported internet', 'internet penetration', 'penetration rate', 'rate hence', 'hence devise', 'devise subsampling', 'subsampling strategy', 'strategy filter', 'filter user', 'user belonging', 'belonging one', 'one four', 'four country', 'country set', 'set user', 'user candidate', 'candidate disclosure', 'disclosure control', 'control datasets', 'datasets inferrable', 'inferrable country', 'country information', 'information first', 'first population', 'population based', 'based subsampling', 'subsampling use', 'use inverse', 'inverse population', 'population rank', 'rank country', 'country respective', 'respective rate', 'rate sampling', 'sampling use', 'use internet', 'internet penetration', 'penetration percentage', 'percentage country', 'country randomly', 'randomly sample', 'sample fraction', 'fraction user', 'user population', 'population subsampled', 'subsampled set', 'set manner', 'manner across', 'across datasets', 'datasets obtained', 'obtained twitter', 'twitter user', 'user u', 'u user', 'user uk', 'uk zanext', 'zanext also', 'also note', 'note possible', 'possible candidate', 'candidate control', 'control dataset', 'dataset includes', 'includes user', 'user engage', 'engage mental', 'mental illness', 'illness post', 'post however', 'however use', 'use keyphrases', 'keyphrases table', 'table eliminate', 'eliminate user', 'user like', 'like compare', 'compare language', 'language used', 'used twitter', 'twitter post', 'post user', 'user reddit', 'reddit mental', 'mental health', 'health post', 'post however', 'however case', 'case interested', 'interested user', 'user whose', 'whose language', 'language distinct', 'distinct least', 'least similar', 'similar used', 'used reddit', 'reddit content', 'content hence', 'hence final', 'final control', 'control dataset', 'dataset obtained', 'obtained filtering', 'filtering user', 'user whose', 'whose language', 'language model', 'model based', 'based similarity', 'similarity le', 'le median', 'median similarity', 'similarity across', 'across control', 'control user', 'user vector', 'vector user', 'user median', 'median distance', 'distance see', 'see figure', 'figure b', 'b distribution', 'distribution cosine', 'cosine cosine', 'cosine similarity', 'similarity refer', 'refer dataset', 'dataset ctl', 'ctl user', 'user ref', 'ref figure', 'figure approach']","['note population four', 'population four country', 'four country widely', 'country widely different', 'widely different along', 'different along overall', 'along overall reported', 'overall reported internet', 'reported internet penetration', 'internet penetration rate', 'penetration rate hence', 'rate hence devise', 'hence devise subsampling', 'devise subsampling strategy', 'subsampling strategy filter', 'strategy filter user', 'filter user belonging', 'user belonging one', 'belonging one four', 'one four country', 'four country set', 'country set user', 'set user candidate', 'user candidate disclosure', 'candidate disclosure control', 'disclosure control datasets', 'control datasets inferrable', 'datasets inferrable country', 'inferrable country information', 'country information first', 'information first population', 'first population based', 'population based subsampling', 'based subsampling use', 'subsampling use inverse', 'use inverse population', 'inverse population rank', 'population rank country', 'rank country respective', 'country respective rate', 'respective rate sampling', 'rate sampling use', 'sampling use internet', 'use internet penetration', 'internet penetration percentage', 'penetration percentage country', 'percentage country randomly', 'country randomly sample', 'randomly sample fraction', 'sample fraction user', 'fraction user population', 'user population subsampled', 'population subsampled set', 'subsampled set manner', 'set manner across', 'manner across datasets', 'across datasets obtained', 'datasets obtained twitter', 'obtained twitter user', 'twitter user u', 'user u user', 'u user uk', 'user uk zanext', 'uk zanext also', 'zanext also note', 'also note possible', 'note possible candidate', 'possible candidate control', 'candidate control dataset', 'control dataset includes', 'dataset includes user', 'includes user engage', 'user engage mental', 'engage mental illness', 'mental illness post', 'illness post however', 'post however use', 'however use keyphrases', 'use keyphrases table', 'keyphrases table eliminate', 'table eliminate user', 'eliminate user like', 'user like compare', 'like compare language', 'compare language used', 'language used twitter', 'used twitter post', 'twitter post user', 'post user reddit', 'user reddit mental', 'reddit mental health', 'mental health post', 'health post however', 'post however case', 'however case interested', 'case interested user', 'interested user whose', 'user whose language', 'whose language distinct', 'language distinct least', 'distinct least similar', 'least similar used', 'similar used reddit', 'used reddit content', 'reddit content hence', 'content hence final', 'hence final control', 'final control dataset', 'control dataset obtained', 'dataset obtained filtering', 'obtained filtering user', 'filtering user whose', 'user whose language', 'whose language model', 'language model based', 'model based similarity', 'based similarity le', 'similarity le median', 'le median similarity', 'median similarity across', 'similarity across control', 'across control user', 'control user vector', 'user vector user', 'vector user median', 'user median distance', 'median distance see', 'distance see figure', 'see figure b', 'figure b distribution', 'b distribution cosine', 'distribution cosine cosine', 'cosine cosine similarity', 'cosine similarity refer', 'similarity refer dataset', 'refer dataset ctl', 'dataset ctl user', 'ctl user ref', 'user ref figure', 'ref figure approach']",,,,,,,,
https://www.jmir.org/2019/6/e14199/,1,The selection of the tweets and their users was based on the filtered real-time streaming support provided by the Twitter API. In the first step we selected the users who showed potential signs of depression on Twitter on the basis of the 20 most frequent words in Spanish expressed by patients suffering from depression in clinical settings. These words were jointly identified and selected by a psychologist and a family physician with clinical experience and were based on the definition and general features of depression according to the Diagnostic and Statistical Manual of Mental Disorders [42]. The list of words used and their English translations are shown in Textbox 1. During June 2018 1470000 tweets including 1 or more occurrences of the words listed in Textbox 1 were collected. From this collection of tweets and to select the users who publicly stated in the textual description associated to their profile that they suffered from depression all the profile descriptions including 1 or more occurrences of the word “depr” and all the possible derivations related to the word depression in Spanish such as “depre” “depresión” “depresivo” “depresiva” “deprimido” and “deprimida” were considered. From the 720 users who included 1 or more of these words in their description profile 90 users who stated they suffered from depression or were receiving treatment for depression were selected for the analysis. This selection was performed by a psychologist verifying that the statements were related to real expressions of depression excluding quotes jokes or fake ones. For each of these depressed Twitter users we collected all the most recent tweets from their timeline up to a maximum of about 3200 tweets. Thus a total of 189669 tweets were collected a figure that was reduced to 140946 after discarding the retweets. These 140946 tweets constituted the depressive users dataset. Examples of sentences appearing in the user profiles that were used for selecting the depressive users are: “Paciente psiquiátrico con depresión crónica” (Psychiatric patient with chronic depression; example of a profile sentence that indicates depression). “Colecciono errores traducidos a tweets depresivos y a uno que otro impulso de amor” (I gather errors translated into depressing tweets and into one or another love impulse; example of a profile sentence that does not indicate depression). Once the users with profile sentences indicating depression had been retrieved their Twitter timelines were collected. Only those users having in their timeline at least 10 tweets that suggested signs of depression were retained for further analyses. For each user the selection of these tweets was performed by manually inspecting the tweets of the user’s complete timeline in reverse temporal order starting from the most recent one to the oldest tweet of the timeline retrieved by means of the Twitter API . Finally a total number of 1000 tweets issued by the 90 depressive users suggesting signs of depression were detected and used for the analysis. This set of tweets provided us with the depressive tweets dataset which was used to analyze linguistic features of tweets showing signs of depression. It has to be mentioned that these 1000 tweets were not to be included in the depressive users dataset (see Figure 1). At the same time more than 97500000 tweets were also collected in June 2018: such tweets were gathered by listening to the public Twitter stream during this time span by only considering tweets with Spanish textual contents (as detected by Twitter language identification support). Given that Twitter requires more restrictive filters than just the language of the tweets we used a list of the most frequently used Spanish words (stopwords) to retrieve all tweets that included 1 or more of these words. The vast majority of Spanish tweets should match this criterion. A sample of 450 users who did not mention in their profile the word depression and its derivations were selected randomly from the 97500000 tweets. The complete timelines of these users were compiled (1141021 tweets) which were reduced to 712589 once retweets were removed. These 712589 tweets constituted the control dataset. To identify the language of a tweet we relied on the language automatically identified by Twitter for each tweet selecting tweets in Spanish. It has to be noted that these data can contain some tweets from unidentified depressive users.,the selection of the tweet and their user wa based on the filtered realtime streaming support provided by the twitter api in the first step we selected the user who showed potential sign of depression on twitter on the basis of the most frequent word in spanish expressed by patient suffering from depression in clinical setting these word were jointly identified and selected by a psychologist and a family physician with clinical experience and were based on the definition and general feature of depression according to the diagnostic and statistical manual of mental disorder the list of word used and their english translation are shown in textbox during june tweet including or more occurrence of the word listed in textbox were collected from this collection of tweet and to select the user who publicly stated in the textual description associated to their profile that they suffered from depression all the profile description including or more occurrence of the word depr and all the possible derivation related to the word depression in spanish such a depre depresin depresivo depresiva deprimido and deprimida were considered from the user who included or more of these word in their description profile user who stated they suffered from depression or were receiving treatment for depression were selected for the analysis this selection wa performed by a psychologist verifying that the statement were related to real expression of depression excluding quote joke or fake one for each of these depressed twitter user we collected all the most recent tweet from their timeline up to a maximum of about tweet thus a total of tweet were collected a figure that wa reduced to after discarding the retweets these tweet constituted the depressive user dataset example of sentence appearing in the user profile that were used for selecting the depressive user are paciente psiquitrico con depresin crnica psychiatric patient with chronic depression example of a profile sentence that indicates depression colecciono errores traducidos a tweet depresivos y a uno que otro impulso de amor i gather error translated into depressing tweet and into one or another love impulse example of a profile sentence that doe not indicate depression once the user with profile sentence indicating depression had been retrieved their twitter timeline were collected only those user having in their timeline at least tweet that suggested sign of depression were retained for further analysis for each user the selection of these tweet wa performed by manually inspecting the tweet of the user complete timeline in reverse temporal order starting from the most recent one to the oldest tweet of the timeline retrieved by mean of the twitter api finally a total number of tweet issued by the depressive user suggesting sign of depression were detected and used for the analysis this set of tweet provided u with the depressive tweet dataset which wa used to analyze linguistic feature of tweet showing sign of depression it ha to be mentioned that these tweet were not to be included in the depressive user dataset see figure at the same time more than tweet were also collected in june such tweet were gathered by listening to the public twitter stream during this time span by only considering tweet with spanish textual content a detected by twitter language identification support given that twitter requires more restrictive filter than just the language of the tweet we used a list of the most frequently used spanish word stopwords to retrieve all tweet that included or more of these word the vast majority of spanish tweet should match this criterion a sample of user who did not mention in their profile the word depression and it derivation were selected randomly from the tweet the complete timeline of these user were compiled tweet which were reduced to once retweets were removed these tweet constituted the control dataset to identify the language of a tweet we relied on the language automatically identified by twitter for each tweet selecting tweet in spanish it ha to be noted that these data can contain some tweet from unidentified depressive user,"['selection', 'tweet', 'user', 'wa', 'based', 'filtered', 'realtime', 'streaming', 'support', 'provided', 'twitter', 'api', 'first', 'step', 'selected', 'user', 'showed', 'potential', 'sign', 'depression', 'twitter', 'basis', 'frequent', 'word', 'spanish', 'expressed', 'patient', 'suffering', 'depression', 'clinical', 'setting', 'word', 'jointly', 'identified', 'selected', 'psychologist', 'family', 'physician', 'clinical', 'experience', 'based', 'definition', 'general', 'feature', 'depression', 'according', 'diagnostic', 'statistical', 'manual', 'mental', 'disorder', 'list', 'word', 'used', 'english', 'translation', 'shown', 'textbox', 'june', 'tweet', 'including', 'occurrence', 'word', 'listed', 'textbox', 'collected', 'collection', 'tweet', 'select', 'user', 'publicly', 'stated', 'textual', 'description', 'associated', 'profile', 'suffered', 'depression', 'profile', 'description', 'including', 'occurrence', 'word', 'depr', 'possible', 'derivation', 'related', 'word', 'depression', 'spanish', 'depre', 'depresin', 'depresivo', 'depresiva', 'deprimido', 'deprimida', 'considered', 'user', 'included', 'word', 'description', 'profile', 'user', 'stated', 'suffered', 'depression', 'receiving', 'treatment', 'depression', 'selected', 'analysis', 'selection', 'wa', 'performed', 'psychologist', 'verifying', 'statement', 'related', 'real', 'expression', 'depression', 'excluding', 'quote', 'joke', 'fake', 'one', 'depressed', 'twitter', 'user', 'collected', 'recent', 'tweet', 'timeline', 'maximum', 'tweet', 'thus', 'total', 'tweet', 'collected', 'figure', 'wa', 'reduced', 'discarding', 'retweets', 'tweet', 'constituted', 'depressive', 'user', 'dataset', 'example', 'sentence', 'appearing', 'user', 'profile', 'used', 'selecting', 'depressive', 'user', 'paciente', 'psiquitrico', 'con', 'depresin', 'crnica', 'psychiatric', 'patient', 'chronic', 'depression', 'example', 'profile', 'sentence', 'indicates', 'depression', 'colecciono', 'errores', 'traducidos', 'tweet', 'depresivos', 'uno', 'que', 'otro', 'impulso', 'de', 'amor', 'gather', 'error', 'translated', 'depressing', 'tweet', 'one', 'another', 'love', 'impulse', 'example', 'profile', 'sentence', 'doe', 'indicate', 'depression', 'user', 'profile', 'sentence', 'indicating', 'depression', 'retrieved', 'twitter', 'timeline', 'collected', 'user', 'timeline', 'least', 'tweet', 'suggested', 'sign', 'depression', 'retained', 'analysis', 'user', 'selection', 'tweet', 'wa', 'performed', 'manually', 'inspecting', 'tweet', 'user', 'complete', 'timeline', 'reverse', 'temporal', 'order', 'starting', 'recent', 'one', 'oldest', 'tweet', 'timeline', 'retrieved', 'mean', 'twitter', 'api', 'finally', 'total', 'number', 'tweet', 'issued', 'depressive', 'user', 'suggesting', 'sign', 'depression', 'detected', 'used', 'analysis', 'set', 'tweet', 'provided', 'u', 'depressive', 'tweet', 'dataset', 'wa', 'used', 'analyze', 'linguistic', 'feature', 'tweet', 'showing', 'sign', 'depression', 'ha', 'mentioned', 'tweet', 'included', 'depressive', 'user', 'dataset', 'see', 'figure', 'time', 'tweet', 'also', 'collected', 'june', 'tweet', 'gathered', 'listening', 'public', 'twitter', 'stream', 'time', 'span', 'considering', 'tweet', 'spanish', 'textual', 'content', 'detected', 'twitter', 'language', 'identification', 'support', 'given', 'twitter', 'requires', 'restrictive', 'filter', 'language', 'tweet', 'used', 'list', 'frequently', 'used', 'spanish', 'word', 'stopwords', 'retrieve', 'tweet', 'included', 'word', 'vast', 'majority', 'spanish', 'tweet', 'match', 'criterion', 'sample', 'user', 'mention', 'profile', 'word', 'depression', 'derivation', 'selected', 'randomly', 'tweet', 'complete', 'timeline', 'user', 'compiled', 'tweet', 'reduced', 'retweets', 'removed', 'tweet', 'constituted', 'control', 'dataset', 'identify', 'language', 'tweet', 'relied', 'language', 'automatically', 'identified', 'twitter', 'tweet', 'selecting', 'tweet', 'spanish', 'ha', 'noted', 'data', 'contain', 'tweet', 'unidentified', 'depressive', 'user']","['selection tweet', 'tweet user', 'user wa', 'wa based', 'based filtered', 'filtered realtime', 'realtime streaming', 'streaming support', 'support provided', 'provided twitter', 'twitter api', 'api first', 'first step', 'step selected', 'selected user', 'user showed', 'showed potential', 'potential sign', 'sign depression', 'depression twitter', 'twitter basis', 'basis frequent', 'frequent word', 'word spanish', 'spanish expressed', 'expressed patient', 'patient suffering', 'suffering depression', 'depression clinical', 'clinical setting', 'setting word', 'word jointly', 'jointly identified', 'identified selected', 'selected psychologist', 'psychologist family', 'family physician', 'physician clinical', 'clinical experience', 'experience based', 'based definition', 'definition general', 'general feature', 'feature depression', 'depression according', 'according diagnostic', 'diagnostic statistical', 'statistical manual', 'manual mental', 'mental disorder', 'disorder list', 'list word', 'word used', 'used english', 'english translation', 'translation shown', 'shown textbox', 'textbox june', 'june tweet', 'tweet including', 'including occurrence', 'occurrence word', 'word listed', 'listed textbox', 'textbox collected', 'collected collection', 'collection tweet', 'tweet select', 'select user', 'user publicly', 'publicly stated', 'stated textual', 'textual description', 'description associated', 'associated profile', 'profile suffered', 'suffered depression', 'depression profile', 'profile description', 'description including', 'including occurrence', 'occurrence word', 'word depr', 'depr possible', 'possible derivation', 'derivation related', 'related word', 'word depression', 'depression spanish', 'spanish depre', 'depre depresin', 'depresin depresivo', 'depresivo depresiva', 'depresiva deprimido', 'deprimido deprimida', 'deprimida considered', 'considered user', 'user included', 'included word', 'word description', 'description profile', 'profile user', 'user stated', 'stated suffered', 'suffered depression', 'depression receiving', 'receiving treatment', 'treatment depression', 'depression selected', 'selected analysis', 'analysis selection', 'selection wa', 'wa performed', 'performed psychologist', 'psychologist verifying', 'verifying statement', 'statement related', 'related real', 'real expression', 'expression depression', 'depression excluding', 'excluding quote', 'quote joke', 'joke fake', 'fake one', 'one depressed', 'depressed twitter', 'twitter user', 'user collected', 'collected recent', 'recent tweet', 'tweet timeline', 'timeline maximum', 'maximum tweet', 'tweet thus', 'thus total', 'total tweet', 'tweet collected', 'collected figure', 'figure wa', 'wa reduced', 'reduced discarding', 'discarding retweets', 'retweets tweet', 'tweet constituted', 'constituted depressive', 'depressive user', 'user dataset', 'dataset example', 'example sentence', 'sentence appearing', 'appearing user', 'user profile', 'profile used', 'used selecting', 'selecting depressive', 'depressive user', 'user paciente', 'paciente psiquitrico', 'psiquitrico con', 'con depresin', 'depresin crnica', 'crnica psychiatric', 'psychiatric patient', 'patient chronic', 'chronic depression', 'depression example', 'example profile', 'profile sentence', 'sentence indicates', 'indicates depression', 'depression colecciono', 'colecciono errores', 'errores traducidos', 'traducidos tweet', 'tweet depresivos', 'depresivos uno', 'uno que', 'que otro', 'otro impulso', 'impulso de', 'de amor', 'amor gather', 'gather error', 'error translated', 'translated depressing', 'depressing tweet', 'tweet one', 'one another', 'another love', 'love impulse', 'impulse example', 'example profile', 'profile sentence', 'sentence doe', 'doe indicate', 'indicate depression', 'depression user', 'user profile', 'profile sentence', 'sentence indicating', 'indicating depression', 'depression retrieved', 'retrieved twitter', 'twitter timeline', 'timeline collected', 'collected user', 'user timeline', 'timeline least', 'least tweet', 'tweet suggested', 'suggested sign', 'sign depression', 'depression retained', 'retained analysis', 'analysis user', 'user selection', 'selection tweet', 'tweet wa', 'wa performed', 'performed manually', 'manually inspecting', 'inspecting tweet', 'tweet user', 'user complete', 'complete timeline', 'timeline reverse', 'reverse temporal', 'temporal order', 'order starting', 'starting recent', 'recent one', 'one oldest', 'oldest tweet', 'tweet timeline', 'timeline retrieved', 'retrieved mean', 'mean twitter', 'twitter api', 'api finally', 'finally total', 'total number', 'number tweet', 'tweet issued', 'issued depressive', 'depressive user', 'user suggesting', 'suggesting sign', 'sign depression', 'depression detected', 'detected used', 'used analysis', 'analysis set', 'set tweet', 'tweet provided', 'provided u', 'u depressive', 'depressive tweet', 'tweet dataset', 'dataset wa', 'wa used', 'used analyze', 'analyze linguistic', 'linguistic feature', 'feature tweet', 'tweet showing', 'showing sign', 'sign depression', 'depression ha', 'ha mentioned', 'mentioned tweet', 'tweet included', 'included depressive', 'depressive user', 'user dataset', 'dataset see', 'see figure', 'figure time', 'time tweet', 'tweet also', 'also collected', 'collected june', 'june tweet', 'tweet gathered', 'gathered listening', 'listening public', 'public twitter', 'twitter stream', 'stream time', 'time span', 'span considering', 'considering tweet', 'tweet spanish', 'spanish textual', 'textual content', 'content detected', 'detected twitter', 'twitter language', 'language identification', 'identification support', 'support given', 'given twitter', 'twitter requires', 'requires restrictive', 'restrictive filter', 'filter language', 'language tweet', 'tweet used', 'used list', 'list frequently', 'frequently used', 'used spanish', 'spanish word', 'word stopwords', 'stopwords retrieve', 'retrieve tweet', 'tweet included', 'included word', 'word vast', 'vast majority', 'majority spanish', 'spanish tweet', 'tweet match', 'match criterion', 'criterion sample', 'sample user', 'user mention', 'mention profile', 'profile word', 'word depression', 'depression derivation', 'derivation selected', 'selected randomly', 'randomly tweet', 'tweet complete', 'complete timeline', 'timeline user', 'user compiled', 'compiled tweet', 'tweet reduced', 'reduced retweets', 'retweets removed', 'removed tweet', 'tweet constituted', 'constituted control', 'control dataset', 'dataset identify', 'identify language', 'language tweet', 'tweet relied', 'relied language', 'language automatically', 'automatically identified', 'identified twitter', 'twitter tweet', 'tweet selecting', 'selecting tweet', 'tweet spanish', 'spanish ha', 'ha noted', 'noted data', 'data contain', 'contain tweet', 'tweet unidentified', 'unidentified depressive', 'depressive user']","['selection tweet user', 'tweet user wa', 'user wa based', 'wa based filtered', 'based filtered realtime', 'filtered realtime streaming', 'realtime streaming support', 'streaming support provided', 'support provided twitter', 'provided twitter api', 'twitter api first', 'api first step', 'first step selected', 'step selected user', 'selected user showed', 'user showed potential', 'showed potential sign', 'potential sign depression', 'sign depression twitter', 'depression twitter basis', 'twitter basis frequent', 'basis frequent word', 'frequent word spanish', 'word spanish expressed', 'spanish expressed patient', 'expressed patient suffering', 'patient suffering depression', 'suffering depression clinical', 'depression clinical setting', 'clinical setting word', 'setting word jointly', 'word jointly identified', 'jointly identified selected', 'identified selected psychologist', 'selected psychologist family', 'psychologist family physician', 'family physician clinical', 'physician clinical experience', 'clinical experience based', 'experience based definition', 'based definition general', 'definition general feature', 'general feature depression', 'feature depression according', 'depression according diagnostic', 'according diagnostic statistical', 'diagnostic statistical manual', 'statistical manual mental', 'manual mental disorder', 'mental disorder list', 'disorder list word', 'list word used', 'word used english', 'used english translation', 'english translation shown', 'translation shown textbox', 'shown textbox june', 'textbox june tweet', 'june tweet including', 'tweet including occurrence', 'including occurrence word', 'occurrence word listed', 'word listed textbox', 'listed textbox collected', 'textbox collected collection', 'collected collection tweet', 'collection tweet select', 'tweet select user', 'select user publicly', 'user publicly stated', 'publicly stated textual', 'stated textual description', 'textual description associated', 'description associated profile', 'associated profile suffered', 'profile suffered depression', 'suffered depression profile', 'depression profile description', 'profile description including', 'description including occurrence', 'including occurrence word', 'occurrence word depr', 'word depr possible', 'depr possible derivation', 'possible derivation related', 'derivation related word', 'related word depression', 'word depression spanish', 'depression spanish depre', 'spanish depre depresin', 'depre depresin depresivo', 'depresin depresivo depresiva', 'depresivo depresiva deprimido', 'depresiva deprimido deprimida', 'deprimido deprimida considered', 'deprimida considered user', 'considered user included', 'user included word', 'included word description', 'word description profile', 'description profile user', 'profile user stated', 'user stated suffered', 'stated suffered depression', 'suffered depression receiving', 'depression receiving treatment', 'receiving treatment depression', 'treatment depression selected', 'depression selected analysis', 'selected analysis selection', 'analysis selection wa', 'selection wa performed', 'wa performed psychologist', 'performed psychologist verifying', 'psychologist verifying statement', 'verifying statement related', 'statement related real', 'related real expression', 'real expression depression', 'expression depression excluding', 'depression excluding quote', 'excluding quote joke', 'quote joke fake', 'joke fake one', 'fake one depressed', 'one depressed twitter', 'depressed twitter user', 'twitter user collected', 'user collected recent', 'collected recent tweet', 'recent tweet timeline', 'tweet timeline maximum', 'timeline maximum tweet', 'maximum tweet thus', 'tweet thus total', 'thus total tweet', 'total tweet collected', 'tweet collected figure', 'collected figure wa', 'figure wa reduced', 'wa reduced discarding', 'reduced discarding retweets', 'discarding retweets tweet', 'retweets tweet constituted', 'tweet constituted depressive', 'constituted depressive user', 'depressive user dataset', 'user dataset example', 'dataset example sentence', 'example sentence appearing', 'sentence appearing user', 'appearing user profile', 'user profile used', 'profile used selecting', 'used selecting depressive', 'selecting depressive user', 'depressive user paciente', 'user paciente psiquitrico', 'paciente psiquitrico con', 'psiquitrico con depresin', 'con depresin crnica', 'depresin crnica psychiatric', 'crnica psychiatric patient', 'psychiatric patient chronic', 'patient chronic depression', 'chronic depression example', 'depression example profile', 'example profile sentence', 'profile sentence indicates', 'sentence indicates depression', 'indicates depression colecciono', 'depression colecciono errores', 'colecciono errores traducidos', 'errores traducidos tweet', 'traducidos tweet depresivos', 'tweet depresivos uno', 'depresivos uno que', 'uno que otro', 'que otro impulso', 'otro impulso de', 'impulso de amor', 'de amor gather', 'amor gather error', 'gather error translated', 'error translated depressing', 'translated depressing tweet', 'depressing tweet one', 'tweet one another', 'one another love', 'another love impulse', 'love impulse example', 'impulse example profile', 'example profile sentence', 'profile sentence doe', 'sentence doe indicate', 'doe indicate depression', 'indicate depression user', 'depression user profile', 'user profile sentence', 'profile sentence indicating', 'sentence indicating depression', 'indicating depression retrieved', 'depression retrieved twitter', 'retrieved twitter timeline', 'twitter timeline collected', 'timeline collected user', 'collected user timeline', 'user timeline least', 'timeline least tweet', 'least tweet suggested', 'tweet suggested sign', 'suggested sign depression', 'sign depression retained', 'depression retained analysis', 'retained analysis user', 'analysis user selection', 'user selection tweet', 'selection tweet wa', 'tweet wa performed', 'wa performed manually', 'performed manually inspecting', 'manually inspecting tweet', 'inspecting tweet user', 'tweet user complete', 'user complete timeline', 'complete timeline reverse', 'timeline reverse temporal', 'reverse temporal order', 'temporal order starting', 'order starting recent', 'starting recent one', 'recent one oldest', 'one oldest tweet', 'oldest tweet timeline', 'tweet timeline retrieved', 'timeline retrieved mean', 'retrieved mean twitter', 'mean twitter api', 'twitter api finally', 'api finally total', 'finally total number', 'total number tweet', 'number tweet issued', 'tweet issued depressive', 'issued depressive user', 'depressive user suggesting', 'user suggesting sign', 'suggesting sign depression', 'sign depression detected', 'depression detected used', 'detected used analysis', 'used analysis set', 'analysis set tweet', 'set tweet provided', 'tweet provided u', 'provided u depressive', 'u depressive tweet', 'depressive tweet dataset', 'tweet dataset wa', 'dataset wa used', 'wa used analyze', 'used analyze linguistic', 'analyze linguistic feature', 'linguistic feature tweet', 'feature tweet showing', 'tweet showing sign', 'showing sign depression', 'sign depression ha', 'depression ha mentioned', 'ha mentioned tweet', 'mentioned tweet included', 'tweet included depressive', 'included depressive user', 'depressive user dataset', 'user dataset see', 'dataset see figure', 'see figure time', 'figure time tweet', 'time tweet also', 'tweet also collected', 'also collected june', 'collected june tweet', 'june tweet gathered', 'tweet gathered listening', 'gathered listening public', 'listening public twitter', 'public twitter stream', 'twitter stream time', 'stream time span', 'time span considering', 'span considering tweet', 'considering tweet spanish', 'tweet spanish textual', 'spanish textual content', 'textual content detected', 'content detected twitter', 'detected twitter language', 'twitter language identification', 'language identification support', 'identification support given', 'support given twitter', 'given twitter requires', 'twitter requires restrictive', 'requires restrictive filter', 'restrictive filter language', 'filter language tweet', 'language tweet used', 'tweet used list', 'used list frequently', 'list frequently used', 'frequently used spanish', 'used spanish word', 'spanish word stopwords', 'word stopwords retrieve', 'stopwords retrieve tweet', 'retrieve tweet included', 'tweet included word', 'included word vast', 'word vast majority', 'vast majority spanish', 'majority spanish tweet', 'spanish tweet match', 'tweet match criterion', 'match criterion sample', 'criterion sample user', 'sample user mention', 'user mention profile', 'mention profile word', 'profile word depression', 'word depression derivation', 'depression derivation selected', 'derivation selected randomly', 'selected randomly tweet', 'randomly tweet complete', 'tweet complete timeline', 'complete timeline user', 'timeline user compiled', 'user compiled tweet', 'compiled tweet reduced', 'tweet reduced retweets', 'reduced retweets removed', 'retweets removed tweet', 'removed tweet constituted', 'tweet constituted control', 'constituted control dataset', 'control dataset identify', 'dataset identify language', 'identify language tweet', 'language tweet relied', 'tweet relied language', 'relied language automatically', 'language automatically identified', 'automatically identified twitter', 'identified twitter tweet', 'twitter tweet selecting', 'tweet selecting tweet', 'selecting tweet spanish', 'tweet spanish ha', 'spanish ha noted', 'ha noted data', 'noted data contain', 'data contain tweet', 'contain tweet unidentified', 'tweet unidentified depressive', 'unidentified depressive user']",,,,,,,,
https://aclanthology.org/W18-0608.pdf,0,Data was collected from 7 Cups of Tea an anonymous online chat-based peer support community for emotional distress1 . Users agree at signup that their data may be used for the purposes of research. All the data used for the current study was anonymous and securely stored. This research was performed in line with the ethical and privacy protocols outlined in detail in (Benton et al. 2017). Data from 7 Cups takes the form of written dialogue between users of the service and volunteers who are trained as “active listeners”. A fragment of an exchange between the user of the service (U) and the volunteer (V) might go as follows: For the analyses reported in this paper we used only text generated by users of the service not the volunteers providing peer support. Users who reported depression as their primary concern at sign up were eligible for inclusion in analyses. Our original sample was comprised of 23048 conversations involving 1937 unique users. Users were excluded from the sample if they did not indicate their culture or if they selected ‘Other’. This resulted in the exclusion of 199 and 130 users respectively. The original sample also included users identifying as Native American or American Indian. This group was excluded from analyses since the majority of the data among these users was not English. This resulted in the removal of 15 users leaving a total sample size of 1593.Users of the service completed a questionnaire at sign-up in which they provided information about their demographic characteristics and mental health. Demographic characteristics assessed included age gender and ethnicity. Ethnicity response categories were White Asian or Pacific Islander Black or African American Latino or Hispanic Native American or American Indian or Other. Users could only select one ethnic group category. Users also select the primary reason for using 7 Cups and the users above all indicated a primary purpose of “Depression”.,data wa collected from cup of tea an anonymous online chatbased peer support community for emotional distress user agree at signup that their data may be used for the purpose of research all the data used for the current study wa anonymous and securely stored this research wa performed in line with the ethical and privacy protocol outlined in detail in benton et al data from cup take the form of written dialogue between user of the service and volunteer who are trained a active listener a fragment of an exchange between the user of the service u and the volunteer v might go a follows for the analysis reported in this paper we used only text generated by user of the service not the volunteer providing peer support user who reported depression a their primary concern at sign up were eligible for inclusion in analysis our original sample wa comprised of conversation involving unique user user were excluded from the sample if they did not indicate their culture or if they selected other this resulted in the exclusion of and user respectively the original sample also included user identifying a native american or american indian this group wa excluded from analysis since the majority of the data among these user wa not english this resulted in the removal of user leaving a total sample size of user of the service completed a questionnaire at signup in which they provided information about their demographic characteristic and mental health demographic characteristic assessed included age gender and ethnicity ethnicity response category were white asian or pacific islander black or african american latino or hispanic native american or american indian or other user could only select one ethnic group category user also select the primary reason for using cup and the user above all indicated a primary purpose of depression,"['data', 'wa', 'collected', 'cup', 'tea', 'anonymous', 'online', 'chatbased', 'peer', 'support', 'community', 'emotional', 'distress', 'user', 'agree', 'signup', 'data', 'may', 'used', 'purpose', 'research', 'data', 'used', 'current', 'study', 'wa', 'anonymous', 'securely', 'stored', 'research', 'wa', 'performed', 'line', 'ethical', 'privacy', 'protocol', 'outlined', 'detail', 'benton', 'et', 'al', 'data', 'cup', 'take', 'form', 'written', 'dialogue', 'user', 'service', 'volunteer', 'trained', 'active', 'listener', 'fragment', 'exchange', 'user', 'service', 'u', 'volunteer', 'v', 'might', 'go', 'follows', 'analysis', 'reported', 'paper', 'used', 'text', 'generated', 'user', 'service', 'volunteer', 'providing', 'peer', 'support', 'user', 'reported', 'depression', 'primary', 'concern', 'sign', 'eligible', 'inclusion', 'analysis', 'original', 'sample', 'wa', 'comprised', 'conversation', 'involving', 'unique', 'user', 'user', 'excluded', 'sample', 'indicate', 'culture', 'selected', 'resulted', 'exclusion', 'user', 'respectively', 'original', 'sample', 'also', 'included', 'user', 'identifying', 'native', 'american', 'american', 'indian', 'group', 'wa', 'excluded', 'analysis', 'since', 'majority', 'data', 'among', 'user', 'wa', 'english', 'resulted', 'removal', 'user', 'leaving', 'total', 'sample', 'size', 'user', 'service', 'completed', 'questionnaire', 'signup', 'provided', 'information', 'demographic', 'characteristic', 'mental', 'health', 'demographic', 'characteristic', 'assessed', 'included', 'age', 'gender', 'ethnicity', 'ethnicity', 'response', 'category', 'white', 'asian', 'pacific', 'islander', 'black', 'african', 'american', 'latino', 'hispanic', 'native', 'american', 'american', 'indian', 'user', 'could', 'select', 'one', 'ethnic', 'group', 'category', 'user', 'also', 'select', 'primary', 'reason', 'using', 'cup', 'user', 'indicated', 'primary', 'purpose', 'depression']","['data wa', 'wa collected', 'collected cup', 'cup tea', 'tea anonymous', 'anonymous online', 'online chatbased', 'chatbased peer', 'peer support', 'support community', 'community emotional', 'emotional distress', 'distress user', 'user agree', 'agree signup', 'signup data', 'data may', 'may used', 'used purpose', 'purpose research', 'research data', 'data used', 'used current', 'current study', 'study wa', 'wa anonymous', 'anonymous securely', 'securely stored', 'stored research', 'research wa', 'wa performed', 'performed line', 'line ethical', 'ethical privacy', 'privacy protocol', 'protocol outlined', 'outlined detail', 'detail benton', 'benton et', 'et al', 'al data', 'data cup', 'cup take', 'take form', 'form written', 'written dialogue', 'dialogue user', 'user service', 'service volunteer', 'volunteer trained', 'trained active', 'active listener', 'listener fragment', 'fragment exchange', 'exchange user', 'user service', 'service u', 'u volunteer', 'volunteer v', 'v might', 'might go', 'go follows', 'follows analysis', 'analysis reported', 'reported paper', 'paper used', 'used text', 'text generated', 'generated user', 'user service', 'service volunteer', 'volunteer providing', 'providing peer', 'peer support', 'support user', 'user reported', 'reported depression', 'depression primary', 'primary concern', 'concern sign', 'sign eligible', 'eligible inclusion', 'inclusion analysis', 'analysis original', 'original sample', 'sample wa', 'wa comprised', 'comprised conversation', 'conversation involving', 'involving unique', 'unique user', 'user user', 'user excluded', 'excluded sample', 'sample indicate', 'indicate culture', 'culture selected', 'selected resulted', 'resulted exclusion', 'exclusion user', 'user respectively', 'respectively original', 'original sample', 'sample also', 'also included', 'included user', 'user identifying', 'identifying native', 'native american', 'american american', 'american indian', 'indian group', 'group wa', 'wa excluded', 'excluded analysis', 'analysis since', 'since majority', 'majority data', 'data among', 'among user', 'user wa', 'wa english', 'english resulted', 'resulted removal', 'removal user', 'user leaving', 'leaving total', 'total sample', 'sample size', 'size user', 'user service', 'service completed', 'completed questionnaire', 'questionnaire signup', 'signup provided', 'provided information', 'information demographic', 'demographic characteristic', 'characteristic mental', 'mental health', 'health demographic', 'demographic characteristic', 'characteristic assessed', 'assessed included', 'included age', 'age gender', 'gender ethnicity', 'ethnicity ethnicity', 'ethnicity response', 'response category', 'category white', 'white asian', 'asian pacific', 'pacific islander', 'islander black', 'black african', 'african american', 'american latino', 'latino hispanic', 'hispanic native', 'native american', 'american american', 'american indian', 'indian user', 'user could', 'could select', 'select one', 'one ethnic', 'ethnic group', 'group category', 'category user', 'user also', 'also select', 'select primary', 'primary reason', 'reason using', 'using cup', 'cup user', 'user indicated', 'indicated primary', 'primary purpose', 'purpose depression']","['data wa collected', 'wa collected cup', 'collected cup tea', 'cup tea anonymous', 'tea anonymous online', 'anonymous online chatbased', 'online chatbased peer', 'chatbased peer support', 'peer support community', 'support community emotional', 'community emotional distress', 'emotional distress user', 'distress user agree', 'user agree signup', 'agree signup data', 'signup data may', 'data may used', 'may used purpose', 'used purpose research', 'purpose research data', 'research data used', 'data used current', 'used current study', 'current study wa', 'study wa anonymous', 'wa anonymous securely', 'anonymous securely stored', 'securely stored research', 'stored research wa', 'research wa performed', 'wa performed line', 'performed line ethical', 'line ethical privacy', 'ethical privacy protocol', 'privacy protocol outlined', 'protocol outlined detail', 'outlined detail benton', 'detail benton et', 'benton et al', 'et al data', 'al data cup', 'data cup take', 'cup take form', 'take form written', 'form written dialogue', 'written dialogue user', 'dialogue user service', 'user service volunteer', 'service volunteer trained', 'volunteer trained active', 'trained active listener', 'active listener fragment', 'listener fragment exchange', 'fragment exchange user', 'exchange user service', 'user service u', 'service u volunteer', 'u volunteer v', 'volunteer v might', 'v might go', 'might go follows', 'go follows analysis', 'follows analysis reported', 'analysis reported paper', 'reported paper used', 'paper used text', 'used text generated', 'text generated user', 'generated user service', 'user service volunteer', 'service volunteer providing', 'volunteer providing peer', 'providing peer support', 'peer support user', 'support user reported', 'user reported depression', 'reported depression primary', 'depression primary concern', 'primary concern sign', 'concern sign eligible', 'sign eligible inclusion', 'eligible inclusion analysis', 'inclusion analysis original', 'analysis original sample', 'original sample wa', 'sample wa comprised', 'wa comprised conversation', 'comprised conversation involving', 'conversation involving unique', 'involving unique user', 'unique user user', 'user user excluded', 'user excluded sample', 'excluded sample indicate', 'sample indicate culture', 'indicate culture selected', 'culture selected resulted', 'selected resulted exclusion', 'resulted exclusion user', 'exclusion user respectively', 'user respectively original', 'respectively original sample', 'original sample also', 'sample also included', 'also included user', 'included user identifying', 'user identifying native', 'identifying native american', 'native american american', 'american american indian', 'american indian group', 'indian group wa', 'group wa excluded', 'wa excluded analysis', 'excluded analysis since', 'analysis since majority', 'since majority data', 'majority data among', 'data among user', 'among user wa', 'user wa english', 'wa english resulted', 'english resulted removal', 'resulted removal user', 'removal user leaving', 'user leaving total', 'leaving total sample', 'total sample size', 'sample size user', 'size user service', 'user service completed', 'service completed questionnaire', 'completed questionnaire signup', 'questionnaire signup provided', 'signup provided information', 'provided information demographic', 'information demographic characteristic', 'demographic characteristic mental', 'characteristic mental health', 'mental health demographic', 'health demographic characteristic', 'demographic characteristic assessed', 'characteristic assessed included', 'assessed included age', 'included age gender', 'age gender ethnicity', 'gender ethnicity ethnicity', 'ethnicity ethnicity response', 'ethnicity response category', 'response category white', 'category white asian', 'white asian pacific', 'asian pacific islander', 'pacific islander black', 'islander black african', 'black african american', 'african american latino', 'american latino hispanic', 'latino hispanic native', 'hispanic native american', 'native american american', 'american american indian', 'american indian user', 'indian user could', 'user could select', 'could select one', 'select one ethnic', 'one ethnic group', 'ethnic group category', 'group category user', 'category user also', 'user also select', 'also select primary', 'select primary reason', 'primary reason using', 'reason using cup', 'using cup user', 'cup user indicated', 'user indicated primary', 'indicated primary purpose', 'primary purpose depression']",,,,,,,,
https://dl.acm.org/doi/pdf/10.1145/3359169,1,"Selection Criteria and Data Scope. To understand the impact of cultural differences on how individuals use online mental health platforms we begin our analysis by creating a dataset of users from different national communities on Talklife a support platform with over half a million users [91]. For this analysis due to the fact that most research in CSCW on mental health online has been done either agnostic of cultural context [12 34] or in a Western context [60 67 88] we choose to focus on users from non-Western countries following Zhang et al. [103]. As researchers located in the Global South and with lived experience interacting with the health system and diverse explanatory models [52] of mental illness we believe that moving the focus of CSCW and CSCWadjacent mental health research away from the West is crucial to better meet the needs of people often underserved by the medical system [70]. To create these subgroups of users we choose the three non-Western countries with the highest user populations on Talklife or India Malaysia and the Philippines. Guided by the rich amount of literature on the unique nuances to mental health expression for each country [35 62 77 80] we examine the national identity linguistic and behavior-based differences of use between each user subgroup. In particular this research notes that as a result of cultural norms around the sharing of distress and alternative conceptualizations of mental illness in India Malaysia and the Philippines symptoms are often expressed in somatic and religious terms as opposed to traditionally clinical or psychiatric terms. We choose to analyze each subgroup at the national level for both theoretical and practical reasons. On a theoretical level in past work in the medical anthropology of mental health national identity has commonly been used for a approximate level of analysis for cultural identity [31 33 52]. Additionally on a more practical level each user’s country was determined using their IP address by Talklife and shared with us in an user-anonymized dataset. Inferring a more precise location could potentially compromise user anonymity as discussed in past work [47] and did not seem to have any more significant value for our analysis of cultural differences than analysis at the national level. We analyze data from 10532 Indian users 3370 Malaysian users and 3370 Filipino users as shown in Table 2. Collectively we refer to these countries as the minority sample. As a comparison set we construct a random sample of all threads on Talklife and refer to it as the majority sample. Due to the relative prevalence of users from Western English-speaking countries in Talklife most of the threads in the majority sample include posts from countries such as the USA UK and Canada. Indians are the largest non-Western minority subgroup on Talklife. Data was sampled from May 2012 to June 2018. Following this cross-national analysis to see if our broader results on Talklife generalize to a differently structured online mental health community we picked the largest Western country (the United States) and the largest non-Western country (India) represented on 7Cups a similar support platform with more than 15000 users actively using the platform each week [7]. Using 7Cups data we repeat our analysis testing for the same cultural differences we found in our Talklife sample. For this analysis we were provided a sample of data on activity from 6055 Indian users and 18581 American users as shown in Table 2. Unlike our sample of Talklife users this dataset is not a random sample. There is an upsampling of Indian users to ensure that we have data from a sufficient number of Indians in the dataset. Like on Talklife Indians are the largest non-Western minority subgroup on 7Cups. We focus on Indian users due to a lack of sufficient data on users from Malaysia or the Philippines. Data was sampled from March 2014 - August 2018. 3.1.2 Defining Cultural Identity and Use of Clinical Language. In this work we examine the relationship between cultural identity and use of online mental health support forums. To do so we leverage Tomlinson’s definition of cultural identity as “self and communal definitions based around specific usually politically inflected differentiations: gender sexuality class religion race and ethnicity nationality"" [94] particularly looking at the aspect that of modern cultural identity that runs along national lines as delineated by Hall et al. [41]. As a diverse and amorphous form of identity cultural identity can often intersect and interact with other forms of identity including religious or ethnic identity. However in the absence of direct information about religious or ethnic identity based on the data available we use national identity as a proxy for cultural identity. Additionally following Schlesinger et al’s [83] call for more intersectional analyses and methods within HCI we also include analyses of adjacent and intersecting identities when relevant including religious identity. To analyze clinical language we use a broader definition of clinical language than just specific medical diagnoses. Following methods used in past work to analyze antidepressant related language [30] we create a dataset of clinical mental health language including unigrams bigrams and trigrams from a list of mental disorders as defined by the International Classification of Diseases (ICD-10) and Diagnostic and Statistical Manual of Mental Disorders (DSM-5) [100]. We also included all unigrams from the MacMillan Dictionary list of words used to describe illnesses and diseases both specifically for mental illness and general illness [1–3]. As a result we include unigrams like “night"" (from night terrors) or sleep (from “sleep disorder"") as these are often correlated with specific symptoms of mental illness or distress such as sleep issues or being awake at night [30]. This included any clinically common abbreviations for mental disorders such as OCD for “obsessive compulsive disorder"" or BPD for “borderline personality disorder."" Shorthand for disorders commonly used by online communities such as “pro-ana” (as used in pro-eating disorder communities) [22] were not included due to the difficulty in finding an exhaustive list of these terms across disorders. We choose to use terms from and associated with DSM and ICD categorized disorders as a result of the common usage of these frameworks globally [99]. Throughout our analysis of these varied factors we use µ to represent means and σ to represent standard deviations. 3.1.3 Constraints Limitations and Tradeoffs. Cultural identity can exist at many different and intersecting levels including subcultures and subcommunities within the larger umbrella of a cultural identity. As a result for the purpose of this analysis we had to adopt some constraints in order to do a meaningful and specific analysis. One large limiting constraint that we chose for this study is to use national identity at the state level as a proxy for cultural identity. Though a major and formative part of modern cultural identity as argued by both Hall [41] and Tomlinson [94] each country we analyze is incredibly diverse with many individual cultural identities that both intersect and diverge from a greater national identity [54 64 89]. A more rich analysis of these other forms of cultural identity is beyond the scope of this work but could lead to richer conclusions about the nature of cultural identity in online mental health support communities particularly with regard to cultural differences between users with the same national identity. Additionally to stay consistent between analyses as a result of a lack of data on users from Malaysia and the Philippines we only analyze users in India on 7Cups and extend these findings to the experience of being part of a minority group on an online mental health forum. We draw validity for these exploratory findings from similar consistent patterns we observe between Indian Malaysian and Filipino users but a deeper analysis with a larger dataset is likely necessary to determine when and for which minority communities these conclusions do not hold true. Additionally while we construct clinical language through use of the commonly used DSM and ICD both frameworks of illness categorization have significant limitations particularly in the countries we have selected. For example there are both mental health disorders that are culturebound [74] as well as mental health language that is used in different ways within the specific countries we analyze such as depression often being an umbrella term for all mental illnesses [53]. Additionally it is clear that online support communities often develop their own cultural norms and language around mental health [21 72] and a deeper understanding of how this plays out on Talklife and 7Cups is neither the focus nor within the scope of this work. In this work we intentionally use standard clinical and medical terms for mental health disorders in our analysis of clinical language. As detailed in past anthropological research [52] it is theorized that the use of medical and clinical language is representative of a medicalized explanatory model of illness and we frame use of this language across cultures as a approximate signifier of a greater awareness of the presence of a mental disorder as opposed to conceptualizing distress as “stress"" “tension"" or “depression"" [25 53 98]. For our analysis we strictly analyzed posts that were in the Latin alphabet with almost all posts on both Talklife and 7Cups being in English. However as both Malay [8] and Tagalog [82] are most commonly written in the Latin script and since it is common for users from India speakers to use romanized versions of Indian languages online [79] it is possible that a small minority of posts in our analysis were text in a different language. However as confirmed by only seeing English words used in our analysis of the top n-grams among each user subgroup it is clear that English is the predominant language on both platforms. Though beyond the immediate scope of this work a greater analysis of non-English code-switching on these platforms could lead to a deeper understanding of the impact of interactions on expression between users with the same national identity but different language preferences.",selection criterion and data scope to understand the impact of cultural difference on how individual use online mental health platform we begin our analysis by creating a dataset of user from different national community on talklife a support platform with over half a million user for this analysis due to the fact that most research in cscw on mental health online ha been done either agnostic of cultural context or in a western context we choose to focus on user from nonwestern country following zhang et al a researcher located in the global south and with lived experience interacting with the health system and diverse explanatory model of mental illness we believe that moving the focus of cscw and cscwadjacent mental health research away from the west is crucial to better meet the need of people often underserved by the medical system to create these subgroup of user we choose the three nonwestern country with the highest user population on talklife or india malaysia and the philippine guided by the rich amount of literature on the unique nuance to mental health expression for each country we examine the national identity linguistic and behaviorbased difference of use between each user subgroup in particular this research note that a a result of cultural norm around the sharing of distress and alternative conceptualization of mental illness in india malaysia and the philippine symptom are often expressed in somatic and religious term a opposed to traditionally clinical or psychiatric term we choose to analyze each subgroup at the national level for both theoretical and practical reason on a theoretical level in past work in the medical anthropology of mental health national identity ha commonly been used for a approximate level of analysis for cultural identity additionally on a more practical level each user country wa determined using their ip address by talklife and shared with u in an useranonymized dataset inferring a more precise location could potentially compromise user anonymity a discussed in past work and did not seem to have any more significant value for our analysis of cultural difference than analysis at the national level we analyze data from indian user malaysian user and filipino user a shown in table collectively we refer to these country a the minority sample a a comparison set we construct a random sample of all thread on talklife and refer to it a the majority sample due to the relative prevalence of user from western englishspeaking country in talklife most of the thread in the majority sample include post from country such a the usa uk and canada indian are the largest nonwestern minority subgroup on talklife data wa sampled from may to june following this crossnational analysis to see if our broader result on talklife generalize to a differently structured online mental health community we picked the largest western country the united state and the largest nonwestern country india represented on cup a similar support platform with more than user actively using the platform each week using cup data we repeat our analysis testing for the same cultural difference we found in our talklife sample for this analysis we were provided a sample of data on activity from indian user and american user a shown in table unlike our sample of talklife user this dataset is not a random sample there is an upsampling of indian user to ensure that we have data from a sufficient number of indian in the dataset like on talklife indian are the largest nonwestern minority subgroup on cup we focus on indian user due to a lack of sufficient data on user from malaysia or the philippine data wa sampled from march august defining cultural identity and use of clinical language in this work we examine the relationship between cultural identity and use of online mental health support forum to do so we leverage tomlinsons definition of cultural identity a self and communal definition based around specific usually politically inflected differentiation gender sexuality class religion race and ethnicity nationality particularly looking at the aspect that of modern cultural identity that run along national line a delineated by hall et al a a diverse and amorphous form of identity cultural identity can often intersect and interact with other form of identity including religious or ethnic identity however in the absence of direct information about religious or ethnic identity based on the data available we use national identity a a proxy for cultural identity additionally following schlesinger et al call for more intersectional analysis and method within hci we also include analysis of adjacent and intersecting identity when relevant including religious identity to analyze clinical language we use a broader definition of clinical language than just specific medical diagnosis following method used in past work to analyze antidepressant related language we create a dataset of clinical mental health language including unigrams bigram and trigram from a list of mental disorder a defined by the international classification of disease icd and diagnostic and statistical manual of mental disorder dsm we also included all unigrams from the macmillan dictionary list of word used to describe illness and disease both specifically for mental illness and general illness a a result we include unigrams like night from night terror or sleep from sleep disorder a these are often correlated with specific symptom of mental illness or distress such a sleep issue or being awake at night this included any clinically common abbreviation for mental disorder such a ocd for obsessive compulsive disorder or bpd for borderline personality disorder shorthand for disorder commonly used by online community such a proana a used in proeating disorder community were not included due to the difficulty in finding an exhaustive list of these term across disorder we choose to use term from and associated with dsm and icd categorized disorder a a result of the common usage of these framework globally throughout our analysis of these varied factor we use to represent mean and to represent standard deviation constraint limitation and tradeoff cultural identity can exist at many different and intersecting level including subculture and subcommunities within the larger umbrella of a cultural identity a a result for the purpose of this analysis we had to adopt some constraint in order to do a meaningful and specific analysis one large limiting constraint that we chose for this study is to use national identity at the state level a a proxy for cultural identity though a major and formative part of modern cultural identity a argued by both hall and tomlinson each country we analyze is incredibly diverse with many individual cultural identity that both intersect and diverge from a greater national identity a more rich analysis of these other form of cultural identity is beyond the scope of this work but could lead to richer conclusion about the nature of cultural identity in online mental health support community particularly with regard to cultural difference between user with the same national identity additionally to stay consistent between analysis a a result of a lack of data on user from malaysia and the philippine we only analyze user in india on cup and extend these finding to the experience of being part of a minority group on an online mental health forum we draw validity for these exploratory finding from similar consistent pattern we observe between indian malaysian and filipino user but a deeper analysis with a larger dataset is likely necessary to determine when and for which minority community these conclusion do not hold true additionally while we construct clinical language through use of the commonly used dsm and icd both framework of illness categorization have significant limitation particularly in the country we have selected for example there are both mental health disorder that are culturebound a well a mental health language that is used in different way within the specific country we analyze such a depression often being an umbrella term for all mental illness additionally it is clear that online support community often develop their own cultural norm and language around mental health and a deeper understanding of how this play out on talklife and cup is neither the focus nor within the scope of this work in this work we intentionally use standard clinical and medical term for mental health disorder in our analysis of clinical language a detailed in past anthropological research it is theorized that the use of medical and clinical language is representative of a medicalized explanatory model of illness and we frame use of this language across culture a a approximate signifier of a greater awareness of the presence of a mental disorder a opposed to conceptualizing distress a stress tension or depression for our analysis we strictly analyzed post that were in the latin alphabet with almost all post on both talklife and cup being in english however a both malay and tagalog are most commonly written in the latin script and since it is common for user from india speaker to use romanized version of indian language online it is possible that a small minority of post in our analysis were text in a different language however a confirmed by only seeing english word used in our analysis of the top ngrams among each user subgroup it is clear that english is the predominant language on both platform though beyond the immediate scope of this work a greater analysis of nonenglish codeswitching on these platform could lead to a deeper understanding of the impact of interaction on expression between user with the same national identity but different language preference,"['selection', 'criterion', 'data', 'scope', 'understand', 'impact', 'cultural', 'difference', 'individual', 'use', 'online', 'mental', 'health', 'platform', 'begin', 'analysis', 'creating', 'dataset', 'user', 'different', 'national', 'community', 'talklife', 'support', 'platform', 'half', 'million', 'user', 'analysis', 'due', 'fact', 'research', 'cscw', 'mental', 'health', 'online', 'ha', 'done', 'either', 'agnostic', 'cultural', 'context', 'western', 'context', 'choose', 'focus', 'user', 'nonwestern', 'country', 'following', 'zhang', 'et', 'al', 'researcher', 'located', 'global', 'south', 'lived', 'experience', 'interacting', 'health', 'system', 'diverse', 'explanatory', 'model', 'mental', 'illness', 'believe', 'moving', 'focus', 'cscw', 'cscwadjacent', 'mental', 'health', 'research', 'away', 'west', 'crucial', 'better', 'meet', 'need', 'people', 'often', 'underserved', 'medical', 'system', 'create', 'subgroup', 'user', 'choose', 'three', 'nonwestern', 'country', 'highest', 'user', 'population', 'talklife', 'india', 'malaysia', 'philippine', 'guided', 'rich', 'amount', 'literature', 'unique', 'nuance', 'mental', 'health', 'expression', 'country', 'examine', 'national', 'identity', 'linguistic', 'behaviorbased', 'difference', 'use', 'user', 'subgroup', 'particular', 'research', 'note', 'result', 'cultural', 'norm', 'around', 'sharing', 'distress', 'alternative', 'conceptualization', 'mental', 'illness', 'india', 'malaysia', 'philippine', 'symptom', 'often', 'expressed', 'somatic', 'religious', 'term', 'opposed', 'traditionally', 'clinical', 'psychiatric', 'term', 'choose', 'analyze', 'subgroup', 'national', 'level', 'theoretical', 'practical', 'reason', 'theoretical', 'level', 'past', 'work', 'medical', 'anthropology', 'mental', 'health', 'national', 'identity', 'ha', 'commonly', 'used', 'approximate', 'level', 'analysis', 'cultural', 'identity', 'additionally', 'practical', 'level', 'user', 'country', 'wa', 'determined', 'using', 'ip', 'address', 'talklife', 'shared', 'u', 'useranonymized', 'dataset', 'inferring', 'precise', 'location', 'could', 'potentially', 'compromise', 'user', 'anonymity', 'discussed', 'past', 'work', 'seem', 'significant', 'value', 'analysis', 'cultural', 'difference', 'analysis', 'national', 'level', 'analyze', 'data', 'indian', 'user', 'malaysian', 'user', 'filipino', 'user', 'shown', 'table', 'collectively', 'refer', 'country', 'minority', 'sample', 'comparison', 'set', 'construct', 'random', 'sample', 'thread', 'talklife', 'refer', 'majority', 'sample', 'due', 'relative', 'prevalence', 'user', 'western', 'englishspeaking', 'country', 'talklife', 'thread', 'majority', 'sample', 'include', 'post', 'country', 'usa', 'uk', 'canada', 'indian', 'largest', 'nonwestern', 'minority', 'subgroup', 'talklife', 'data', 'wa', 'sampled', 'may', 'june', 'following', 'crossnational', 'analysis', 'see', 'broader', 'result', 'talklife', 'generalize', 'differently', 'structured', 'online', 'mental', 'health', 'community', 'picked', 'largest', 'western', 'country', 'united', 'state', 'largest', 'nonwestern', 'country', 'india', 'represented', 'cup', 'similar', 'support', 'platform', 'user', 'actively', 'using', 'platform', 'week', 'using', 'cup', 'data', 'repeat', 'analysis', 'testing', 'cultural', 'difference', 'found', 'talklife', 'sample', 'analysis', 'provided', 'sample', 'data', 'activity', 'indian', 'user', 'american', 'user', 'shown', 'table', 'unlike', 'sample', 'talklife', 'user', 'dataset', 'random', 'sample', 'upsampling', 'indian', 'user', 'ensure', 'data', 'sufficient', 'number', 'indian', 'dataset', 'like', 'talklife', 'indian', 'largest', 'nonwestern', 'minority', 'subgroup', 'cup', 'focus', 'indian', 'user', 'due', 'lack', 'sufficient', 'data', 'user', 'malaysia', 'philippine', 'data', 'wa', 'sampled', 'march', 'august', 'defining', 'cultural', 'identity', 'use', 'clinical', 'language', 'work', 'examine', 'relationship', 'cultural', 'identity', 'use', 'online', 'mental', 'health', 'support', 'forum', 'leverage', 'tomlinsons', 'definition', 'cultural', 'identity', 'self', 'communal', 'definition', 'based', 'around', 'specific', 'usually', 'politically', 'inflected', 'differentiation', 'gender', 'sexuality', 'class', 'religion', 'race', 'ethnicity', 'nationality', 'particularly', 'looking', 'aspect', 'modern', 'cultural', 'identity', 'run', 'along', 'national', 'line', 'delineated', 'hall', 'et', 'al', 'diverse', 'amorphous', 'form', 'identity', 'cultural', 'identity', 'often', 'intersect', 'interact', 'form', 'identity', 'including', 'religious', 'ethnic', 'identity', 'however', 'absence', 'direct', 'information', 'religious', 'ethnic', 'identity', 'based', 'data', 'available', 'use', 'national', 'identity', 'proxy', 'cultural', 'identity', 'additionally', 'following', 'schlesinger', 'et', 'al', 'call', 'intersectional', 'analysis', 'method', 'within', 'hci', 'also', 'include', 'analysis', 'adjacent', 'intersecting', 'identity', 'relevant', 'including', 'religious', 'identity', 'analyze', 'clinical', 'language', 'use', 'broader', 'definition', 'clinical', 'language', 'specific', 'medical', 'diagnosis', 'following', 'method', 'used', 'past', 'work', 'analyze', 'antidepressant', 'related', 'language', 'create', 'dataset', 'clinical', 'mental', 'health', 'language', 'including', 'unigrams', 'bigram', 'trigram', 'list', 'mental', 'disorder', 'defined', 'international', 'classification', 'disease', 'icd', 'diagnostic', 'statistical', 'manual', 'mental', 'disorder', 'dsm', 'also', 'included', 'unigrams', 'macmillan', 'dictionary', 'list', 'word', 'used', 'describe', 'illness', 'disease', 'specifically', 'mental', 'illness', 'general', 'illness', 'result', 'include', 'unigrams', 'like', 'night', 'night', 'terror', 'sleep', 'sleep', 'disorder', 'often', 'correlated', 'specific', 'symptom', 'mental', 'illness', 'distress', 'sleep', 'issue', 'awake', 'night', 'included', 'clinically', 'common', 'abbreviation', 'mental', 'disorder', 'ocd', 'obsessive', 'compulsive', 'disorder', 'bpd', 'borderline', 'personality', 'disorder', 'shorthand', 'disorder', 'commonly', 'used', 'online', 'community', 'proana', 'used', 'proeating', 'disorder', 'community', 'included', 'due', 'difficulty', 'finding', 'exhaustive', 'list', 'term', 'across', 'disorder', 'choose', 'use', 'term', 'associated', 'dsm', 'icd', 'categorized', 'disorder', 'result', 'common', 'usage', 'framework', 'globally', 'throughout', 'analysis', 'varied', 'factor', 'use', 'represent', 'mean', 'represent', 'standard', 'deviation', 'constraint', 'limitation', 'tradeoff', 'cultural', 'identity', 'exist', 'many', 'different', 'intersecting', 'level', 'including', 'subculture', 'subcommunities', 'within', 'larger', 'umbrella', 'cultural', 'identity', 'result', 'purpose', 'analysis', 'adopt', 'constraint', 'order', 'meaningful', 'specific', 'analysis', 'one', 'large', 'limiting', 'constraint', 'chose', 'study', 'use', 'national', 'identity', 'state', 'level', 'proxy', 'cultural', 'identity', 'though', 'major', 'formative', 'part', 'modern', 'cultural', 'identity', 'argued', 'hall', 'tomlinson', 'country', 'analyze', 'incredibly', 'diverse', 'many', 'individual', 'cultural', 'identity', 'intersect', 'diverge', 'greater', 'national', 'identity', 'rich', 'analysis', 'form', 'cultural', 'identity', 'beyond', 'scope', 'work', 'could', 'lead', 'richer', 'conclusion', 'nature', 'cultural', 'identity', 'online', 'mental', 'health', 'support', 'community', 'particularly', 'regard', 'cultural', 'difference', 'user', 'national', 'identity', 'additionally', 'stay', 'consistent', 'analysis', 'result', 'lack', 'data', 'user', 'malaysia', 'philippine', 'analyze', 'user', 'india', 'cup', 'extend', 'finding', 'experience', 'part', 'minority', 'group', 'online', 'mental', 'health', 'forum', 'draw', 'validity', 'exploratory', 'finding', 'similar', 'consistent', 'pattern', 'observe', 'indian', 'malaysian', 'filipino', 'user', 'deeper', 'analysis', 'larger', 'dataset', 'likely', 'necessary', 'determine', 'minority', 'community', 'conclusion', 'hold', 'true', 'additionally', 'construct', 'clinical', 'language', 'use', 'commonly', 'used', 'dsm', 'icd', 'framework', 'illness', 'categorization', 'significant', 'limitation', 'particularly', 'country', 'selected', 'example', 'mental', 'health', 'disorder', 'culturebound', 'well', 'mental', 'health', 'language', 'used', 'different', 'way', 'within', 'specific', 'country', 'analyze', 'depression', 'often', 'umbrella', 'term', 'mental', 'illness', 'additionally', 'clear', 'online', 'support', 'community', 'often', 'develop', 'cultural', 'norm', 'language', 'around', 'mental', 'health', 'deeper', 'understanding', 'play', 'talklife', 'cup', 'neither', 'focus', 'within', 'scope', 'work', 'work', 'intentionally', 'use', 'standard', 'clinical', 'medical', 'term', 'mental', 'health', 'disorder', 'analysis', 'clinical', 'language', 'detailed', 'past', 'anthropological', 'research', 'theorized', 'use', 'medical', 'clinical', 'language', 'representative', 'medicalized', 'explanatory', 'model', 'illness', 'frame', 'use', 'language', 'across', 'culture', 'approximate', 'signifier', 'greater', 'awareness', 'presence', 'mental', 'disorder', 'opposed', 'conceptualizing', 'distress', 'stress', 'tension', 'depression', 'analysis', 'strictly', 'analyzed', 'post', 'latin', 'alphabet', 'almost', 'post', 'talklife', 'cup', 'english', 'however', 'malay', 'tagalog', 'commonly', 'written', 'latin', 'script', 'since', 'common', 'user', 'india', 'speaker', 'use', 'romanized', 'version', 'indian', 'language', 'online', 'possible', 'small', 'minority', 'post', 'analysis', 'text', 'different', 'language', 'however', 'confirmed', 'seeing', 'english', 'word', 'used', 'analysis', 'top', 'ngrams', 'among', 'user', 'subgroup', 'clear', 'english', 'predominant', 'language', 'platform', 'though', 'beyond', 'immediate', 'scope', 'work', 'greater', 'analysis', 'nonenglish', 'codeswitching', 'platform', 'could', 'lead', 'deeper', 'understanding', 'impact', 'interaction', 'expression', 'user', 'national', 'identity', 'different', 'language', 'preference']","['selection criterion', 'criterion data', 'data scope', 'scope understand', 'understand impact', 'impact cultural', 'cultural difference', 'difference individual', 'individual use', 'use online', 'online mental', 'mental health', 'health platform', 'platform begin', 'begin analysis', 'analysis creating', 'creating dataset', 'dataset user', 'user different', 'different national', 'national community', 'community talklife', 'talklife support', 'support platform', 'platform half', 'half million', 'million user', 'user analysis', 'analysis due', 'due fact', 'fact research', 'research cscw', 'cscw mental', 'mental health', 'health online', 'online ha', 'ha done', 'done either', 'either agnostic', 'agnostic cultural', 'cultural context', 'context western', 'western context', 'context choose', 'choose focus', 'focus user', 'user nonwestern', 'nonwestern country', 'country following', 'following zhang', 'zhang et', 'et al', 'al researcher', 'researcher located', 'located global', 'global south', 'south lived', 'lived experience', 'experience interacting', 'interacting health', 'health system', 'system diverse', 'diverse explanatory', 'explanatory model', 'model mental', 'mental illness', 'illness believe', 'believe moving', 'moving focus', 'focus cscw', 'cscw cscwadjacent', 'cscwadjacent mental', 'mental health', 'health research', 'research away', 'away west', 'west crucial', 'crucial better', 'better meet', 'meet need', 'need people', 'people often', 'often underserved', 'underserved medical', 'medical system', 'system create', 'create subgroup', 'subgroup user', 'user choose', 'choose three', 'three nonwestern', 'nonwestern country', 'country highest', 'highest user', 'user population', 'population talklife', 'talklife india', 'india malaysia', 'malaysia philippine', 'philippine guided', 'guided rich', 'rich amount', 'amount literature', 'literature unique', 'unique nuance', 'nuance mental', 'mental health', 'health expression', 'expression country', 'country examine', 'examine national', 'national identity', 'identity linguistic', 'linguistic behaviorbased', 'behaviorbased difference', 'difference use', 'use user', 'user subgroup', 'subgroup particular', 'particular research', 'research note', 'note result', 'result cultural', 'cultural norm', 'norm around', 'around sharing', 'sharing distress', 'distress alternative', 'alternative conceptualization', 'conceptualization mental', 'mental illness', 'illness india', 'india malaysia', 'malaysia philippine', 'philippine symptom', 'symptom often', 'often expressed', 'expressed somatic', 'somatic religious', 'religious term', 'term opposed', 'opposed traditionally', 'traditionally clinical', 'clinical psychiatric', 'psychiatric term', 'term choose', 'choose analyze', 'analyze subgroup', 'subgroup national', 'national level', 'level theoretical', 'theoretical practical', 'practical reason', 'reason theoretical', 'theoretical level', 'level past', 'past work', 'work medical', 'medical anthropology', 'anthropology mental', 'mental health', 'health national', 'national identity', 'identity ha', 'ha commonly', 'commonly used', 'used approximate', 'approximate level', 'level analysis', 'analysis cultural', 'cultural identity', 'identity additionally', 'additionally practical', 'practical level', 'level user', 'user country', 'country wa', 'wa determined', 'determined using', 'using ip', 'ip address', 'address talklife', 'talklife shared', 'shared u', 'u useranonymized', 'useranonymized dataset', 'dataset inferring', 'inferring precise', 'precise location', 'location could', 'could potentially', 'potentially compromise', 'compromise user', 'user anonymity', 'anonymity discussed', 'discussed past', 'past work', 'work seem', 'seem significant', 'significant value', 'value analysis', 'analysis cultural', 'cultural difference', 'difference analysis', 'analysis national', 'national level', 'level analyze', 'analyze data', 'data indian', 'indian user', 'user malaysian', 'malaysian user', 'user filipino', 'filipino user', 'user shown', 'shown table', 'table collectively', 'collectively refer', 'refer country', 'country minority', 'minority sample', 'sample comparison', 'comparison set', 'set construct', 'construct random', 'random sample', 'sample thread', 'thread talklife', 'talklife refer', 'refer majority', 'majority sample', 'sample due', 'due relative', 'relative prevalence', 'prevalence user', 'user western', 'western englishspeaking', 'englishspeaking country', 'country talklife', 'talklife thread', 'thread majority', 'majority sample', 'sample include', 'include post', 'post country', 'country usa', 'usa uk', 'uk canada', 'canada indian', 'indian largest', 'largest nonwestern', 'nonwestern minority', 'minority subgroup', 'subgroup talklife', 'talklife data', 'data wa', 'wa sampled', 'sampled may', 'may june', 'june following', 'following crossnational', 'crossnational analysis', 'analysis see', 'see broader', 'broader result', 'result talklife', 'talklife generalize', 'generalize differently', 'differently structured', 'structured online', 'online mental', 'mental health', 'health community', 'community picked', 'picked largest', 'largest western', 'western country', 'country united', 'united state', 'state largest', 'largest nonwestern', 'nonwestern country', 'country india', 'india represented', 'represented cup', 'cup similar', 'similar support', 'support platform', 'platform user', 'user actively', 'actively using', 'using platform', 'platform week', 'week using', 'using cup', 'cup data', 'data repeat', 'repeat analysis', 'analysis testing', 'testing cultural', 'cultural difference', 'difference found', 'found talklife', 'talklife sample', 'sample analysis', 'analysis provided', 'provided sample', 'sample data', 'data activity', 'activity indian', 'indian user', 'user american', 'american user', 'user shown', 'shown table', 'table unlike', 'unlike sample', 'sample talklife', 'talklife user', 'user dataset', 'dataset random', 'random sample', 'sample upsampling', 'upsampling indian', 'indian user', 'user ensure', 'ensure data', 'data sufficient', 'sufficient number', 'number indian', 'indian dataset', 'dataset like', 'like talklife', 'talklife indian', 'indian largest', 'largest nonwestern', 'nonwestern minority', 'minority subgroup', 'subgroup cup', 'cup focus', 'focus indian', 'indian user', 'user due', 'due lack', 'lack sufficient', 'sufficient data', 'data user', 'user malaysia', 'malaysia philippine', 'philippine data', 'data wa', 'wa sampled', 'sampled march', 'march august', 'august defining', 'defining cultural', 'cultural identity', 'identity use', 'use clinical', 'clinical language', 'language work', 'work examine', 'examine relationship', 'relationship cultural', 'cultural identity', 'identity use', 'use online', 'online mental', 'mental health', 'health support', 'support forum', 'forum leverage', 'leverage tomlinsons', 'tomlinsons definition', 'definition cultural', 'cultural identity', 'identity self', 'self communal', 'communal definition', 'definition based', 'based around', 'around specific', 'specific usually', 'usually politically', 'politically inflected', 'inflected differentiation', 'differentiation gender', 'gender sexuality', 'sexuality class', 'class religion', 'religion race', 'race ethnicity', 'ethnicity nationality', 'nationality particularly', 'particularly looking', 'looking aspect', 'aspect modern', 'modern cultural', 'cultural identity', 'identity run', 'run along', 'along national', 'national line', 'line delineated', 'delineated hall', 'hall et', 'et al', 'al diverse', 'diverse amorphous', 'amorphous form', 'form identity', 'identity cultural', 'cultural identity', 'identity often', 'often intersect', 'intersect interact', 'interact form', 'form identity', 'identity including', 'including religious', 'religious ethnic', 'ethnic identity', 'identity however', 'however absence', 'absence direct', 'direct information', 'information religious', 'religious ethnic', 'ethnic identity', 'identity based', 'based data', 'data available', 'available use', 'use national', 'national identity', 'identity proxy', 'proxy cultural', 'cultural identity', 'identity additionally', 'additionally following', 'following schlesinger', 'schlesinger et', 'et al', 'al call', 'call intersectional', 'intersectional analysis', 'analysis method', 'method within', 'within hci', 'hci also', 'also include', 'include analysis', 'analysis adjacent', 'adjacent intersecting', 'intersecting identity', 'identity relevant', 'relevant including', 'including religious', 'religious identity', 'identity analyze', 'analyze clinical', 'clinical language', 'language use', 'use broader', 'broader definition', 'definition clinical', 'clinical language', 'language specific', 'specific medical', 'medical diagnosis', 'diagnosis following', 'following method', 'method used', 'used past', 'past work', 'work analyze', 'analyze antidepressant', 'antidepressant related', 'related language', 'language create', 'create dataset', 'dataset clinical', 'clinical mental', 'mental health', 'health language', 'language including', 'including unigrams', 'unigrams bigram', 'bigram trigram', 'trigram list', 'list mental', 'mental disorder', 'disorder defined', 'defined international', 'international classification', 'classification disease', 'disease icd', 'icd diagnostic', 'diagnostic statistical', 'statistical manual', 'manual mental', 'mental disorder', 'disorder dsm', 'dsm also', 'also included', 'included unigrams', 'unigrams macmillan', 'macmillan dictionary', 'dictionary list', 'list word', 'word used', 'used describe', 'describe illness', 'illness disease', 'disease specifically', 'specifically mental', 'mental illness', 'illness general', 'general illness', 'illness result', 'result include', 'include unigrams', 'unigrams like', 'like night', 'night night', 'night terror', 'terror sleep', 'sleep sleep', 'sleep disorder', 'disorder often', 'often correlated', 'correlated specific', 'specific symptom', 'symptom mental', 'mental illness', 'illness distress', 'distress sleep', 'sleep issue', 'issue awake', 'awake night', 'night included', 'included clinically', 'clinically common', 'common abbreviation', 'abbreviation mental', 'mental disorder', 'disorder ocd', 'ocd obsessive', 'obsessive compulsive', 'compulsive disorder', 'disorder bpd', 'bpd borderline', 'borderline personality', 'personality disorder', 'disorder shorthand', 'shorthand disorder', 'disorder commonly', 'commonly used', 'used online', 'online community', 'community proana', 'proana used', 'used proeating', 'proeating disorder', 'disorder community', 'community included', 'included due', 'due difficulty', 'difficulty finding', 'finding exhaustive', 'exhaustive list', 'list term', 'term across', 'across disorder', 'disorder choose', 'choose use', 'use term', 'term associated', 'associated dsm', 'dsm icd', 'icd categorized', 'categorized disorder', 'disorder result', 'result common', 'common usage', 'usage framework', 'framework globally', 'globally throughout', 'throughout analysis', 'analysis varied', 'varied factor', 'factor use', 'use represent', 'represent mean', 'mean represent', 'represent standard', 'standard deviation', 'deviation constraint', 'constraint limitation', 'limitation tradeoff', 'tradeoff cultural', 'cultural identity', 'identity exist', 'exist many', 'many different', 'different intersecting', 'intersecting level', 'level including', 'including subculture', 'subculture subcommunities', 'subcommunities within', 'within larger', 'larger umbrella', 'umbrella cultural', 'cultural identity', 'identity result', 'result purpose', 'purpose analysis', 'analysis adopt', 'adopt constraint', 'constraint order', 'order meaningful', 'meaningful specific', 'specific analysis', 'analysis one', 'one large', 'large limiting', 'limiting constraint', 'constraint chose', 'chose study', 'study use', 'use national', 'national identity', 'identity state', 'state level', 'level proxy', 'proxy cultural', 'cultural identity', 'identity though', 'though major', 'major formative', 'formative part', 'part modern', 'modern cultural', 'cultural identity', 'identity argued', 'argued hall', 'hall tomlinson', 'tomlinson country', 'country analyze', 'analyze incredibly', 'incredibly diverse', 'diverse many', 'many individual', 'individual cultural', 'cultural identity', 'identity intersect', 'intersect diverge', 'diverge greater', 'greater national', 'national identity', 'identity rich', 'rich analysis', 'analysis form', 'form cultural', 'cultural identity', 'identity beyond', 'beyond scope', 'scope work', 'work could', 'could lead', 'lead richer', 'richer conclusion', 'conclusion nature', 'nature cultural', 'cultural identity', 'identity online', 'online mental', 'mental health', 'health support', 'support community', 'community particularly', 'particularly regard', 'regard cultural', 'cultural difference', 'difference user', 'user national', 'national identity', 'identity additionally', 'additionally stay', 'stay consistent', 'consistent analysis', 'analysis result', 'result lack', 'lack data', 'data user', 'user malaysia', 'malaysia philippine', 'philippine analyze', 'analyze user', 'user india', 'india cup', 'cup extend', 'extend finding', 'finding experience', 'experience part', 'part minority', 'minority group', 'group online', 'online mental', 'mental health', 'health forum', 'forum draw', 'draw validity', 'validity exploratory', 'exploratory finding', 'finding similar', 'similar consistent', 'consistent pattern', 'pattern observe', 'observe indian', 'indian malaysian', 'malaysian filipino', 'filipino user', 'user deeper', 'deeper analysis', 'analysis larger', 'larger dataset', 'dataset likely', 'likely necessary', 'necessary determine', 'determine minority', 'minority community', 'community conclusion', 'conclusion hold', 'hold true', 'true additionally', 'additionally construct', 'construct clinical', 'clinical language', 'language use', 'use commonly', 'commonly used', 'used dsm', 'dsm icd', 'icd framework', 'framework illness', 'illness categorization', 'categorization significant', 'significant limitation', 'limitation particularly', 'particularly country', 'country selected', 'selected example', 'example mental', 'mental health', 'health disorder', 'disorder culturebound', 'culturebound well', 'well mental', 'mental health', 'health language', 'language used', 'used different', 'different way', 'way within', 'within specific', 'specific country', 'country analyze', 'analyze depression', 'depression often', 'often umbrella', 'umbrella term', 'term mental', 'mental illness', 'illness additionally', 'additionally clear', 'clear online', 'online support', 'support community', 'community often', 'often develop', 'develop cultural', 'cultural norm', 'norm language', 'language around', 'around mental', 'mental health', 'health deeper', 'deeper understanding', 'understanding play', 'play talklife', 'talklife cup', 'cup neither', 'neither focus', 'focus within', 'within scope', 'scope work', 'work work', 'work intentionally', 'intentionally use', 'use standard', 'standard clinical', 'clinical medical', 'medical term', 'term mental', 'mental health', 'health disorder', 'disorder analysis', 'analysis clinical', 'clinical language', 'language detailed', 'detailed past', 'past anthropological', 'anthropological research', 'research theorized', 'theorized use', 'use medical', 'medical clinical', 'clinical language', 'language representative', 'representative medicalized', 'medicalized explanatory', 'explanatory model', 'model illness', 'illness frame', 'frame use', 'use language', 'language across', 'across culture', 'culture approximate', 'approximate signifier', 'signifier greater', 'greater awareness', 'awareness presence', 'presence mental', 'mental disorder', 'disorder opposed', 'opposed conceptualizing', 'conceptualizing distress', 'distress stress', 'stress tension', 'tension depression', 'depression analysis', 'analysis strictly', 'strictly analyzed', 'analyzed post', 'post latin', 'latin alphabet', 'alphabet almost', 'almost post', 'post talklife', 'talklife cup', 'cup english', 'english however', 'however malay', 'malay tagalog', 'tagalog commonly', 'commonly written', 'written latin', 'latin script', 'script since', 'since common', 'common user', 'user india', 'india speaker', 'speaker use', 'use romanized', 'romanized version', 'version indian', 'indian language', 'language online', 'online possible', 'possible small', 'small minority', 'minority post', 'post analysis', 'analysis text', 'text different', 'different language', 'language however', 'however confirmed', 'confirmed seeing', 'seeing english', 'english word', 'word used', 'used analysis', 'analysis top', 'top ngrams', 'ngrams among', 'among user', 'user subgroup', 'subgroup clear', 'clear english', 'english predominant', 'predominant language', 'language platform', 'platform though', 'though beyond', 'beyond immediate', 'immediate scope', 'scope work', 'work greater', 'greater analysis', 'analysis nonenglish', 'nonenglish codeswitching', 'codeswitching platform', 'platform could', 'could lead', 'lead deeper', 'deeper understanding', 'understanding impact', 'impact interaction', 'interaction expression', 'expression user', 'user national', 'national identity', 'identity different', 'different language', 'language preference']","['selection criterion data', 'criterion data scope', 'data scope understand', 'scope understand impact', 'understand impact cultural', 'impact cultural difference', 'cultural difference individual', 'difference individual use', 'individual use online', 'use online mental', 'online mental health', 'mental health platform', 'health platform begin', 'platform begin analysis', 'begin analysis creating', 'analysis creating dataset', 'creating dataset user', 'dataset user different', 'user different national', 'different national community', 'national community talklife', 'community talklife support', 'talklife support platform', 'support platform half', 'platform half million', 'half million user', 'million user analysis', 'user analysis due', 'analysis due fact', 'due fact research', 'fact research cscw', 'research cscw mental', 'cscw mental health', 'mental health online', 'health online ha', 'online ha done', 'ha done either', 'done either agnostic', 'either agnostic cultural', 'agnostic cultural context', 'cultural context western', 'context western context', 'western context choose', 'context choose focus', 'choose focus user', 'focus user nonwestern', 'user nonwestern country', 'nonwestern country following', 'country following zhang', 'following zhang et', 'zhang et al', 'et al researcher', 'al researcher located', 'researcher located global', 'located global south', 'global south lived', 'south lived experience', 'lived experience interacting', 'experience interacting health', 'interacting health system', 'health system diverse', 'system diverse explanatory', 'diverse explanatory model', 'explanatory model mental', 'model mental illness', 'mental illness believe', 'illness believe moving', 'believe moving focus', 'moving focus cscw', 'focus cscw cscwadjacent', 'cscw cscwadjacent mental', 'cscwadjacent mental health', 'mental health research', 'health research away', 'research away west', 'away west crucial', 'west crucial better', 'crucial better meet', 'better meet need', 'meet need people', 'need people often', 'people often underserved', 'often underserved medical', 'underserved medical system', 'medical system create', 'system create subgroup', 'create subgroup user', 'subgroup user choose', 'user choose three', 'choose three nonwestern', 'three nonwestern country', 'nonwestern country highest', 'country highest user', 'highest user population', 'user population talklife', 'population talklife india', 'talklife india malaysia', 'india malaysia philippine', 'malaysia philippine guided', 'philippine guided rich', 'guided rich amount', 'rich amount literature', 'amount literature unique', 'literature unique nuance', 'unique nuance mental', 'nuance mental health', 'mental health expression', 'health expression country', 'expression country examine', 'country examine national', 'examine national identity', 'national identity linguistic', 'identity linguistic behaviorbased', 'linguistic behaviorbased difference', 'behaviorbased difference use', 'difference use user', 'use user subgroup', 'user subgroup particular', 'subgroup particular research', 'particular research note', 'research note result', 'note result cultural', 'result cultural norm', 'cultural norm around', 'norm around sharing', 'around sharing distress', 'sharing distress alternative', 'distress alternative conceptualization', 'alternative conceptualization mental', 'conceptualization mental illness', 'mental illness india', 'illness india malaysia', 'india malaysia philippine', 'malaysia philippine symptom', 'philippine symptom often', 'symptom often expressed', 'often expressed somatic', 'expressed somatic religious', 'somatic religious term', 'religious term opposed', 'term opposed traditionally', 'opposed traditionally clinical', 'traditionally clinical psychiatric', 'clinical psychiatric term', 'psychiatric term choose', 'term choose analyze', 'choose analyze subgroup', 'analyze subgroup national', 'subgroup national level', 'national level theoretical', 'level theoretical practical', 'theoretical practical reason', 'practical reason theoretical', 'reason theoretical level', 'theoretical level past', 'level past work', 'past work medical', 'work medical anthropology', 'medical anthropology mental', 'anthropology mental health', 'mental health national', 'health national identity', 'national identity ha', 'identity ha commonly', 'ha commonly used', 'commonly used approximate', 'used approximate level', 'approximate level analysis', 'level analysis cultural', 'analysis cultural identity', 'cultural identity additionally', 'identity additionally practical', 'additionally practical level', 'practical level user', 'level user country', 'user country wa', 'country wa determined', 'wa determined using', 'determined using ip', 'using ip address', 'ip address talklife', 'address talklife shared', 'talklife shared u', 'shared u useranonymized', 'u useranonymized dataset', 'useranonymized dataset inferring', 'dataset inferring precise', 'inferring precise location', 'precise location could', 'location could potentially', 'could potentially compromise', 'potentially compromise user', 'compromise user anonymity', 'user anonymity discussed', 'anonymity discussed past', 'discussed past work', 'past work seem', 'work seem significant', 'seem significant value', 'significant value analysis', 'value analysis cultural', 'analysis cultural difference', 'cultural difference analysis', 'difference analysis national', 'analysis national level', 'national level analyze', 'level analyze data', 'analyze data indian', 'data indian user', 'indian user malaysian', 'user malaysian user', 'malaysian user filipino', 'user filipino user', 'filipino user shown', 'user shown table', 'shown table collectively', 'table collectively refer', 'collectively refer country', 'refer country minority', 'country minority sample', 'minority sample comparison', 'sample comparison set', 'comparison set construct', 'set construct random', 'construct random sample', 'random sample thread', 'sample thread talklife', 'thread talklife refer', 'talklife refer majority', 'refer majority sample', 'majority sample due', 'sample due relative', 'due relative prevalence', 'relative prevalence user', 'prevalence user western', 'user western englishspeaking', 'western englishspeaking country', 'englishspeaking country talklife', 'country talklife thread', 'talklife thread majority', 'thread majority sample', 'majority sample include', 'sample include post', 'include post country', 'post country usa', 'country usa uk', 'usa uk canada', 'uk canada indian', 'canada indian largest', 'indian largest nonwestern', 'largest nonwestern minority', 'nonwestern minority subgroup', 'minority subgroup talklife', 'subgroup talklife data', 'talklife data wa', 'data wa sampled', 'wa sampled may', 'sampled may june', 'may june following', 'june following crossnational', 'following crossnational analysis', 'crossnational analysis see', 'analysis see broader', 'see broader result', 'broader result talklife', 'result talklife generalize', 'talklife generalize differently', 'generalize differently structured', 'differently structured online', 'structured online mental', 'online mental health', 'mental health community', 'health community picked', 'community picked largest', 'picked largest western', 'largest western country', 'western country united', 'country united state', 'united state largest', 'state largest nonwestern', 'largest nonwestern country', 'nonwestern country india', 'country india represented', 'india represented cup', 'represented cup similar', 'cup similar support', 'similar support platform', 'support platform user', 'platform user actively', 'user actively using', 'actively using platform', 'using platform week', 'platform week using', 'week using cup', 'using cup data', 'cup data repeat', 'data repeat analysis', 'repeat analysis testing', 'analysis testing cultural', 'testing cultural difference', 'cultural difference found', 'difference found talklife', 'found talklife sample', 'talklife sample analysis', 'sample analysis provided', 'analysis provided sample', 'provided sample data', 'sample data activity', 'data activity indian', 'activity indian user', 'indian user american', 'user american user', 'american user shown', 'user shown table', 'shown table unlike', 'table unlike sample', 'unlike sample talklife', 'sample talklife user', 'talklife user dataset', 'user dataset random', 'dataset random sample', 'random sample upsampling', 'sample upsampling indian', 'upsampling indian user', 'indian user ensure', 'user ensure data', 'ensure data sufficient', 'data sufficient number', 'sufficient number indian', 'number indian dataset', 'indian dataset like', 'dataset like talklife', 'like talklife indian', 'talklife indian largest', 'indian largest nonwestern', 'largest nonwestern minority', 'nonwestern minority subgroup', 'minority subgroup cup', 'subgroup cup focus', 'cup focus indian', 'focus indian user', 'indian user due', 'user due lack', 'due lack sufficient', 'lack sufficient data', 'sufficient data user', 'data user malaysia', 'user malaysia philippine', 'malaysia philippine data', 'philippine data wa', 'data wa sampled', 'wa sampled march', 'sampled march august', 'march august defining', 'august defining cultural', 'defining cultural identity', 'cultural identity use', 'identity use clinical', 'use clinical language', 'clinical language work', 'language work examine', 'work examine relationship', 'examine relationship cultural', 'relationship cultural identity', 'cultural identity use', 'identity use online', 'use online mental', 'online mental health', 'mental health support', 'health support forum', 'support forum leverage', 'forum leverage tomlinsons', 'leverage tomlinsons definition', 'tomlinsons definition cultural', 'definition cultural identity', 'cultural identity self', 'identity self communal', 'self communal definition', 'communal definition based', 'definition based around', 'based around specific', 'around specific usually', 'specific usually politically', 'usually politically inflected', 'politically inflected differentiation', 'inflected differentiation gender', 'differentiation gender sexuality', 'gender sexuality class', 'sexuality class religion', 'class religion race', 'religion race ethnicity', 'race ethnicity nationality', 'ethnicity nationality particularly', 'nationality particularly looking', 'particularly looking aspect', 'looking aspect modern', 'aspect modern cultural', 'modern cultural identity', 'cultural identity run', 'identity run along', 'run along national', 'along national line', 'national line delineated', 'line delineated hall', 'delineated hall et', 'hall et al', 'et al diverse', 'al diverse amorphous', 'diverse amorphous form', 'amorphous form identity', 'form identity cultural', 'identity cultural identity', 'cultural identity often', 'identity often intersect', 'often intersect interact', 'intersect interact form', 'interact form identity', 'form identity including', 'identity including religious', 'including religious ethnic', 'religious ethnic identity', 'ethnic identity however', 'identity however absence', 'however absence direct', 'absence direct information', 'direct information religious', 'information religious ethnic', 'religious ethnic identity', 'ethnic identity based', 'identity based data', 'based data available', 'data available use', 'available use national', 'use national identity', 'national identity proxy', 'identity proxy cultural', 'proxy cultural identity', 'cultural identity additionally', 'identity additionally following', 'additionally following schlesinger', 'following schlesinger et', 'schlesinger et al', 'et al call', 'al call intersectional', 'call intersectional analysis', 'intersectional analysis method', 'analysis method within', 'method within hci', 'within hci also', 'hci also include', 'also include analysis', 'include analysis adjacent', 'analysis adjacent intersecting', 'adjacent intersecting identity', 'intersecting identity relevant', 'identity relevant including', 'relevant including religious', 'including religious identity', 'religious identity analyze', 'identity analyze clinical', 'analyze clinical language', 'clinical language use', 'language use broader', 'use broader definition', 'broader definition clinical', 'definition clinical language', 'clinical language specific', 'language specific medical', 'specific medical diagnosis', 'medical diagnosis following', 'diagnosis following method', 'following method used', 'method used past', 'used past work', 'past work analyze', 'work analyze antidepressant', 'analyze antidepressant related', 'antidepressant related language', 'related language create', 'language create dataset', 'create dataset clinical', 'dataset clinical mental', 'clinical mental health', 'mental health language', 'health language including', 'language including unigrams', 'including unigrams bigram', 'unigrams bigram trigram', 'bigram trigram list', 'trigram list mental', 'list mental disorder', 'mental disorder defined', 'disorder defined international', 'defined international classification', 'international classification disease', 'classification disease icd', 'disease icd diagnostic', 'icd diagnostic statistical', 'diagnostic statistical manual', 'statistical manual mental', 'manual mental disorder', 'mental disorder dsm', 'disorder dsm also', 'dsm also included', 'also included unigrams', 'included unigrams macmillan', 'unigrams macmillan dictionary', 'macmillan dictionary list', 'dictionary list word', 'list word used', 'word used describe', 'used describe illness', 'describe illness disease', 'illness disease specifically', 'disease specifically mental', 'specifically mental illness', 'mental illness general', 'illness general illness', 'general illness result', 'illness result include', 'result include unigrams', 'include unigrams like', 'unigrams like night', 'like night night', 'night night terror', 'night terror sleep', 'terror sleep sleep', 'sleep sleep disorder', 'sleep disorder often', 'disorder often correlated', 'often correlated specific', 'correlated specific symptom', 'specific symptom mental', 'symptom mental illness', 'mental illness distress', 'illness distress sleep', 'distress sleep issue', 'sleep issue awake', 'issue awake night', 'awake night included', 'night included clinically', 'included clinically common', 'clinically common abbreviation', 'common abbreviation mental', 'abbreviation mental disorder', 'mental disorder ocd', 'disorder ocd obsessive', 'ocd obsessive compulsive', 'obsessive compulsive disorder', 'compulsive disorder bpd', 'disorder bpd borderline', 'bpd borderline personality', 'borderline personality disorder', 'personality disorder shorthand', 'disorder shorthand disorder', 'shorthand disorder commonly', 'disorder commonly used', 'commonly used online', 'used online community', 'online community proana', 'community proana used', 'proana used proeating', 'used proeating disorder', 'proeating disorder community', 'disorder community included', 'community included due', 'included due difficulty', 'due difficulty finding', 'difficulty finding exhaustive', 'finding exhaustive list', 'exhaustive list term', 'list term across', 'term across disorder', 'across disorder choose', 'disorder choose use', 'choose use term', 'use term associated', 'term associated dsm', 'associated dsm icd', 'dsm icd categorized', 'icd categorized disorder', 'categorized disorder result', 'disorder result common', 'result common usage', 'common usage framework', 'usage framework globally', 'framework globally throughout', 'globally throughout analysis', 'throughout analysis varied', 'analysis varied factor', 'varied factor use', 'factor use represent', 'use represent mean', 'represent mean represent', 'mean represent standard', 'represent standard deviation', 'standard deviation constraint', 'deviation constraint limitation', 'constraint limitation tradeoff', 'limitation tradeoff cultural', 'tradeoff cultural identity', 'cultural identity exist', 'identity exist many', 'exist many different', 'many different intersecting', 'different intersecting level', 'intersecting level including', 'level including subculture', 'including subculture subcommunities', 'subculture subcommunities within', 'subcommunities within larger', 'within larger umbrella', 'larger umbrella cultural', 'umbrella cultural identity', 'cultural identity result', 'identity result purpose', 'result purpose analysis', 'purpose analysis adopt', 'analysis adopt constraint', 'adopt constraint order', 'constraint order meaningful', 'order meaningful specific', 'meaningful specific analysis', 'specific analysis one', 'analysis one large', 'one large limiting', 'large limiting constraint', 'limiting constraint chose', 'constraint chose study', 'chose study use', 'study use national', 'use national identity', 'national identity state', 'identity state level', 'state level proxy', 'level proxy cultural', 'proxy cultural identity', 'cultural identity though', 'identity though major', 'though major formative', 'major formative part', 'formative part modern', 'part modern cultural', 'modern cultural identity', 'cultural identity argued', 'identity argued hall', 'argued hall tomlinson', 'hall tomlinson country', 'tomlinson country analyze', 'country analyze incredibly', 'analyze incredibly diverse', 'incredibly diverse many', 'diverse many individual', 'many individual cultural', 'individual cultural identity', 'cultural identity intersect', 'identity intersect diverge', 'intersect diverge greater', 'diverge greater national', 'greater national identity', 'national identity rich', 'identity rich analysis', 'rich analysis form', 'analysis form cultural', 'form cultural identity', 'cultural identity beyond', 'identity beyond scope', 'beyond scope work', 'scope work could', 'work could lead', 'could lead richer', 'lead richer conclusion', 'richer conclusion nature', 'conclusion nature cultural', 'nature cultural identity', 'cultural identity online', 'identity online mental', 'online mental health', 'mental health support', 'health support community', 'support community particularly', 'community particularly regard', 'particularly regard cultural', 'regard cultural difference', 'cultural difference user', 'difference user national', 'user national identity', 'national identity additionally', 'identity additionally stay', 'additionally stay consistent', 'stay consistent analysis', 'consistent analysis result', 'analysis result lack', 'result lack data', 'lack data user', 'data user malaysia', 'user malaysia philippine', 'malaysia philippine analyze', 'philippine analyze user', 'analyze user india', 'user india cup', 'india cup extend', 'cup extend finding', 'extend finding experience', 'finding experience part', 'experience part minority', 'part minority group', 'minority group online', 'group online mental', 'online mental health', 'mental health forum', 'health forum draw', 'forum draw validity', 'draw validity exploratory', 'validity exploratory finding', 'exploratory finding similar', 'finding similar consistent', 'similar consistent pattern', 'consistent pattern observe', 'pattern observe indian', 'observe indian malaysian', 'indian malaysian filipino', 'malaysian filipino user', 'filipino user deeper', 'user deeper analysis', 'deeper analysis larger', 'analysis larger dataset', 'larger dataset likely', 'dataset likely necessary', 'likely necessary determine', 'necessary determine minority', 'determine minority community', 'minority community conclusion', 'community conclusion hold', 'conclusion hold true', 'hold true additionally', 'true additionally construct', 'additionally construct clinical', 'construct clinical language', 'clinical language use', 'language use commonly', 'use commonly used', 'commonly used dsm', 'used dsm icd', 'dsm icd framework', 'icd framework illness', 'framework illness categorization', 'illness categorization significant', 'categorization significant limitation', 'significant limitation particularly', 'limitation particularly country', 'particularly country selected', 'country selected example', 'selected example mental', 'example mental health', 'mental health disorder', 'health disorder culturebound', 'disorder culturebound well', 'culturebound well mental', 'well mental health', 'mental health language', 'health language used', 'language used different', 'used different way', 'different way within', 'way within specific', 'within specific country', 'specific country analyze', 'country analyze depression', 'analyze depression often', 'depression often umbrella', 'often umbrella term', 'umbrella term mental', 'term mental illness', 'mental illness additionally', 'illness additionally clear', 'additionally clear online', 'clear online support', 'online support community', 'support community often', 'community often develop', 'often develop cultural', 'develop cultural norm', 'cultural norm language', 'norm language around', 'language around mental', 'around mental health', 'mental health deeper', 'health deeper understanding', 'deeper understanding play', 'understanding play talklife', 'play talklife cup', 'talklife cup neither', 'cup neither focus', 'neither focus within', 'focus within scope', 'within scope work', 'scope work work', 'work work intentionally', 'work intentionally use', 'intentionally use standard', 'use standard clinical', 'standard clinical medical', 'clinical medical term', 'medical term mental', 'term mental health', 'mental health disorder', 'health disorder analysis', 'disorder analysis clinical', 'analysis clinical language', 'clinical language detailed', 'language detailed past', 'detailed past anthropological', 'past anthropological research', 'anthropological research theorized', 'research theorized use', 'theorized use medical', 'use medical clinical', 'medical clinical language', 'clinical language representative', 'language representative medicalized', 'representative medicalized explanatory', 'medicalized explanatory model', 'explanatory model illness', 'model illness frame', 'illness frame use', 'frame use language', 'use language across', 'language across culture', 'across culture approximate', 'culture approximate signifier', 'approximate signifier greater', 'signifier greater awareness', 'greater awareness presence', 'awareness presence mental', 'presence mental disorder', 'mental disorder opposed', 'disorder opposed conceptualizing', 'opposed conceptualizing distress', 'conceptualizing distress stress', 'distress stress tension', 'stress tension depression', 'tension depression analysis', 'depression analysis strictly', 'analysis strictly analyzed', 'strictly analyzed post', 'analyzed post latin', 'post latin alphabet', 'latin alphabet almost', 'alphabet almost post', 'almost post talklife', 'post talklife cup', 'talklife cup english', 'cup english however', 'english however malay', 'however malay tagalog', 'malay tagalog commonly', 'tagalog commonly written', 'commonly written latin', 'written latin script', 'latin script since', 'script since common', 'since common user', 'common user india', 'user india speaker', 'india speaker use', 'speaker use romanized', 'use romanized version', 'romanized version indian', 'version indian language', 'indian language online', 'language online possible', 'online possible small', 'possible small minority', 'small minority post', 'minority post analysis', 'post analysis text', 'analysis text different', 'text different language', 'different language however', 'language however confirmed', 'however confirmed seeing', 'confirmed seeing english', 'seeing english word', 'english word used', 'word used analysis', 'used analysis top', 'analysis top ngrams', 'top ngrams among', 'ngrams among user', 'among user subgroup', 'user subgroup clear', 'subgroup clear english', 'clear english predominant', 'english predominant language', 'predominant language platform', 'language platform though', 'platform though beyond', 'though beyond immediate', 'beyond immediate scope', 'immediate scope work', 'scope work greater', 'work greater analysis', 'greater analysis nonenglish', 'analysis nonenglish codeswitching', 'nonenglish codeswitching platform', 'codeswitching platform could', 'platform could lead', 'could lead deeper', 'lead deeper understanding', 'deeper understanding impact', 'understanding impact interaction', 'impact interaction expression', 'interaction expression user', 'expression user national', 'user national identity', 'national identity different', 'identity different language', 'different language preference']",,,,,,,,
https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-018-2197-z,0,In this section we first present the data gathered and used in our analysis. Researchers interested in the code and the data are invited to contact the authors. Reddit is a website which enables users to aggregate rate and discuss news entertainment politics and many other topics. According to Alexa it is the 8th most popular website in the world. It was estimated by the Pew research center that 6% of online adults use Reddit [26]. The site is organized into a collection of “subreddits” each focused on a particular topic and administered by a collection of moderators. The subreddit r/SuicideWatch is a forum in which online users are encouraged to post their thoughts regarding suicide. At the time of our data collection it had over 58000 subscribers. Sometimes users express a preoccupation with the thought of suicide. Other times users discuss immediate plans to take their own life. These posts often contain a description of their mental state including depression reaction to stress their feelings of being alone and having a low self-esteem. While most online sources of data are notoriously noisy this particular subreddit is remarkably clean. Given the serious nature of the subreddit individuals are less likely to post harassing comments or off-topic remarks. When users post such comments the moderators of the subreddit quickly remove them. We collected all posts from its inception in 2008 to 2016. Each post is often commented on by other individuals. In this work we focused on the original post as it most often represents the suicidal ideation of a user and comments often represent emotional support from other users. We cleaned this data. First we removed empty posts in which the content had been deleted. Second we removed links and replaced them with the word “link”. Third we concatenated the text of the post to the title as many users begin their post in the title and continue in the body of the post. Finally we removed punctuation and other special characters. After cleaning this data we had 131728 posts with 27978246 words of which 84607 words were unique posted by 63252 unique users.,in this section we first present the data gathered and used in our analysis researcher interested in the code and the data are invited to contact the author reddit is a website which enables user to aggregate rate and discus news entertainment politics and many other topic according to alexa it is the th most popular website in the world it wa estimated by the pew research center that of online adult use reddit the site is organized into a collection of subreddits each focused on a particular topic and administered by a collection of moderator the subreddit rsuicidewatch is a forum in which online user are encouraged to post their thought regarding suicide at the time of our data collection it had over subscriber sometimes user express a preoccupation with the thought of suicide other time user discus immediate plan to take their own life these post often contain a description of their mental state including depression reaction to stress their feeling of being alone and having a low selfesteem while most online source of data are notoriously noisy this particular subreddit is remarkably clean given the serious nature of the subreddit individual are le likely to post harassing comment or offtopic remark when user post such comment the moderator of the subreddit quickly remove them we collected all post from it inception in to each post is often commented on by other individual in this work we focused on the original post a it most often represents the suicidal ideation of a user and comment often represent emotional support from other user we cleaned this data first we removed empty post in which the content had been deleted second we removed link and replaced them with the word link third we concatenated the text of the post to the title a many user begin their post in the title and continue in the body of the post finally we removed punctuation and other special character after cleaning this data we had post with word of which word were unique posted by unique user,"['section', 'first', 'present', 'data', 'gathered', 'used', 'analysis', 'researcher', 'interested', 'code', 'data', 'invited', 'contact', 'author', 'reddit', 'website', 'enables', 'user', 'aggregate', 'rate', 'discus', 'news', 'entertainment', 'politics', 'many', 'topic', 'according', 'alexa', 'th', 'popular', 'website', 'world', 'wa', 'estimated', 'pew', 'research', 'center', 'online', 'adult', 'use', 'reddit', 'site', 'organized', 'collection', 'subreddits', 'focused', 'particular', 'topic', 'administered', 'collection', 'moderator', 'subreddit', 'rsuicidewatch', 'forum', 'online', 'user', 'encouraged', 'post', 'thought', 'regarding', 'suicide', 'time', 'data', 'collection', 'subscriber', 'sometimes', 'user', 'express', 'preoccupation', 'thought', 'suicide', 'time', 'user', 'discus', 'immediate', 'plan', 'take', 'life', 'post', 'often', 'contain', 'description', 'mental', 'state', 'including', 'depression', 'reaction', 'stress', 'feeling', 'alone', 'low', 'selfesteem', 'online', 'source', 'data', 'notoriously', 'noisy', 'particular', 'subreddit', 'remarkably', 'clean', 'given', 'serious', 'nature', 'subreddit', 'individual', 'le', 'likely', 'post', 'harassing', 'comment', 'offtopic', 'remark', 'user', 'post', 'comment', 'moderator', 'subreddit', 'quickly', 'remove', 'collected', 'post', 'inception', 'post', 'often', 'commented', 'individual', 'work', 'focused', 'original', 'post', 'often', 'represents', 'suicidal', 'ideation', 'user', 'comment', 'often', 'represent', 'emotional', 'support', 'user', 'cleaned', 'data', 'first', 'removed', 'empty', 'post', 'content', 'deleted', 'second', 'removed', 'link', 'replaced', 'word', 'link', 'third', 'concatenated', 'text', 'post', 'title', 'many', 'user', 'begin', 'post', 'title', 'continue', 'body', 'post', 'finally', 'removed', 'punctuation', 'special', 'character', 'cleaning', 'data', 'post', 'word', 'word', 'unique', 'posted', 'unique', 'user']","['section first', 'first present', 'present data', 'data gathered', 'gathered used', 'used analysis', 'analysis researcher', 'researcher interested', 'interested code', 'code data', 'data invited', 'invited contact', 'contact author', 'author reddit', 'reddit website', 'website enables', 'enables user', 'user aggregate', 'aggregate rate', 'rate discus', 'discus news', 'news entertainment', 'entertainment politics', 'politics many', 'many topic', 'topic according', 'according alexa', 'alexa th', 'th popular', 'popular website', 'website world', 'world wa', 'wa estimated', 'estimated pew', 'pew research', 'research center', 'center online', 'online adult', 'adult use', 'use reddit', 'reddit site', 'site organized', 'organized collection', 'collection subreddits', 'subreddits focused', 'focused particular', 'particular topic', 'topic administered', 'administered collection', 'collection moderator', 'moderator subreddit', 'subreddit rsuicidewatch', 'rsuicidewatch forum', 'forum online', 'online user', 'user encouraged', 'encouraged post', 'post thought', 'thought regarding', 'regarding suicide', 'suicide time', 'time data', 'data collection', 'collection subscriber', 'subscriber sometimes', 'sometimes user', 'user express', 'express preoccupation', 'preoccupation thought', 'thought suicide', 'suicide time', 'time user', 'user discus', 'discus immediate', 'immediate plan', 'plan take', 'take life', 'life post', 'post often', 'often contain', 'contain description', 'description mental', 'mental state', 'state including', 'including depression', 'depression reaction', 'reaction stress', 'stress feeling', 'feeling alone', 'alone low', 'low selfesteem', 'selfesteem online', 'online source', 'source data', 'data notoriously', 'notoriously noisy', 'noisy particular', 'particular subreddit', 'subreddit remarkably', 'remarkably clean', 'clean given', 'given serious', 'serious nature', 'nature subreddit', 'subreddit individual', 'individual le', 'le likely', 'likely post', 'post harassing', 'harassing comment', 'comment offtopic', 'offtopic remark', 'remark user', 'user post', 'post comment', 'comment moderator', 'moderator subreddit', 'subreddit quickly', 'quickly remove', 'remove collected', 'collected post', 'post inception', 'inception post', 'post often', 'often commented', 'commented individual', 'individual work', 'work focused', 'focused original', 'original post', 'post often', 'often represents', 'represents suicidal', 'suicidal ideation', 'ideation user', 'user comment', 'comment often', 'often represent', 'represent emotional', 'emotional support', 'support user', 'user cleaned', 'cleaned data', 'data first', 'first removed', 'removed empty', 'empty post', 'post content', 'content deleted', 'deleted second', 'second removed', 'removed link', 'link replaced', 'replaced word', 'word link', 'link third', 'third concatenated', 'concatenated text', 'text post', 'post title', 'title many', 'many user', 'user begin', 'begin post', 'post title', 'title continue', 'continue body', 'body post', 'post finally', 'finally removed', 'removed punctuation', 'punctuation special', 'special character', 'character cleaning', 'cleaning data', 'data post', 'post word', 'word word', 'word unique', 'unique posted', 'posted unique', 'unique user']","['section first present', 'first present data', 'present data gathered', 'data gathered used', 'gathered used analysis', 'used analysis researcher', 'analysis researcher interested', 'researcher interested code', 'interested code data', 'code data invited', 'data invited contact', 'invited contact author', 'contact author reddit', 'author reddit website', 'reddit website enables', 'website enables user', 'enables user aggregate', 'user aggregate rate', 'aggregate rate discus', 'rate discus news', 'discus news entertainment', 'news entertainment politics', 'entertainment politics many', 'politics many topic', 'many topic according', 'topic according alexa', 'according alexa th', 'alexa th popular', 'th popular website', 'popular website world', 'website world wa', 'world wa estimated', 'wa estimated pew', 'estimated pew research', 'pew research center', 'research center online', 'center online adult', 'online adult use', 'adult use reddit', 'use reddit site', 'reddit site organized', 'site organized collection', 'organized collection subreddits', 'collection subreddits focused', 'subreddits focused particular', 'focused particular topic', 'particular topic administered', 'topic administered collection', 'administered collection moderator', 'collection moderator subreddit', 'moderator subreddit rsuicidewatch', 'subreddit rsuicidewatch forum', 'rsuicidewatch forum online', 'forum online user', 'online user encouraged', 'user encouraged post', 'encouraged post thought', 'post thought regarding', 'thought regarding suicide', 'regarding suicide time', 'suicide time data', 'time data collection', 'data collection subscriber', 'collection subscriber sometimes', 'subscriber sometimes user', 'sometimes user express', 'user express preoccupation', 'express preoccupation thought', 'preoccupation thought suicide', 'thought suicide time', 'suicide time user', 'time user discus', 'user discus immediate', 'discus immediate plan', 'immediate plan take', 'plan take life', 'take life post', 'life post often', 'post often contain', 'often contain description', 'contain description mental', 'description mental state', 'mental state including', 'state including depression', 'including depression reaction', 'depression reaction stress', 'reaction stress feeling', 'stress feeling alone', 'feeling alone low', 'alone low selfesteem', 'low selfesteem online', 'selfesteem online source', 'online source data', 'source data notoriously', 'data notoriously noisy', 'notoriously noisy particular', 'noisy particular subreddit', 'particular subreddit remarkably', 'subreddit remarkably clean', 'remarkably clean given', 'clean given serious', 'given serious nature', 'serious nature subreddit', 'nature subreddit individual', 'subreddit individual le', 'individual le likely', 'le likely post', 'likely post harassing', 'post harassing comment', 'harassing comment offtopic', 'comment offtopic remark', 'offtopic remark user', 'remark user post', 'user post comment', 'post comment moderator', 'comment moderator subreddit', 'moderator subreddit quickly', 'subreddit quickly remove', 'quickly remove collected', 'remove collected post', 'collected post inception', 'post inception post', 'inception post often', 'post often commented', 'often commented individual', 'commented individual work', 'individual work focused', 'work focused original', 'focused original post', 'original post often', 'post often represents', 'often represents suicidal', 'represents suicidal ideation', 'suicidal ideation user', 'ideation user comment', 'user comment often', 'comment often represent', 'often represent emotional', 'represent emotional support', 'emotional support user', 'support user cleaned', 'user cleaned data', 'cleaned data first', 'data first removed', 'first removed empty', 'removed empty post', 'empty post content', 'post content deleted', 'content deleted second', 'deleted second removed', 'second removed link', 'removed link replaced', 'link replaced word', 'replaced word link', 'word link third', 'link third concatenated', 'third concatenated text', 'concatenated text post', 'text post title', 'post title many', 'title many user', 'many user begin', 'user begin post', 'begin post title', 'post title continue', 'title continue body', 'continue body post', 'body post finally', 'post finally removed', 'finally removed punctuation', 'removed punctuation special', 'punctuation special character', 'special character cleaning', 'character cleaning data', 'cleaning data post', 'data post word', 'post word word', 'word word unique', 'word unique posted', 'unique posted unique', 'posted unique user']",,,,,,,,
https://ieeexplore.ieee.org/abstract/document/8609647,0,Reddit is a multilingual Online Social Network founded in 2005 and organized in subcommunities by areas of interest called subreddits. We obtained data from the Reddit's data repository4 focusing on four subreddits where people discuss issues related to mental heath disorders: Depression (/r/depression) Suicide Watch (/r/Suicide Watch) Anxiety (/r/anxiety) and Bipolar (/r/bipolar). Our dataset is comprised of user activities (posts and comments) that took place between 2011 and 201 7. Here we focus on data from January 2017 to December 2017. In total we obtained 261511 posts and 1256669 comments from 184708 unique users. Table I shows the total number of users posts and comments per subreddit. The total number of comments in each community is at least 4.2 times larger than the number of posts which suggests a supportive behavior among users.We model user interactions as a weighted directed graph G where each node represents a user each directed edge (u v) indicates that user u commented on one or more posts made by user v and the edge weight is equal to the number of u’s comments summed over all v’s posts. Given a user u in G the in-degree of u is the number of users who interact with user u i.e. the number of unique users who commented on posts from u. The out-degree of u in turn is the number of interactions u had within the community i.e. the number of posts u commented on. Social support is the process of interactions in relationships which improves coping esteem belonging and competence through actual or perceived exchanges of psychosocial resources (adapted from [14]). In addition to measuring support from the interaction graph we also measure it from discussion trees. In a discussion tree the root node corresponds to a post while other nodes correspond to comments made either in response to the post or to other comments in the same thread. Analyzing tree sizes (depth) and shapes (width) can shed some light on the topics that most attract user attention as well as pinpoint key members in each community. For instance a highly emotional comment can trigger more reactions than the original post i.e. the majority of the discussion might be concentrated in one of the branches.RMN is a recursive neural network designed to model relationships between pairs of entities from text [13]. Each relationship is represented at a given point in time as a vector of weights over K descriptors. Entities that form a relationship do not need to be of the same class: for example in this work we model the relationships between a user and the community in which she interacts. Each post or comment corresponds to a different instant. Words are represented as embeddings of dimension P that is each word w of a vocabulary V is a vector in RP . Users and communities are represented by embeddings of dimension U and C respectively. As in previous works we generated embeddings using GloVe [15]. The descriptors obtained from RMN are vectors in RP  allowing us to find the closest words to each descriptor. The post’s (or comment’s) representation is denoted by vpost ∈ RP . This vector is the average of the word embeddings contained in the post. The representations of users and communities are denoted by vuser and vcomm. For each post or comment RMN takes as input a vector v ∈ RP +U+C obtained by concatenating vpost vuser and vcomm. These vectors are combined through the weights of the neural network to obtain a representation dt ∈ RK of the relationship between the user and the community at that particular time. RMN uses a smoothing parameter α ∈ (0 1) to avoid abrupt changes in the representation of the same relation in consecutive instants dt and dt−1. The descriptor array R ∈ RK×P is used for attempting to reconstruct the post vpost by making rt = Rdt. RMN parameters (weights and matrix of descriptors) are trained in order to maximize an objective function that aims to approximate rt and vpost while retaining some distance between rt and other randomly sampled posts. See [13] for more details on RMN. The input data for RMN was preprocessed as follows. First we removed all posts and comments marked as [deleted] or [removed] standard stop-words (using the NLTK library) punctuation and accents. Second for each subreddit we removed posts and comments from users who performed less than 50 activities (posts or comments) following the methodology presented in [16]. Finally we selected the words that appear at least once in each of the four subreddits analyzed seeking to find similarities in the way people express themselves when discussing mental health disorders. The final subset of data analyzed by RMN is composed of 18020 unique words 25101 posts and 401428 comments.,reddit is a multilingual online social network founded in and organized in subcommunities by area of interest called subreddits we obtained data from the reddits data repository focusing on four subreddits where people discus issue related to mental heath disorder depression rdepression suicide watch rsuicide watch anxiety ranxiety and bipolar rbipolar our dataset is comprised of user activity post and comment that took place between and here we focus on data from january to december in total we obtained post and comment from unique user table i show the total number of user post and comment per subreddit the total number of comment in each community is at least time larger than the number of post which suggests a supportive behavior among userswe model user interaction a a weighted directed graph g where each node represents a user each directed edge u v indicates that user u commented on one or more post made by user v and the edge weight is equal to the number of u comment summed over all v post given a user u in g the indegree of u is the number of user who interact with user u ie the number of unique user who commented on post from u the outdegree of u in turn is the number of interaction u had within the community ie the number of post u commented on social support is the process of interaction in relationship which improves coping esteem belonging and competence through actual or perceived exchange of psychosocial resource adapted from in addition to measuring support from the interaction graph we also measure it from discussion tree in a discussion tree the root node corresponds to a post while other node correspond to comment made either in response to the post or to other comment in the same thread analyzing tree size depth and shape width can shed some light on the topic that most attract user attention a well a pinpoint key member in each community for instance a highly emotional comment can trigger more reaction than the original post ie the majority of the discussion might be concentrated in one of the branchesrmn is a recursive neural network designed to model relationship between pair of entity from text each relationship is represented at a given point in time a a vector of weight over k descriptor entity that form a relationship do not need to be of the same class for example in this work we model the relationship between a user and the community in which she interacts each post or comment corresponds to a different instant word are represented a embeddings of dimension p that is each word w of a vocabulary v is a vector in rp user and community are represented by embeddings of dimension u and c respectively a in previous work we generated embeddings using glove the descriptor obtained from rmn are vector in rp allowing u to find the closest word to each descriptor the post or comment representation is denoted by vpost rp this vector is the average of the word embeddings contained in the post the representation of user and community are denoted by vuser and vcomm for each post or comment rmn take a input a vector v rp uc obtained by concatenating vpost vuser and vcomm these vector are combined through the weight of the neural network to obtain a representation dt rk of the relationship between the user and the community at that particular time rmn us a smoothing parameter to avoid abrupt change in the representation of the same relation in consecutive instant dt and dt the descriptor array r rkp is used for attempting to reconstruct the post vpost by making rt rdt rmn parameter weight and matrix of descriptor are trained in order to maximize an objective function that aim to approximate rt and vpost while retaining some distance between rt and other randomly sampled post see for more detail on rmn the input data for rmn wa preprocessed a follows first we removed all post and comment marked a deleted or removed standard stopwords using the nltk library punctuation and accent second for each subreddit we removed post and comment from user who performed le than activity post or comment following the methodology presented in finally we selected the word that appear at least once in each of the four subreddits analyzed seeking to find similarity in the way people express themselves when discussing mental health disorder the final subset of data analyzed by rmn is composed of unique word post and comment,"['reddit', 'multilingual', 'online', 'social', 'network', 'founded', 'organized', 'subcommunities', 'area', 'interest', 'called', 'subreddits', 'obtained', 'data', 'reddits', 'data', 'repository', 'focusing', 'four', 'subreddits', 'people', 'discus', 'issue', 'related', 'mental', 'heath', 'disorder', 'depression', 'rdepression', 'suicide', 'watch', 'rsuicide', 'watch', 'anxiety', 'ranxiety', 'bipolar', 'rbipolar', 'dataset', 'comprised', 'user', 'activity', 'post', 'comment', 'took', 'place', 'focus', 'data', 'january', 'december', 'total', 'obtained', 'post', 'comment', 'unique', 'user', 'table', 'show', 'total', 'number', 'user', 'post', 'comment', 'per', 'subreddit', 'total', 'number', 'comment', 'community', 'least', 'time', 'larger', 'number', 'post', 'suggests', 'supportive', 'behavior', 'among', 'userswe', 'model', 'user', 'interaction', 'weighted', 'directed', 'graph', 'g', 'node', 'represents', 'user', 'directed', 'edge', 'u', 'v', 'indicates', 'user', 'u', 'commented', 'one', 'post', 'made', 'user', 'v', 'edge', 'weight', 'equal', 'number', 'u', 'comment', 'summed', 'v', 'post', 'given', 'user', 'u', 'g', 'indegree', 'u', 'number', 'user', 'interact', 'user', 'u', 'ie', 'number', 'unique', 'user', 'commented', 'post', 'u', 'outdegree', 'u', 'turn', 'number', 'interaction', 'u', 'within', 'community', 'ie', 'number', 'post', 'u', 'commented', 'social', 'support', 'process', 'interaction', 'relationship', 'improves', 'coping', 'esteem', 'belonging', 'competence', 'actual', 'perceived', 'exchange', 'psychosocial', 'resource', 'adapted', 'addition', 'measuring', 'support', 'interaction', 'graph', 'also', 'measure', 'discussion', 'tree', 'discussion', 'tree', 'root', 'node', 'corresponds', 'post', 'node', 'correspond', 'comment', 'made', 'either', 'response', 'post', 'comment', 'thread', 'analyzing', 'tree', 'size', 'depth', 'shape', 'width', 'shed', 'light', 'topic', 'attract', 'user', 'attention', 'well', 'pinpoint', 'key', 'member', 'community', 'instance', 'highly', 'emotional', 'comment', 'trigger', 'reaction', 'original', 'post', 'ie', 'majority', 'discussion', 'might', 'concentrated', 'one', 'branchesrmn', 'recursive', 'neural', 'network', 'designed', 'model', 'relationship', 'pair', 'entity', 'text', 'relationship', 'represented', 'given', 'point', 'time', 'vector', 'weight', 'k', 'descriptor', 'entity', 'form', 'relationship', 'need', 'class', 'example', 'work', 'model', 'relationship', 'user', 'community', 'interacts', 'post', 'comment', 'corresponds', 'different', 'instant', 'word', 'represented', 'embeddings', 'dimension', 'p', 'word', 'w', 'vocabulary', 'v', 'vector', 'rp', 'user', 'community', 'represented', 'embeddings', 'dimension', 'u', 'c', 'respectively', 'previous', 'work', 'generated', 'embeddings', 'using', 'glove', 'descriptor', 'obtained', 'rmn', 'vector', 'rp', 'allowing', 'u', 'find', 'closest', 'word', 'descriptor', 'post', 'comment', 'representation', 'denoted', 'vpost', 'rp', 'vector', 'average', 'word', 'embeddings', 'contained', 'post', 'representation', 'user', 'community', 'denoted', 'vuser', 'vcomm', 'post', 'comment', 'rmn', 'take', 'input', 'vector', 'v', 'rp', 'uc', 'obtained', 'concatenating', 'vpost', 'vuser', 'vcomm', 'vector', 'combined', 'weight', 'neural', 'network', 'obtain', 'representation', 'dt', 'rk', 'relationship', 'user', 'community', 'particular', 'time', 'rmn', 'us', 'smoothing', 'parameter', 'avoid', 'abrupt', 'change', 'representation', 'relation', 'consecutive', 'instant', 'dt', 'dt', 'descriptor', 'array', 'r', 'rkp', 'used', 'attempting', 'reconstruct', 'post', 'vpost', 'making', 'rt', 'rdt', 'rmn', 'parameter', 'weight', 'matrix', 'descriptor', 'trained', 'order', 'maximize', 'objective', 'function', 'aim', 'approximate', 'rt', 'vpost', 'retaining', 'distance', 'rt', 'randomly', 'sampled', 'post', 'see', 'detail', 'rmn', 'input', 'data', 'rmn', 'wa', 'preprocessed', 'follows', 'first', 'removed', 'post', 'comment', 'marked', 'deleted', 'removed', 'standard', 'stopwords', 'using', 'nltk', 'library', 'punctuation', 'accent', 'second', 'subreddit', 'removed', 'post', 'comment', 'user', 'performed', 'le', 'activity', 'post', 'comment', 'following', 'methodology', 'presented', 'finally', 'selected', 'word', 'appear', 'least', 'four', 'subreddits', 'analyzed', 'seeking', 'find', 'similarity', 'way', 'people', 'express', 'discussing', 'mental', 'health', 'disorder', 'final', 'subset', 'data', 'analyzed', 'rmn', 'composed', 'unique', 'word', 'post', 'comment']","['reddit multilingual', 'multilingual online', 'online social', 'social network', 'network founded', 'founded organized', 'organized subcommunities', 'subcommunities area', 'area interest', 'interest called', 'called subreddits', 'subreddits obtained', 'obtained data', 'data reddits', 'reddits data', 'data repository', 'repository focusing', 'focusing four', 'four subreddits', 'subreddits people', 'people discus', 'discus issue', 'issue related', 'related mental', 'mental heath', 'heath disorder', 'disorder depression', 'depression rdepression', 'rdepression suicide', 'suicide watch', 'watch rsuicide', 'rsuicide watch', 'watch anxiety', 'anxiety ranxiety', 'ranxiety bipolar', 'bipolar rbipolar', 'rbipolar dataset', 'dataset comprised', 'comprised user', 'user activity', 'activity post', 'post comment', 'comment took', 'took place', 'place focus', 'focus data', 'data january', 'january december', 'december total', 'total obtained', 'obtained post', 'post comment', 'comment unique', 'unique user', 'user table', 'table show', 'show total', 'total number', 'number user', 'user post', 'post comment', 'comment per', 'per subreddit', 'subreddit total', 'total number', 'number comment', 'comment community', 'community least', 'least time', 'time larger', 'larger number', 'number post', 'post suggests', 'suggests supportive', 'supportive behavior', 'behavior among', 'among userswe', 'userswe model', 'model user', 'user interaction', 'interaction weighted', 'weighted directed', 'directed graph', 'graph g', 'g node', 'node represents', 'represents user', 'user directed', 'directed edge', 'edge u', 'u v', 'v indicates', 'indicates user', 'user u', 'u commented', 'commented one', 'one post', 'post made', 'made user', 'user v', 'v edge', 'edge weight', 'weight equal', 'equal number', 'number u', 'u comment', 'comment summed', 'summed v', 'v post', 'post given', 'given user', 'user u', 'u g', 'g indegree', 'indegree u', 'u number', 'number user', 'user interact', 'interact user', 'user u', 'u ie', 'ie number', 'number unique', 'unique user', 'user commented', 'commented post', 'post u', 'u outdegree', 'outdegree u', 'u turn', 'turn number', 'number interaction', 'interaction u', 'u within', 'within community', 'community ie', 'ie number', 'number post', 'post u', 'u commented', 'commented social', 'social support', 'support process', 'process interaction', 'interaction relationship', 'relationship improves', 'improves coping', 'coping esteem', 'esteem belonging', 'belonging competence', 'competence actual', 'actual perceived', 'perceived exchange', 'exchange psychosocial', 'psychosocial resource', 'resource adapted', 'adapted addition', 'addition measuring', 'measuring support', 'support interaction', 'interaction graph', 'graph also', 'also measure', 'measure discussion', 'discussion tree', 'tree discussion', 'discussion tree', 'tree root', 'root node', 'node corresponds', 'corresponds post', 'post node', 'node correspond', 'correspond comment', 'comment made', 'made either', 'either response', 'response post', 'post comment', 'comment thread', 'thread analyzing', 'analyzing tree', 'tree size', 'size depth', 'depth shape', 'shape width', 'width shed', 'shed light', 'light topic', 'topic attract', 'attract user', 'user attention', 'attention well', 'well pinpoint', 'pinpoint key', 'key member', 'member community', 'community instance', 'instance highly', 'highly emotional', 'emotional comment', 'comment trigger', 'trigger reaction', 'reaction original', 'original post', 'post ie', 'ie majority', 'majority discussion', 'discussion might', 'might concentrated', 'concentrated one', 'one branchesrmn', 'branchesrmn recursive', 'recursive neural', 'neural network', 'network designed', 'designed model', 'model relationship', 'relationship pair', 'pair entity', 'entity text', 'text relationship', 'relationship represented', 'represented given', 'given point', 'point time', 'time vector', 'vector weight', 'weight k', 'k descriptor', 'descriptor entity', 'entity form', 'form relationship', 'relationship need', 'need class', 'class example', 'example work', 'work model', 'model relationship', 'relationship user', 'user community', 'community interacts', 'interacts post', 'post comment', 'comment corresponds', 'corresponds different', 'different instant', 'instant word', 'word represented', 'represented embeddings', 'embeddings dimension', 'dimension p', 'p word', 'word w', 'w vocabulary', 'vocabulary v', 'v vector', 'vector rp', 'rp user', 'user community', 'community represented', 'represented embeddings', 'embeddings dimension', 'dimension u', 'u c', 'c respectively', 'respectively previous', 'previous work', 'work generated', 'generated embeddings', 'embeddings using', 'using glove', 'glove descriptor', 'descriptor obtained', 'obtained rmn', 'rmn vector', 'vector rp', 'rp allowing', 'allowing u', 'u find', 'find closest', 'closest word', 'word descriptor', 'descriptor post', 'post comment', 'comment representation', 'representation denoted', 'denoted vpost', 'vpost rp', 'rp vector', 'vector average', 'average word', 'word embeddings', 'embeddings contained', 'contained post', 'post representation', 'representation user', 'user community', 'community denoted', 'denoted vuser', 'vuser vcomm', 'vcomm post', 'post comment', 'comment rmn', 'rmn take', 'take input', 'input vector', 'vector v', 'v rp', 'rp uc', 'uc obtained', 'obtained concatenating', 'concatenating vpost', 'vpost vuser', 'vuser vcomm', 'vcomm vector', 'vector combined', 'combined weight', 'weight neural', 'neural network', 'network obtain', 'obtain representation', 'representation dt', 'dt rk', 'rk relationship', 'relationship user', 'user community', 'community particular', 'particular time', 'time rmn', 'rmn us', 'us smoothing', 'smoothing parameter', 'parameter avoid', 'avoid abrupt', 'abrupt change', 'change representation', 'representation relation', 'relation consecutive', 'consecutive instant', 'instant dt', 'dt dt', 'dt descriptor', 'descriptor array', 'array r', 'r rkp', 'rkp used', 'used attempting', 'attempting reconstruct', 'reconstruct post', 'post vpost', 'vpost making', 'making rt', 'rt rdt', 'rdt rmn', 'rmn parameter', 'parameter weight', 'weight matrix', 'matrix descriptor', 'descriptor trained', 'trained order', 'order maximize', 'maximize objective', 'objective function', 'function aim', 'aim approximate', 'approximate rt', 'rt vpost', 'vpost retaining', 'retaining distance', 'distance rt', 'rt randomly', 'randomly sampled', 'sampled post', 'post see', 'see detail', 'detail rmn', 'rmn input', 'input data', 'data rmn', 'rmn wa', 'wa preprocessed', 'preprocessed follows', 'follows first', 'first removed', 'removed post', 'post comment', 'comment marked', 'marked deleted', 'deleted removed', 'removed standard', 'standard stopwords', 'stopwords using', 'using nltk', 'nltk library', 'library punctuation', 'punctuation accent', 'accent second', 'second subreddit', 'subreddit removed', 'removed post', 'post comment', 'comment user', 'user performed', 'performed le', 'le activity', 'activity post', 'post comment', 'comment following', 'following methodology', 'methodology presented', 'presented finally', 'finally selected', 'selected word', 'word appear', 'appear least', 'least four', 'four subreddits', 'subreddits analyzed', 'analyzed seeking', 'seeking find', 'find similarity', 'similarity way', 'way people', 'people express', 'express discussing', 'discussing mental', 'mental health', 'health disorder', 'disorder final', 'final subset', 'subset data', 'data analyzed', 'analyzed rmn', 'rmn composed', 'composed unique', 'unique word', 'word post', 'post comment']","['reddit multilingual online', 'multilingual online social', 'online social network', 'social network founded', 'network founded organized', 'founded organized subcommunities', 'organized subcommunities area', 'subcommunities area interest', 'area interest called', 'interest called subreddits', 'called subreddits obtained', 'subreddits obtained data', 'obtained data reddits', 'data reddits data', 'reddits data repository', 'data repository focusing', 'repository focusing four', 'focusing four subreddits', 'four subreddits people', 'subreddits people discus', 'people discus issue', 'discus issue related', 'issue related mental', 'related mental heath', 'mental heath disorder', 'heath disorder depression', 'disorder depression rdepression', 'depression rdepression suicide', 'rdepression suicide watch', 'suicide watch rsuicide', 'watch rsuicide watch', 'rsuicide watch anxiety', 'watch anxiety ranxiety', 'anxiety ranxiety bipolar', 'ranxiety bipolar rbipolar', 'bipolar rbipolar dataset', 'rbipolar dataset comprised', 'dataset comprised user', 'comprised user activity', 'user activity post', 'activity post comment', 'post comment took', 'comment took place', 'took place focus', 'place focus data', 'focus data january', 'data january december', 'january december total', 'december total obtained', 'total obtained post', 'obtained post comment', 'post comment unique', 'comment unique user', 'unique user table', 'user table show', 'table show total', 'show total number', 'total number user', 'number user post', 'user post comment', 'post comment per', 'comment per subreddit', 'per subreddit total', 'subreddit total number', 'total number comment', 'number comment community', 'comment community least', 'community least time', 'least time larger', 'time larger number', 'larger number post', 'number post suggests', 'post suggests supportive', 'suggests supportive behavior', 'supportive behavior among', 'behavior among userswe', 'among userswe model', 'userswe model user', 'model user interaction', 'user interaction weighted', 'interaction weighted directed', 'weighted directed graph', 'directed graph g', 'graph g node', 'g node represents', 'node represents user', 'represents user directed', 'user directed edge', 'directed edge u', 'edge u v', 'u v indicates', 'v indicates user', 'indicates user u', 'user u commented', 'u commented one', 'commented one post', 'one post made', 'post made user', 'made user v', 'user v edge', 'v edge weight', 'edge weight equal', 'weight equal number', 'equal number u', 'number u comment', 'u comment summed', 'comment summed v', 'summed v post', 'v post given', 'post given user', 'given user u', 'user u g', 'u g indegree', 'g indegree u', 'indegree u number', 'u number user', 'number user interact', 'user interact user', 'interact user u', 'user u ie', 'u ie number', 'ie number unique', 'number unique user', 'unique user commented', 'user commented post', 'commented post u', 'post u outdegree', 'u outdegree u', 'outdegree u turn', 'u turn number', 'turn number interaction', 'number interaction u', 'interaction u within', 'u within community', 'within community ie', 'community ie number', 'ie number post', 'number post u', 'post u commented', 'u commented social', 'commented social support', 'social support process', 'support process interaction', 'process interaction relationship', 'interaction relationship improves', 'relationship improves coping', 'improves coping esteem', 'coping esteem belonging', 'esteem belonging competence', 'belonging competence actual', 'competence actual perceived', 'actual perceived exchange', 'perceived exchange psychosocial', 'exchange psychosocial resource', 'psychosocial resource adapted', 'resource adapted addition', 'adapted addition measuring', 'addition measuring support', 'measuring support interaction', 'support interaction graph', 'interaction graph also', 'graph also measure', 'also measure discussion', 'measure discussion tree', 'discussion tree discussion', 'tree discussion tree', 'discussion tree root', 'tree root node', 'root node corresponds', 'node corresponds post', 'corresponds post node', 'post node correspond', 'node correspond comment', 'correspond comment made', 'comment made either', 'made either response', 'either response post', 'response post comment', 'post comment thread', 'comment thread analyzing', 'thread analyzing tree', 'analyzing tree size', 'tree size depth', 'size depth shape', 'depth shape width', 'shape width shed', 'width shed light', 'shed light topic', 'light topic attract', 'topic attract user', 'attract user attention', 'user attention well', 'attention well pinpoint', 'well pinpoint key', 'pinpoint key member', 'key member community', 'member community instance', 'community instance highly', 'instance highly emotional', 'highly emotional comment', 'emotional comment trigger', 'comment trigger reaction', 'trigger reaction original', 'reaction original post', 'original post ie', 'post ie majority', 'ie majority discussion', 'majority discussion might', 'discussion might concentrated', 'might concentrated one', 'concentrated one branchesrmn', 'one branchesrmn recursive', 'branchesrmn recursive neural', 'recursive neural network', 'neural network designed', 'network designed model', 'designed model relationship', 'model relationship pair', 'relationship pair entity', 'pair entity text', 'entity text relationship', 'text relationship represented', 'relationship represented given', 'represented given point', 'given point time', 'point time vector', 'time vector weight', 'vector weight k', 'weight k descriptor', 'k descriptor entity', 'descriptor entity form', 'entity form relationship', 'form relationship need', 'relationship need class', 'need class example', 'class example work', 'example work model', 'work model relationship', 'model relationship user', 'relationship user community', 'user community interacts', 'community interacts post', 'interacts post comment', 'post comment corresponds', 'comment corresponds different', 'corresponds different instant', 'different instant word', 'instant word represented', 'word represented embeddings', 'represented embeddings dimension', 'embeddings dimension p', 'dimension p word', 'p word w', 'word w vocabulary', 'w vocabulary v', 'vocabulary v vector', 'v vector rp', 'vector rp user', 'rp user community', 'user community represented', 'community represented embeddings', 'represented embeddings dimension', 'embeddings dimension u', 'dimension u c', 'u c respectively', 'c respectively previous', 'respectively previous work', 'previous work generated', 'work generated embeddings', 'generated embeddings using', 'embeddings using glove', 'using glove descriptor', 'glove descriptor obtained', 'descriptor obtained rmn', 'obtained rmn vector', 'rmn vector rp', 'vector rp allowing', 'rp allowing u', 'allowing u find', 'u find closest', 'find closest word', 'closest word descriptor', 'word descriptor post', 'descriptor post comment', 'post comment representation', 'comment representation denoted', 'representation denoted vpost', 'denoted vpost rp', 'vpost rp vector', 'rp vector average', 'vector average word', 'average word embeddings', 'word embeddings contained', 'embeddings contained post', 'contained post representation', 'post representation user', 'representation user community', 'user community denoted', 'community denoted vuser', 'denoted vuser vcomm', 'vuser vcomm post', 'vcomm post comment', 'post comment rmn', 'comment rmn take', 'rmn take input', 'take input vector', 'input vector v', 'vector v rp', 'v rp uc', 'rp uc obtained', 'uc obtained concatenating', 'obtained concatenating vpost', 'concatenating vpost vuser', 'vpost vuser vcomm', 'vuser vcomm vector', 'vcomm vector combined', 'vector combined weight', 'combined weight neural', 'weight neural network', 'neural network obtain', 'network obtain representation', 'obtain representation dt', 'representation dt rk', 'dt rk relationship', 'rk relationship user', 'relationship user community', 'user community particular', 'community particular time', 'particular time rmn', 'time rmn us', 'rmn us smoothing', 'us smoothing parameter', 'smoothing parameter avoid', 'parameter avoid abrupt', 'avoid abrupt change', 'abrupt change representation', 'change representation relation', 'representation relation consecutive', 'relation consecutive instant', 'consecutive instant dt', 'instant dt dt', 'dt dt descriptor', 'dt descriptor array', 'descriptor array r', 'array r rkp', 'r rkp used', 'rkp used attempting', 'used attempting reconstruct', 'attempting reconstruct post', 'reconstruct post vpost', 'post vpost making', 'vpost making rt', 'making rt rdt', 'rt rdt rmn', 'rdt rmn parameter', 'rmn parameter weight', 'parameter weight matrix', 'weight matrix descriptor', 'matrix descriptor trained', 'descriptor trained order', 'trained order maximize', 'order maximize objective', 'maximize objective function', 'objective function aim', 'function aim approximate', 'aim approximate rt', 'approximate rt vpost', 'rt vpost retaining', 'vpost retaining distance', 'retaining distance rt', 'distance rt randomly', 'rt randomly sampled', 'randomly sampled post', 'sampled post see', 'post see detail', 'see detail rmn', 'detail rmn input', 'rmn input data', 'input data rmn', 'data rmn wa', 'rmn wa preprocessed', 'wa preprocessed follows', 'preprocessed follows first', 'follows first removed', 'first removed post', 'removed post comment', 'post comment marked', 'comment marked deleted', 'marked deleted removed', 'deleted removed standard', 'removed standard stopwords', 'standard stopwords using', 'stopwords using nltk', 'using nltk library', 'nltk library punctuation', 'library punctuation accent', 'punctuation accent second', 'accent second subreddit', 'second subreddit removed', 'subreddit removed post', 'removed post comment', 'post comment user', 'comment user performed', 'user performed le', 'performed le activity', 'le activity post', 'activity post comment', 'post comment following', 'comment following methodology', 'following methodology presented', 'methodology presented finally', 'presented finally selected', 'finally selected word', 'selected word appear', 'word appear least', 'appear least four', 'least four subreddits', 'four subreddits analyzed', 'subreddits analyzed seeking', 'analyzed seeking find', 'seeking find similarity', 'find similarity way', 'similarity way people', 'way people express', 'people express discussing', 'express discussing mental', 'discussing mental health', 'mental health disorder', 'health disorder final', 'disorder final subset', 'final subset data', 'subset data analyzed', 'data analyzed rmn', 'analyzed rmn composed', 'rmn composed unique', 'composed unique word', 'unique word post', 'word post comment']",,,,,,,,
