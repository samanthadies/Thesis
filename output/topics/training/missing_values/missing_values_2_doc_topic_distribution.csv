Link to paper,Score,Text,Cleaned,unigrams,bigrams,trigrams,topic1,topic2,topic3,topic4,topic5,topic6,topic7
https://link.springer.com/content/pdf/10.1140/epjds/s13688-017-0110-z.pdf,0,We employed several quality assurance measures in our data collection process to reduce noisy and unreliable data. Our surveys were only visible to MTurk crowdworkers who had completed at least  previous tasks with a minimum % approval rating; MTurk workers with this level of experience and approval rating have been found to provide reliable valid survey responses []. We also restricted access to only American IP addresses as MTurk data collected from outside the United States are generally of poorer quality []. All participants were only permitted to take the survey once. We excluded participants who had successfully completed our survey but who had a lifetime total of fewer than five Instagram posts. We also excluded participants with CESD scores of  or higher. Studies have indicated that a CES-D score of  represents an optimal cutoff for identifying clinically relevant depression across a range of age groups and circumstances [ ].,we employed several quality assurance measure in our data collection process to reduce noisy and unreliable data our survey were only visible to mturk crowdworkers who had completed at least previous task with a minimum approval rating mturk worker with this level of experience and approval rating have been found to provide reliable valid survey response we also restricted access to only american ip address a mturk data collected from outside the united state are generally of poorer quality all participant were only permitted to take the survey once we excluded participant who had successfully completed our survey but who had a lifetime total of fewer than five instagram post we also excluded participant with cesd score of or higher study have indicated that a cesd score of represents an optimal cutoff for identifying clinically relevant depression across a range of age group and circumstance,"['employed', 'several', 'quality', 'assurance', 'measure', 'data', 'collection', 'process', 'reduce', 'noisy', 'unreliable', 'data', 'survey', 'visible', 'mturk', 'crowdworkers', 'completed', 'least', 'previous', 'task', 'minimum', 'approval', 'rating', 'mturk', 'worker', 'level', 'experience', 'approval', 'rating', 'found', 'provide', 'reliable', 'valid', 'survey', 'response', 'also', 'restricted', 'access', 'american', 'ip', 'address', 'mturk', 'data', 'collected', 'outside', 'united', 'state', 'generally', 'poorer', 'quality', 'participant', 'permitted', 'take', 'survey', 'excluded', 'participant', 'successfully', 'completed', 'survey', 'lifetime', 'total', 'fewer', 'five', 'instagram', 'post', 'also', 'excluded', 'participant', 'cesd', 'score', 'higher', 'study', 'indicated', 'cesd', 'score', 'represents', 'optimal', 'cutoff', 'identifying', 'clinically', 'relevant', 'depression', 'across', 'range', 'age', 'group', 'circumstance']","['employed several', 'several quality', 'quality assurance', 'assurance measure', 'measure data', 'data collection', 'collection process', 'process reduce', 'reduce noisy', 'noisy unreliable', 'unreliable data', 'data survey', 'survey visible', 'visible mturk', 'mturk crowdworkers', 'crowdworkers completed', 'completed least', 'least previous', 'previous task', 'task minimum', 'minimum approval', 'approval rating', 'rating mturk', 'mturk worker', 'worker level', 'level experience', 'experience approval', 'approval rating', 'rating found', 'found provide', 'provide reliable', 'reliable valid', 'valid survey', 'survey response', 'response also', 'also restricted', 'restricted access', 'access american', 'american ip', 'ip address', 'address mturk', 'mturk data', 'data collected', 'collected outside', 'outside united', 'united state', 'state generally', 'generally poorer', 'poorer quality', 'quality participant', 'participant permitted', 'permitted take', 'take survey', 'survey excluded', 'excluded participant', 'participant successfully', 'successfully completed', 'completed survey', 'survey lifetime', 'lifetime total', 'total fewer', 'fewer five', 'five instagram', 'instagram post', 'post also', 'also excluded', 'excluded participant', 'participant cesd', 'cesd score', 'score higher', 'higher study', 'study indicated', 'indicated cesd', 'cesd score', 'score represents', 'represents optimal', 'optimal cutoff', 'cutoff identifying', 'identifying clinically', 'clinically relevant', 'relevant depression', 'depression across', 'across range', 'range age', 'age group', 'group circumstance']","['employed several quality', 'several quality assurance', 'quality assurance measure', 'assurance measure data', 'measure data collection', 'data collection process', 'collection process reduce', 'process reduce noisy', 'reduce noisy unreliable', 'noisy unreliable data', 'unreliable data survey', 'data survey visible', 'survey visible mturk', 'visible mturk crowdworkers', 'mturk crowdworkers completed', 'crowdworkers completed least', 'completed least previous', 'least previous task', 'previous task minimum', 'task minimum approval', 'minimum approval rating', 'approval rating mturk', 'rating mturk worker', 'mturk worker level', 'worker level experience', 'level experience approval', 'experience approval rating', 'approval rating found', 'rating found provide', 'found provide reliable', 'provide reliable valid', 'reliable valid survey', 'valid survey response', 'survey response also', 'response also restricted', 'also restricted access', 'restricted access american', 'access american ip', 'american ip address', 'ip address mturk', 'address mturk data', 'mturk data collected', 'data collected outside', 'collected outside united', 'outside united state', 'united state generally', 'state generally poorer', 'generally poorer quality', 'poorer quality participant', 'quality participant permitted', 'participant permitted take', 'permitted take survey', 'take survey excluded', 'survey excluded participant', 'excluded participant successfully', 'participant successfully completed', 'successfully completed survey', 'completed survey lifetime', 'survey lifetime total', 'lifetime total fewer', 'total fewer five', 'fewer five instagram', 'five instagram post', 'instagram post also', 'post also excluded', 'also excluded participant', 'excluded participant cesd', 'participant cesd score', 'cesd score higher', 'score higher study', 'higher study indicated', 'study indicated cesd', 'indicated cesd score', 'cesd score represents', 'score represents optimal', 'represents optimal cutoff', 'optimal cutoff identifying', 'cutoff identifying clinically', 'identifying clinically relevant', 'clinically relevant depression', 'relevant depression across', 'depression across range', 'across range age', 'range age group', 'age group circumstance']",,,,,,,
https://dl.acm.org/doi/abs/10.1145/2858036.2858207 ,0,We split our data into two sequential time periods (t1 from Feb 11 2014 to Aug 11 2014 and t2 from Aug 12 2014 to November 11 2014). Using these two time periods we created two sets of users. Note that since Reddit does not enforce the real name rule of having exactly one account per person our reference to “users” in this paper is equivalent to “user accounts”. First we identified those users that posted on MHs during t1 but did not post on SW during t1 or t2 (i.e. users that discuss mental health topics but not on SW; hereafter “MH”). The second class included those who posted on MHs during t1 and posted in SW during t2 (i.e. users that discuss mental health topics originally not related to suicide but eventually transition to talk about suicide; hereafter “MH → SW”). Figure 1 shows a schematic description of our user class construction. Note that by focusing on users that initiate at least one post on SW or the MHs as opposed to only commenting we can focus on those frequenting the communities for support disregarding those primarily providing help through commentary. This split yielded 440 MH → SW users; which is 1.52% of the total number of 28831 accounts who posted in MHs but never on SW during either of the periods. To construct a MH cohort of equal size who did not post on SW in either period we randomly sampled a set of 440 users from the 28831 users. Note although MH users did not post on SW during our timeframe of analysis they may have done so outside the bounds of our analysis. To support our goal of characterizing differences between the MH → SW and MH users we obtained via Reddit’s API the timeline of posts and comments authored by the 880 users (the API only provides the last 1000 public posts and comments for a user). For each post we obtained their associated metadata (e.g. vote difference or score) and comments. Our final dataset contained 4731 posts and 46949 comments from the 440 MH → SW users and 8318 posts and 54086 comments from the 440 MH users. We note an important concern: individuals may post suicidal thoughts on MHs never engaging on SW and thus “corrupting” the MHs data with discussions of suicidal ideation. We argue against this possibility. (1) SW is a prominent suicide support forum and the role of this community in suicide prevention and in acting as an inoculator of vulnerable thoughts is well-recognized [31]. (2) Most MHs (e.g. r/depression) clearly specify in their guidelines that suicidal thoughts should go to SW: “It’s usually better to post anything that specifically involves suicidal thoughts or intent in /r/SuicideWatch rather than here. If you’re concerned about someone else who may be at risk for suicide please check out their talking tips and risk assessment guide.” (3) Finally discussions with the moderators of SW confirmed that active steps are taken to move all suicidal ideation related content to SW. Given these considerations we expect that few suicidal ideation posts appear on subreddits outside of SW.We obtained post and comment data from a number of mental health subreddits (henceforth MHs) and a suicide support subreddit “r/SuicideWatch” (henceforth SW). We focused on a set of 14 MHs that have been examined in prior work on mental health discourse [51 39]. These subreddits included r/depression r/mentalhealth r/traumatoolbox r/bipolarreddit r/BPD r/ptsd r/psychoticreddit r/EatingDisorders r/StopSelfHarm r/survivorsofabuse r/rapecounseling r/hardshipmates r/panicparty r/socialanxiety. While SW solely focuses on helping those contemplating suicide the other MHs cover a variety of mental health concerns but not specifically suicidal ideation [31]. All of these subreddits host public content. We used Reddit’s official API to collect posts comments and associated metadata from the SW and MHs subreddits (http://www.reddit.com/dev/api). Our analysis in this paper is based on all content shared on MHs between February 11 and November 11 2014 (63485 posts 209766 comments and 35038 users). We refer to the data obtained from SW during the same time period (16348 posts 9224 users) to identify those individuals in MHs who go on to post on SW over time.Following our data collection we focused on verifying whether MHs and SW subreddit content actually relate to discussion of mental health concerns and suicidal ideation. The MHs have been previously examined for understanding mental health discourse on Reddit [51 39]. For SW we consulted (1) a licensed clinical psychologist/suicide prevention expert and (2) two active moderators of SW to obtain qualitative grounding that the content in SW indeed related to expressions of suicidal ideation. Example (paraphrased) titles of posts from one of the MHs and SW are given in Table 1.,we split our data into two sequential time period t from feb to aug and t from aug to november using these two time period we created two set of user note that since reddit doe not enforce the real name rule of having exactly one account per person our reference to user in this paper is equivalent to user account first we identified those user that posted on mhs during t but did not post on sw during t or t ie user that discus mental health topic but not on sw hereafter mh the second class included those who posted on mhs during t and posted in sw during t ie user that discus mental health topic originally not related to suicide but eventually transition to talk about suicide hereafter mh sw figure show a schematic description of our user class construction note that by focusing on user that initiate at least one post on sw or the mhs a opposed to only commenting we can focus on those frequenting the community for support disregarding those primarily providing help through commentary this split yielded mh sw user which is of the total number of account who posted in mhs but never on sw during either of the period to construct a mh cohort of equal size who did not post on sw in either period we randomly sampled a set of user from the user note although mh user did not post on sw during our timeframe of analysis they may have done so outside the bound of our analysis to support our goal of characterizing difference between the mh sw and mh user we obtained via reddits api the timeline of post and comment authored by the user the api only provides the last public post and comment for a user for each post we obtained their associated metadata eg vote difference or score and comment our final dataset contained post and comment from the mh sw user and post and comment from the mh user we note an important concern individual may post suicidal thought on mhs never engaging on sw and thus corrupting the mhs data with discussion of suicidal ideation we argue against this possibility sw is a prominent suicide support forum and the role of this community in suicide prevention and in acting a an inoculator of vulnerable thought is wellrecognized most mhs eg rdepression clearly specify in their guideline that suicidal thought should go to sw it usually better to post anything that specifically involves suicidal thought or intent in rsuicidewatch rather than here if youre concerned about someone else who may be at risk for suicide please check out their talking tip and risk assessment guide finally discussion with the moderator of sw confirmed that active step are taken to move all suicidal ideation related content to sw given these consideration we expect that few suicidal ideation post appear on subreddits outside of swwe obtained post and comment data from a number of mental health subreddits henceforth mhs and a suicide support subreddit rsuicidewatch henceforth sw we focused on a set of mhs that have been examined in prior work on mental health discourse these subreddits included rdepression rmentalhealth rtraumatoolbox rbipolarreddit rbpd rptsd rpsychoticreddit reatingdisorders rstopselfharm rsurvivorsofabuse rrapecounseling rhardshipmates rpanicparty rsocialanxiety while sw solely focus on helping those contemplating suicide the other mhs cover a variety of mental health concern but not specifically suicidal ideation all of these subreddits host public content we used reddits official api to collect post comment and associated metadata from the sw and mhs subreddits httpwwwredditcomdevapi our analysis in this paper is based on all content shared on mhs between february and november post comment and user we refer to the data obtained from sw during the same time period post user to identify those individual in mhs who go on to post on sw over timefollowing our data collection we focused on verifying whether mhs and sw subreddit content actually relate to discussion of mental health concern and suicidal ideation the mhs have been previously examined for understanding mental health discourse on reddit for sw we consulted a licensed clinical psychologistsuicide prevention expert and two active moderator of sw to obtain qualitative grounding that the content in sw indeed related to expression of suicidal ideation example paraphrased title of post from one of the mhs and sw are given in table,"['split', 'data', 'two', 'sequential', 'time', 'period', 'feb', 'aug', 'aug', 'november', 'using', 'two', 'time', 'period', 'created', 'two', 'set', 'user', 'note', 'since', 'reddit', 'doe', 'enforce', 'real', 'name', 'rule', 'exactly', 'one', 'account', 'per', 'person', 'reference', 'user', 'paper', 'equivalent', 'user', 'account', 'first', 'identified', 'user', 'posted', 'mhs', 'post', 'sw', 'ie', 'user', 'discus', 'mental', 'health', 'topic', 'sw', 'hereafter', 'mh', 'second', 'class', 'included', 'posted', 'mhs', 'posted', 'sw', 'ie', 'user', 'discus', 'mental', 'health', 'topic', 'originally', 'related', 'suicide', 'eventually', 'transition', 'talk', 'suicide', 'hereafter', 'mh', 'sw', 'figure', 'show', 'schematic', 'description', 'user', 'class', 'construction', 'note', 'focusing', 'user', 'initiate', 'least', 'one', 'post', 'sw', 'mhs', 'opposed', 'commenting', 'focus', 'frequenting', 'community', 'support', 'disregarding', 'primarily', 'providing', 'help', 'commentary', 'split', 'yielded', 'mh', 'sw', 'user', 'total', 'number', 'account', 'posted', 'mhs', 'never', 'sw', 'either', 'period', 'construct', 'mh', 'cohort', 'equal', 'size', 'post', 'sw', 'either', 'period', 'randomly', 'sampled', 'set', 'user', 'user', 'note', 'although', 'mh', 'user', 'post', 'sw', 'timeframe', 'analysis', 'may', 'done', 'outside', 'bound', 'analysis', 'support', 'goal', 'characterizing', 'difference', 'mh', 'sw', 'mh', 'user', 'obtained', 'via', 'reddits', 'api', 'timeline', 'post', 'comment', 'authored', 'user', 'api', 'provides', 'last', 'public', 'post', 'comment', 'user', 'post', 'obtained', 'associated', 'metadata', 'eg', 'vote', 'difference', 'score', 'comment', 'final', 'dataset', 'contained', 'post', 'comment', 'mh', 'sw', 'user', 'post', 'comment', 'mh', 'user', 'note', 'important', 'concern', 'individual', 'may', 'post', 'suicidal', 'thought', 'mhs', 'never', 'engaging', 'sw', 'thus', 'corrupting', 'mhs', 'data', 'discussion', 'suicidal', 'ideation', 'argue', 'possibility', 'sw', 'prominent', 'suicide', 'support', 'forum', 'role', 'community', 'suicide', 'prevention', 'acting', 'inoculator', 'vulnerable', 'thought', 'wellrecognized', 'mhs', 'eg', 'rdepression', 'clearly', 'specify', 'guideline', 'suicidal', 'thought', 'go', 'sw', 'usually', 'better', 'post', 'anything', 'specifically', 'involves', 'suicidal', 'thought', 'intent', 'rsuicidewatch', 'rather', 'youre', 'concerned', 'someone', 'else', 'may', 'risk', 'suicide', 'please', 'check', 'talking', 'tip', 'risk', 'assessment', 'guide', 'finally', 'discussion', 'moderator', 'sw', 'confirmed', 'active', 'step', 'taken', 'move', 'suicidal', 'ideation', 'related', 'content', 'sw', 'given', 'consideration', 'expect', 'suicidal', 'ideation', 'post', 'appear', 'subreddits', 'outside', 'swwe', 'obtained', 'post', 'comment', 'data', 'number', 'mental', 'health', 'subreddits', 'henceforth', 'mhs', 'suicide', 'support', 'subreddit', 'rsuicidewatch', 'henceforth', 'sw', 'focused', 'set', 'mhs', 'examined', 'prior', 'work', 'mental', 'health', 'discourse', 'subreddits', 'included', 'rdepression', 'rmentalhealth', 'rtraumatoolbox', 'rbipolarreddit', 'rbpd', 'rptsd', 'rpsychoticreddit', 'reatingdisorders', 'rstopselfharm', 'rsurvivorsofabuse', 'rrapecounseling', 'rhardshipmates', 'rpanicparty', 'rsocialanxiety', 'sw', 'solely', 'focus', 'helping', 'contemplating', 'suicide', 'mhs', 'cover', 'variety', 'mental', 'health', 'concern', 'specifically', 'suicidal', 'ideation', 'subreddits', 'host', 'public', 'content', 'used', 'reddits', 'official', 'api', 'collect', 'post', 'comment', 'associated', 'metadata', 'sw', 'mhs', 'subreddits', 'httpwwwredditcomdevapi', 'analysis', 'paper', 'based', 'content', 'shared', 'mhs', 'february', 'november', 'post', 'comment', 'user', 'refer', 'data', 'obtained', 'sw', 'time', 'period', 'post', 'user', 'identify', 'individual', 'mhs', 'go', 'post', 'sw', 'timefollowing', 'data', 'collection', 'focused', 'verifying', 'whether', 'mhs', 'sw', 'subreddit', 'content', 'actually', 'relate', 'discussion', 'mental', 'health', 'concern', 'suicidal', 'ideation', 'mhs', 'previously', 'examined', 'understanding', 'mental', 'health', 'discourse', 'reddit', 'sw', 'consulted', 'licensed', 'clinical', 'psychologistsuicide', 'prevention', 'expert', 'two', 'active', 'moderator', 'sw', 'obtain', 'qualitative', 'grounding', 'content', 'sw', 'indeed', 'related', 'expression', 'suicidal', 'ideation', 'example', 'paraphrased', 'title', 'post', 'one', 'mhs', 'sw', 'given', 'table']","['split data', 'data two', 'two sequential', 'sequential time', 'time period', 'period feb', 'feb aug', 'aug aug', 'aug november', 'november using', 'using two', 'two time', 'time period', 'period created', 'created two', 'two set', 'set user', 'user note', 'note since', 'since reddit', 'reddit doe', 'doe enforce', 'enforce real', 'real name', 'name rule', 'rule exactly', 'exactly one', 'one account', 'account per', 'per person', 'person reference', 'reference user', 'user paper', 'paper equivalent', 'equivalent user', 'user account', 'account first', 'first identified', 'identified user', 'user posted', 'posted mhs', 'mhs post', 'post sw', 'sw ie', 'ie user', 'user discus', 'discus mental', 'mental health', 'health topic', 'topic sw', 'sw hereafter', 'hereafter mh', 'mh second', 'second class', 'class included', 'included posted', 'posted mhs', 'mhs posted', 'posted sw', 'sw ie', 'ie user', 'user discus', 'discus mental', 'mental health', 'health topic', 'topic originally', 'originally related', 'related suicide', 'suicide eventually', 'eventually transition', 'transition talk', 'talk suicide', 'suicide hereafter', 'hereafter mh', 'mh sw', 'sw figure', 'figure show', 'show schematic', 'schematic description', 'description user', 'user class', 'class construction', 'construction note', 'note focusing', 'focusing user', 'user initiate', 'initiate least', 'least one', 'one post', 'post sw', 'sw mhs', 'mhs opposed', 'opposed commenting', 'commenting focus', 'focus frequenting', 'frequenting community', 'community support', 'support disregarding', 'disregarding primarily', 'primarily providing', 'providing help', 'help commentary', 'commentary split', 'split yielded', 'yielded mh', 'mh sw', 'sw user', 'user total', 'total number', 'number account', 'account posted', 'posted mhs', 'mhs never', 'never sw', 'sw either', 'either period', 'period construct', 'construct mh', 'mh cohort', 'cohort equal', 'equal size', 'size post', 'post sw', 'sw either', 'either period', 'period randomly', 'randomly sampled', 'sampled set', 'set user', 'user user', 'user note', 'note although', 'although mh', 'mh user', 'user post', 'post sw', 'sw timeframe', 'timeframe analysis', 'analysis may', 'may done', 'done outside', 'outside bound', 'bound analysis', 'analysis support', 'support goal', 'goal characterizing', 'characterizing difference', 'difference mh', 'mh sw', 'sw mh', 'mh user', 'user obtained', 'obtained via', 'via reddits', 'reddits api', 'api timeline', 'timeline post', 'post comment', 'comment authored', 'authored user', 'user api', 'api provides', 'provides last', 'last public', 'public post', 'post comment', 'comment user', 'user post', 'post obtained', 'obtained associated', 'associated metadata', 'metadata eg', 'eg vote', 'vote difference', 'difference score', 'score comment', 'comment final', 'final dataset', 'dataset contained', 'contained post', 'post comment', 'comment mh', 'mh sw', 'sw user', 'user post', 'post comment', 'comment mh', 'mh user', 'user note', 'note important', 'important concern', 'concern individual', 'individual may', 'may post', 'post suicidal', 'suicidal thought', 'thought mhs', 'mhs never', 'never engaging', 'engaging sw', 'sw thus', 'thus corrupting', 'corrupting mhs', 'mhs data', 'data discussion', 'discussion suicidal', 'suicidal ideation', 'ideation argue', 'argue possibility', 'possibility sw', 'sw prominent', 'prominent suicide', 'suicide support', 'support forum', 'forum role', 'role community', 'community suicide', 'suicide prevention', 'prevention acting', 'acting inoculator', 'inoculator vulnerable', 'vulnerable thought', 'thought wellrecognized', 'wellrecognized mhs', 'mhs eg', 'eg rdepression', 'rdepression clearly', 'clearly specify', 'specify guideline', 'guideline suicidal', 'suicidal thought', 'thought go', 'go sw', 'sw usually', 'usually better', 'better post', 'post anything', 'anything specifically', 'specifically involves', 'involves suicidal', 'suicidal thought', 'thought intent', 'intent rsuicidewatch', 'rsuicidewatch rather', 'rather youre', 'youre concerned', 'concerned someone', 'someone else', 'else may', 'may risk', 'risk suicide', 'suicide please', 'please check', 'check talking', 'talking tip', 'tip risk', 'risk assessment', 'assessment guide', 'guide finally', 'finally discussion', 'discussion moderator', 'moderator sw', 'sw confirmed', 'confirmed active', 'active step', 'step taken', 'taken move', 'move suicidal', 'suicidal ideation', 'ideation related', 'related content', 'content sw', 'sw given', 'given consideration', 'consideration expect', 'expect suicidal', 'suicidal ideation', 'ideation post', 'post appear', 'appear subreddits', 'subreddits outside', 'outside swwe', 'swwe obtained', 'obtained post', 'post comment', 'comment data', 'data number', 'number mental', 'mental health', 'health subreddits', 'subreddits henceforth', 'henceforth mhs', 'mhs suicide', 'suicide support', 'support subreddit', 'subreddit rsuicidewatch', 'rsuicidewatch henceforth', 'henceforth sw', 'sw focused', 'focused set', 'set mhs', 'mhs examined', 'examined prior', 'prior work', 'work mental', 'mental health', 'health discourse', 'discourse subreddits', 'subreddits included', 'included rdepression', 'rdepression rmentalhealth', 'rmentalhealth rtraumatoolbox', 'rtraumatoolbox rbipolarreddit', 'rbipolarreddit rbpd', 'rbpd rptsd', 'rptsd rpsychoticreddit', 'rpsychoticreddit reatingdisorders', 'reatingdisorders rstopselfharm', 'rstopselfharm rsurvivorsofabuse', 'rsurvivorsofabuse rrapecounseling', 'rrapecounseling rhardshipmates', 'rhardshipmates rpanicparty', 'rpanicparty rsocialanxiety', 'rsocialanxiety sw', 'sw solely', 'solely focus', 'focus helping', 'helping contemplating', 'contemplating suicide', 'suicide mhs', 'mhs cover', 'cover variety', 'variety mental', 'mental health', 'health concern', 'concern specifically', 'specifically suicidal', 'suicidal ideation', 'ideation subreddits', 'subreddits host', 'host public', 'public content', 'content used', 'used reddits', 'reddits official', 'official api', 'api collect', 'collect post', 'post comment', 'comment associated', 'associated metadata', 'metadata sw', 'sw mhs', 'mhs subreddits', 'subreddits httpwwwredditcomdevapi', 'httpwwwredditcomdevapi analysis', 'analysis paper', 'paper based', 'based content', 'content shared', 'shared mhs', 'mhs february', 'february november', 'november post', 'post comment', 'comment user', 'user refer', 'refer data', 'data obtained', 'obtained sw', 'sw time', 'time period', 'period post', 'post user', 'user identify', 'identify individual', 'individual mhs', 'mhs go', 'go post', 'post sw', 'sw timefollowing', 'timefollowing data', 'data collection', 'collection focused', 'focused verifying', 'verifying whether', 'whether mhs', 'mhs sw', 'sw subreddit', 'subreddit content', 'content actually', 'actually relate', 'relate discussion', 'discussion mental', 'mental health', 'health concern', 'concern suicidal', 'suicidal ideation', 'ideation mhs', 'mhs previously', 'previously examined', 'examined understanding', 'understanding mental', 'mental health', 'health discourse', 'discourse reddit', 'reddit sw', 'sw consulted', 'consulted licensed', 'licensed clinical', 'clinical psychologistsuicide', 'psychologistsuicide prevention', 'prevention expert', 'expert two', 'two active', 'active moderator', 'moderator sw', 'sw obtain', 'obtain qualitative', 'qualitative grounding', 'grounding content', 'content sw', 'sw indeed', 'indeed related', 'related expression', 'expression suicidal', 'suicidal ideation', 'ideation example', 'example paraphrased', 'paraphrased title', 'title post', 'post one', 'one mhs', 'mhs sw', 'sw given', 'given table']","['split data two', 'data two sequential', 'two sequential time', 'sequential time period', 'time period feb', 'period feb aug', 'feb aug aug', 'aug aug november', 'aug november using', 'november using two', 'using two time', 'two time period', 'time period created', 'period created two', 'created two set', 'two set user', 'set user note', 'user note since', 'note since reddit', 'since reddit doe', 'reddit doe enforce', 'doe enforce real', 'enforce real name', 'real name rule', 'name rule exactly', 'rule exactly one', 'exactly one account', 'one account per', 'account per person', 'per person reference', 'person reference user', 'reference user paper', 'user paper equivalent', 'paper equivalent user', 'equivalent user account', 'user account first', 'account first identified', 'first identified user', 'identified user posted', 'user posted mhs', 'posted mhs post', 'mhs post sw', 'post sw ie', 'sw ie user', 'ie user discus', 'user discus mental', 'discus mental health', 'mental health topic', 'health topic sw', 'topic sw hereafter', 'sw hereafter mh', 'hereafter mh second', 'mh second class', 'second class included', 'class included posted', 'included posted mhs', 'posted mhs posted', 'mhs posted sw', 'posted sw ie', 'sw ie user', 'ie user discus', 'user discus mental', 'discus mental health', 'mental health topic', 'health topic originally', 'topic originally related', 'originally related suicide', 'related suicide eventually', 'suicide eventually transition', 'eventually transition talk', 'transition talk suicide', 'talk suicide hereafter', 'suicide hereafter mh', 'hereafter mh sw', 'mh sw figure', 'sw figure show', 'figure show schematic', 'show schematic description', 'schematic description user', 'description user class', 'user class construction', 'class construction note', 'construction note focusing', 'note focusing user', 'focusing user initiate', 'user initiate least', 'initiate least one', 'least one post', 'one post sw', 'post sw mhs', 'sw mhs opposed', 'mhs opposed commenting', 'opposed commenting focus', 'commenting focus frequenting', 'focus frequenting community', 'frequenting community support', 'community support disregarding', 'support disregarding primarily', 'disregarding primarily providing', 'primarily providing help', 'providing help commentary', 'help commentary split', 'commentary split yielded', 'split yielded mh', 'yielded mh sw', 'mh sw user', 'sw user total', 'user total number', 'total number account', 'number account posted', 'account posted mhs', 'posted mhs never', 'mhs never sw', 'never sw either', 'sw either period', 'either period construct', 'period construct mh', 'construct mh cohort', 'mh cohort equal', 'cohort equal size', 'equal size post', 'size post sw', 'post sw either', 'sw either period', 'either period randomly', 'period randomly sampled', 'randomly sampled set', 'sampled set user', 'set user user', 'user user note', 'user note although', 'note although mh', 'although mh user', 'mh user post', 'user post sw', 'post sw timeframe', 'sw timeframe analysis', 'timeframe analysis may', 'analysis may done', 'may done outside', 'done outside bound', 'outside bound analysis', 'bound analysis support', 'analysis support goal', 'support goal characterizing', 'goal characterizing difference', 'characterizing difference mh', 'difference mh sw', 'mh sw mh', 'sw mh user', 'mh user obtained', 'user obtained via', 'obtained via reddits', 'via reddits api', 'reddits api timeline', 'api timeline post', 'timeline post comment', 'post comment authored', 'comment authored user', 'authored user api', 'user api provides', 'api provides last', 'provides last public', 'last public post', 'public post comment', 'post comment user', 'comment user post', 'user post obtained', 'post obtained associated', 'obtained associated metadata', 'associated metadata eg', 'metadata eg vote', 'eg vote difference', 'vote difference score', 'difference score comment', 'score comment final', 'comment final dataset', 'final dataset contained', 'dataset contained post', 'contained post comment', 'post comment mh', 'comment mh sw', 'mh sw user', 'sw user post', 'user post comment', 'post comment mh', 'comment mh user', 'mh user note', 'user note important', 'note important concern', 'important concern individual', 'concern individual may', 'individual may post', 'may post suicidal', 'post suicidal thought', 'suicidal thought mhs', 'thought mhs never', 'mhs never engaging', 'never engaging sw', 'engaging sw thus', 'sw thus corrupting', 'thus corrupting mhs', 'corrupting mhs data', 'mhs data discussion', 'data discussion suicidal', 'discussion suicidal ideation', 'suicidal ideation argue', 'ideation argue possibility', 'argue possibility sw', 'possibility sw prominent', 'sw prominent suicide', 'prominent suicide support', 'suicide support forum', 'support forum role', 'forum role community', 'role community suicide', 'community suicide prevention', 'suicide prevention acting', 'prevention acting inoculator', 'acting inoculator vulnerable', 'inoculator vulnerable thought', 'vulnerable thought wellrecognized', 'thought wellrecognized mhs', 'wellrecognized mhs eg', 'mhs eg rdepression', 'eg rdepression clearly', 'rdepression clearly specify', 'clearly specify guideline', 'specify guideline suicidal', 'guideline suicidal thought', 'suicidal thought go', 'thought go sw', 'go sw usually', 'sw usually better', 'usually better post', 'better post anything', 'post anything specifically', 'anything specifically involves', 'specifically involves suicidal', 'involves suicidal thought', 'suicidal thought intent', 'thought intent rsuicidewatch', 'intent rsuicidewatch rather', 'rsuicidewatch rather youre', 'rather youre concerned', 'youre concerned someone', 'concerned someone else', 'someone else may', 'else may risk', 'may risk suicide', 'risk suicide please', 'suicide please check', 'please check talking', 'check talking tip', 'talking tip risk', 'tip risk assessment', 'risk assessment guide', 'assessment guide finally', 'guide finally discussion', 'finally discussion moderator', 'discussion moderator sw', 'moderator sw confirmed', 'sw confirmed active', 'confirmed active step', 'active step taken', 'step taken move', 'taken move suicidal', 'move suicidal ideation', 'suicidal ideation related', 'ideation related content', 'related content sw', 'content sw given', 'sw given consideration', 'given consideration expect', 'consideration expect suicidal', 'expect suicidal ideation', 'suicidal ideation post', 'ideation post appear', 'post appear subreddits', 'appear subreddits outside', 'subreddits outside swwe', 'outside swwe obtained', 'swwe obtained post', 'obtained post comment', 'post comment data', 'comment data number', 'data number mental', 'number mental health', 'mental health subreddits', 'health subreddits henceforth', 'subreddits henceforth mhs', 'henceforth mhs suicide', 'mhs suicide support', 'suicide support subreddit', 'support subreddit rsuicidewatch', 'subreddit rsuicidewatch henceforth', 'rsuicidewatch henceforth sw', 'henceforth sw focused', 'sw focused set', 'focused set mhs', 'set mhs examined', 'mhs examined prior', 'examined prior work', 'prior work mental', 'work mental health', 'mental health discourse', 'health discourse subreddits', 'discourse subreddits included', 'subreddits included rdepression', 'included rdepression rmentalhealth', 'rdepression rmentalhealth rtraumatoolbox', 'rmentalhealth rtraumatoolbox rbipolarreddit', 'rtraumatoolbox rbipolarreddit rbpd', 'rbipolarreddit rbpd rptsd', 'rbpd rptsd rpsychoticreddit', 'rptsd rpsychoticreddit reatingdisorders', 'rpsychoticreddit reatingdisorders rstopselfharm', 'reatingdisorders rstopselfharm rsurvivorsofabuse', 'rstopselfharm rsurvivorsofabuse rrapecounseling', 'rsurvivorsofabuse rrapecounseling rhardshipmates', 'rrapecounseling rhardshipmates rpanicparty', 'rhardshipmates rpanicparty rsocialanxiety', 'rpanicparty rsocialanxiety sw', 'rsocialanxiety sw solely', 'sw solely focus', 'solely focus helping', 'focus helping contemplating', 'helping contemplating suicide', 'contemplating suicide mhs', 'suicide mhs cover', 'mhs cover variety', 'cover variety mental', 'variety mental health', 'mental health concern', 'health concern specifically', 'concern specifically suicidal', 'specifically suicidal ideation', 'suicidal ideation subreddits', 'ideation subreddits host', 'subreddits host public', 'host public content', 'public content used', 'content used reddits', 'used reddits official', 'reddits official api', 'official api collect', 'api collect post', 'collect post comment', 'post comment associated', 'comment associated metadata', 'associated metadata sw', 'metadata sw mhs', 'sw mhs subreddits', 'mhs subreddits httpwwwredditcomdevapi', 'subreddits httpwwwredditcomdevapi analysis', 'httpwwwredditcomdevapi analysis paper', 'analysis paper based', 'paper based content', 'based content shared', 'content shared mhs', 'shared mhs february', 'mhs february november', 'february november post', 'november post comment', 'post comment user', 'comment user refer', 'user refer data', 'refer data obtained', 'data obtained sw', 'obtained sw time', 'sw time period', 'time period post', 'period post user', 'post user identify', 'user identify individual', 'identify individual mhs', 'individual mhs go', 'mhs go post', 'go post sw', 'post sw timefollowing', 'sw timefollowing data', 'timefollowing data collection', 'data collection focused', 'collection focused verifying', 'focused verifying whether', 'verifying whether mhs', 'whether mhs sw', 'mhs sw subreddit', 'sw subreddit content', 'subreddit content actually', 'content actually relate', 'actually relate discussion', 'relate discussion mental', 'discussion mental health', 'mental health concern', 'health concern suicidal', 'concern suicidal ideation', 'suicidal ideation mhs', 'ideation mhs previously', 'mhs previously examined', 'previously examined understanding', 'examined understanding mental', 'understanding mental health', 'mental health discourse', 'health discourse reddit', 'discourse reddit sw', 'reddit sw consulted', 'sw consulted licensed', 'consulted licensed clinical', 'licensed clinical psychologistsuicide', 'clinical psychologistsuicide prevention', 'psychologistsuicide prevention expert', 'prevention expert two', 'expert two active', 'two active moderator', 'active moderator sw', 'moderator sw obtain', 'sw obtain qualitative', 'obtain qualitative grounding', 'qualitative grounding content', 'grounding content sw', 'content sw indeed', 'sw indeed related', 'indeed related expression', 'related expression suicidal', 'expression suicidal ideation', 'suicidal ideation example', 'ideation example paraphrased', 'example paraphrased title', 'paraphrased title post', 'title post one', 'post one mhs', 'one mhs sw', 'mhs sw given', 'sw given table']",,,,,,,
https://dl.acm.org/doi/abs/10.1145/2702613.2732733,0,Based on the training data thus created we pursued the use of supervised learning to develop a classifier which would indicate whether a post is of high low or no self-disclosure. We tested a variety of different classification techniques (decision trees k Nearest Neighbor naive Bayes). The best performing classifier was found to be a perceptron classifier with adaptive boosting used to amplify performance [17] whose results will be used in the remainder of this paper. We used the following feature generation rules: First we eliminated stopwords from each post based on standard list provided by Python’s NLTK library. Next we performed stemming using Porter Stemmer. We extracted uni- bi- and tri-grams from each post and considered those with five or more occurrences. We also computed two additional features – length of each post and whether the author of the post is an exclusive poster on mental health forums or is observed in our dataset to post on other forums as well. Thus each post was characterized by 1070 features. We used standard 10-fold cross validation (CV) to evaluate the classifier and ran our model over 100 random 10-fold CV assignments for generalizability of the results. We report the average accuracy precision recall F1 specificity as metrics of performance. We find that our classifier based on the perception model yields an average accuracy of 78.4% in detecting high or low self-disclosure with .74 precision and .86 recall (see Table 4 for details). Other methods like k-NN (k=5) give higher precision but at the expense of very low recall. Figure 1 gives the ROC (receiver operating characteristic) curves for all the models. Per the ROC curve corresponding to the perceptron model we find it to yield the maximum area under curve (.81) hence best performance. We further identify in Table 5 the n-grams (or features) with the highest weights given by the perceptron – it implies these features were the most significant in the classification task. We provide some brief qualitative examinations of these n-grams in the light of prior psychology literature on selfdisclosure and mental health [10 11]. We find that the ngrams primarily are associated with vulnerable and selfloathing thoughts (e.g. thoughts of suicide) bear a negative tone or depict confessional experiences. Based on prior research [10 11 12] and our own work on mental health discourse on Reddit [4] we find that these are the topical dimensions along which high self-disclosure and low/no selfdisclosure posts vary. In essence high self-disclosure posts share extensively their personal beliefs and fear for instance their vital constructs and private sensitive informational attributes. The post excerpts below have been classified to be of high self-disclosure and through them we demonstrate the use of some of the n-grams in Table 7:,based on the training data thus created we pursued the use of supervised learning to develop a classifier which would indicate whether a post is of high low or no selfdisclosure we tested a variety of different classification technique decision tree k nearest neighbor naive bayes the best performing classifier wa found to be a perceptron classifier with adaptive boosting used to amplify performance whose result will be used in the remainder of this paper we used the following feature generation rule first we eliminated stopwords from each post based on standard list provided by python nltk library next we performed stemming using porter stemmer we extracted uni bi and trigram from each post and considered those with five or more occurrence we also computed two additional feature length of each post and whether the author of the post is an exclusive poster on mental health forum or is observed in our dataset to post on other forum a well thus each post wa characterized by feature we used standard fold cross validation cv to evaluate the classifier and ran our model over random fold cv assignment for generalizability of the result we report the average accuracy precision recall f specificity a metric of performance we find that our classifier based on the perception model yield an average accuracy of in detecting high or low selfdisclosure with precision and recall see table for detail other method like knn k give higher precision but at the expense of very low recall figure give the roc receiver operating characteristic curve for all the model per the roc curve corresponding to the perceptron model we find it to yield the maximum area under curve hence best performance we further identify in table the ngrams or feature with the highest weight given by the perceptron it implies these feature were the most significant in the classification task we provide some brief qualitative examination of these ngrams in the light of prior psychology literature on selfdisclosure and mental health we find that the ngrams primarily are associated with vulnerable and selfloathing thought eg thought of suicide bear a negative tone or depict confessional experience based on prior research and our own work on mental health discourse on reddit we find that these are the topical dimension along which high selfdisclosure and lowno selfdisclosure post vary in essence high selfdisclosure post share extensively their personal belief and fear for instance their vital construct and private sensitive informational attribute the post excerpt below have been classified to be of high selfdisclosure and through them we demonstrate the use of some of the ngrams in table,"['based', 'training', 'data', 'thus', 'created', 'pursued', 'use', 'supervised', 'learning', 'develop', 'classifier', 'would', 'indicate', 'whether', 'post', 'high', 'low', 'selfdisclosure', 'tested', 'variety', 'different', 'classification', 'technique', 'decision', 'tree', 'k', 'nearest', 'neighbor', 'naive', 'bayes', 'best', 'performing', 'classifier', 'wa', 'found', 'perceptron', 'classifier', 'adaptive', 'boosting', 'used', 'amplify', 'performance', 'whose', 'result', 'used', 'remainder', 'paper', 'used', 'following', 'feature', 'generation', 'rule', 'first', 'eliminated', 'stopwords', 'post', 'based', 'standard', 'list', 'provided', 'python', 'nltk', 'library', 'next', 'performed', 'stemming', 'using', 'porter', 'stemmer', 'extracted', 'uni', 'bi', 'trigram', 'post', 'considered', 'five', 'occurrence', 'also', 'computed', 'two', 'additional', 'feature', 'length', 'post', 'whether', 'author', 'post', 'exclusive', 'poster', 'mental', 'health', 'forum', 'observed', 'dataset', 'post', 'forum', 'well', 'thus', 'post', 'wa', 'characterized', 'feature', 'used', 'standard', 'fold', 'cross', 'validation', 'cv', 'evaluate', 'classifier', 'ran', 'model', 'random', 'fold', 'cv', 'assignment', 'generalizability', 'result', 'report', 'average', 'accuracy', 'precision', 'recall', 'f', 'specificity', 'metric', 'performance', 'find', 'classifier', 'based', 'perception', 'model', 'yield', 'average', 'accuracy', 'detecting', 'high', 'low', 'selfdisclosure', 'precision', 'recall', 'see', 'table', 'detail', 'method', 'like', 'knn', 'k', 'give', 'higher', 'precision', 'expense', 'low', 'recall', 'figure', 'give', 'roc', 'receiver', 'operating', 'characteristic', 'curve', 'model', 'per', 'roc', 'curve', 'corresponding', 'perceptron', 'model', 'find', 'yield', 'maximum', 'area', 'curve', 'hence', 'best', 'performance', 'identify', 'table', 'ngrams', 'feature', 'highest', 'weight', 'given', 'perceptron', 'implies', 'feature', 'significant', 'classification', 'task', 'provide', 'brief', 'qualitative', 'examination', 'ngrams', 'light', 'prior', 'psychology', 'literature', 'selfdisclosure', 'mental', 'health', 'find', 'ngrams', 'primarily', 'associated', 'vulnerable', 'selfloathing', 'thought', 'eg', 'thought', 'suicide', 'bear', 'negative', 'tone', 'depict', 'confessional', 'experience', 'based', 'prior', 'research', 'work', 'mental', 'health', 'discourse', 'reddit', 'find', 'topical', 'dimension', 'along', 'high', 'selfdisclosure', 'lowno', 'selfdisclosure', 'post', 'vary', 'essence', 'high', 'selfdisclosure', 'post', 'share', 'extensively', 'personal', 'belief', 'fear', 'instance', 'vital', 'construct', 'private', 'sensitive', 'informational', 'attribute', 'post', 'excerpt', 'classified', 'high', 'selfdisclosure', 'demonstrate', 'use', 'ngrams', 'table']","['based training', 'training data', 'data thus', 'thus created', 'created pursued', 'pursued use', 'use supervised', 'supervised learning', 'learning develop', 'develop classifier', 'classifier would', 'would indicate', 'indicate whether', 'whether post', 'post high', 'high low', 'low selfdisclosure', 'selfdisclosure tested', 'tested variety', 'variety different', 'different classification', 'classification technique', 'technique decision', 'decision tree', 'tree k', 'k nearest', 'nearest neighbor', 'neighbor naive', 'naive bayes', 'bayes best', 'best performing', 'performing classifier', 'classifier wa', 'wa found', 'found perceptron', 'perceptron classifier', 'classifier adaptive', 'adaptive boosting', 'boosting used', 'used amplify', 'amplify performance', 'performance whose', 'whose result', 'result used', 'used remainder', 'remainder paper', 'paper used', 'used following', 'following feature', 'feature generation', 'generation rule', 'rule first', 'first eliminated', 'eliminated stopwords', 'stopwords post', 'post based', 'based standard', 'standard list', 'list provided', 'provided python', 'python nltk', 'nltk library', 'library next', 'next performed', 'performed stemming', 'stemming using', 'using porter', 'porter stemmer', 'stemmer extracted', 'extracted uni', 'uni bi', 'bi trigram', 'trigram post', 'post considered', 'considered five', 'five occurrence', 'occurrence also', 'also computed', 'computed two', 'two additional', 'additional feature', 'feature length', 'length post', 'post whether', 'whether author', 'author post', 'post exclusive', 'exclusive poster', 'poster mental', 'mental health', 'health forum', 'forum observed', 'observed dataset', 'dataset post', 'post forum', 'forum well', 'well thus', 'thus post', 'post wa', 'wa characterized', 'characterized feature', 'feature used', 'used standard', 'standard fold', 'fold cross', 'cross validation', 'validation cv', 'cv evaluate', 'evaluate classifier', 'classifier ran', 'ran model', 'model random', 'random fold', 'fold cv', 'cv assignment', 'assignment generalizability', 'generalizability result', 'result report', 'report average', 'average accuracy', 'accuracy precision', 'precision recall', 'recall f', 'f specificity', 'specificity metric', 'metric performance', 'performance find', 'find classifier', 'classifier based', 'based perception', 'perception model', 'model yield', 'yield average', 'average accuracy', 'accuracy detecting', 'detecting high', 'high low', 'low selfdisclosure', 'selfdisclosure precision', 'precision recall', 'recall see', 'see table', 'table detail', 'detail method', 'method like', 'like knn', 'knn k', 'k give', 'give higher', 'higher precision', 'precision expense', 'expense low', 'low recall', 'recall figure', 'figure give', 'give roc', 'roc receiver', 'receiver operating', 'operating characteristic', 'characteristic curve', 'curve model', 'model per', 'per roc', 'roc curve', 'curve corresponding', 'corresponding perceptron', 'perceptron model', 'model find', 'find yield', 'yield maximum', 'maximum area', 'area curve', 'curve hence', 'hence best', 'best performance', 'performance identify', 'identify table', 'table ngrams', 'ngrams feature', 'feature highest', 'highest weight', 'weight given', 'given perceptron', 'perceptron implies', 'implies feature', 'feature significant', 'significant classification', 'classification task', 'task provide', 'provide brief', 'brief qualitative', 'qualitative examination', 'examination ngrams', 'ngrams light', 'light prior', 'prior psychology', 'psychology literature', 'literature selfdisclosure', 'selfdisclosure mental', 'mental health', 'health find', 'find ngrams', 'ngrams primarily', 'primarily associated', 'associated vulnerable', 'vulnerable selfloathing', 'selfloathing thought', 'thought eg', 'eg thought', 'thought suicide', 'suicide bear', 'bear negative', 'negative tone', 'tone depict', 'depict confessional', 'confessional experience', 'experience based', 'based prior', 'prior research', 'research work', 'work mental', 'mental health', 'health discourse', 'discourse reddit', 'reddit find', 'find topical', 'topical dimension', 'dimension along', 'along high', 'high selfdisclosure', 'selfdisclosure lowno', 'lowno selfdisclosure', 'selfdisclosure post', 'post vary', 'vary essence', 'essence high', 'high selfdisclosure', 'selfdisclosure post', 'post share', 'share extensively', 'extensively personal', 'personal belief', 'belief fear', 'fear instance', 'instance vital', 'vital construct', 'construct private', 'private sensitive', 'sensitive informational', 'informational attribute', 'attribute post', 'post excerpt', 'excerpt classified', 'classified high', 'high selfdisclosure', 'selfdisclosure demonstrate', 'demonstrate use', 'use ngrams', 'ngrams table']","['based training data', 'training data thus', 'data thus created', 'thus created pursued', 'created pursued use', 'pursued use supervised', 'use supervised learning', 'supervised learning develop', 'learning develop classifier', 'develop classifier would', 'classifier would indicate', 'would indicate whether', 'indicate whether post', 'whether post high', 'post high low', 'high low selfdisclosure', 'low selfdisclosure tested', 'selfdisclosure tested variety', 'tested variety different', 'variety different classification', 'different classification technique', 'classification technique decision', 'technique decision tree', 'decision tree k', 'tree k nearest', 'k nearest neighbor', 'nearest neighbor naive', 'neighbor naive bayes', 'naive bayes best', 'bayes best performing', 'best performing classifier', 'performing classifier wa', 'classifier wa found', 'wa found perceptron', 'found perceptron classifier', 'perceptron classifier adaptive', 'classifier adaptive boosting', 'adaptive boosting used', 'boosting used amplify', 'used amplify performance', 'amplify performance whose', 'performance whose result', 'whose result used', 'result used remainder', 'used remainder paper', 'remainder paper used', 'paper used following', 'used following feature', 'following feature generation', 'feature generation rule', 'generation rule first', 'rule first eliminated', 'first eliminated stopwords', 'eliminated stopwords post', 'stopwords post based', 'post based standard', 'based standard list', 'standard list provided', 'list provided python', 'provided python nltk', 'python nltk library', 'nltk library next', 'library next performed', 'next performed stemming', 'performed stemming using', 'stemming using porter', 'using porter stemmer', 'porter stemmer extracted', 'stemmer extracted uni', 'extracted uni bi', 'uni bi trigram', 'bi trigram post', 'trigram post considered', 'post considered five', 'considered five occurrence', 'five occurrence also', 'occurrence also computed', 'also computed two', 'computed two additional', 'two additional feature', 'additional feature length', 'feature length post', 'length post whether', 'post whether author', 'whether author post', 'author post exclusive', 'post exclusive poster', 'exclusive poster mental', 'poster mental health', 'mental health forum', 'health forum observed', 'forum observed dataset', 'observed dataset post', 'dataset post forum', 'post forum well', 'forum well thus', 'well thus post', 'thus post wa', 'post wa characterized', 'wa characterized feature', 'characterized feature used', 'feature used standard', 'used standard fold', 'standard fold cross', 'fold cross validation', 'cross validation cv', 'validation cv evaluate', 'cv evaluate classifier', 'evaluate classifier ran', 'classifier ran model', 'ran model random', 'model random fold', 'random fold cv', 'fold cv assignment', 'cv assignment generalizability', 'assignment generalizability result', 'generalizability result report', 'result report average', 'report average accuracy', 'average accuracy precision', 'accuracy precision recall', 'precision recall f', 'recall f specificity', 'f specificity metric', 'specificity metric performance', 'metric performance find', 'performance find classifier', 'find classifier based', 'classifier based perception', 'based perception model', 'perception model yield', 'model yield average', 'yield average accuracy', 'average accuracy detecting', 'accuracy detecting high', 'detecting high low', 'high low selfdisclosure', 'low selfdisclosure precision', 'selfdisclosure precision recall', 'precision recall see', 'recall see table', 'see table detail', 'table detail method', 'detail method like', 'method like knn', 'like knn k', 'knn k give', 'k give higher', 'give higher precision', 'higher precision expense', 'precision expense low', 'expense low recall', 'low recall figure', 'recall figure give', 'figure give roc', 'give roc receiver', 'roc receiver operating', 'receiver operating characteristic', 'operating characteristic curve', 'characteristic curve model', 'curve model per', 'model per roc', 'per roc curve', 'roc curve corresponding', 'curve corresponding perceptron', 'corresponding perceptron model', 'perceptron model find', 'model find yield', 'find yield maximum', 'yield maximum area', 'maximum area curve', 'area curve hence', 'curve hence best', 'hence best performance', 'best performance identify', 'performance identify table', 'identify table ngrams', 'table ngrams feature', 'ngrams feature highest', 'feature highest weight', 'highest weight given', 'weight given perceptron', 'given perceptron implies', 'perceptron implies feature', 'implies feature significant', 'feature significant classification', 'significant classification task', 'classification task provide', 'task provide brief', 'provide brief qualitative', 'brief qualitative examination', 'qualitative examination ngrams', 'examination ngrams light', 'ngrams light prior', 'light prior psychology', 'prior psychology literature', 'psychology literature selfdisclosure', 'literature selfdisclosure mental', 'selfdisclosure mental health', 'mental health find', 'health find ngrams', 'find ngrams primarily', 'ngrams primarily associated', 'primarily associated vulnerable', 'associated vulnerable selfloathing', 'vulnerable selfloathing thought', 'selfloathing thought eg', 'thought eg thought', 'eg thought suicide', 'thought suicide bear', 'suicide bear negative', 'bear negative tone', 'negative tone depict', 'tone depict confessional', 'depict confessional experience', 'confessional experience based', 'experience based prior', 'based prior research', 'prior research work', 'research work mental', 'work mental health', 'mental health discourse', 'health discourse reddit', 'discourse reddit find', 'reddit find topical', 'find topical dimension', 'topical dimension along', 'dimension along high', 'along high selfdisclosure', 'high selfdisclosure lowno', 'selfdisclosure lowno selfdisclosure', 'lowno selfdisclosure post', 'selfdisclosure post vary', 'post vary essence', 'vary essence high', 'essence high selfdisclosure', 'high selfdisclosure post', 'selfdisclosure post share', 'post share extensively', 'share extensively personal', 'extensively personal belief', 'personal belief fear', 'belief fear instance', 'fear instance vital', 'instance vital construct', 'vital construct private', 'construct private sensitive', 'private sensitive informational', 'sensitive informational attribute', 'informational attribute post', 'attribute post excerpt', 'post excerpt classified', 'excerpt classified high', 'classified high selfdisclosure', 'high selfdisclosure demonstrate', 'selfdisclosure demonstrate use', 'demonstrate use ngrams', 'use ngrams table']",,,,,,,
https://dl.acm.org/doi/abs/10.1145/2702123.2702280,0,In this study we gathered information on depression levels of Twitter users and their activity histories. To do this we published a website to administer a questionnaire and disseminated information about the website over Twitter1. In contrast to De Choudhury et al. [14] who collected data from Englishspeaking users through crowdsourcing this study collected data from Japanese-speaking volunteers. This approach was used to investigate the extent to which depression risk can be estimated for a population different from the population considered by the prior research [14]. Figure 1 shows a screenshot of our website. The website collected the responses to a questionnaire to evaluate the degree of depression of the Twitter users who participated (hereinafter the participants) and to collect the histories of participants activities on Twitter. The activity histories of participants were collected through the Twitter application programming interface (API)2 and the questionnaires to determine degree of depression were completed by participants through their web browsers. Before data collection visitors to the website were presented with a written explanation of the aims of the experiment the information that would be collected and how that information would be handled. Those who consented to become participants after receiving the explanation logged into their individual Twitter accounts through the OAuth authorization process. Next participants were surveyed on gender age occupation and history of depression following which they answered a questionnaire designed to evaluate degree of depression. A message called the “kokoro score” (“kokoro” is a Japanese word meaning “heart”) determined on the basis of answers to the questionnaire and information in the collected tweets was displayed to participants after completion of the questionnaire (Fig. 2). Experiment participants were able to tweet the message displayed which made it possible to promote the website over Twitter by word-of-mouth in a type of snowball sampling. The CES-D questionnaire was used to evaluate the degree of depression [30]. In the CES-D test participants answered 20 questions on a Likert-type 4-point scale. Each answer was assigned a score of 0-3 points with the sum of the points from all answers used as the score to estimate likelihood of depression. Several standards exist by which to determine the appropriate cutoff score for identifying depression. In this research we regarded a score of 22 points or higher as indicating active depression and a score of 21 points or lower as indicating no active depression; these are the same values as used in [14] and give a cutoff score of 22. In addition answers to BDI [2] a depression scale used with characteristics similar to CESD were collected to ensure the reliability of data. For each participant scores were calculated on both scales with poor correlation regarded as indicating unreliable answers. The time taken to answer the questionnaires was also recorded and those completed in too brief a time were excluded. After each participant answered the questionnaire the activity history of that participant on Twitter was collected from Twitter by using the API. At most 3200 tweets were collected for each participant and the number of users following the participant and being followed by the participant were recorded. Tweets published after the questionnaire was taken were discarded. The website was opened to the public on 4 December 2013 at which time the authors publicized it on their Twitter accounts. Between 4 December 2013 and 8 February 2014 219 people participated in the experiment. After eliminating participants who did not tweet and participants who answered the questionnaire in fewer than 30 seconds (as previously mentioned to ensure the reliability of the questionnaire answers) 214 sets of answers remained. Only the first set of answers was used for participants who completed the questionnaire more than once. As a result data about 209 experiment participants (male: 121; female: 88) aged 16 to 55 (mean: 28.8 years; standard deviation: 8.2 years) were analyzed. The correlations between CES-D score and BDI score for these participants were high 0.87 and there were no participants with uncorrelated scores so the data for all 209 participants were used; excluded datasets are not discussed any further. Figure 3 shows the histogram of CES-D scores of 209 participants. Among the participants 81 (resp. 128) were estimated to have (resp. not have) active depression for an incidence of approximately 39%. This incidence is similar to that found by De Choudhury et al. [14] who identified depression in approximately 36% of participants. Table 1 gives statistics on the activity histories of participants.,in this study we gathered information on depression level of twitter user and their activity history to do this we published a website to administer a questionnaire and disseminated information about the website over twitter in contrast to de choudhury et al who collected data from englishspeaking user through crowdsourcing this study collected data from japanesespeaking volunteer this approach wa used to investigate the extent to which depression risk can be estimated for a population different from the population considered by the prior research figure show a screenshot of our website the website collected the response to a questionnaire to evaluate the degree of depression of the twitter user who participated hereinafter the participant and to collect the history of participant activity on twitter the activity history of participant were collected through the twitter application programming interface api and the questionnaire to determine degree of depression were completed by participant through their web browser before data collection visitor to the website were presented with a written explanation of the aim of the experiment the information that would be collected and how that information would be handled those who consented to become participant after receiving the explanation logged into their individual twitter account through the oauth authorization process next participant were surveyed on gender age occupation and history of depression following which they answered a questionnaire designed to evaluate degree of depression a message called the kokoro score kokoro is a japanese word meaning heart determined on the basis of answer to the questionnaire and information in the collected tweet wa displayed to participant after completion of the questionnaire fig experiment participant were able to tweet the message displayed which made it possible to promote the website over twitter by wordofmouth in a type of snowball sampling the cesd questionnaire wa used to evaluate the degree of depression in the cesd test participant answered question on a likerttype point scale each answer wa assigned a score of point with the sum of the point from all answer used a the score to estimate likelihood of depression several standard exist by which to determine the appropriate cutoff score for identifying depression in this research we regarded a score of point or higher a indicating active depression and a score of point or lower a indicating no active depression these are the same value a used in and give a cutoff score of in addition answer to bdi a depression scale used with characteristic similar to cesd were collected to ensure the reliability of data for each participant score were calculated on both scale with poor correlation regarded a indicating unreliable answer the time taken to answer the questionnaire wa also recorded and those completed in too brief a time were excluded after each participant answered the questionnaire the activity history of that participant on twitter wa collected from twitter by using the api at most tweet were collected for each participant and the number of user following the participant and being followed by the participant were recorded tweet published after the questionnaire wa taken were discarded the website wa opened to the public on december at which time the author publicized it on their twitter account between december and february people participated in the experiment after eliminating participant who did not tweet and participant who answered the questionnaire in fewer than second a previously mentioned to ensure the reliability of the questionnaire answer set of answer remained only the first set of answer wa used for participant who completed the questionnaire more than once a a result data about experiment participant male female aged to mean year standard deviation year were analyzed the correlation between cesd score and bdi score for these participant were high and there were no participant with uncorrelated score so the data for all participant were used excluded datasets are not discussed any further figure show the histogram of cesd score of participant among the participant resp were estimated to have resp not have active depression for an incidence of approximately this incidence is similar to that found by de choudhury et al who identified depression in approximately of participant table give statistic on the activity history of participant,"['study', 'gathered', 'information', 'depression', 'level', 'twitter', 'user', 'activity', 'history', 'published', 'website', 'administer', 'questionnaire', 'disseminated', 'information', 'website', 'twitter', 'contrast', 'de', 'choudhury', 'et', 'al', 'collected', 'data', 'englishspeaking', 'user', 'crowdsourcing', 'study', 'collected', 'data', 'japanesespeaking', 'volunteer', 'approach', 'wa', 'used', 'investigate', 'extent', 'depression', 'risk', 'estimated', 'population', 'different', 'population', 'considered', 'prior', 'research', 'figure', 'show', 'screenshot', 'website', 'website', 'collected', 'response', 'questionnaire', 'evaluate', 'degree', 'depression', 'twitter', 'user', 'participated', 'hereinafter', 'participant', 'collect', 'history', 'participant', 'activity', 'twitter', 'activity', 'history', 'participant', 'collected', 'twitter', 'application', 'programming', 'interface', 'api', 'questionnaire', 'determine', 'degree', 'depression', 'completed', 'participant', 'web', 'browser', 'data', 'collection', 'visitor', 'website', 'presented', 'written', 'explanation', 'aim', 'experiment', 'information', 'would', 'collected', 'information', 'would', 'handled', 'consented', 'become', 'participant', 'receiving', 'explanation', 'logged', 'individual', 'twitter', 'account', 'oauth', 'authorization', 'process', 'next', 'participant', 'surveyed', 'gender', 'age', 'occupation', 'history', 'depression', 'following', 'answered', 'questionnaire', 'designed', 'evaluate', 'degree', 'depression', 'message', 'called', 'kokoro', 'score', 'kokoro', 'japanese', 'word', 'meaning', 'heart', 'determined', 'basis', 'answer', 'questionnaire', 'information', 'collected', 'tweet', 'wa', 'displayed', 'participant', 'completion', 'questionnaire', 'fig', 'experiment', 'participant', 'able', 'tweet', 'message', 'displayed', 'made', 'possible', 'promote', 'website', 'twitter', 'wordofmouth', 'type', 'snowball', 'sampling', 'cesd', 'questionnaire', 'wa', 'used', 'evaluate', 'degree', 'depression', 'cesd', 'test', 'participant', 'answered', 'question', 'likerttype', 'point', 'scale', 'answer', 'wa', 'assigned', 'score', 'point', 'sum', 'point', 'answer', 'used', 'score', 'estimate', 'likelihood', 'depression', 'several', 'standard', 'exist', 'determine', 'appropriate', 'cutoff', 'score', 'identifying', 'depression', 'research', 'regarded', 'score', 'point', 'higher', 'indicating', 'active', 'depression', 'score', 'point', 'lower', 'indicating', 'active', 'depression', 'value', 'used', 'give', 'cutoff', 'score', 'addition', 'answer', 'bdi', 'depression', 'scale', 'used', 'characteristic', 'similar', 'cesd', 'collected', 'ensure', 'reliability', 'data', 'participant', 'score', 'calculated', 'scale', 'poor', 'correlation', 'regarded', 'indicating', 'unreliable', 'answer', 'time', 'taken', 'answer', 'questionnaire', 'wa', 'also', 'recorded', 'completed', 'brief', 'time', 'excluded', 'participant', 'answered', 'questionnaire', 'activity', 'history', 'participant', 'twitter', 'wa', 'collected', 'twitter', 'using', 'api', 'tweet', 'collected', 'participant', 'number', 'user', 'following', 'participant', 'followed', 'participant', 'recorded', 'tweet', 'published', 'questionnaire', 'wa', 'taken', 'discarded', 'website', 'wa', 'opened', 'public', 'december', 'time', 'author', 'publicized', 'twitter', 'account', 'december', 'february', 'people', 'participated', 'experiment', 'eliminating', 'participant', 'tweet', 'participant', 'answered', 'questionnaire', 'fewer', 'second', 'previously', 'mentioned', 'ensure', 'reliability', 'questionnaire', 'answer', 'set', 'answer', 'remained', 'first', 'set', 'answer', 'wa', 'used', 'participant', 'completed', 'questionnaire', 'result', 'data', 'experiment', 'participant', 'male', 'female', 'aged', 'mean', 'year', 'standard', 'deviation', 'year', 'analyzed', 'correlation', 'cesd', 'score', 'bdi', 'score', 'participant', 'high', 'participant', 'uncorrelated', 'score', 'data', 'participant', 'used', 'excluded', 'datasets', 'discussed', 'figure', 'show', 'histogram', 'cesd', 'score', 'participant', 'among', 'participant', 'resp', 'estimated', 'resp', 'active', 'depression', 'incidence', 'approximately', 'incidence', 'similar', 'found', 'de', 'choudhury', 'et', 'al', 'identified', 'depression', 'approximately', 'participant', 'table', 'give', 'statistic', 'activity', 'history', 'participant']","['study gathered', 'gathered information', 'information depression', 'depression level', 'level twitter', 'twitter user', 'user activity', 'activity history', 'history published', 'published website', 'website administer', 'administer questionnaire', 'questionnaire disseminated', 'disseminated information', 'information website', 'website twitter', 'twitter contrast', 'contrast de', 'de choudhury', 'choudhury et', 'et al', 'al collected', 'collected data', 'data englishspeaking', 'englishspeaking user', 'user crowdsourcing', 'crowdsourcing study', 'study collected', 'collected data', 'data japanesespeaking', 'japanesespeaking volunteer', 'volunteer approach', 'approach wa', 'wa used', 'used investigate', 'investigate extent', 'extent depression', 'depression risk', 'risk estimated', 'estimated population', 'population different', 'different population', 'population considered', 'considered prior', 'prior research', 'research figure', 'figure show', 'show screenshot', 'screenshot website', 'website website', 'website collected', 'collected response', 'response questionnaire', 'questionnaire evaluate', 'evaluate degree', 'degree depression', 'depression twitter', 'twitter user', 'user participated', 'participated hereinafter', 'hereinafter participant', 'participant collect', 'collect history', 'history participant', 'participant activity', 'activity twitter', 'twitter activity', 'activity history', 'history participant', 'participant collected', 'collected twitter', 'twitter application', 'application programming', 'programming interface', 'interface api', 'api questionnaire', 'questionnaire determine', 'determine degree', 'degree depression', 'depression completed', 'completed participant', 'participant web', 'web browser', 'browser data', 'data collection', 'collection visitor', 'visitor website', 'website presented', 'presented written', 'written explanation', 'explanation aim', 'aim experiment', 'experiment information', 'information would', 'would collected', 'collected information', 'information would', 'would handled', 'handled consented', 'consented become', 'become participant', 'participant receiving', 'receiving explanation', 'explanation logged', 'logged individual', 'individual twitter', 'twitter account', 'account oauth', 'oauth authorization', 'authorization process', 'process next', 'next participant', 'participant surveyed', 'surveyed gender', 'gender age', 'age occupation', 'occupation history', 'history depression', 'depression following', 'following answered', 'answered questionnaire', 'questionnaire designed', 'designed evaluate', 'evaluate degree', 'degree depression', 'depression message', 'message called', 'called kokoro', 'kokoro score', 'score kokoro', 'kokoro japanese', 'japanese word', 'word meaning', 'meaning heart', 'heart determined', 'determined basis', 'basis answer', 'answer questionnaire', 'questionnaire information', 'information collected', 'collected tweet', 'tweet wa', 'wa displayed', 'displayed participant', 'participant completion', 'completion questionnaire', 'questionnaire fig', 'fig experiment', 'experiment participant', 'participant able', 'able tweet', 'tweet message', 'message displayed', 'displayed made', 'made possible', 'possible promote', 'promote website', 'website twitter', 'twitter wordofmouth', 'wordofmouth type', 'type snowball', 'snowball sampling', 'sampling cesd', 'cesd questionnaire', 'questionnaire wa', 'wa used', 'used evaluate', 'evaluate degree', 'degree depression', 'depression cesd', 'cesd test', 'test participant', 'participant answered', 'answered question', 'question likerttype', 'likerttype point', 'point scale', 'scale answer', 'answer wa', 'wa assigned', 'assigned score', 'score point', 'point sum', 'sum point', 'point answer', 'answer used', 'used score', 'score estimate', 'estimate likelihood', 'likelihood depression', 'depression several', 'several standard', 'standard exist', 'exist determine', 'determine appropriate', 'appropriate cutoff', 'cutoff score', 'score identifying', 'identifying depression', 'depression research', 'research regarded', 'regarded score', 'score point', 'point higher', 'higher indicating', 'indicating active', 'active depression', 'depression score', 'score point', 'point lower', 'lower indicating', 'indicating active', 'active depression', 'depression value', 'value used', 'used give', 'give cutoff', 'cutoff score', 'score addition', 'addition answer', 'answer bdi', 'bdi depression', 'depression scale', 'scale used', 'used characteristic', 'characteristic similar', 'similar cesd', 'cesd collected', 'collected ensure', 'ensure reliability', 'reliability data', 'data participant', 'participant score', 'score calculated', 'calculated scale', 'scale poor', 'poor correlation', 'correlation regarded', 'regarded indicating', 'indicating unreliable', 'unreliable answer', 'answer time', 'time taken', 'taken answer', 'answer questionnaire', 'questionnaire wa', 'wa also', 'also recorded', 'recorded completed', 'completed brief', 'brief time', 'time excluded', 'excluded participant', 'participant answered', 'answered questionnaire', 'questionnaire activity', 'activity history', 'history participant', 'participant twitter', 'twitter wa', 'wa collected', 'collected twitter', 'twitter using', 'using api', 'api tweet', 'tweet collected', 'collected participant', 'participant number', 'number user', 'user following', 'following participant', 'participant followed', 'followed participant', 'participant recorded', 'recorded tweet', 'tweet published', 'published questionnaire', 'questionnaire wa', 'wa taken', 'taken discarded', 'discarded website', 'website wa', 'wa opened', 'opened public', 'public december', 'december time', 'time author', 'author publicized', 'publicized twitter', 'twitter account', 'account december', 'december february', 'february people', 'people participated', 'participated experiment', 'experiment eliminating', 'eliminating participant', 'participant tweet', 'tweet participant', 'participant answered', 'answered questionnaire', 'questionnaire fewer', 'fewer second', 'second previously', 'previously mentioned', 'mentioned ensure', 'ensure reliability', 'reliability questionnaire', 'questionnaire answer', 'answer set', 'set answer', 'answer remained', 'remained first', 'first set', 'set answer', 'answer wa', 'wa used', 'used participant', 'participant completed', 'completed questionnaire', 'questionnaire result', 'result data', 'data experiment', 'experiment participant', 'participant male', 'male female', 'female aged', 'aged mean', 'mean year', 'year standard', 'standard deviation', 'deviation year', 'year analyzed', 'analyzed correlation', 'correlation cesd', 'cesd score', 'score bdi', 'bdi score', 'score participant', 'participant high', 'high participant', 'participant uncorrelated', 'uncorrelated score', 'score data', 'data participant', 'participant used', 'used excluded', 'excluded datasets', 'datasets discussed', 'discussed figure', 'figure show', 'show histogram', 'histogram cesd', 'cesd score', 'score participant', 'participant among', 'among participant', 'participant resp', 'resp estimated', 'estimated resp', 'resp active', 'active depression', 'depression incidence', 'incidence approximately', 'approximately incidence', 'incidence similar', 'similar found', 'found de', 'de choudhury', 'choudhury et', 'et al', 'al identified', 'identified depression', 'depression approximately', 'approximately participant', 'participant table', 'table give', 'give statistic', 'statistic activity', 'activity history', 'history participant']","['study gathered information', 'gathered information depression', 'information depression level', 'depression level twitter', 'level twitter user', 'twitter user activity', 'user activity history', 'activity history published', 'history published website', 'published website administer', 'website administer questionnaire', 'administer questionnaire disseminated', 'questionnaire disseminated information', 'disseminated information website', 'information website twitter', 'website twitter contrast', 'twitter contrast de', 'contrast de choudhury', 'de choudhury et', 'choudhury et al', 'et al collected', 'al collected data', 'collected data englishspeaking', 'data englishspeaking user', 'englishspeaking user crowdsourcing', 'user crowdsourcing study', 'crowdsourcing study collected', 'study collected data', 'collected data japanesespeaking', 'data japanesespeaking volunteer', 'japanesespeaking volunteer approach', 'volunteer approach wa', 'approach wa used', 'wa used investigate', 'used investigate extent', 'investigate extent depression', 'extent depression risk', 'depression risk estimated', 'risk estimated population', 'estimated population different', 'population different population', 'different population considered', 'population considered prior', 'considered prior research', 'prior research figure', 'research figure show', 'figure show screenshot', 'show screenshot website', 'screenshot website website', 'website website collected', 'website collected response', 'collected response questionnaire', 'response questionnaire evaluate', 'questionnaire evaluate degree', 'evaluate degree depression', 'degree depression twitter', 'depression twitter user', 'twitter user participated', 'user participated hereinafter', 'participated hereinafter participant', 'hereinafter participant collect', 'participant collect history', 'collect history participant', 'history participant activity', 'participant activity twitter', 'activity twitter activity', 'twitter activity history', 'activity history participant', 'history participant collected', 'participant collected twitter', 'collected twitter application', 'twitter application programming', 'application programming interface', 'programming interface api', 'interface api questionnaire', 'api questionnaire determine', 'questionnaire determine degree', 'determine degree depression', 'degree depression completed', 'depression completed participant', 'completed participant web', 'participant web browser', 'web browser data', 'browser data collection', 'data collection visitor', 'collection visitor website', 'visitor website presented', 'website presented written', 'presented written explanation', 'written explanation aim', 'explanation aim experiment', 'aim experiment information', 'experiment information would', 'information would collected', 'would collected information', 'collected information would', 'information would handled', 'would handled consented', 'handled consented become', 'consented become participant', 'become participant receiving', 'participant receiving explanation', 'receiving explanation logged', 'explanation logged individual', 'logged individual twitter', 'individual twitter account', 'twitter account oauth', 'account oauth authorization', 'oauth authorization process', 'authorization process next', 'process next participant', 'next participant surveyed', 'participant surveyed gender', 'surveyed gender age', 'gender age occupation', 'age occupation history', 'occupation history depression', 'history depression following', 'depression following answered', 'following answered questionnaire', 'answered questionnaire designed', 'questionnaire designed evaluate', 'designed evaluate degree', 'evaluate degree depression', 'degree depression message', 'depression message called', 'message called kokoro', 'called kokoro score', 'kokoro score kokoro', 'score kokoro japanese', 'kokoro japanese word', 'japanese word meaning', 'word meaning heart', 'meaning heart determined', 'heart determined basis', 'determined basis answer', 'basis answer questionnaire', 'answer questionnaire information', 'questionnaire information collected', 'information collected tweet', 'collected tweet wa', 'tweet wa displayed', 'wa displayed participant', 'displayed participant completion', 'participant completion questionnaire', 'completion questionnaire fig', 'questionnaire fig experiment', 'fig experiment participant', 'experiment participant able', 'participant able tweet', 'able tweet message', 'tweet message displayed', 'message displayed made', 'displayed made possible', 'made possible promote', 'possible promote website', 'promote website twitter', 'website twitter wordofmouth', 'twitter wordofmouth type', 'wordofmouth type snowball', 'type snowball sampling', 'snowball sampling cesd', 'sampling cesd questionnaire', 'cesd questionnaire wa', 'questionnaire wa used', 'wa used evaluate', 'used evaluate degree', 'evaluate degree depression', 'degree depression cesd', 'depression cesd test', 'cesd test participant', 'test participant answered', 'participant answered question', 'answered question likerttype', 'question likerttype point', 'likerttype point scale', 'point scale answer', 'scale answer wa', 'answer wa assigned', 'wa assigned score', 'assigned score point', 'score point sum', 'point sum point', 'sum point answer', 'point answer used', 'answer used score', 'used score estimate', 'score estimate likelihood', 'estimate likelihood depression', 'likelihood depression several', 'depression several standard', 'several standard exist', 'standard exist determine', 'exist determine appropriate', 'determine appropriate cutoff', 'appropriate cutoff score', 'cutoff score identifying', 'score identifying depression', 'identifying depression research', 'depression research regarded', 'research regarded score', 'regarded score point', 'score point higher', 'point higher indicating', 'higher indicating active', 'indicating active depression', 'active depression score', 'depression score point', 'score point lower', 'point lower indicating', 'lower indicating active', 'indicating active depression', 'active depression value', 'depression value used', 'value used give', 'used give cutoff', 'give cutoff score', 'cutoff score addition', 'score addition answer', 'addition answer bdi', 'answer bdi depression', 'bdi depression scale', 'depression scale used', 'scale used characteristic', 'used characteristic similar', 'characteristic similar cesd', 'similar cesd collected', 'cesd collected ensure', 'collected ensure reliability', 'ensure reliability data', 'reliability data participant', 'data participant score', 'participant score calculated', 'score calculated scale', 'calculated scale poor', 'scale poor correlation', 'poor correlation regarded', 'correlation regarded indicating', 'regarded indicating unreliable', 'indicating unreliable answer', 'unreliable answer time', 'answer time taken', 'time taken answer', 'taken answer questionnaire', 'answer questionnaire wa', 'questionnaire wa also', 'wa also recorded', 'also recorded completed', 'recorded completed brief', 'completed brief time', 'brief time excluded', 'time excluded participant', 'excluded participant answered', 'participant answered questionnaire', 'answered questionnaire activity', 'questionnaire activity history', 'activity history participant', 'history participant twitter', 'participant twitter wa', 'twitter wa collected', 'wa collected twitter', 'collected twitter using', 'twitter using api', 'using api tweet', 'api tweet collected', 'tweet collected participant', 'collected participant number', 'participant number user', 'number user following', 'user following participant', 'following participant followed', 'participant followed participant', 'followed participant recorded', 'participant recorded tweet', 'recorded tweet published', 'tweet published questionnaire', 'published questionnaire wa', 'questionnaire wa taken', 'wa taken discarded', 'taken discarded website', 'discarded website wa', 'website wa opened', 'wa opened public', 'opened public december', 'public december time', 'december time author', 'time author publicized', 'author publicized twitter', 'publicized twitter account', 'twitter account december', 'account december february', 'december february people', 'february people participated', 'people participated experiment', 'participated experiment eliminating', 'experiment eliminating participant', 'eliminating participant tweet', 'participant tweet participant', 'tweet participant answered', 'participant answered questionnaire', 'answered questionnaire fewer', 'questionnaire fewer second', 'fewer second previously', 'second previously mentioned', 'previously mentioned ensure', 'mentioned ensure reliability', 'ensure reliability questionnaire', 'reliability questionnaire answer', 'questionnaire answer set', 'answer set answer', 'set answer remained', 'answer remained first', 'remained first set', 'first set answer', 'set answer wa', 'answer wa used', 'wa used participant', 'used participant completed', 'participant completed questionnaire', 'completed questionnaire result', 'questionnaire result data', 'result data experiment', 'data experiment participant', 'experiment participant male', 'participant male female', 'male female aged', 'female aged mean', 'aged mean year', 'mean year standard', 'year standard deviation', 'standard deviation year', 'deviation year analyzed', 'year analyzed correlation', 'analyzed correlation cesd', 'correlation cesd score', 'cesd score bdi', 'score bdi score', 'bdi score participant', 'score participant high', 'participant high participant', 'high participant uncorrelated', 'participant uncorrelated score', 'uncorrelated score data', 'score data participant', 'data participant used', 'participant used excluded', 'used excluded datasets', 'excluded datasets discussed', 'datasets discussed figure', 'discussed figure show', 'figure show histogram', 'show histogram cesd', 'histogram cesd score', 'cesd score participant', 'score participant among', 'participant among participant', 'among participant resp', 'participant resp estimated', 'resp estimated resp', 'estimated resp active', 'resp active depression', 'active depression incidence', 'depression incidence approximately', 'incidence approximately incidence', 'approximately incidence similar', 'incidence similar found', 'similar found de', 'found de choudhury', 'de choudhury et', 'choudhury et al', 'et al identified', 'al identified depression', 'identified depression approximately', 'depression approximately participant', 'approximately participant table', 'participant table give', 'table give statistic', 'give statistic activity', 'statistic activity history', 'activity history participant']",,,,,,,
https://www.nature.com/articles/s41598-017-12961-9,0,In an effort to minimize noisy and unreliable data we applied several quality assurance measures in our data collection process. MTurk workers who have completed at least 100 tasks with a minimum 95% approval rating have been found to provide reliable valid survey responses33. We restricted survey visibility only to workers with these qualifications. Survey access was also restricted to U.S. IP addresses as MTurk data collected from outside the United States are generally of poorer quality34. All participants were only permitted to take the survey once. We excluded participants with a total of fewer than five Twitter posts. We also excluded participants with CES-D scores of 21 or lower (depression) or TSQ scores of 5 or lower (PTSD). Studies have indicated that a CES-D score of 22 represents an optimal cutoff for identifying clinically relevant depression3536; an equivalent TSQ cutoff of 6 has been found to be optimal in the case of PTSD32. We note here that in the study that inspired the present work De Choudhury et al.8 used two depression scales (CES-D and BDI) and filtered individuals whose depression score did not correlate across the both scales. This additional criteria is a methodological strength of De Choudhury et al.8 with respect to the present work.,in an effort to minimize noisy and unreliable data we applied several quality assurance measure in our data collection process mturk worker who have completed at least task with a minimum approval rating have been found to provide reliable valid survey response we restricted survey visibility only to worker with these qualification survey access wa also restricted to u ip address a mturk data collected from outside the united state are generally of poorer quality all participant were only permitted to take the survey once we excluded participant with a total of fewer than five twitter post we also excluded participant with cesd score of or lower depression or tsq score of or lower ptsd study have indicated that a cesd score of represents an optimal cutoff for identifying clinically relevant depression an equivalent tsq cutoff of ha been found to be optimal in the case of ptsd we note here that in the study that inspired the present work de choudhury et al used two depression scale cesd and bdi and filtered individual whose depression score did not correlate across the both scale this additional criterion is a methodological strength of de choudhury et al with respect to the present work,"['effort', 'minimize', 'noisy', 'unreliable', 'data', 'applied', 'several', 'quality', 'assurance', 'measure', 'data', 'collection', 'process', 'mturk', 'worker', 'completed', 'least', 'task', 'minimum', 'approval', 'rating', 'found', 'provide', 'reliable', 'valid', 'survey', 'response', 'restricted', 'survey', 'visibility', 'worker', 'qualification', 'survey', 'access', 'wa', 'also', 'restricted', 'u', 'ip', 'address', 'mturk', 'data', 'collected', 'outside', 'united', 'state', 'generally', 'poorer', 'quality', 'participant', 'permitted', 'take', 'survey', 'excluded', 'participant', 'total', 'fewer', 'five', 'twitter', 'post', 'also', 'excluded', 'participant', 'cesd', 'score', 'lower', 'depression', 'tsq', 'score', 'lower', 'ptsd', 'study', 'indicated', 'cesd', 'score', 'represents', 'optimal', 'cutoff', 'identifying', 'clinically', 'relevant', 'depression', 'equivalent', 'tsq', 'cutoff', 'ha', 'found', 'optimal', 'case', 'ptsd', 'note', 'study', 'inspired', 'present', 'work', 'de', 'choudhury', 'et', 'al', 'used', 'two', 'depression', 'scale', 'cesd', 'bdi', 'filtered', 'individual', 'whose', 'depression', 'score', 'correlate', 'across', 'scale', 'additional', 'criterion', 'methodological', 'strength', 'de', 'choudhury', 'et', 'al', 'respect', 'present', 'work']","['effort minimize', 'minimize noisy', 'noisy unreliable', 'unreliable data', 'data applied', 'applied several', 'several quality', 'quality assurance', 'assurance measure', 'measure data', 'data collection', 'collection process', 'process mturk', 'mturk worker', 'worker completed', 'completed least', 'least task', 'task minimum', 'minimum approval', 'approval rating', 'rating found', 'found provide', 'provide reliable', 'reliable valid', 'valid survey', 'survey response', 'response restricted', 'restricted survey', 'survey visibility', 'visibility worker', 'worker qualification', 'qualification survey', 'survey access', 'access wa', 'wa also', 'also restricted', 'restricted u', 'u ip', 'ip address', 'address mturk', 'mturk data', 'data collected', 'collected outside', 'outside united', 'united state', 'state generally', 'generally poorer', 'poorer quality', 'quality participant', 'participant permitted', 'permitted take', 'take survey', 'survey excluded', 'excluded participant', 'participant total', 'total fewer', 'fewer five', 'five twitter', 'twitter post', 'post also', 'also excluded', 'excluded participant', 'participant cesd', 'cesd score', 'score lower', 'lower depression', 'depression tsq', 'tsq score', 'score lower', 'lower ptsd', 'ptsd study', 'study indicated', 'indicated cesd', 'cesd score', 'score represents', 'represents optimal', 'optimal cutoff', 'cutoff identifying', 'identifying clinically', 'clinically relevant', 'relevant depression', 'depression equivalent', 'equivalent tsq', 'tsq cutoff', 'cutoff ha', 'ha found', 'found optimal', 'optimal case', 'case ptsd', 'ptsd note', 'note study', 'study inspired', 'inspired present', 'present work', 'work de', 'de choudhury', 'choudhury et', 'et al', 'al used', 'used two', 'two depression', 'depression scale', 'scale cesd', 'cesd bdi', 'bdi filtered', 'filtered individual', 'individual whose', 'whose depression', 'depression score', 'score correlate', 'correlate across', 'across scale', 'scale additional', 'additional criterion', 'criterion methodological', 'methodological strength', 'strength de', 'de choudhury', 'choudhury et', 'et al', 'al respect', 'respect present', 'present work']","['effort minimize noisy', 'minimize noisy unreliable', 'noisy unreliable data', 'unreliable data applied', 'data applied several', 'applied several quality', 'several quality assurance', 'quality assurance measure', 'assurance measure data', 'measure data collection', 'data collection process', 'collection process mturk', 'process mturk worker', 'mturk worker completed', 'worker completed least', 'completed least task', 'least task minimum', 'task minimum approval', 'minimum approval rating', 'approval rating found', 'rating found provide', 'found provide reliable', 'provide reliable valid', 'reliable valid survey', 'valid survey response', 'survey response restricted', 'response restricted survey', 'restricted survey visibility', 'survey visibility worker', 'visibility worker qualification', 'worker qualification survey', 'qualification survey access', 'survey access wa', 'access wa also', 'wa also restricted', 'also restricted u', 'restricted u ip', 'u ip address', 'ip address mturk', 'address mturk data', 'mturk data collected', 'data collected outside', 'collected outside united', 'outside united state', 'united state generally', 'state generally poorer', 'generally poorer quality', 'poorer quality participant', 'quality participant permitted', 'participant permitted take', 'permitted take survey', 'take survey excluded', 'survey excluded participant', 'excluded participant total', 'participant total fewer', 'total fewer five', 'fewer five twitter', 'five twitter post', 'twitter post also', 'post also excluded', 'also excluded participant', 'excluded participant cesd', 'participant cesd score', 'cesd score lower', 'score lower depression', 'lower depression tsq', 'depression tsq score', 'tsq score lower', 'score lower ptsd', 'lower ptsd study', 'ptsd study indicated', 'study indicated cesd', 'indicated cesd score', 'cesd score represents', 'score represents optimal', 'represents optimal cutoff', 'optimal cutoff identifying', 'cutoff identifying clinically', 'identifying clinically relevant', 'clinically relevant depression', 'relevant depression equivalent', 'depression equivalent tsq', 'equivalent tsq cutoff', 'tsq cutoff ha', 'cutoff ha found', 'ha found optimal', 'found optimal case', 'optimal case ptsd', 'case ptsd note', 'ptsd note study', 'note study inspired', 'study inspired present', 'inspired present work', 'present work de', 'work de choudhury', 'de choudhury et', 'choudhury et al', 'et al used', 'al used two', 'used two depression', 'two depression scale', 'depression scale cesd', 'scale cesd bdi', 'cesd bdi filtered', 'bdi filtered individual', 'filtered individual whose', 'individual whose depression', 'whose depression score', 'depression score correlate', 'score correlate across', 'correlate across scale', 'across scale additional', 'scale additional criterion', 'additional criterion methodological', 'criterion methodological strength', 'methodological strength de', 'strength de choudhury', 'de choudhury et', 'choudhury et al', 'et al respect', 'al respect present', 'respect present work']",,,,,,,
https://aclanthology.org/W14-3214.pdf,0,We used a dataset of 28749 nonclinical users who opted into a Facebook application (“MyPersonality”; Kosinski and Stillwell 2012) between June 2009 and March 2011 completed a 100-item personality questionnaire (an International Personality Item Pool (IPIP) proxy to the NEO-PI-R (Goldberg 1999) and shared access to their status updates containing at least 500 words. Users wrote on average of 4236 words (69917624 total word instances) and a subset of 16507 users provided gender and age in which 57.0% were female and the mean age was 24.8. The dataset was divided into training and testing samples. In particular the testing sample consisted of a random set of 1000 users who wrote at least 1000 words and completed the personality measure while the training set contained the 27749 remaining users.,we used a dataset of nonclinical user who opted into a facebook application mypersonality kosinski and stillwell between june and march completed a item personality questionnaire an international personality item pool ipip proxy to the neopir goldberg and shared access to their status update containing at least word user wrote on average of word total word instance and a subset of user provided gender and age in which were female and the mean age wa the dataset wa divided into training and testing sample in particular the testing sample consisted of a random set of user who wrote at least word and completed the personality measure while the training set contained the remaining user,"['used', 'dataset', 'nonclinical', 'user', 'opted', 'facebook', 'application', 'mypersonality', 'kosinski', 'stillwell', 'june', 'march', 'completed', 'item', 'personality', 'questionnaire', 'international', 'personality', 'item', 'pool', 'ipip', 'proxy', 'neopir', 'goldberg', 'shared', 'access', 'status', 'update', 'containing', 'least', 'word', 'user', 'wrote', 'average', 'word', 'total', 'word', 'instance', 'subset', 'user', 'provided', 'gender', 'age', 'female', 'mean', 'age', 'wa', 'dataset', 'wa', 'divided', 'training', 'testing', 'sample', 'particular', 'testing', 'sample', 'consisted', 'random', 'set', 'user', 'wrote', 'least', 'word', 'completed', 'personality', 'measure', 'training', 'set', 'contained', 'remaining', 'user']","['used dataset', 'dataset nonclinical', 'nonclinical user', 'user opted', 'opted facebook', 'facebook application', 'application mypersonality', 'mypersonality kosinski', 'kosinski stillwell', 'stillwell june', 'june march', 'march completed', 'completed item', 'item personality', 'personality questionnaire', 'questionnaire international', 'international personality', 'personality item', 'item pool', 'pool ipip', 'ipip proxy', 'proxy neopir', 'neopir goldberg', 'goldberg shared', 'shared access', 'access status', 'status update', 'update containing', 'containing least', 'least word', 'word user', 'user wrote', 'wrote average', 'average word', 'word total', 'total word', 'word instance', 'instance subset', 'subset user', 'user provided', 'provided gender', 'gender age', 'age female', 'female mean', 'mean age', 'age wa', 'wa dataset', 'dataset wa', 'wa divided', 'divided training', 'training testing', 'testing sample', 'sample particular', 'particular testing', 'testing sample', 'sample consisted', 'consisted random', 'random set', 'set user', 'user wrote', 'wrote least', 'least word', 'word completed', 'completed personality', 'personality measure', 'measure training', 'training set', 'set contained', 'contained remaining', 'remaining user']","['used dataset nonclinical', 'dataset nonclinical user', 'nonclinical user opted', 'user opted facebook', 'opted facebook application', 'facebook application mypersonality', 'application mypersonality kosinski', 'mypersonality kosinski stillwell', 'kosinski stillwell june', 'stillwell june march', 'june march completed', 'march completed item', 'completed item personality', 'item personality questionnaire', 'personality questionnaire international', 'questionnaire international personality', 'international personality item', 'personality item pool', 'item pool ipip', 'pool ipip proxy', 'ipip proxy neopir', 'proxy neopir goldberg', 'neopir goldberg shared', 'goldberg shared access', 'shared access status', 'access status update', 'status update containing', 'update containing least', 'containing least word', 'least word user', 'word user wrote', 'user wrote average', 'wrote average word', 'average word total', 'word total word', 'total word instance', 'word instance subset', 'instance subset user', 'subset user provided', 'user provided gender', 'provided gender age', 'gender age female', 'age female mean', 'female mean age', 'mean age wa', 'age wa dataset', 'wa dataset wa', 'dataset wa divided', 'wa divided training', 'divided training testing', 'training testing sample', 'testing sample particular', 'sample particular testing', 'particular testing sample', 'testing sample consisted', 'sample consisted random', 'consisted random set', 'random set user', 'set user wrote', 'user wrote least', 'wrote least word', 'least word completed', 'word completed personality', 'completed personality measure', 'personality measure training', 'measure training set', 'training set contained', 'set contained remaining', 'contained remaining user']",,,,,,,
https://ieeexplore.ieee.org/abstract/document/6784326,0,To characterize the difference between CLINICAL and CONTROL communities a variety of features are extracted: Affective features: We use the lexicon—Affective Norms for English Words (ANEW) [5]—to extract the sentiment conveyed in the content. This lexicon consists of 1034 words rated in terms of valence and arousal and is thus suitable for a quantitative estimation. The valence of ANEW words is on a scale of 1 (very unpleasant) to 9 (very pleasant). The arousal is measured on the same scale—1 (least active) to 9 (most active). A cloud visualization of ANEW words used in the blog posts made by CLINICAL and CONTROL groups is illustrated in Fig. 1. Mood tags: LiveJournal provides a mechanism for users to tag their posts from a list of 132 pre-defined mood labels.4 Thus in addition to the emotion expressed in the text of posts the mood tag produced allows us direct access to the user sentiment. A cloud visualization of moods tagged on blog posts made by CLINICAL and CONTROL communities is llustrated in Fig. 2. LIWC features: We examine the proportions of words in psycholinguistic categories as defined in the LIWC package [27]: linguistic social affective cognitive perceptual biological relativity personal concerns and spoken.5 Table 3 presents the mean of these LIWC psycholinguistic processes for the CLINICAL and CONTROL communities. Whilst similar in the use words with positive emotion people in the CLINICAL communities tend to use words with more negative emotion—as examples anxiety anger and sadness. Further they discuss more issues about health and death in comparison with the CONTROL group. On the other hand the users in the CONTROL group discuss more neutral life related topics—ingestion home and leisure words. Topics: For extracting topics latent Dirichlet allocation (LDA) [4] is used as a Bayesian probabilistic modelling framework. LDA extracts the probabilities —that is words in a topic and then assigns a topic to each word in a document. For the inference part we implemented Gibbs inference detailed in [10]. We set the number of topics to 50 run the Gibbs for 5000 samples and use the last Gibbs sample to interpret the results.,to characterize the difference between clinical and control community a variety of feature are extracted affective feature we use the lexiconaffective norm for english word anew to extract the sentiment conveyed in the content this lexicon consists of word rated in term of valence and arousal and is thus suitable for a quantitative estimation the valence of anew word is on a scale of very unpleasant to very pleasant the arousal is measured on the same scale least active to most active a cloud visualization of anew word used in the blog post made by clinical and control group is illustrated in fig mood tag livejournal provides a mechanism for user to tag their post from a list of predefined mood label thus in addition to the emotion expressed in the text of post the mood tag produced allows u direct access to the user sentiment a cloud visualization of mood tagged on blog post made by clinical and control community is llustrated in fig liwc feature we examine the proportion of word in psycholinguistic category a defined in the liwc package linguistic social affective cognitive perceptual biological relativity personal concern and spoken table present the mean of these liwc psycholinguistic process for the clinical and control community whilst similar in the use word with positive emotion people in the clinical community tend to use word with more negative emotionas example anxiety anger and sadness further they discus more issue about health and death in comparison with the control group on the other hand the user in the control group discus more neutral life related topicsingestion home and leisure word topic for extracting topic latent dirichlet allocation lda is used a a bayesian probabilistic modelling framework lda extract the probability that is word in a topic and then assigns a topic to each word in a document for the inference part we implemented gibbs inference detailed in we set the number of topic to run the gibbs for sample and use the last gibbs sample to interpret the result,"['characterize', 'difference', 'clinical', 'control', 'community', 'variety', 'feature', 'extracted', 'affective', 'feature', 'use', 'lexiconaffective', 'norm', 'english', 'word', 'anew', 'extract', 'sentiment', 'conveyed', 'content', 'lexicon', 'consists', 'word', 'rated', 'term', 'valence', 'arousal', 'thus', 'suitable', 'quantitative', 'estimation', 'valence', 'anew', 'word', 'scale', 'unpleasant', 'pleasant', 'arousal', 'measured', 'scale', 'least', 'active', 'active', 'cloud', 'visualization', 'anew', 'word', 'used', 'blog', 'post', 'made', 'clinical', 'control', 'group', 'illustrated', 'fig', 'mood', 'tag', 'livejournal', 'provides', 'mechanism', 'user', 'tag', 'post', 'list', 'predefined', 'mood', 'label', 'thus', 'addition', 'emotion', 'expressed', 'text', 'post', 'mood', 'tag', 'produced', 'allows', 'u', 'direct', 'access', 'user', 'sentiment', 'cloud', 'visualization', 'mood', 'tagged', 'blog', 'post', 'made', 'clinical', 'control', 'community', 'llustrated', 'fig', 'liwc', 'feature', 'examine', 'proportion', 'word', 'psycholinguistic', 'category', 'defined', 'liwc', 'package', 'linguistic', 'social', 'affective', 'cognitive', 'perceptual', 'biological', 'relativity', 'personal', 'concern', 'spoken', 'table', 'present', 'mean', 'liwc', 'psycholinguistic', 'process', 'clinical', 'control', 'community', 'whilst', 'similar', 'use', 'word', 'positive', 'emotion', 'people', 'clinical', 'community', 'tend', 'use', 'word', 'negative', 'emotionas', 'example', 'anxiety', 'anger', 'sadness', 'discus', 'issue', 'health', 'death', 'comparison', 'control', 'group', 'hand', 'user', 'control', 'group', 'discus', 'neutral', 'life', 'related', 'topicsingestion', 'home', 'leisure', 'word', 'topic', 'extracting', 'topic', 'latent', 'dirichlet', 'allocation', 'lda', 'used', 'bayesian', 'probabilistic', 'modelling', 'framework', 'lda', 'extract', 'probability', 'word', 'topic', 'assigns', 'topic', 'word', 'document', 'inference', 'part', 'implemented', 'gibbs', 'inference', 'detailed', 'set', 'number', 'topic', 'run', 'gibbs', 'sample', 'use', 'last', 'gibbs', 'sample', 'interpret', 'result']","['characterize difference', 'difference clinical', 'clinical control', 'control community', 'community variety', 'variety feature', 'feature extracted', 'extracted affective', 'affective feature', 'feature use', 'use lexiconaffective', 'lexiconaffective norm', 'norm english', 'english word', 'word anew', 'anew extract', 'extract sentiment', 'sentiment conveyed', 'conveyed content', 'content lexicon', 'lexicon consists', 'consists word', 'word rated', 'rated term', 'term valence', 'valence arousal', 'arousal thus', 'thus suitable', 'suitable quantitative', 'quantitative estimation', 'estimation valence', 'valence anew', 'anew word', 'word scale', 'scale unpleasant', 'unpleasant pleasant', 'pleasant arousal', 'arousal measured', 'measured scale', 'scale least', 'least active', 'active active', 'active cloud', 'cloud visualization', 'visualization anew', 'anew word', 'word used', 'used blog', 'blog post', 'post made', 'made clinical', 'clinical control', 'control group', 'group illustrated', 'illustrated fig', 'fig mood', 'mood tag', 'tag livejournal', 'livejournal provides', 'provides mechanism', 'mechanism user', 'user tag', 'tag post', 'post list', 'list predefined', 'predefined mood', 'mood label', 'label thus', 'thus addition', 'addition emotion', 'emotion expressed', 'expressed text', 'text post', 'post mood', 'mood tag', 'tag produced', 'produced allows', 'allows u', 'u direct', 'direct access', 'access user', 'user sentiment', 'sentiment cloud', 'cloud visualization', 'visualization mood', 'mood tagged', 'tagged blog', 'blog post', 'post made', 'made clinical', 'clinical control', 'control community', 'community llustrated', 'llustrated fig', 'fig liwc', 'liwc feature', 'feature examine', 'examine proportion', 'proportion word', 'word psycholinguistic', 'psycholinguistic category', 'category defined', 'defined liwc', 'liwc package', 'package linguistic', 'linguistic social', 'social affective', 'affective cognitive', 'cognitive perceptual', 'perceptual biological', 'biological relativity', 'relativity personal', 'personal concern', 'concern spoken', 'spoken table', 'table present', 'present mean', 'mean liwc', 'liwc psycholinguistic', 'psycholinguistic process', 'process clinical', 'clinical control', 'control community', 'community whilst', 'whilst similar', 'similar use', 'use word', 'word positive', 'positive emotion', 'emotion people', 'people clinical', 'clinical community', 'community tend', 'tend use', 'use word', 'word negative', 'negative emotionas', 'emotionas example', 'example anxiety', 'anxiety anger', 'anger sadness', 'sadness discus', 'discus issue', 'issue health', 'health death', 'death comparison', 'comparison control', 'control group', 'group hand', 'hand user', 'user control', 'control group', 'group discus', 'discus neutral', 'neutral life', 'life related', 'related topicsingestion', 'topicsingestion home', 'home leisure', 'leisure word', 'word topic', 'topic extracting', 'extracting topic', 'topic latent', 'latent dirichlet', 'dirichlet allocation', 'allocation lda', 'lda used', 'used bayesian', 'bayesian probabilistic', 'probabilistic modelling', 'modelling framework', 'framework lda', 'lda extract', 'extract probability', 'probability word', 'word topic', 'topic assigns', 'assigns topic', 'topic word', 'word document', 'document inference', 'inference part', 'part implemented', 'implemented gibbs', 'gibbs inference', 'inference detailed', 'detailed set', 'set number', 'number topic', 'topic run', 'run gibbs', 'gibbs sample', 'sample use', 'use last', 'last gibbs', 'gibbs sample', 'sample interpret', 'interpret result']","['characterize difference clinical', 'difference clinical control', 'clinical control community', 'control community variety', 'community variety feature', 'variety feature extracted', 'feature extracted affective', 'extracted affective feature', 'affective feature use', 'feature use lexiconaffective', 'use lexiconaffective norm', 'lexiconaffective norm english', 'norm english word', 'english word anew', 'word anew extract', 'anew extract sentiment', 'extract sentiment conveyed', 'sentiment conveyed content', 'conveyed content lexicon', 'content lexicon consists', 'lexicon consists word', 'consists word rated', 'word rated term', 'rated term valence', 'term valence arousal', 'valence arousal thus', 'arousal thus suitable', 'thus suitable quantitative', 'suitable quantitative estimation', 'quantitative estimation valence', 'estimation valence anew', 'valence anew word', 'anew word scale', 'word scale unpleasant', 'scale unpleasant pleasant', 'unpleasant pleasant arousal', 'pleasant arousal measured', 'arousal measured scale', 'measured scale least', 'scale least active', 'least active active', 'active active cloud', 'active cloud visualization', 'cloud visualization anew', 'visualization anew word', 'anew word used', 'word used blog', 'used blog post', 'blog post made', 'post made clinical', 'made clinical control', 'clinical control group', 'control group illustrated', 'group illustrated fig', 'illustrated fig mood', 'fig mood tag', 'mood tag livejournal', 'tag livejournal provides', 'livejournal provides mechanism', 'provides mechanism user', 'mechanism user tag', 'user tag post', 'tag post list', 'post list predefined', 'list predefined mood', 'predefined mood label', 'mood label thus', 'label thus addition', 'thus addition emotion', 'addition emotion expressed', 'emotion expressed text', 'expressed text post', 'text post mood', 'post mood tag', 'mood tag produced', 'tag produced allows', 'produced allows u', 'allows u direct', 'u direct access', 'direct access user', 'access user sentiment', 'user sentiment cloud', 'sentiment cloud visualization', 'cloud visualization mood', 'visualization mood tagged', 'mood tagged blog', 'tagged blog post', 'blog post made', 'post made clinical', 'made clinical control', 'clinical control community', 'control community llustrated', 'community llustrated fig', 'llustrated fig liwc', 'fig liwc feature', 'liwc feature examine', 'feature examine proportion', 'examine proportion word', 'proportion word psycholinguistic', 'word psycholinguistic category', 'psycholinguistic category defined', 'category defined liwc', 'defined liwc package', 'liwc package linguistic', 'package linguistic social', 'linguistic social affective', 'social affective cognitive', 'affective cognitive perceptual', 'cognitive perceptual biological', 'perceptual biological relativity', 'biological relativity personal', 'relativity personal concern', 'personal concern spoken', 'concern spoken table', 'spoken table present', 'table present mean', 'present mean liwc', 'mean liwc psycholinguistic', 'liwc psycholinguistic process', 'psycholinguistic process clinical', 'process clinical control', 'clinical control community', 'control community whilst', 'community whilst similar', 'whilst similar use', 'similar use word', 'use word positive', 'word positive emotion', 'positive emotion people', 'emotion people clinical', 'people clinical community', 'clinical community tend', 'community tend use', 'tend use word', 'use word negative', 'word negative emotionas', 'negative emotionas example', 'emotionas example anxiety', 'example anxiety anger', 'anxiety anger sadness', 'anger sadness discus', 'sadness discus issue', 'discus issue health', 'issue health death', 'health death comparison', 'death comparison control', 'comparison control group', 'control group hand', 'group hand user', 'hand user control', 'user control group', 'control group discus', 'group discus neutral', 'discus neutral life', 'neutral life related', 'life related topicsingestion', 'related topicsingestion home', 'topicsingestion home leisure', 'home leisure word', 'leisure word topic', 'word topic extracting', 'topic extracting topic', 'extracting topic latent', 'topic latent dirichlet', 'latent dirichlet allocation', 'dirichlet allocation lda', 'allocation lda used', 'lda used bayesian', 'used bayesian probabilistic', 'bayesian probabilistic modelling', 'probabilistic modelling framework', 'modelling framework lda', 'framework lda extract', 'lda extract probability', 'extract probability word', 'probability word topic', 'word topic assigns', 'topic assigns topic', 'assigns topic word', 'topic word document', 'word document inference', 'document inference part', 'inference part implemented', 'part implemented gibbs', 'implemented gibbs inference', 'gibbs inference detailed', 'inference detailed set', 'detailed set number', 'set number topic', 'number topic run', 'topic run gibbs', 'run gibbs sample', 'gibbs sample use', 'sample use last', 'use last gibbs', 'last gibbs sample', 'gibbs sample interpret', 'sample interpret result']",,,,,,,
https://www.jmir.org/2017/7/e243/,0,A Web-based survey of Weibo users was conducted to assess the respondents’ suicide risk and emotional distress (ie depression anxiety and stress). The invitation letter to participate in this survey was widely sent out to general Weibo users by various promotion activities. For a Weibo user to be eligible for the study she or he had to be 18 years or older (by self-report). A 30 Renminbi incentive for each complete survey was provided to boost the respond rate. With the respondents’ consent their Weibo posts that were posted in the public domain during the 12 months before the survey were downloaded by calling Weibo API. The survey fulfilled the Checklist for Reporting Results of Internet E-Surveys (CHERRIES) checklist and details of the procedure have been reported in previous publications [2232]. In addition when multiple survey feedback were submitted from the same Internet protocol addresses only the first submission was used to avoid duplicate participation. In contrast to a previous study [32] this study excluded those who posted nothing throughout the 12 months but not those who posted fewer than 100 posts. Eventually data provided by 974 respondents remained for further analyses. The study has obtained ethical approvals from the Human Research Ethical Review Committee at the University of Hong Kong and the Institute Review Board of the Institute of Psychology at the Chinese Academy of Sciences. The survey measured respondents’ suicide probability score depression anxiety stress and Weibo suicide communication (WSC) as the outcome variables. In addition the respondents’ Weibo posts language features were extracted as independent variables or features for machine learning. The details of how those data were obtained are elaborated in the following subsections.,a webbased survey of weibo user wa conducted to ass the respondent suicide risk and emotional distress ie depression anxiety and stress the invitation letter to participate in this survey wa widely sent out to general weibo user by various promotion activity for a weibo user to be eligible for the study she or he had to be year or older by selfreport a renminbi incentive for each complete survey wa provided to boost the respond rate with the respondent consent their weibo post that were posted in the public domain during the month before the survey were downloaded by calling weibo api the survey fulfilled the checklist for reporting result of internet esurveys cherry checklist and detail of the procedure have been reported in previous publication in addition when multiple survey feedback were submitted from the same internet protocol address only the first submission wa used to avoid duplicate participation in contrast to a previous study this study excluded those who posted nothing throughout the month but not those who posted fewer than post eventually data provided by respondent remained for further analysis the study ha obtained ethical approval from the human research ethical review committee at the university of hong kong and the institute review board of the institute of psychology at the chinese academy of science the survey measured respondent suicide probability score depression anxiety stress and weibo suicide communication wsc a the outcome variable in addition the respondent weibo post language feature were extracted a independent variable or feature for machine learning the detail of how those data were obtained are elaborated in the following subsection,"['webbased', 'survey', 'weibo', 'user', 'wa', 'conducted', 'ass', 'respondent', 'suicide', 'risk', 'emotional', 'distress', 'ie', 'depression', 'anxiety', 'stress', 'invitation', 'letter', 'participate', 'survey', 'wa', 'widely', 'sent', 'general', 'weibo', 'user', 'various', 'promotion', 'activity', 'weibo', 'user', 'eligible', 'study', 'year', 'older', 'selfreport', 'renminbi', 'incentive', 'complete', 'survey', 'wa', 'provided', 'boost', 'respond', 'rate', 'respondent', 'consent', 'weibo', 'post', 'posted', 'public', 'domain', 'month', 'survey', 'downloaded', 'calling', 'weibo', 'api', 'survey', 'fulfilled', 'checklist', 'reporting', 'result', 'internet', 'esurveys', 'cherry', 'checklist', 'detail', 'procedure', 'reported', 'previous', 'publication', 'addition', 'multiple', 'survey', 'feedback', 'submitted', 'internet', 'protocol', 'address', 'first', 'submission', 'wa', 'used', 'avoid', 'duplicate', 'participation', 'contrast', 'previous', 'study', 'study', 'excluded', 'posted', 'nothing', 'throughout', 'month', 'posted', 'fewer', 'post', 'eventually', 'data', 'provided', 'respondent', 'remained', 'analysis', 'study', 'ha', 'obtained', 'ethical', 'approval', 'human', 'research', 'ethical', 'review', 'committee', 'university', 'hong', 'kong', 'institute', 'review', 'board', 'institute', 'psychology', 'chinese', 'academy', 'science', 'survey', 'measured', 'respondent', 'suicide', 'probability', 'score', 'depression', 'anxiety', 'stress', 'weibo', 'suicide', 'communication', 'wsc', 'outcome', 'variable', 'addition', 'respondent', 'weibo', 'post', 'language', 'feature', 'extracted', 'independent', 'variable', 'feature', 'machine', 'learning', 'detail', 'data', 'obtained', 'elaborated', 'following', 'subsection']","['webbased survey', 'survey weibo', 'weibo user', 'user wa', 'wa conducted', 'conducted ass', 'ass respondent', 'respondent suicide', 'suicide risk', 'risk emotional', 'emotional distress', 'distress ie', 'ie depression', 'depression anxiety', 'anxiety stress', 'stress invitation', 'invitation letter', 'letter participate', 'participate survey', 'survey wa', 'wa widely', 'widely sent', 'sent general', 'general weibo', 'weibo user', 'user various', 'various promotion', 'promotion activity', 'activity weibo', 'weibo user', 'user eligible', 'eligible study', 'study year', 'year older', 'older selfreport', 'selfreport renminbi', 'renminbi incentive', 'incentive complete', 'complete survey', 'survey wa', 'wa provided', 'provided boost', 'boost respond', 'respond rate', 'rate respondent', 'respondent consent', 'consent weibo', 'weibo post', 'post posted', 'posted public', 'public domain', 'domain month', 'month survey', 'survey downloaded', 'downloaded calling', 'calling weibo', 'weibo api', 'api survey', 'survey fulfilled', 'fulfilled checklist', 'checklist reporting', 'reporting result', 'result internet', 'internet esurveys', 'esurveys cherry', 'cherry checklist', 'checklist detail', 'detail procedure', 'procedure reported', 'reported previous', 'previous publication', 'publication addition', 'addition multiple', 'multiple survey', 'survey feedback', 'feedback submitted', 'submitted internet', 'internet protocol', 'protocol address', 'address first', 'first submission', 'submission wa', 'wa used', 'used avoid', 'avoid duplicate', 'duplicate participation', 'participation contrast', 'contrast previous', 'previous study', 'study study', 'study excluded', 'excluded posted', 'posted nothing', 'nothing throughout', 'throughout month', 'month posted', 'posted fewer', 'fewer post', 'post eventually', 'eventually data', 'data provided', 'provided respondent', 'respondent remained', 'remained analysis', 'analysis study', 'study ha', 'ha obtained', 'obtained ethical', 'ethical approval', 'approval human', 'human research', 'research ethical', 'ethical review', 'review committee', 'committee university', 'university hong', 'hong kong', 'kong institute', 'institute review', 'review board', 'board institute', 'institute psychology', 'psychology chinese', 'chinese academy', 'academy science', 'science survey', 'survey measured', 'measured respondent', 'respondent suicide', 'suicide probability', 'probability score', 'score depression', 'depression anxiety', 'anxiety stress', 'stress weibo', 'weibo suicide', 'suicide communication', 'communication wsc', 'wsc outcome', 'outcome variable', 'variable addition', 'addition respondent', 'respondent weibo', 'weibo post', 'post language', 'language feature', 'feature extracted', 'extracted independent', 'independent variable', 'variable feature', 'feature machine', 'machine learning', 'learning detail', 'detail data', 'data obtained', 'obtained elaborated', 'elaborated following', 'following subsection']","['webbased survey weibo', 'survey weibo user', 'weibo user wa', 'user wa conducted', 'wa conducted ass', 'conducted ass respondent', 'ass respondent suicide', 'respondent suicide risk', 'suicide risk emotional', 'risk emotional distress', 'emotional distress ie', 'distress ie depression', 'ie depression anxiety', 'depression anxiety stress', 'anxiety stress invitation', 'stress invitation letter', 'invitation letter participate', 'letter participate survey', 'participate survey wa', 'survey wa widely', 'wa widely sent', 'widely sent general', 'sent general weibo', 'general weibo user', 'weibo user various', 'user various promotion', 'various promotion activity', 'promotion activity weibo', 'activity weibo user', 'weibo user eligible', 'user eligible study', 'eligible study year', 'study year older', 'year older selfreport', 'older selfreport renminbi', 'selfreport renminbi incentive', 'renminbi incentive complete', 'incentive complete survey', 'complete survey wa', 'survey wa provided', 'wa provided boost', 'provided boost respond', 'boost respond rate', 'respond rate respondent', 'rate respondent consent', 'respondent consent weibo', 'consent weibo post', 'weibo post posted', 'post posted public', 'posted public domain', 'public domain month', 'domain month survey', 'month survey downloaded', 'survey downloaded calling', 'downloaded calling weibo', 'calling weibo api', 'weibo api survey', 'api survey fulfilled', 'survey fulfilled checklist', 'fulfilled checklist reporting', 'checklist reporting result', 'reporting result internet', 'result internet esurveys', 'internet esurveys cherry', 'esurveys cherry checklist', 'cherry checklist detail', 'checklist detail procedure', 'detail procedure reported', 'procedure reported previous', 'reported previous publication', 'previous publication addition', 'publication addition multiple', 'addition multiple survey', 'multiple survey feedback', 'survey feedback submitted', 'feedback submitted internet', 'submitted internet protocol', 'internet protocol address', 'protocol address first', 'address first submission', 'first submission wa', 'submission wa used', 'wa used avoid', 'used avoid duplicate', 'avoid duplicate participation', 'duplicate participation contrast', 'participation contrast previous', 'contrast previous study', 'previous study study', 'study study excluded', 'study excluded posted', 'excluded posted nothing', 'posted nothing throughout', 'nothing throughout month', 'throughout month posted', 'month posted fewer', 'posted fewer post', 'fewer post eventually', 'post eventually data', 'eventually data provided', 'data provided respondent', 'provided respondent remained', 'respondent remained analysis', 'remained analysis study', 'analysis study ha', 'study ha obtained', 'ha obtained ethical', 'obtained ethical approval', 'ethical approval human', 'approval human research', 'human research ethical', 'research ethical review', 'ethical review committee', 'review committee university', 'committee university hong', 'university hong kong', 'hong kong institute', 'kong institute review', 'institute review board', 'review board institute', 'board institute psychology', 'institute psychology chinese', 'psychology chinese academy', 'chinese academy science', 'academy science survey', 'science survey measured', 'survey measured respondent', 'measured respondent suicide', 'respondent suicide probability', 'suicide probability score', 'probability score depression', 'score depression anxiety', 'depression anxiety stress', 'anxiety stress weibo', 'stress weibo suicide', 'weibo suicide communication', 'suicide communication wsc', 'communication wsc outcome', 'wsc outcome variable', 'outcome variable addition', 'variable addition respondent', 'addition respondent weibo', 'respondent weibo post', 'weibo post language', 'post language feature', 'language feature extracted', 'feature extracted independent', 'extracted independent variable', 'independent variable feature', 'variable feature machine', 'feature machine learning', 'machine learning detail', 'learning detail data', 'detail data obtained', 'data obtained elaborated', 'obtained elaborated following', 'elaborated following subsection']",,,,,,,
https://dl.acm.org/doi/abs/10.1145/3025453.3025909,1,We first obtained a list of 150 ranked major universities in the United States by crawling the US News and World Report website [48]. This list is constructed based on the Carnegie classification employed extensively by higher education researchers and using a set of 16 indicators of academic excellence defined by US News. The list includes a variety of universities spread across the US in different settings (e.g. urban rural) and with a wide range of student enrollment sizes. Figure 1(a) shows their geographic distribution. As a part of this crawl we also obtained university metadata: gender distribution of students average tuition and fees and academic calendar (semester/quarter). To obtain further information about the nature of the student body we crawled the Wikipedia pages of all of the 150 universities. From these pages we extracted the size of student enrollment type (public/private) and setting (rural/suburban/urban/city) at every institution. These definitions come from a formal categorization scheme used by the US Department of Education. The student body enrollment sizes ranged from 2255 to 97494 with 98 public and 52 private universities. 50 universities were reported to be urban 47 city 39 suburban and 13 rural. Finally we obtained information on racial diversity of the universities from a website known as Priceonomics [58]. The website calculates the Herfindahl-Hirschman Index (HHI) by combining the race/ethnicity distribution of student bodies at different universities with data given from the Department of Education. HHI ranges from 1 (the least diverse: a population of all one type) to 1/N (the most diverse) where N is the number of different racial categories being analyzed. Social Media Data of Universities Next we obtained social media data of the above universities. Specifically we focused on the social media Reddit. Why Reddit? Reddit is known to be a widely used online forum and social media site among the college student demographic [23]. Due to its forum structure it is extensively used for both content sharing as well as for obtaining feedback and information from communities of interest. Reddit harbors a variety of communities known as “subreddits” including many dedicated to specific university campuses. This allows a large sample of posts shared by students of a university to be collected in one place. Our preliminary manual inspection of university subreddits (e.g. r/gatech or r/KState) revealed that these subreddits are appropriated by students to discuss college topics (Table 1). Focusing on these public Reddit communities also does not require explicit data collection efforts to be coordinated at each of the 150 university sites. Although more students are likely to use Facebook due to its largely privately shared content it is challenging to obtain access to a large dataset of a university’s students. Next while Twitter is also widely adopted without explicit self-reported information it is challenging to identify college student accounts. Finally prior work [2 18] notes that semianonymity of Reddit enables candid self disclosure around stigmatized topics like mental health. Initial Data Acquisition. We leveraged the archive of all of Reddit data made available on Google’s BigQuery [11]. BigQuery is a cloud based managed data warehouse that allows third parties to access large publicly available dataset through simple SQL-type queries. Our queries grabbed all posts ranging between June 2011 and February 2016 available in the Reddit data archive. This included 424984 posts from 153378 unique users across all of the 146 universities with a mean of 2910.8 posts ( = 4329.6) and 1050 unique users ( = 1407) per subreddit. Filling the Gaps in Subreddit Data. The second step of our data collection process focused on identifying subreddits with insufficient data and supplementing them through additional alternative data collection. Through Reddit’s official API (https://www.reddit.com/dev/api/) we obtained the most recent number of subscribers in the 146 university subreddits (as of July 2016). Then to investigate if and to what extent some subreddits may have had unusually low data as given in step 1 we determined the median unique user to subscriber ratio in each subreddit. This allows us to capture the subreddits where the subscriber count is high however the data obtained is not sufficiently representative. For subreddits with unique user to subscriber ratio under median (.42) (73 in all) we performed a one-time data collection using the Reddit API. This gave us a set of (at most) 1000 most recent posts for each subreddit with a total of 39824 posts added to the data obtained in step 1 following de-duplication. We note that this procedure did not skew the yearly distributions of data across the subreddits: The skew (yearly rate of change) before and after data filling were 4.86 and 5.05 respectively which were found to be statistically equivalent based on a two-sample equivalence test (p = .013 p = .025) a test that uses two one-sided t-tests on the before-after yearly rates of change from both sides of a chosen difference interval [1 1].,we first obtained a list of ranked major university in the united state by crawling the u news and world report website this list is constructed based on the carnegie classification employed extensively by higher education researcher and using a set of indicator of academic excellence defined by u news the list includes a variety of university spread across the u in different setting eg urban rural and with a wide range of student enrollment size figure a show their geographic distribution a a part of this crawl we also obtained university metadata gender distribution of student average tuition and fee and academic calendar semesterquarter to obtain further information about the nature of the student body we crawled the wikipedia page of all of the university from these page we extracted the size of student enrollment type publicprivate and setting ruralsuburbanurbancity at every institution these definition come from a formal categorization scheme used by the u department of education the student body enrollment size ranged from to with public and private university university were reported to be urban city suburban and rural finally we obtained information on racial diversity of the university from a website known a priceonomics the website calculates the herfindahlhirschman index hhi by combining the raceethnicity distribution of student body at different university with data given from the department of education hhi range from the least diverse a population of all one type to n the most diverse where n is the number of different racial category being analyzed social medium data of university next we obtained social medium data of the above university specifically we focused on the social medium reddit why reddit reddit is known to be a widely used online forum and social medium site among the college student demographic due to it forum structure it is extensively used for both content sharing a well a for obtaining feedback and information from community of interest reddit harbor a variety of community known a subreddits including many dedicated to specific university campus this allows a large sample of post shared by student of a university to be collected in one place our preliminary manual inspection of university subreddits eg rgatech or rkstate revealed that these subreddits are appropriated by student to discus college topic table focusing on these public reddit community also doe not require explicit data collection effort to be coordinated at each of the university site although more student are likely to use facebook due to it largely privately shared content it is challenging to obtain access to a large dataset of a university student next while twitter is also widely adopted without explicit selfreported information it is challenging to identify college student account finally prior work note that semianonymity of reddit enables candid self disclosure around stigmatized topic like mental health initial data acquisition we leveraged the archive of all of reddit data made available on google bigquery bigquery is a cloud based managed data warehouse that allows third party to access large publicly available dataset through simple sqltype query our query grabbed all post ranging between june and february available in the reddit data archive this included post from unique user across all of the university with a mean of post and unique user per subreddit filling the gap in subreddit data the second step of our data collection process focused on identifying subreddits with insufficient data and supplementing them through additional alternative data collection through reddits official api httpswwwredditcomdevapi we obtained the most recent number of subscriber in the university subreddits a of july then to investigate if and to what extent some subreddits may have had unusually low data a given in step we determined the median unique user to subscriber ratio in each subreddit this allows u to capture the subreddits where the subscriber count is high however the data obtained is not sufficiently representative for subreddits with unique user to subscriber ratio under median in all we performed a onetime data collection using the reddit api this gave u a set of at most most recent post for each subreddit with a total of post added to the data obtained in step following deduplication we note that this procedure did not skew the yearly distribution of data across the subreddits the skew yearly rate of change before and after data filling were and respectively which were found to be statistically equivalent based on a twosample equivalence test p p a test that us two onesided ttests on the beforeafter yearly rate of change from both side of a chosen difference interval,"['first', 'obtained', 'list', 'ranked', 'major', 'university', 'united', 'state', 'crawling', 'u', 'news', 'world', 'report', 'website', 'list', 'constructed', 'based', 'carnegie', 'classification', 'employed', 'extensively', 'higher', 'education', 'researcher', 'using', 'set', 'indicator', 'academic', 'excellence', 'defined', 'u', 'news', 'list', 'includes', 'variety', 'university', 'spread', 'across', 'u', 'different', 'setting', 'eg', 'urban', 'rural', 'wide', 'range', 'student', 'enrollment', 'size', 'figure', 'show', 'geographic', 'distribution', 'part', 'crawl', 'also', 'obtained', 'university', 'metadata', 'gender', 'distribution', 'student', 'average', 'tuition', 'fee', 'academic', 'calendar', 'semesterquarter', 'obtain', 'information', 'nature', 'student', 'body', 'crawled', 'wikipedia', 'page', 'university', 'page', 'extracted', 'size', 'student', 'enrollment', 'type', 'publicprivate', 'setting', 'ruralsuburbanurbancity', 'every', 'institution', 'definition', 'come', 'formal', 'categorization', 'scheme', 'used', 'u', 'department', 'education', 'student', 'body', 'enrollment', 'size', 'ranged', 'public', 'private', 'university', 'university', 'reported', 'urban', 'city', 'suburban', 'rural', 'finally', 'obtained', 'information', 'racial', 'diversity', 'university', 'website', 'known', 'priceonomics', 'website', 'calculates', 'herfindahlhirschman', 'index', 'hhi', 'combining', 'raceethnicity', 'distribution', 'student', 'body', 'different', 'university', 'data', 'given', 'department', 'education', 'hhi', 'range', 'least', 'diverse', 'population', 'one', 'type', 'n', 'diverse', 'n', 'number', 'different', 'racial', 'category', 'analyzed', 'social', 'medium', 'data', 'university', 'next', 'obtained', 'social', 'medium', 'data', 'university', 'specifically', 'focused', 'social', 'medium', 'reddit', 'reddit', 'reddit', 'known', 'widely', 'used', 'online', 'forum', 'social', 'medium', 'site', 'among', 'college', 'student', 'demographic', 'due', 'forum', 'structure', 'extensively', 'used', 'content', 'sharing', 'well', 'obtaining', 'feedback', 'information', 'community', 'interest', 'reddit', 'harbor', 'variety', 'community', 'known', 'subreddits', 'including', 'many', 'dedicated', 'specific', 'university', 'campus', 'allows', 'large', 'sample', 'post', 'shared', 'student', 'university', 'collected', 'one', 'place', 'preliminary', 'manual', 'inspection', 'university', 'subreddits', 'eg', 'rgatech', 'rkstate', 'revealed', 'subreddits', 'appropriated', 'student', 'discus', 'college', 'topic', 'table', 'focusing', 'public', 'reddit', 'community', 'also', 'doe', 'require', 'explicit', 'data', 'collection', 'effort', 'coordinated', 'university', 'site', 'although', 'student', 'likely', 'use', 'facebook', 'due', 'largely', 'privately', 'shared', 'content', 'challenging', 'obtain', 'access', 'large', 'dataset', 'university', 'student', 'next', 'twitter', 'also', 'widely', 'adopted', 'without', 'explicit', 'selfreported', 'information', 'challenging', 'identify', 'college', 'student', 'account', 'finally', 'prior', 'work', 'note', 'semianonymity', 'reddit', 'enables', 'candid', 'self', 'disclosure', 'around', 'stigmatized', 'topic', 'like', 'mental', 'health', 'initial', 'data', 'acquisition', 'leveraged', 'archive', 'reddit', 'data', 'made', 'available', 'google', 'bigquery', 'bigquery', 'cloud', 'based', 'managed', 'data', 'warehouse', 'allows', 'third', 'party', 'access', 'large', 'publicly', 'available', 'dataset', 'simple', 'sqltype', 'query', 'query', 'grabbed', 'post', 'ranging', 'june', 'february', 'available', 'reddit', 'data', 'archive', 'included', 'post', 'unique', 'user', 'across', 'university', 'mean', 'post', 'unique', 'user', 'per', 'subreddit', 'filling', 'gap', 'subreddit', 'data', 'second', 'step', 'data', 'collection', 'process', 'focused', 'identifying', 'subreddits', 'insufficient', 'data', 'supplementing', 'additional', 'alternative', 'data', 'collection', 'reddits', 'official', 'api', 'httpswwwredditcomdevapi', 'obtained', 'recent', 'number', 'subscriber', 'university', 'subreddits', 'july', 'investigate', 'extent', 'subreddits', 'may', 'unusually', 'low', 'data', 'given', 'step', 'determined', 'median', 'unique', 'user', 'subscriber', 'ratio', 'subreddit', 'allows', 'u', 'capture', 'subreddits', 'subscriber', 'count', 'high', 'however', 'data', 'obtained', 'sufficiently', 'representative', 'subreddits', 'unique', 'user', 'subscriber', 'ratio', 'median', 'performed', 'onetime', 'data', 'collection', 'using', 'reddit', 'api', 'gave', 'u', 'set', 'recent', 'post', 'subreddit', 'total', 'post', 'added', 'data', 'obtained', 'step', 'following', 'deduplication', 'note', 'procedure', 'skew', 'yearly', 'distribution', 'data', 'across', 'subreddits', 'skew', 'yearly', 'rate', 'change', 'data', 'filling', 'respectively', 'found', 'statistically', 'equivalent', 'based', 'twosample', 'equivalence', 'test', 'p', 'p', 'test', 'us', 'two', 'onesided', 'ttests', 'beforeafter', 'yearly', 'rate', 'change', 'side', 'chosen', 'difference', 'interval']","['first obtained', 'obtained list', 'list ranked', 'ranked major', 'major university', 'university united', 'united state', 'state crawling', 'crawling u', 'u news', 'news world', 'world report', 'report website', 'website list', 'list constructed', 'constructed based', 'based carnegie', 'carnegie classification', 'classification employed', 'employed extensively', 'extensively higher', 'higher education', 'education researcher', 'researcher using', 'using set', 'set indicator', 'indicator academic', 'academic excellence', 'excellence defined', 'defined u', 'u news', 'news list', 'list includes', 'includes variety', 'variety university', 'university spread', 'spread across', 'across u', 'u different', 'different setting', 'setting eg', 'eg urban', 'urban rural', 'rural wide', 'wide range', 'range student', 'student enrollment', 'enrollment size', 'size figure', 'figure show', 'show geographic', 'geographic distribution', 'distribution part', 'part crawl', 'crawl also', 'also obtained', 'obtained university', 'university metadata', 'metadata gender', 'gender distribution', 'distribution student', 'student average', 'average tuition', 'tuition fee', 'fee academic', 'academic calendar', 'calendar semesterquarter', 'semesterquarter obtain', 'obtain information', 'information nature', 'nature student', 'student body', 'body crawled', 'crawled wikipedia', 'wikipedia page', 'page university', 'university page', 'page extracted', 'extracted size', 'size student', 'student enrollment', 'enrollment type', 'type publicprivate', 'publicprivate setting', 'setting ruralsuburbanurbancity', 'ruralsuburbanurbancity every', 'every institution', 'institution definition', 'definition come', 'come formal', 'formal categorization', 'categorization scheme', 'scheme used', 'used u', 'u department', 'department education', 'education student', 'student body', 'body enrollment', 'enrollment size', 'size ranged', 'ranged public', 'public private', 'private university', 'university university', 'university reported', 'reported urban', 'urban city', 'city suburban', 'suburban rural', 'rural finally', 'finally obtained', 'obtained information', 'information racial', 'racial diversity', 'diversity university', 'university website', 'website known', 'known priceonomics', 'priceonomics website', 'website calculates', 'calculates herfindahlhirschman', 'herfindahlhirschman index', 'index hhi', 'hhi combining', 'combining raceethnicity', 'raceethnicity distribution', 'distribution student', 'student body', 'body different', 'different university', 'university data', 'data given', 'given department', 'department education', 'education hhi', 'hhi range', 'range least', 'least diverse', 'diverse population', 'population one', 'one type', 'type n', 'n diverse', 'diverse n', 'n number', 'number different', 'different racial', 'racial category', 'category analyzed', 'analyzed social', 'social medium', 'medium data', 'data university', 'university next', 'next obtained', 'obtained social', 'social medium', 'medium data', 'data university', 'university specifically', 'specifically focused', 'focused social', 'social medium', 'medium reddit', 'reddit reddit', 'reddit reddit', 'reddit known', 'known widely', 'widely used', 'used online', 'online forum', 'forum social', 'social medium', 'medium site', 'site among', 'among college', 'college student', 'student demographic', 'demographic due', 'due forum', 'forum structure', 'structure extensively', 'extensively used', 'used content', 'content sharing', 'sharing well', 'well obtaining', 'obtaining feedback', 'feedback information', 'information community', 'community interest', 'interest reddit', 'reddit harbor', 'harbor variety', 'variety community', 'community known', 'known subreddits', 'subreddits including', 'including many', 'many dedicated', 'dedicated specific', 'specific university', 'university campus', 'campus allows', 'allows large', 'large sample', 'sample post', 'post shared', 'shared student', 'student university', 'university collected', 'collected one', 'one place', 'place preliminary', 'preliminary manual', 'manual inspection', 'inspection university', 'university subreddits', 'subreddits eg', 'eg rgatech', 'rgatech rkstate', 'rkstate revealed', 'revealed subreddits', 'subreddits appropriated', 'appropriated student', 'student discus', 'discus college', 'college topic', 'topic table', 'table focusing', 'focusing public', 'public reddit', 'reddit community', 'community also', 'also doe', 'doe require', 'require explicit', 'explicit data', 'data collection', 'collection effort', 'effort coordinated', 'coordinated university', 'university site', 'site although', 'although student', 'student likely', 'likely use', 'use facebook', 'facebook due', 'due largely', 'largely privately', 'privately shared', 'shared content', 'content challenging', 'challenging obtain', 'obtain access', 'access large', 'large dataset', 'dataset university', 'university student', 'student next', 'next twitter', 'twitter also', 'also widely', 'widely adopted', 'adopted without', 'without explicit', 'explicit selfreported', 'selfreported information', 'information challenging', 'challenging identify', 'identify college', 'college student', 'student account', 'account finally', 'finally prior', 'prior work', 'work note', 'note semianonymity', 'semianonymity reddit', 'reddit enables', 'enables candid', 'candid self', 'self disclosure', 'disclosure around', 'around stigmatized', 'stigmatized topic', 'topic like', 'like mental', 'mental health', 'health initial', 'initial data', 'data acquisition', 'acquisition leveraged', 'leveraged archive', 'archive reddit', 'reddit data', 'data made', 'made available', 'available google', 'google bigquery', 'bigquery bigquery', 'bigquery cloud', 'cloud based', 'based managed', 'managed data', 'data warehouse', 'warehouse allows', 'allows third', 'third party', 'party access', 'access large', 'large publicly', 'publicly available', 'available dataset', 'dataset simple', 'simple sqltype', 'sqltype query', 'query query', 'query grabbed', 'grabbed post', 'post ranging', 'ranging june', 'june february', 'february available', 'available reddit', 'reddit data', 'data archive', 'archive included', 'included post', 'post unique', 'unique user', 'user across', 'across university', 'university mean', 'mean post', 'post unique', 'unique user', 'user per', 'per subreddit', 'subreddit filling', 'filling gap', 'gap subreddit', 'subreddit data', 'data second', 'second step', 'step data', 'data collection', 'collection process', 'process focused', 'focused identifying', 'identifying subreddits', 'subreddits insufficient', 'insufficient data', 'data supplementing', 'supplementing additional', 'additional alternative', 'alternative data', 'data collection', 'collection reddits', 'reddits official', 'official api', 'api httpswwwredditcomdevapi', 'httpswwwredditcomdevapi obtained', 'obtained recent', 'recent number', 'number subscriber', 'subscriber university', 'university subreddits', 'subreddits july', 'july investigate', 'investigate extent', 'extent subreddits', 'subreddits may', 'may unusually', 'unusually low', 'low data', 'data given', 'given step', 'step determined', 'determined median', 'median unique', 'unique user', 'user subscriber', 'subscriber ratio', 'ratio subreddit', 'subreddit allows', 'allows u', 'u capture', 'capture subreddits', 'subreddits subscriber', 'subscriber count', 'count high', 'high however', 'however data', 'data obtained', 'obtained sufficiently', 'sufficiently representative', 'representative subreddits', 'subreddits unique', 'unique user', 'user subscriber', 'subscriber ratio', 'ratio median', 'median performed', 'performed onetime', 'onetime data', 'data collection', 'collection using', 'using reddit', 'reddit api', 'api gave', 'gave u', 'u set', 'set recent', 'recent post', 'post subreddit', 'subreddit total', 'total post', 'post added', 'added data', 'data obtained', 'obtained step', 'step following', 'following deduplication', 'deduplication note', 'note procedure', 'procedure skew', 'skew yearly', 'yearly distribution', 'distribution data', 'data across', 'across subreddits', 'subreddits skew', 'skew yearly', 'yearly rate', 'rate change', 'change data', 'data filling', 'filling respectively', 'respectively found', 'found statistically', 'statistically equivalent', 'equivalent based', 'based twosample', 'twosample equivalence', 'equivalence test', 'test p', 'p p', 'p test', 'test us', 'us two', 'two onesided', 'onesided ttests', 'ttests beforeafter', 'beforeafter yearly', 'yearly rate', 'rate change', 'change side', 'side chosen', 'chosen difference', 'difference interval']","['first obtained list', 'obtained list ranked', 'list ranked major', 'ranked major university', 'major university united', 'university united state', 'united state crawling', 'state crawling u', 'crawling u news', 'u news world', 'news world report', 'world report website', 'report website list', 'website list constructed', 'list constructed based', 'constructed based carnegie', 'based carnegie classification', 'carnegie classification employed', 'classification employed extensively', 'employed extensively higher', 'extensively higher education', 'higher education researcher', 'education researcher using', 'researcher using set', 'using set indicator', 'set indicator academic', 'indicator academic excellence', 'academic excellence defined', 'excellence defined u', 'defined u news', 'u news list', 'news list includes', 'list includes variety', 'includes variety university', 'variety university spread', 'university spread across', 'spread across u', 'across u different', 'u different setting', 'different setting eg', 'setting eg urban', 'eg urban rural', 'urban rural wide', 'rural wide range', 'wide range student', 'range student enrollment', 'student enrollment size', 'enrollment size figure', 'size figure show', 'figure show geographic', 'show geographic distribution', 'geographic distribution part', 'distribution part crawl', 'part crawl also', 'crawl also obtained', 'also obtained university', 'obtained university metadata', 'university metadata gender', 'metadata gender distribution', 'gender distribution student', 'distribution student average', 'student average tuition', 'average tuition fee', 'tuition fee academic', 'fee academic calendar', 'academic calendar semesterquarter', 'calendar semesterquarter obtain', 'semesterquarter obtain information', 'obtain information nature', 'information nature student', 'nature student body', 'student body crawled', 'body crawled wikipedia', 'crawled wikipedia page', 'wikipedia page university', 'page university page', 'university page extracted', 'page extracted size', 'extracted size student', 'size student enrollment', 'student enrollment type', 'enrollment type publicprivate', 'type publicprivate setting', 'publicprivate setting ruralsuburbanurbancity', 'setting ruralsuburbanurbancity every', 'ruralsuburbanurbancity every institution', 'every institution definition', 'institution definition come', 'definition come formal', 'come formal categorization', 'formal categorization scheme', 'categorization scheme used', 'scheme used u', 'used u department', 'u department education', 'department education student', 'education student body', 'student body enrollment', 'body enrollment size', 'enrollment size ranged', 'size ranged public', 'ranged public private', 'public private university', 'private university university', 'university university reported', 'university reported urban', 'reported urban city', 'urban city suburban', 'city suburban rural', 'suburban rural finally', 'rural finally obtained', 'finally obtained information', 'obtained information racial', 'information racial diversity', 'racial diversity university', 'diversity university website', 'university website known', 'website known priceonomics', 'known priceonomics website', 'priceonomics website calculates', 'website calculates herfindahlhirschman', 'calculates herfindahlhirschman index', 'herfindahlhirschman index hhi', 'index hhi combining', 'hhi combining raceethnicity', 'combining raceethnicity distribution', 'raceethnicity distribution student', 'distribution student body', 'student body different', 'body different university', 'different university data', 'university data given', 'data given department', 'given department education', 'department education hhi', 'education hhi range', 'hhi range least', 'range least diverse', 'least diverse population', 'diverse population one', 'population one type', 'one type n', 'type n diverse', 'n diverse n', 'diverse n number', 'n number different', 'number different racial', 'different racial category', 'racial category analyzed', 'category analyzed social', 'analyzed social medium', 'social medium data', 'medium data university', 'data university next', 'university next obtained', 'next obtained social', 'obtained social medium', 'social medium data', 'medium data university', 'data university specifically', 'university specifically focused', 'specifically focused social', 'focused social medium', 'social medium reddit', 'medium reddit reddit', 'reddit reddit reddit', 'reddit reddit known', 'reddit known widely', 'known widely used', 'widely used online', 'used online forum', 'online forum social', 'forum social medium', 'social medium site', 'medium site among', 'site among college', 'among college student', 'college student demographic', 'student demographic due', 'demographic due forum', 'due forum structure', 'forum structure extensively', 'structure extensively used', 'extensively used content', 'used content sharing', 'content sharing well', 'sharing well obtaining', 'well obtaining feedback', 'obtaining feedback information', 'feedback information community', 'information community interest', 'community interest reddit', 'interest reddit harbor', 'reddit harbor variety', 'harbor variety community', 'variety community known', 'community known subreddits', 'known subreddits including', 'subreddits including many', 'including many dedicated', 'many dedicated specific', 'dedicated specific university', 'specific university campus', 'university campus allows', 'campus allows large', 'allows large sample', 'large sample post', 'sample post shared', 'post shared student', 'shared student university', 'student university collected', 'university collected one', 'collected one place', 'one place preliminary', 'place preliminary manual', 'preliminary manual inspection', 'manual inspection university', 'inspection university subreddits', 'university subreddits eg', 'subreddits eg rgatech', 'eg rgatech rkstate', 'rgatech rkstate revealed', 'rkstate revealed subreddits', 'revealed subreddits appropriated', 'subreddits appropriated student', 'appropriated student discus', 'student discus college', 'discus college topic', 'college topic table', 'topic table focusing', 'table focusing public', 'focusing public reddit', 'public reddit community', 'reddit community also', 'community also doe', 'also doe require', 'doe require explicit', 'require explicit data', 'explicit data collection', 'data collection effort', 'collection effort coordinated', 'effort coordinated university', 'coordinated university site', 'university site although', 'site although student', 'although student likely', 'student likely use', 'likely use facebook', 'use facebook due', 'facebook due largely', 'due largely privately', 'largely privately shared', 'privately shared content', 'shared content challenging', 'content challenging obtain', 'challenging obtain access', 'obtain access large', 'access large dataset', 'large dataset university', 'dataset university student', 'university student next', 'student next twitter', 'next twitter also', 'twitter also widely', 'also widely adopted', 'widely adopted without', 'adopted without explicit', 'without explicit selfreported', 'explicit selfreported information', 'selfreported information challenging', 'information challenging identify', 'challenging identify college', 'identify college student', 'college student account', 'student account finally', 'account finally prior', 'finally prior work', 'prior work note', 'work note semianonymity', 'note semianonymity reddit', 'semianonymity reddit enables', 'reddit enables candid', 'enables candid self', 'candid self disclosure', 'self disclosure around', 'disclosure around stigmatized', 'around stigmatized topic', 'stigmatized topic like', 'topic like mental', 'like mental health', 'mental health initial', 'health initial data', 'initial data acquisition', 'data acquisition leveraged', 'acquisition leveraged archive', 'leveraged archive reddit', 'archive reddit data', 'reddit data made', 'data made available', 'made available google', 'available google bigquery', 'google bigquery bigquery', 'bigquery bigquery cloud', 'bigquery cloud based', 'cloud based managed', 'based managed data', 'managed data warehouse', 'data warehouse allows', 'warehouse allows third', 'allows third party', 'third party access', 'party access large', 'access large publicly', 'large publicly available', 'publicly available dataset', 'available dataset simple', 'dataset simple sqltype', 'simple sqltype query', 'sqltype query query', 'query query grabbed', 'query grabbed post', 'grabbed post ranging', 'post ranging june', 'ranging june february', 'june february available', 'february available reddit', 'available reddit data', 'reddit data archive', 'data archive included', 'archive included post', 'included post unique', 'post unique user', 'unique user across', 'user across university', 'across university mean', 'university mean post', 'mean post unique', 'post unique user', 'unique user per', 'user per subreddit', 'per subreddit filling', 'subreddit filling gap', 'filling gap subreddit', 'gap subreddit data', 'subreddit data second', 'data second step', 'second step data', 'step data collection', 'data collection process', 'collection process focused', 'process focused identifying', 'focused identifying subreddits', 'identifying subreddits insufficient', 'subreddits insufficient data', 'insufficient data supplementing', 'data supplementing additional', 'supplementing additional alternative', 'additional alternative data', 'alternative data collection', 'data collection reddits', 'collection reddits official', 'reddits official api', 'official api httpswwwredditcomdevapi', 'api httpswwwredditcomdevapi obtained', 'httpswwwredditcomdevapi obtained recent', 'obtained recent number', 'recent number subscriber', 'number subscriber university', 'subscriber university subreddits', 'university subreddits july', 'subreddits july investigate', 'july investigate extent', 'investigate extent subreddits', 'extent subreddits may', 'subreddits may unusually', 'may unusually low', 'unusually low data', 'low data given', 'data given step', 'given step determined', 'step determined median', 'determined median unique', 'median unique user', 'unique user subscriber', 'user subscriber ratio', 'subscriber ratio subreddit', 'ratio subreddit allows', 'subreddit allows u', 'allows u capture', 'u capture subreddits', 'capture subreddits subscriber', 'subreddits subscriber count', 'subscriber count high', 'count high however', 'high however data', 'however data obtained', 'data obtained sufficiently', 'obtained sufficiently representative', 'sufficiently representative subreddits', 'representative subreddits unique', 'subreddits unique user', 'unique user subscriber', 'user subscriber ratio', 'subscriber ratio median', 'ratio median performed', 'median performed onetime', 'performed onetime data', 'onetime data collection', 'data collection using', 'collection using reddit', 'using reddit api', 'reddit api gave', 'api gave u', 'gave u set', 'u set recent', 'set recent post', 'recent post subreddit', 'post subreddit total', 'subreddit total post', 'total post added', 'post added data', 'added data obtained', 'data obtained step', 'obtained step following', 'step following deduplication', 'following deduplication note', 'deduplication note procedure', 'note procedure skew', 'procedure skew yearly', 'skew yearly distribution', 'yearly distribution data', 'distribution data across', 'data across subreddits', 'across subreddits skew', 'subreddits skew yearly', 'skew yearly rate', 'yearly rate change', 'rate change data', 'change data filling', 'data filling respectively', 'filling respectively found', 'respectively found statistically', 'found statistically equivalent', 'statistically equivalent based', 'equivalent based twosample', 'based twosample equivalence', 'twosample equivalence test', 'equivalence test p', 'test p p', 'p p test', 'p test us', 'test us two', 'us two onesided', 'two onesided ttests', 'onesided ttests beforeafter', 'ttests beforeafter yearly', 'beforeafter yearly rate', 'yearly rate change', 'rate change side', 'change side chosen', 'side chosen difference', 'chosen difference interval']",,,,,,,
https://ieeexplore.ieee.org/abstract/document/7752434,1,In this work we are focused on two main type of features (linguistic and behavioral). TF-IDF is adopted to model the linguist features of patients and Pattern of Life Features (PLF) adopted from the work of Coppersmith et al. [1] is used to model the behavioral style of patients. TF-IDF Features To capture the frequent and representative words used by the patients TF-IDF is applied on the unigram and bigrams collected from all the patients' tweets. Pattern of Life Features (PLF) These features reveal the emotional patterns and behavioral tendency of users by measuring polarity emotion and social interactions. In order to fully compose the PLF we combined the following list of features: Age and Gender: Twitter does not publicly provide information about the age and gender of its users mainly due to privacy concerns so we adopted the work of Sap et al. [5] to fill in this information. Polarity Features: The Sentiment140 API 3 was used to label each tweet as either positive negative or neutral. The polarity is furthermore transformed into five different values to capture the affective traits of each user: 1) Positive Ratio: the percentage of positive tweets 2) Negative Ratio: the percentage of negative tweets 3) Positive Combo: captures the mania and hypomania traits of patients which is determined by the number of continuous positive posts appearing more than x amount of times within a period of time in minutes T. 4) Negative Combos: captures the depression traits of patients and is determined by the number of continuous negative posts appearing more than x amount of times within a period of time in minutes T. 5) Flips Ratio: quantifies the emotional unstableness and is determined by counting how frequently two continuous tweets with different polarity (either positive to negative or negative to positive) appear together within a period of time in minutes T. In our work x is set to 2 and T is set to 30 minutes. Social Features: These features can demonstrate how users are behaving with respect to their environment. The following are the social features designed for each user: 1) Tweeting Frequency; the frequency of daily posts; 2) Mention Ratio: the percentage of posts which contain at least one mention of another user; 3) Frequent Mentions: the number of Twitter users mentioned more than three times which is a measurement of how many close friends a particular user may have; 4) Unique Mentions: the number of unique users mentioned which is a measure of the width of a user's social network.,in this work we are focused on two main type of feature linguistic and behavioral tfidf is adopted to model the linguist feature of patient and pattern of life feature plf adopted from the work of coppersmith et al is used to model the behavioral style of patient tfidf feature to capture the frequent and representative word used by the patient tfidf is applied on the unigram and bigram collected from all the patient tweet pattern of life feature plf these feature reveal the emotional pattern and behavioral tendency of user by measuring polarity emotion and social interaction in order to fully compose the plf we combined the following list of feature age and gender twitter doe not publicly provide information about the age and gender of it user mainly due to privacy concern so we adopted the work of sap et al to fill in this information polarity feature the sentiment api wa used to label each tweet a either positive negative or neutral the polarity is furthermore transformed into five different value to capture the affective trait of each user positive ratio the percentage of positive tweet negative ratio the percentage of negative tweet positive combo capture the mania and hypomania trait of patient which is determined by the number of continuous positive post appearing more than x amount of time within a period of time in minute t negative combo capture the depression trait of patient and is determined by the number of continuous negative post appearing more than x amount of time within a period of time in minute t flip ratio quantifies the emotional unstableness and is determined by counting how frequently two continuous tweet with different polarity either positive to negative or negative to positive appear together within a period of time in minute t in our work x is set to and t is set to minute social feature these feature can demonstrate how user are behaving with respect to their environment the following are the social feature designed for each user tweeting frequency the frequency of daily post mention ratio the percentage of post which contain at least one mention of another user frequent mention the number of twitter user mentioned more than three time which is a measurement of how many close friend a particular user may have unique mention the number of unique user mentioned which is a measure of the width of a user social network,"['work', 'focused', 'two', 'main', 'type', 'feature', 'linguistic', 'behavioral', 'tfidf', 'adopted', 'model', 'linguist', 'feature', 'patient', 'pattern', 'life', 'feature', 'plf', 'adopted', 'work', 'coppersmith', 'et', 'al', 'used', 'model', 'behavioral', 'style', 'patient', 'tfidf', 'feature', 'capture', 'frequent', 'representative', 'word', 'used', 'patient', 'tfidf', 'applied', 'unigram', 'bigram', 'collected', 'patient', 'tweet', 'pattern', 'life', 'feature', 'plf', 'feature', 'reveal', 'emotional', 'pattern', 'behavioral', 'tendency', 'user', 'measuring', 'polarity', 'emotion', 'social', 'interaction', 'order', 'fully', 'compose', 'plf', 'combined', 'following', 'list', 'feature', 'age', 'gender', 'twitter', 'doe', 'publicly', 'provide', 'information', 'age', 'gender', 'user', 'mainly', 'due', 'privacy', 'concern', 'adopted', 'work', 'sap', 'et', 'al', 'fill', 'information', 'polarity', 'feature', 'sentiment', 'api', 'wa', 'used', 'label', 'tweet', 'either', 'positive', 'negative', 'neutral', 'polarity', 'furthermore', 'transformed', 'five', 'different', 'value', 'capture', 'affective', 'trait', 'user', 'positive', 'ratio', 'percentage', 'positive', 'tweet', 'negative', 'ratio', 'percentage', 'negative', 'tweet', 'positive', 'combo', 'capture', 'mania', 'hypomania', 'trait', 'patient', 'determined', 'number', 'continuous', 'positive', 'post', 'appearing', 'x', 'amount', 'time', 'within', 'period', 'time', 'minute', 'negative', 'combo', 'capture', 'depression', 'trait', 'patient', 'determined', 'number', 'continuous', 'negative', 'post', 'appearing', 'x', 'amount', 'time', 'within', 'period', 'time', 'minute', 'flip', 'ratio', 'quantifies', 'emotional', 'unstableness', 'determined', 'counting', 'frequently', 'two', 'continuous', 'tweet', 'different', 'polarity', 'either', 'positive', 'negative', 'negative', 'positive', 'appear', 'together', 'within', 'period', 'time', 'minute', 'work', 'x', 'set', 'set', 'minute', 'social', 'feature', 'feature', 'demonstrate', 'user', 'behaving', 'respect', 'environment', 'following', 'social', 'feature', 'designed', 'user', 'tweeting', 'frequency', 'frequency', 'daily', 'post', 'mention', 'ratio', 'percentage', 'post', 'contain', 'least', 'one', 'mention', 'another', 'user', 'frequent', 'mention', 'number', 'twitter', 'user', 'mentioned', 'three', 'time', 'measurement', 'many', 'close', 'friend', 'particular', 'user', 'may', 'unique', 'mention', 'number', 'unique', 'user', 'mentioned', 'measure', 'width', 'user', 'social', 'network']","['work focused', 'focused two', 'two main', 'main type', 'type feature', 'feature linguistic', 'linguistic behavioral', 'behavioral tfidf', 'tfidf adopted', 'adopted model', 'model linguist', 'linguist feature', 'feature patient', 'patient pattern', 'pattern life', 'life feature', 'feature plf', 'plf adopted', 'adopted work', 'work coppersmith', 'coppersmith et', 'et al', 'al used', 'used model', 'model behavioral', 'behavioral style', 'style patient', 'patient tfidf', 'tfidf feature', 'feature capture', 'capture frequent', 'frequent representative', 'representative word', 'word used', 'used patient', 'patient tfidf', 'tfidf applied', 'applied unigram', 'unigram bigram', 'bigram collected', 'collected patient', 'patient tweet', 'tweet pattern', 'pattern life', 'life feature', 'feature plf', 'plf feature', 'feature reveal', 'reveal emotional', 'emotional pattern', 'pattern behavioral', 'behavioral tendency', 'tendency user', 'user measuring', 'measuring polarity', 'polarity emotion', 'emotion social', 'social interaction', 'interaction order', 'order fully', 'fully compose', 'compose plf', 'plf combined', 'combined following', 'following list', 'list feature', 'feature age', 'age gender', 'gender twitter', 'twitter doe', 'doe publicly', 'publicly provide', 'provide information', 'information age', 'age gender', 'gender user', 'user mainly', 'mainly due', 'due privacy', 'privacy concern', 'concern adopted', 'adopted work', 'work sap', 'sap et', 'et al', 'al fill', 'fill information', 'information polarity', 'polarity feature', 'feature sentiment', 'sentiment api', 'api wa', 'wa used', 'used label', 'label tweet', 'tweet either', 'either positive', 'positive negative', 'negative neutral', 'neutral polarity', 'polarity furthermore', 'furthermore transformed', 'transformed five', 'five different', 'different value', 'value capture', 'capture affective', 'affective trait', 'trait user', 'user positive', 'positive ratio', 'ratio percentage', 'percentage positive', 'positive tweet', 'tweet negative', 'negative ratio', 'ratio percentage', 'percentage negative', 'negative tweet', 'tweet positive', 'positive combo', 'combo capture', 'capture mania', 'mania hypomania', 'hypomania trait', 'trait patient', 'patient determined', 'determined number', 'number continuous', 'continuous positive', 'positive post', 'post appearing', 'appearing x', 'x amount', 'amount time', 'time within', 'within period', 'period time', 'time minute', 'minute negative', 'negative combo', 'combo capture', 'capture depression', 'depression trait', 'trait patient', 'patient determined', 'determined number', 'number continuous', 'continuous negative', 'negative post', 'post appearing', 'appearing x', 'x amount', 'amount time', 'time within', 'within period', 'period time', 'time minute', 'minute flip', 'flip ratio', 'ratio quantifies', 'quantifies emotional', 'emotional unstableness', 'unstableness determined', 'determined counting', 'counting frequently', 'frequently two', 'two continuous', 'continuous tweet', 'tweet different', 'different polarity', 'polarity either', 'either positive', 'positive negative', 'negative negative', 'negative positive', 'positive appear', 'appear together', 'together within', 'within period', 'period time', 'time minute', 'minute work', 'work x', 'x set', 'set set', 'set minute', 'minute social', 'social feature', 'feature feature', 'feature demonstrate', 'demonstrate user', 'user behaving', 'behaving respect', 'respect environment', 'environment following', 'following social', 'social feature', 'feature designed', 'designed user', 'user tweeting', 'tweeting frequency', 'frequency frequency', 'frequency daily', 'daily post', 'post mention', 'mention ratio', 'ratio percentage', 'percentage post', 'post contain', 'contain least', 'least one', 'one mention', 'mention another', 'another user', 'user frequent', 'frequent mention', 'mention number', 'number twitter', 'twitter user', 'user mentioned', 'mentioned three', 'three time', 'time measurement', 'measurement many', 'many close', 'close friend', 'friend particular', 'particular user', 'user may', 'may unique', 'unique mention', 'mention number', 'number unique', 'unique user', 'user mentioned', 'mentioned measure', 'measure width', 'width user', 'user social', 'social network']","['work focused two', 'focused two main', 'two main type', 'main type feature', 'type feature linguistic', 'feature linguistic behavioral', 'linguistic behavioral tfidf', 'behavioral tfidf adopted', 'tfidf adopted model', 'adopted model linguist', 'model linguist feature', 'linguist feature patient', 'feature patient pattern', 'patient pattern life', 'pattern life feature', 'life feature plf', 'feature plf adopted', 'plf adopted work', 'adopted work coppersmith', 'work coppersmith et', 'coppersmith et al', 'et al used', 'al used model', 'used model behavioral', 'model behavioral style', 'behavioral style patient', 'style patient tfidf', 'patient tfidf feature', 'tfidf feature capture', 'feature capture frequent', 'capture frequent representative', 'frequent representative word', 'representative word used', 'word used patient', 'used patient tfidf', 'patient tfidf applied', 'tfidf applied unigram', 'applied unigram bigram', 'unigram bigram collected', 'bigram collected patient', 'collected patient tweet', 'patient tweet pattern', 'tweet pattern life', 'pattern life feature', 'life feature plf', 'feature plf feature', 'plf feature reveal', 'feature reveal emotional', 'reveal emotional pattern', 'emotional pattern behavioral', 'pattern behavioral tendency', 'behavioral tendency user', 'tendency user measuring', 'user measuring polarity', 'measuring polarity emotion', 'polarity emotion social', 'emotion social interaction', 'social interaction order', 'interaction order fully', 'order fully compose', 'fully compose plf', 'compose plf combined', 'plf combined following', 'combined following list', 'following list feature', 'list feature age', 'feature age gender', 'age gender twitter', 'gender twitter doe', 'twitter doe publicly', 'doe publicly provide', 'publicly provide information', 'provide information age', 'information age gender', 'age gender user', 'gender user mainly', 'user mainly due', 'mainly due privacy', 'due privacy concern', 'privacy concern adopted', 'concern adopted work', 'adopted work sap', 'work sap et', 'sap et al', 'et al fill', 'al fill information', 'fill information polarity', 'information polarity feature', 'polarity feature sentiment', 'feature sentiment api', 'sentiment api wa', 'api wa used', 'wa used label', 'used label tweet', 'label tweet either', 'tweet either positive', 'either positive negative', 'positive negative neutral', 'negative neutral polarity', 'neutral polarity furthermore', 'polarity furthermore transformed', 'furthermore transformed five', 'transformed five different', 'five different value', 'different value capture', 'value capture affective', 'capture affective trait', 'affective trait user', 'trait user positive', 'user positive ratio', 'positive ratio percentage', 'ratio percentage positive', 'percentage positive tweet', 'positive tweet negative', 'tweet negative ratio', 'negative ratio percentage', 'ratio percentage negative', 'percentage negative tweet', 'negative tweet positive', 'tweet positive combo', 'positive combo capture', 'combo capture mania', 'capture mania hypomania', 'mania hypomania trait', 'hypomania trait patient', 'trait patient determined', 'patient determined number', 'determined number continuous', 'number continuous positive', 'continuous positive post', 'positive post appearing', 'post appearing x', 'appearing x amount', 'x amount time', 'amount time within', 'time within period', 'within period time', 'period time minute', 'time minute negative', 'minute negative combo', 'negative combo capture', 'combo capture depression', 'capture depression trait', 'depression trait patient', 'trait patient determined', 'patient determined number', 'determined number continuous', 'number continuous negative', 'continuous negative post', 'negative post appearing', 'post appearing x', 'appearing x amount', 'x amount time', 'amount time within', 'time within period', 'within period time', 'period time minute', 'time minute flip', 'minute flip ratio', 'flip ratio quantifies', 'ratio quantifies emotional', 'quantifies emotional unstableness', 'emotional unstableness determined', 'unstableness determined counting', 'determined counting frequently', 'counting frequently two', 'frequently two continuous', 'two continuous tweet', 'continuous tweet different', 'tweet different polarity', 'different polarity either', 'polarity either positive', 'either positive negative', 'positive negative negative', 'negative negative positive', 'negative positive appear', 'positive appear together', 'appear together within', 'together within period', 'within period time', 'period time minute', 'time minute work', 'minute work x', 'work x set', 'x set set', 'set set minute', 'set minute social', 'minute social feature', 'social feature feature', 'feature feature demonstrate', 'feature demonstrate user', 'demonstrate user behaving', 'user behaving respect', 'behaving respect environment', 'respect environment following', 'environment following social', 'following social feature', 'social feature designed', 'feature designed user', 'designed user tweeting', 'user tweeting frequency', 'tweeting frequency frequency', 'frequency frequency daily', 'frequency daily post', 'daily post mention', 'post mention ratio', 'mention ratio percentage', 'ratio percentage post', 'percentage post contain', 'post contain least', 'contain least one', 'least one mention', 'one mention another', 'mention another user', 'another user frequent', 'user frequent mention', 'frequent mention number', 'mention number twitter', 'number twitter user', 'twitter user mentioned', 'user mentioned three', 'mentioned three time', 'three time measurement', 'time measurement many', 'measurement many close', 'many close friend', 'close friend particular', 'friend particular user', 'particular user may', 'user may unique', 'may unique mention', 'unique mention number', 'mention number unique', 'number unique user', 'unique user mentioned', 'user mentioned measure', 'mentioned measure width', 'measure width user', 'width user social', 'user social network']",,,,,,,
https://www.nature.com/articles/s41598-020-68764-y,0,The data pre-processing procedure for the collected post data is presented in Fig. 1. After collecting the data each title was combined with its corresponding post. We removed unnecessary punctuation marks and white spaces for each post. Then we used the natural language toolkit (NLTK) implemented in Python to tokenize users’ posts and filter frequently employed words (stop words). Porter Stemmer a tool used to define a series of guidelines for exploring word meaning and source was employed on the tokenized words to convert a word to its root meaning and to decrease the number of word corpus. After this procedure data from 228060 users with 488472 posts in total were employed for the analysis.,the data preprocessing procedure for the collected post data is presented in fig after collecting the data each title wa combined with it corresponding post we removed unnecessary punctuation mark and white space for each post then we used the natural language toolkit nltk implemented in python to tokenize user post and filter frequently employed word stop word porter stemmer a tool used to define a series of guideline for exploring word meaning and source wa employed on the tokenized word to convert a word to it root meaning and to decrease the number of word corpus after this procedure data from user with post in total were employed for the analysis,"['data', 'preprocessing', 'procedure', 'collected', 'post', 'data', 'presented', 'fig', 'collecting', 'data', 'title', 'wa', 'combined', 'corresponding', 'post', 'removed', 'unnecessary', 'punctuation', 'mark', 'white', 'space', 'post', 'used', 'natural', 'language', 'toolkit', 'nltk', 'implemented', 'python', 'tokenize', 'user', 'post', 'filter', 'frequently', 'employed', 'word', 'stop', 'word', 'porter', 'stemmer', 'tool', 'used', 'define', 'series', 'guideline', 'exploring', 'word', 'meaning', 'source', 'wa', 'employed', 'tokenized', 'word', 'convert', 'word', 'root', 'meaning', 'decrease', 'number', 'word', 'corpus', 'procedure', 'data', 'user', 'post', 'total', 'employed', 'analysis']","['data preprocessing', 'preprocessing procedure', 'procedure collected', 'collected post', 'post data', 'data presented', 'presented fig', 'fig collecting', 'collecting data', 'data title', 'title wa', 'wa combined', 'combined corresponding', 'corresponding post', 'post removed', 'removed unnecessary', 'unnecessary punctuation', 'punctuation mark', 'mark white', 'white space', 'space post', 'post used', 'used natural', 'natural language', 'language toolkit', 'toolkit nltk', 'nltk implemented', 'implemented python', 'python tokenize', 'tokenize user', 'user post', 'post filter', 'filter frequently', 'frequently employed', 'employed word', 'word stop', 'stop word', 'word porter', 'porter stemmer', 'stemmer tool', 'tool used', 'used define', 'define series', 'series guideline', 'guideline exploring', 'exploring word', 'word meaning', 'meaning source', 'source wa', 'wa employed', 'employed tokenized', 'tokenized word', 'word convert', 'convert word', 'word root', 'root meaning', 'meaning decrease', 'decrease number', 'number word', 'word corpus', 'corpus procedure', 'procedure data', 'data user', 'user post', 'post total', 'total employed', 'employed analysis']","['data preprocessing procedure', 'preprocessing procedure collected', 'procedure collected post', 'collected post data', 'post data presented', 'data presented fig', 'presented fig collecting', 'fig collecting data', 'collecting data title', 'data title wa', 'title wa combined', 'wa combined corresponding', 'combined corresponding post', 'corresponding post removed', 'post removed unnecessary', 'removed unnecessary punctuation', 'unnecessary punctuation mark', 'punctuation mark white', 'mark white space', 'white space post', 'space post used', 'post used natural', 'used natural language', 'natural language toolkit', 'language toolkit nltk', 'toolkit nltk implemented', 'nltk implemented python', 'implemented python tokenize', 'python tokenize user', 'tokenize user post', 'user post filter', 'post filter frequently', 'filter frequently employed', 'frequently employed word', 'employed word stop', 'word stop word', 'stop word porter', 'word porter stemmer', 'porter stemmer tool', 'stemmer tool used', 'tool used define', 'used define series', 'define series guideline', 'series guideline exploring', 'guideline exploring word', 'exploring word meaning', 'word meaning source', 'meaning source wa', 'source wa employed', 'wa employed tokenized', 'employed tokenized word', 'tokenized word convert', 'word convert word', 'convert word root', 'word root meaning', 'root meaning decrease', 'meaning decrease number', 'decrease number word', 'number word corpus', 'word corpus procedure', 'corpus procedure data', 'procedure data user', 'data user post', 'user post total', 'post total employed', 'total employed analysis']",,,,,,,
https://aclanthology.org/W19-3013.pdf,1,Our cohort construction process entails two key steps: first randomly selecting a large sample of Twitter users; and second annotating those users with key demographic attributes. While such attributes are not provided by the API automated methods can be used to infer such traits from data (Cesare et al. 2017). Following this approach we develop a demographic inference pipeline to automatically infer age gender race/ethnicity and location for each cohort candidate. Age Identifying age based on the content of a user can be challenging and exact age often cannot be determined based on language use alone. Therefore we use discrete categories that provide a more accurate estimate of age: Teenager (below 19) 20s 30s 40s 50s (50 years or older). Gender The gender was inferred using Demographer a supervised model that predicts the (binary) gender of Twitter users with features based on the name field on the user profile (Knowles et al. 2016). Race/Ethnicity The standard formulation of race and ethnicity is not well understood by the general public so categorizing social media users along these two axes may not be reasonable. Therefore we use a single measure of multicultural expression that includes five categories: White (W) Asian (A) Black (B) Hispanic (H) and Other. Location The location was inferred using Carmen an open-source library for geolocating tweets that uses a series of rules to lookup location strings in a location knowledge-base (Dredze et al. 2013). We use the inferred location to select users that live in the United States. The age and race/ethnicity attributes were inferred with custom supervised classifiers based on Amir et al. (2017)’s user-level model. The classifiers were trained and evaluated on a dataset of 5K annotated users attaining performances of 0.28 and 0.41 Average F1 respectively. See the supplemental notes for additional details on these experiments1 .,our cohort construction process entail two key step first randomly selecting a large sample of twitter user and second annotating those user with key demographic attribute while such attribute are not provided by the api automated method can be used to infer such trait from data cesare et al following this approach we develop a demographic inference pipeline to automatically infer age gender raceethnicity and location for each cohort candidate age identifying age based on the content of a user can be challenging and exact age often cannot be determined based on language use alone therefore we use discrete category that provide a more accurate estimate of age teenager below s s s s year or older gender the gender wa inferred using demographer a supervised model that predicts the binary gender of twitter user with feature based on the name field on the user profile knowles et al raceethnicity the standard formulation of race and ethnicity is not well understood by the general public so categorizing social medium user along these two ax may not be reasonable therefore we use a single measure of multicultural expression that includes five category white w asian a black b hispanic h and other location the location wa inferred using carmen an opensource library for geolocating tweet that us a series of rule to lookup location string in a location knowledgebase dredze et al we use the inferred location to select user that live in the united state the age and raceethnicity attribute were inferred with custom supervised classifier based on amir et al s userlevel model the classifier were trained and evaluated on a dataset of k annotated user attaining performance of and average f respectively see the supplemental note for additional detail on these experiment,"['cohort', 'construction', 'process', 'entail', 'two', 'key', 'step', 'first', 'randomly', 'selecting', 'large', 'sample', 'twitter', 'user', 'second', 'annotating', 'user', 'key', 'demographic', 'attribute', 'attribute', 'provided', 'api', 'automated', 'method', 'used', 'infer', 'trait', 'data', 'cesare', 'et', 'al', 'following', 'approach', 'develop', 'demographic', 'inference', 'pipeline', 'automatically', 'infer', 'age', 'gender', 'raceethnicity', 'location', 'cohort', 'candidate', 'age', 'identifying', 'age', 'based', 'content', 'user', 'challenging', 'exact', 'age', 'often', 'cannot', 'determined', 'based', 'language', 'use', 'alone', 'therefore', 'use', 'discrete', 'category', 'provide', 'accurate', 'estimate', 'age', 'teenager', 'year', 'older', 'gender', 'gender', 'wa', 'inferred', 'using', 'demographer', 'supervised', 'model', 'predicts', 'binary', 'gender', 'twitter', 'user', 'feature', 'based', 'name', 'field', 'user', 'profile', 'knowles', 'et', 'al', 'raceethnicity', 'standard', 'formulation', 'race', 'ethnicity', 'well', 'understood', 'general', 'public', 'categorizing', 'social', 'medium', 'user', 'along', 'two', 'ax', 'may', 'reasonable', 'therefore', 'use', 'single', 'measure', 'multicultural', 'expression', 'includes', 'five', 'category', 'white', 'w', 'asian', 'black', 'b', 'hispanic', 'h', 'location', 'location', 'wa', 'inferred', 'using', 'carmen', 'opensource', 'library', 'geolocating', 'tweet', 'us', 'series', 'rule', 'lookup', 'location', 'string', 'location', 'knowledgebase', 'dredze', 'et', 'al', 'use', 'inferred', 'location', 'select', 'user', 'live', 'united', 'state', 'age', 'raceethnicity', 'attribute', 'inferred', 'custom', 'supervised', 'classifier', 'based', 'amir', 'et', 'al', 'userlevel', 'model', 'classifier', 'trained', 'evaluated', 'dataset', 'k', 'annotated', 'user', 'attaining', 'performance', 'average', 'f', 'respectively', 'see', 'supplemental', 'note', 'additional', 'detail', 'experiment']","['cohort construction', 'construction process', 'process entail', 'entail two', 'two key', 'key step', 'step first', 'first randomly', 'randomly selecting', 'selecting large', 'large sample', 'sample twitter', 'twitter user', 'user second', 'second annotating', 'annotating user', 'user key', 'key demographic', 'demographic attribute', 'attribute attribute', 'attribute provided', 'provided api', 'api automated', 'automated method', 'method used', 'used infer', 'infer trait', 'trait data', 'data cesare', 'cesare et', 'et al', 'al following', 'following approach', 'approach develop', 'develop demographic', 'demographic inference', 'inference pipeline', 'pipeline automatically', 'automatically infer', 'infer age', 'age gender', 'gender raceethnicity', 'raceethnicity location', 'location cohort', 'cohort candidate', 'candidate age', 'age identifying', 'identifying age', 'age based', 'based content', 'content user', 'user challenging', 'challenging exact', 'exact age', 'age often', 'often cannot', 'cannot determined', 'determined based', 'based language', 'language use', 'use alone', 'alone therefore', 'therefore use', 'use discrete', 'discrete category', 'category provide', 'provide accurate', 'accurate estimate', 'estimate age', 'age teenager', 'teenager year', 'year older', 'older gender', 'gender gender', 'gender wa', 'wa inferred', 'inferred using', 'using demographer', 'demographer supervised', 'supervised model', 'model predicts', 'predicts binary', 'binary gender', 'gender twitter', 'twitter user', 'user feature', 'feature based', 'based name', 'name field', 'field user', 'user profile', 'profile knowles', 'knowles et', 'et al', 'al raceethnicity', 'raceethnicity standard', 'standard formulation', 'formulation race', 'race ethnicity', 'ethnicity well', 'well understood', 'understood general', 'general public', 'public categorizing', 'categorizing social', 'social medium', 'medium user', 'user along', 'along two', 'two ax', 'ax may', 'may reasonable', 'reasonable therefore', 'therefore use', 'use single', 'single measure', 'measure multicultural', 'multicultural expression', 'expression includes', 'includes five', 'five category', 'category white', 'white w', 'w asian', 'asian black', 'black b', 'b hispanic', 'hispanic h', 'h location', 'location location', 'location wa', 'wa inferred', 'inferred using', 'using carmen', 'carmen opensource', 'opensource library', 'library geolocating', 'geolocating tweet', 'tweet us', 'us series', 'series rule', 'rule lookup', 'lookup location', 'location string', 'string location', 'location knowledgebase', 'knowledgebase dredze', 'dredze et', 'et al', 'al use', 'use inferred', 'inferred location', 'location select', 'select user', 'user live', 'live united', 'united state', 'state age', 'age raceethnicity', 'raceethnicity attribute', 'attribute inferred', 'inferred custom', 'custom supervised', 'supervised classifier', 'classifier based', 'based amir', 'amir et', 'et al', 'al userlevel', 'userlevel model', 'model classifier', 'classifier trained', 'trained evaluated', 'evaluated dataset', 'dataset k', 'k annotated', 'annotated user', 'user attaining', 'attaining performance', 'performance average', 'average f', 'f respectively', 'respectively see', 'see supplemental', 'supplemental note', 'note additional', 'additional detail', 'detail experiment']","['cohort construction process', 'construction process entail', 'process entail two', 'entail two key', 'two key step', 'key step first', 'step first randomly', 'first randomly selecting', 'randomly selecting large', 'selecting large sample', 'large sample twitter', 'sample twitter user', 'twitter user second', 'user second annotating', 'second annotating user', 'annotating user key', 'user key demographic', 'key demographic attribute', 'demographic attribute attribute', 'attribute attribute provided', 'attribute provided api', 'provided api automated', 'api automated method', 'automated method used', 'method used infer', 'used infer trait', 'infer trait data', 'trait data cesare', 'data cesare et', 'cesare et al', 'et al following', 'al following approach', 'following approach develop', 'approach develop demographic', 'develop demographic inference', 'demographic inference pipeline', 'inference pipeline automatically', 'pipeline automatically infer', 'automatically infer age', 'infer age gender', 'age gender raceethnicity', 'gender raceethnicity location', 'raceethnicity location cohort', 'location cohort candidate', 'cohort candidate age', 'candidate age identifying', 'age identifying age', 'identifying age based', 'age based content', 'based content user', 'content user challenging', 'user challenging exact', 'challenging exact age', 'exact age often', 'age often cannot', 'often cannot determined', 'cannot determined based', 'determined based language', 'based language use', 'language use alone', 'use alone therefore', 'alone therefore use', 'therefore use discrete', 'use discrete category', 'discrete category provide', 'category provide accurate', 'provide accurate estimate', 'accurate estimate age', 'estimate age teenager', 'age teenager year', 'teenager year older', 'year older gender', 'older gender gender', 'gender gender wa', 'gender wa inferred', 'wa inferred using', 'inferred using demographer', 'using demographer supervised', 'demographer supervised model', 'supervised model predicts', 'model predicts binary', 'predicts binary gender', 'binary gender twitter', 'gender twitter user', 'twitter user feature', 'user feature based', 'feature based name', 'based name field', 'name field user', 'field user profile', 'user profile knowles', 'profile knowles et', 'knowles et al', 'et al raceethnicity', 'al raceethnicity standard', 'raceethnicity standard formulation', 'standard formulation race', 'formulation race ethnicity', 'race ethnicity well', 'ethnicity well understood', 'well understood general', 'understood general public', 'general public categorizing', 'public categorizing social', 'categorizing social medium', 'social medium user', 'medium user along', 'user along two', 'along two ax', 'two ax may', 'ax may reasonable', 'may reasonable therefore', 'reasonable therefore use', 'therefore use single', 'use single measure', 'single measure multicultural', 'measure multicultural expression', 'multicultural expression includes', 'expression includes five', 'includes five category', 'five category white', 'category white w', 'white w asian', 'w asian black', 'asian black b', 'black b hispanic', 'b hispanic h', 'hispanic h location', 'h location location', 'location location wa', 'location wa inferred', 'wa inferred using', 'inferred using carmen', 'using carmen opensource', 'carmen opensource library', 'opensource library geolocating', 'library geolocating tweet', 'geolocating tweet us', 'tweet us series', 'us series rule', 'series rule lookup', 'rule lookup location', 'lookup location string', 'location string location', 'string location knowledgebase', 'location knowledgebase dredze', 'knowledgebase dredze et', 'dredze et al', 'et al use', 'al use inferred', 'use inferred location', 'inferred location select', 'location select user', 'select user live', 'user live united', 'live united state', 'united state age', 'state age raceethnicity', 'age raceethnicity attribute', 'raceethnicity attribute inferred', 'attribute inferred custom', 'inferred custom supervised', 'custom supervised classifier', 'supervised classifier based', 'classifier based amir', 'based amir et', 'amir et al', 'et al userlevel', 'al userlevel model', 'userlevel model classifier', 'model classifier trained', 'classifier trained evaluated', 'trained evaluated dataset', 'evaluated dataset k', 'dataset k annotated', 'k annotated user', 'annotated user attaining', 'user attaining performance', 'attaining performance average', 'performance average f', 'average f respectively', 'f respectively see', 'respectively see supplemental', 'see supplemental note', 'supplemental note additional', 'note additional detail', 'additional detail experiment']",,,,,,,
https://link.springer.com/chapter/10.1007/978-3-319-67186-4_6,1,First we removed journals with no text and those with fewer than 20 characters1 leaving 1.1 million journals for topic modelling. Next we pre-processed the text using the Stanford Tweet Tokenizer which is a “Twitter-aware” tokenizer designed to handle short informal text [1]. We used the option that truncates characters repeating 3 or more times converting phrases such as “I’m sooooo happyy” to “I’m soo happyy”. On average the number of tokens per journal was 27.7. Since we are interested in topics we removed stopwords and tokens with fewer than two letters and we only retained nouns which appear in the WordNet corpus [10]. After this filtering the average number of nouns per journal was 7. Examples of frequently appearing nouns in alphabetical order include “anxiety” “class” “dinner” “family” “god” “job” “lunch” “miss” “school” “sick” “sleep” and “work”. We then iteratively clustered the journals into topics (details below) and removed nouns that do not refer to topics such as numbers timings (e.g. “today” “yesterday”) general feelings (e.g. “feel” “like”) proper nouns and nouns that have ambiguous meanings (e.g. “overall” “true”). Lastly we only retained nouns that appeared more than ten times in the dataset. This process resulted in a vocabulary of 8386 words for topic modelling. Each journal is represented as a 8386-dimensional term frequency vector with each component denoting the term-frequency/ inverse-document-frequency (TF-IDF) of the corresponding term. Algorithm 1 summarizes our topic modelling methodology. Given a TF-IDF term frequency vector for each journal we run non-negative matrix factorization (NMF) [8] implemented in Python’s scikit-learn package [12]. The objective of NMF is to find two matrices whose product approximates the original matrix. In our case one matrix is the weighted set of topics in each journal and the other is the weighted set of words that belong to each topic. Hence each journal is represented as a combination of topics which are themselves composed of a weighted combination of words. We chose NMF because its non-negativity constraint aids with interpretability. In the context of analyzing word frequencies negative presence of a word would not be interpretable. This is because we only track word occurrences and not semantics or syntax. Unlike other matrix factorization methods NMF reconstructs each document from a sum of positive parts which enables us to easily manually label the discovered topics. Iterating from 4 to 40 topics we derived 37 different topic matrices (steps 1 and 2 of Algorithm 1). Each matrix consists of one topic per row. Each topic has a positive weight for each word in the vocabulary. Stronger weights indicate higher relevance to the topic. The final topic matrix we used has 14 topics and is shown in Table 1. We show the first six words in this table for simplicity where we sorted the words associated with each topic from highest relevance to lowest. When judging the topic matrices we considered the top twenty most important words per topic. Using this information we manually labeled each row in the matrix with a corresponding topic. Furthermore we manually evaluated each matrix based on the distinctness between topics consistency within topics and interpretability. During this process we compiled a custom list of removed words that we mentioned earlier in this section. The groups of words we removed appeared as stand-alone topics that did not offer information about what the journal was about. For example proper nouns appeared as a stand-alone topic. Other words which we deemed too general or ambiguous appeared across several topics and hence did not provide discriminative information. We tested different levels of regularization to enforce sparseness in our models (see [8] for a discussion) but did not find significant differences. However one important modification we made to regularize each topic was to make their first words only as strong as their second ones (by default first words are stronger than second words which are stronger than third words and so on). This is since the most relevant word for each topic tended to be too strong of a signal regardless of how we changed the number of topics pre-processing procedure or regularization in the objective function. For example the word “love” in a journal about sports would be so strong that the journal would be labeled as relating to romantic love. Lowering the importance of first words was sufficient to eliminate the false positives we identified. Given the final topic matrix (summarized in Table 1) the next step is to use it to assign labels to journals (steps 3 and 4 of Algorithm 1). We plotted the distribution of how important each topic was to all journals in the dataset with importance ranging from zero to one. Each distribution had a similar shape with a clear inflection point between 0.05 to 0.15 importance. Figure 4 shows an example importance distribution for the topic “Work” where the inflection point occurs at 0.1 importance.,first we removed journal with no text and those with fewer than character leaving million journal for topic modelling next we preprocessed the text using the stanford tweet tokenizer which is a twitteraware tokenizer designed to handle short informal text we used the option that truncates character repeating or more time converting phrase such a im sooooo happyy to im soo happyy on average the number of token per journal wa since we are interested in topic we removed stopwords and token with fewer than two letter and we only retained noun which appear in the wordnet corpus after this filtering the average number of noun per journal wa example of frequently appearing noun in alphabetical order include anxiety class dinner family god job lunch miss school sick sleep and work we then iteratively clustered the journal into topic detail below and removed noun that do not refer to topic such a number timing eg today yesterday general feeling eg feel like proper noun and noun that have ambiguous meaning eg overall true lastly we only retained noun that appeared more than ten time in the dataset this process resulted in a vocabulary of word for topic modelling each journal is represented a a dimensional term frequency vector with each component denoting the termfrequency inversedocumentfrequency tfidf of the corresponding term algorithm summarizes our topic modelling methodology given a tfidf term frequency vector for each journal we run nonnegative matrix factorization nmf implemented in python scikitlearn package the objective of nmf is to find two matrix whose product approximates the original matrix in our case one matrix is the weighted set of topic in each journal and the other is the weighted set of word that belong to each topic hence each journal is represented a a combination of topic which are themselves composed of a weighted combination of word we chose nmf because it nonnegativity constraint aid with interpretability in the context of analyzing word frequency negative presence of a word would not be interpretable this is because we only track word occurrence and not semantics or syntax unlike other matrix factorization method nmf reconstructs each document from a sum of positive part which enables u to easily manually label the discovered topic iterating from to topic we derived different topic matrix step and of algorithm each matrix consists of one topic per row each topic ha a positive weight for each word in the vocabulary stronger weight indicate higher relevance to the topic the final topic matrix we used ha topic and is shown in table we show the first six word in this table for simplicity where we sorted the word associated with each topic from highest relevance to lowest when judging the topic matrix we considered the top twenty most important word per topic using this information we manually labeled each row in the matrix with a corresponding topic furthermore we manually evaluated each matrix based on the distinctness between topic consistency within topic and interpretability during this process we compiled a custom list of removed word that we mentioned earlier in this section the group of word we removed appeared a standalone topic that did not offer information about what the journal wa about for example proper noun appeared a a standalone topic other word which we deemed too general or ambiguous appeared across several topic and hence did not provide discriminative information we tested different level of regularization to enforce sparseness in our model see for a discussion but did not find significant difference however one important modification we made to regularize each topic wa to make their first word only a strong a their second one by default first word are stronger than second word which are stronger than third word and so on this is since the most relevant word for each topic tended to be too strong of a signal regardless of how we changed the number of topic preprocessing procedure or regularization in the objective function for example the word love in a journal about sport would be so strong that the journal would be labeled a relating to romantic love lowering the importance of first word wa sufficient to eliminate the false positive we identified given the final topic matrix summarized in table the next step is to use it to assign label to journal step and of algorithm we plotted the distribution of how important each topic wa to all journal in the dataset with importance ranging from zero to one each distribution had a similar shape with a clear inflection point between to importance figure show an example importance distribution for the topic work where the inflection point occurs at importance,"['first', 'removed', 'journal', 'text', 'fewer', 'character', 'leaving', 'million', 'journal', 'topic', 'modelling', 'next', 'preprocessed', 'text', 'using', 'stanford', 'tweet', 'tokenizer', 'twitteraware', 'tokenizer', 'designed', 'handle', 'short', 'informal', 'text', 'used', 'option', 'truncates', 'character', 'repeating', 'time', 'converting', 'phrase', 'im', 'sooooo', 'happyy', 'im', 'soo', 'happyy', 'average', 'number', 'token', 'per', 'journal', 'wa', 'since', 'interested', 'topic', 'removed', 'stopwords', 'token', 'fewer', 'two', 'letter', 'retained', 'noun', 'appear', 'wordnet', 'corpus', 'filtering', 'average', 'number', 'noun', 'per', 'journal', 'wa', 'example', 'frequently', 'appearing', 'noun', 'alphabetical', 'order', 'include', 'anxiety', 'class', 'dinner', 'family', 'god', 'job', 'lunch', 'miss', 'school', 'sick', 'sleep', 'work', 'iteratively', 'clustered', 'journal', 'topic', 'detail', 'removed', 'noun', 'refer', 'topic', 'number', 'timing', 'eg', 'today', 'yesterday', 'general', 'feeling', 'eg', 'feel', 'like', 'proper', 'noun', 'noun', 'ambiguous', 'meaning', 'eg', 'overall', 'true', 'lastly', 'retained', 'noun', 'appeared', 'ten', 'time', 'dataset', 'process', 'resulted', 'vocabulary', 'word', 'topic', 'modelling', 'journal', 'represented', 'dimensional', 'term', 'frequency', 'vector', 'component', 'denoting', 'termfrequency', 'inversedocumentfrequency', 'tfidf', 'corresponding', 'term', 'algorithm', 'summarizes', 'topic', 'modelling', 'methodology', 'given', 'tfidf', 'term', 'frequency', 'vector', 'journal', 'run', 'nonnegative', 'matrix', 'factorization', 'nmf', 'implemented', 'python', 'scikitlearn', 'package', 'objective', 'nmf', 'find', 'two', 'matrix', 'whose', 'product', 'approximates', 'original', 'matrix', 'case', 'one', 'matrix', 'weighted', 'set', 'topic', 'journal', 'weighted', 'set', 'word', 'belong', 'topic', 'hence', 'journal', 'represented', 'combination', 'topic', 'composed', 'weighted', 'combination', 'word', 'chose', 'nmf', 'nonnegativity', 'constraint', 'aid', 'interpretability', 'context', 'analyzing', 'word', 'frequency', 'negative', 'presence', 'word', 'would', 'interpretable', 'track', 'word', 'occurrence', 'semantics', 'syntax', 'unlike', 'matrix', 'factorization', 'method', 'nmf', 'reconstructs', 'document', 'sum', 'positive', 'part', 'enables', 'u', 'easily', 'manually', 'label', 'discovered', 'topic', 'iterating', 'topic', 'derived', 'different', 'topic', 'matrix', 'step', 'algorithm', 'matrix', 'consists', 'one', 'topic', 'per', 'row', 'topic', 'ha', 'positive', 'weight', 'word', 'vocabulary', 'stronger', 'weight', 'indicate', 'higher', 'relevance', 'topic', 'final', 'topic', 'matrix', 'used', 'ha', 'topic', 'shown', 'table', 'show', 'first', 'six', 'word', 'table', 'simplicity', 'sorted', 'word', 'associated', 'topic', 'highest', 'relevance', 'lowest', 'judging', 'topic', 'matrix', 'considered', 'top', 'twenty', 'important', 'word', 'per', 'topic', 'using', 'information', 'manually', 'labeled', 'row', 'matrix', 'corresponding', 'topic', 'furthermore', 'manually', 'evaluated', 'matrix', 'based', 'distinctness', 'topic', 'consistency', 'within', 'topic', 'interpretability', 'process', 'compiled', 'custom', 'list', 'removed', 'word', 'mentioned', 'earlier', 'section', 'group', 'word', 'removed', 'appeared', 'standalone', 'topic', 'offer', 'information', 'journal', 'wa', 'example', 'proper', 'noun', 'appeared', 'standalone', 'topic', 'word', 'deemed', 'general', 'ambiguous', 'appeared', 'across', 'several', 'topic', 'hence', 'provide', 'discriminative', 'information', 'tested', 'different', 'level', 'regularization', 'enforce', 'sparseness', 'model', 'see', 'discussion', 'find', 'significant', 'difference', 'however', 'one', 'important', 'modification', 'made', 'regularize', 'topic', 'wa', 'make', 'first', 'word', 'strong', 'second', 'one', 'default', 'first', 'word', 'stronger', 'second', 'word', 'stronger', 'third', 'word', 'since', 'relevant', 'word', 'topic', 'tended', 'strong', 'signal', 'regardless', 'changed', 'number', 'topic', 'preprocessing', 'procedure', 'regularization', 'objective', 'function', 'example', 'word', 'love', 'journal', 'sport', 'would', 'strong', 'journal', 'would', 'labeled', 'relating', 'romantic', 'love', 'lowering', 'importance', 'first', 'word', 'wa', 'sufficient', 'eliminate', 'false', 'positive', 'identified', 'given', 'final', 'topic', 'matrix', 'summarized', 'table', 'next', 'step', 'use', 'assign', 'label', 'journal', 'step', 'algorithm', 'plotted', 'distribution', 'important', 'topic', 'wa', 'journal', 'dataset', 'importance', 'ranging', 'zero', 'one', 'distribution', 'similar', 'shape', 'clear', 'inflection', 'point', 'importance', 'figure', 'show', 'example', 'importance', 'distribution', 'topic', 'work', 'inflection', 'point', 'occurs', 'importance']","['first removed', 'removed journal', 'journal text', 'text fewer', 'fewer character', 'character leaving', 'leaving million', 'million journal', 'journal topic', 'topic modelling', 'modelling next', 'next preprocessed', 'preprocessed text', 'text using', 'using stanford', 'stanford tweet', 'tweet tokenizer', 'tokenizer twitteraware', 'twitteraware tokenizer', 'tokenizer designed', 'designed handle', 'handle short', 'short informal', 'informal text', 'text used', 'used option', 'option truncates', 'truncates character', 'character repeating', 'repeating time', 'time converting', 'converting phrase', 'phrase im', 'im sooooo', 'sooooo happyy', 'happyy im', 'im soo', 'soo happyy', 'happyy average', 'average number', 'number token', 'token per', 'per journal', 'journal wa', 'wa since', 'since interested', 'interested topic', 'topic removed', 'removed stopwords', 'stopwords token', 'token fewer', 'fewer two', 'two letter', 'letter retained', 'retained noun', 'noun appear', 'appear wordnet', 'wordnet corpus', 'corpus filtering', 'filtering average', 'average number', 'number noun', 'noun per', 'per journal', 'journal wa', 'wa example', 'example frequently', 'frequently appearing', 'appearing noun', 'noun alphabetical', 'alphabetical order', 'order include', 'include anxiety', 'anxiety class', 'class dinner', 'dinner family', 'family god', 'god job', 'job lunch', 'lunch miss', 'miss school', 'school sick', 'sick sleep', 'sleep work', 'work iteratively', 'iteratively clustered', 'clustered journal', 'journal topic', 'topic detail', 'detail removed', 'removed noun', 'noun refer', 'refer topic', 'topic number', 'number timing', 'timing eg', 'eg today', 'today yesterday', 'yesterday general', 'general feeling', 'feeling eg', 'eg feel', 'feel like', 'like proper', 'proper noun', 'noun noun', 'noun ambiguous', 'ambiguous meaning', 'meaning eg', 'eg overall', 'overall true', 'true lastly', 'lastly retained', 'retained noun', 'noun appeared', 'appeared ten', 'ten time', 'time dataset', 'dataset process', 'process resulted', 'resulted vocabulary', 'vocabulary word', 'word topic', 'topic modelling', 'modelling journal', 'journal represented', 'represented dimensional', 'dimensional term', 'term frequency', 'frequency vector', 'vector component', 'component denoting', 'denoting termfrequency', 'termfrequency inversedocumentfrequency', 'inversedocumentfrequency tfidf', 'tfidf corresponding', 'corresponding term', 'term algorithm', 'algorithm summarizes', 'summarizes topic', 'topic modelling', 'modelling methodology', 'methodology given', 'given tfidf', 'tfidf term', 'term frequency', 'frequency vector', 'vector journal', 'journal run', 'run nonnegative', 'nonnegative matrix', 'matrix factorization', 'factorization nmf', 'nmf implemented', 'implemented python', 'python scikitlearn', 'scikitlearn package', 'package objective', 'objective nmf', 'nmf find', 'find two', 'two matrix', 'matrix whose', 'whose product', 'product approximates', 'approximates original', 'original matrix', 'matrix case', 'case one', 'one matrix', 'matrix weighted', 'weighted set', 'set topic', 'topic journal', 'journal weighted', 'weighted set', 'set word', 'word belong', 'belong topic', 'topic hence', 'hence journal', 'journal represented', 'represented combination', 'combination topic', 'topic composed', 'composed weighted', 'weighted combination', 'combination word', 'word chose', 'chose nmf', 'nmf nonnegativity', 'nonnegativity constraint', 'constraint aid', 'aid interpretability', 'interpretability context', 'context analyzing', 'analyzing word', 'word frequency', 'frequency negative', 'negative presence', 'presence word', 'word would', 'would interpretable', 'interpretable track', 'track word', 'word occurrence', 'occurrence semantics', 'semantics syntax', 'syntax unlike', 'unlike matrix', 'matrix factorization', 'factorization method', 'method nmf', 'nmf reconstructs', 'reconstructs document', 'document sum', 'sum positive', 'positive part', 'part enables', 'enables u', 'u easily', 'easily manually', 'manually label', 'label discovered', 'discovered topic', 'topic iterating', 'iterating topic', 'topic derived', 'derived different', 'different topic', 'topic matrix', 'matrix step', 'step algorithm', 'algorithm matrix', 'matrix consists', 'consists one', 'one topic', 'topic per', 'per row', 'row topic', 'topic ha', 'ha positive', 'positive weight', 'weight word', 'word vocabulary', 'vocabulary stronger', 'stronger weight', 'weight indicate', 'indicate higher', 'higher relevance', 'relevance topic', 'topic final', 'final topic', 'topic matrix', 'matrix used', 'used ha', 'ha topic', 'topic shown', 'shown table', 'table show', 'show first', 'first six', 'six word', 'word table', 'table simplicity', 'simplicity sorted', 'sorted word', 'word associated', 'associated topic', 'topic highest', 'highest relevance', 'relevance lowest', 'lowest judging', 'judging topic', 'topic matrix', 'matrix considered', 'considered top', 'top twenty', 'twenty important', 'important word', 'word per', 'per topic', 'topic using', 'using information', 'information manually', 'manually labeled', 'labeled row', 'row matrix', 'matrix corresponding', 'corresponding topic', 'topic furthermore', 'furthermore manually', 'manually evaluated', 'evaluated matrix', 'matrix based', 'based distinctness', 'distinctness topic', 'topic consistency', 'consistency within', 'within topic', 'topic interpretability', 'interpretability process', 'process compiled', 'compiled custom', 'custom list', 'list removed', 'removed word', 'word mentioned', 'mentioned earlier', 'earlier section', 'section group', 'group word', 'word removed', 'removed appeared', 'appeared standalone', 'standalone topic', 'topic offer', 'offer information', 'information journal', 'journal wa', 'wa example', 'example proper', 'proper noun', 'noun appeared', 'appeared standalone', 'standalone topic', 'topic word', 'word deemed', 'deemed general', 'general ambiguous', 'ambiguous appeared', 'appeared across', 'across several', 'several topic', 'topic hence', 'hence provide', 'provide discriminative', 'discriminative information', 'information tested', 'tested different', 'different level', 'level regularization', 'regularization enforce', 'enforce sparseness', 'sparseness model', 'model see', 'see discussion', 'discussion find', 'find significant', 'significant difference', 'difference however', 'however one', 'one important', 'important modification', 'modification made', 'made regularize', 'regularize topic', 'topic wa', 'wa make', 'make first', 'first word', 'word strong', 'strong second', 'second one', 'one default', 'default first', 'first word', 'word stronger', 'stronger second', 'second word', 'word stronger', 'stronger third', 'third word', 'word since', 'since relevant', 'relevant word', 'word topic', 'topic tended', 'tended strong', 'strong signal', 'signal regardless', 'regardless changed', 'changed number', 'number topic', 'topic preprocessing', 'preprocessing procedure', 'procedure regularization', 'regularization objective', 'objective function', 'function example', 'example word', 'word love', 'love journal', 'journal sport', 'sport would', 'would strong', 'strong journal', 'journal would', 'would labeled', 'labeled relating', 'relating romantic', 'romantic love', 'love lowering', 'lowering importance', 'importance first', 'first word', 'word wa', 'wa sufficient', 'sufficient eliminate', 'eliminate false', 'false positive', 'positive identified', 'identified given', 'given final', 'final topic', 'topic matrix', 'matrix summarized', 'summarized table', 'table next', 'next step', 'step use', 'use assign', 'assign label', 'label journal', 'journal step', 'step algorithm', 'algorithm plotted', 'plotted distribution', 'distribution important', 'important topic', 'topic wa', 'wa journal', 'journal dataset', 'dataset importance', 'importance ranging', 'ranging zero', 'zero one', 'one distribution', 'distribution similar', 'similar shape', 'shape clear', 'clear inflection', 'inflection point', 'point importance', 'importance figure', 'figure show', 'show example', 'example importance', 'importance distribution', 'distribution topic', 'topic work', 'work inflection', 'inflection point', 'point occurs', 'occurs importance']","['first removed journal', 'removed journal text', 'journal text fewer', 'text fewer character', 'fewer character leaving', 'character leaving million', 'leaving million journal', 'million journal topic', 'journal topic modelling', 'topic modelling next', 'modelling next preprocessed', 'next preprocessed text', 'preprocessed text using', 'text using stanford', 'using stanford tweet', 'stanford tweet tokenizer', 'tweet tokenizer twitteraware', 'tokenizer twitteraware tokenizer', 'twitteraware tokenizer designed', 'tokenizer designed handle', 'designed handle short', 'handle short informal', 'short informal text', 'informal text used', 'text used option', 'used option truncates', 'option truncates character', 'truncates character repeating', 'character repeating time', 'repeating time converting', 'time converting phrase', 'converting phrase im', 'phrase im sooooo', 'im sooooo happyy', 'sooooo happyy im', 'happyy im soo', 'im soo happyy', 'soo happyy average', 'happyy average number', 'average number token', 'number token per', 'token per journal', 'per journal wa', 'journal wa since', 'wa since interested', 'since interested topic', 'interested topic removed', 'topic removed stopwords', 'removed stopwords token', 'stopwords token fewer', 'token fewer two', 'fewer two letter', 'two letter retained', 'letter retained noun', 'retained noun appear', 'noun appear wordnet', 'appear wordnet corpus', 'wordnet corpus filtering', 'corpus filtering average', 'filtering average number', 'average number noun', 'number noun per', 'noun per journal', 'per journal wa', 'journal wa example', 'wa example frequently', 'example frequently appearing', 'frequently appearing noun', 'appearing noun alphabetical', 'noun alphabetical order', 'alphabetical order include', 'order include anxiety', 'include anxiety class', 'anxiety class dinner', 'class dinner family', 'dinner family god', 'family god job', 'god job lunch', 'job lunch miss', 'lunch miss school', 'miss school sick', 'school sick sleep', 'sick sleep work', 'sleep work iteratively', 'work iteratively clustered', 'iteratively clustered journal', 'clustered journal topic', 'journal topic detail', 'topic detail removed', 'detail removed noun', 'removed noun refer', 'noun refer topic', 'refer topic number', 'topic number timing', 'number timing eg', 'timing eg today', 'eg today yesterday', 'today yesterday general', 'yesterday general feeling', 'general feeling eg', 'feeling eg feel', 'eg feel like', 'feel like proper', 'like proper noun', 'proper noun noun', 'noun noun ambiguous', 'noun ambiguous meaning', 'ambiguous meaning eg', 'meaning eg overall', 'eg overall true', 'overall true lastly', 'true lastly retained', 'lastly retained noun', 'retained noun appeared', 'noun appeared ten', 'appeared ten time', 'ten time dataset', 'time dataset process', 'dataset process resulted', 'process resulted vocabulary', 'resulted vocabulary word', 'vocabulary word topic', 'word topic modelling', 'topic modelling journal', 'modelling journal represented', 'journal represented dimensional', 'represented dimensional term', 'dimensional term frequency', 'term frequency vector', 'frequency vector component', 'vector component denoting', 'component denoting termfrequency', 'denoting termfrequency inversedocumentfrequency', 'termfrequency inversedocumentfrequency tfidf', 'inversedocumentfrequency tfidf corresponding', 'tfidf corresponding term', 'corresponding term algorithm', 'term algorithm summarizes', 'algorithm summarizes topic', 'summarizes topic modelling', 'topic modelling methodology', 'modelling methodology given', 'methodology given tfidf', 'given tfidf term', 'tfidf term frequency', 'term frequency vector', 'frequency vector journal', 'vector journal run', 'journal run nonnegative', 'run nonnegative matrix', 'nonnegative matrix factorization', 'matrix factorization nmf', 'factorization nmf implemented', 'nmf implemented python', 'implemented python scikitlearn', 'python scikitlearn package', 'scikitlearn package objective', 'package objective nmf', 'objective nmf find', 'nmf find two', 'find two matrix', 'two matrix whose', 'matrix whose product', 'whose product approximates', 'product approximates original', 'approximates original matrix', 'original matrix case', 'matrix case one', 'case one matrix', 'one matrix weighted', 'matrix weighted set', 'weighted set topic', 'set topic journal', 'topic journal weighted', 'journal weighted set', 'weighted set word', 'set word belong', 'word belong topic', 'belong topic hence', 'topic hence journal', 'hence journal represented', 'journal represented combination', 'represented combination topic', 'combination topic composed', 'topic composed weighted', 'composed weighted combination', 'weighted combination word', 'combination word chose', 'word chose nmf', 'chose nmf nonnegativity', 'nmf nonnegativity constraint', 'nonnegativity constraint aid', 'constraint aid interpretability', 'aid interpretability context', 'interpretability context analyzing', 'context analyzing word', 'analyzing word frequency', 'word frequency negative', 'frequency negative presence', 'negative presence word', 'presence word would', 'word would interpretable', 'would interpretable track', 'interpretable track word', 'track word occurrence', 'word occurrence semantics', 'occurrence semantics syntax', 'semantics syntax unlike', 'syntax unlike matrix', 'unlike matrix factorization', 'matrix factorization method', 'factorization method nmf', 'method nmf reconstructs', 'nmf reconstructs document', 'reconstructs document sum', 'document sum positive', 'sum positive part', 'positive part enables', 'part enables u', 'enables u easily', 'u easily manually', 'easily manually label', 'manually label discovered', 'label discovered topic', 'discovered topic iterating', 'topic iterating topic', 'iterating topic derived', 'topic derived different', 'derived different topic', 'different topic matrix', 'topic matrix step', 'matrix step algorithm', 'step algorithm matrix', 'algorithm matrix consists', 'matrix consists one', 'consists one topic', 'one topic per', 'topic per row', 'per row topic', 'row topic ha', 'topic ha positive', 'ha positive weight', 'positive weight word', 'weight word vocabulary', 'word vocabulary stronger', 'vocabulary stronger weight', 'stronger weight indicate', 'weight indicate higher', 'indicate higher relevance', 'higher relevance topic', 'relevance topic final', 'topic final topic', 'final topic matrix', 'topic matrix used', 'matrix used ha', 'used ha topic', 'ha topic shown', 'topic shown table', 'shown table show', 'table show first', 'show first six', 'first six word', 'six word table', 'word table simplicity', 'table simplicity sorted', 'simplicity sorted word', 'sorted word associated', 'word associated topic', 'associated topic highest', 'topic highest relevance', 'highest relevance lowest', 'relevance lowest judging', 'lowest judging topic', 'judging topic matrix', 'topic matrix considered', 'matrix considered top', 'considered top twenty', 'top twenty important', 'twenty important word', 'important word per', 'word per topic', 'per topic using', 'topic using information', 'using information manually', 'information manually labeled', 'manually labeled row', 'labeled row matrix', 'row matrix corresponding', 'matrix corresponding topic', 'corresponding topic furthermore', 'topic furthermore manually', 'furthermore manually evaluated', 'manually evaluated matrix', 'evaluated matrix based', 'matrix based distinctness', 'based distinctness topic', 'distinctness topic consistency', 'topic consistency within', 'consistency within topic', 'within topic interpretability', 'topic interpretability process', 'interpretability process compiled', 'process compiled custom', 'compiled custom list', 'custom list removed', 'list removed word', 'removed word mentioned', 'word mentioned earlier', 'mentioned earlier section', 'earlier section group', 'section group word', 'group word removed', 'word removed appeared', 'removed appeared standalone', 'appeared standalone topic', 'standalone topic offer', 'topic offer information', 'offer information journal', 'information journal wa', 'journal wa example', 'wa example proper', 'example proper noun', 'proper noun appeared', 'noun appeared standalone', 'appeared standalone topic', 'standalone topic word', 'topic word deemed', 'word deemed general', 'deemed general ambiguous', 'general ambiguous appeared', 'ambiguous appeared across', 'appeared across several', 'across several topic', 'several topic hence', 'topic hence provide', 'hence provide discriminative', 'provide discriminative information', 'discriminative information tested', 'information tested different', 'tested different level', 'different level regularization', 'level regularization enforce', 'regularization enforce sparseness', 'enforce sparseness model', 'sparseness model see', 'model see discussion', 'see discussion find', 'discussion find significant', 'find significant difference', 'significant difference however', 'difference however one', 'however one important', 'one important modification', 'important modification made', 'modification made regularize', 'made regularize topic', 'regularize topic wa', 'topic wa make', 'wa make first', 'make first word', 'first word strong', 'word strong second', 'strong second one', 'second one default', 'one default first', 'default first word', 'first word stronger', 'word stronger second', 'stronger second word', 'second word stronger', 'word stronger third', 'stronger third word', 'third word since', 'word since relevant', 'since relevant word', 'relevant word topic', 'word topic tended', 'topic tended strong', 'tended strong signal', 'strong signal regardless', 'signal regardless changed', 'regardless changed number', 'changed number topic', 'number topic preprocessing', 'topic preprocessing procedure', 'preprocessing procedure regularization', 'procedure regularization objective', 'regularization objective function', 'objective function example', 'function example word', 'example word love', 'word love journal', 'love journal sport', 'journal sport would', 'sport would strong', 'would strong journal', 'strong journal would', 'journal would labeled', 'would labeled relating', 'labeled relating romantic', 'relating romantic love', 'romantic love lowering', 'love lowering importance', 'lowering importance first', 'importance first word', 'first word wa', 'word wa sufficient', 'wa sufficient eliminate', 'sufficient eliminate false', 'eliminate false positive', 'false positive identified', 'positive identified given', 'identified given final', 'given final topic', 'final topic matrix', 'topic matrix summarized', 'matrix summarized table', 'summarized table next', 'table next step', 'next step use', 'step use assign', 'use assign label', 'assign label journal', 'label journal step', 'journal step algorithm', 'step algorithm plotted', 'algorithm plotted distribution', 'plotted distribution important', 'distribution important topic', 'important topic wa', 'topic wa journal', 'wa journal dataset', 'journal dataset importance', 'dataset importance ranging', 'importance ranging zero', 'ranging zero one', 'zero one distribution', 'one distribution similar', 'distribution similar shape', 'similar shape clear', 'shape clear inflection', 'clear inflection point', 'inflection point importance', 'point importance figure', 'importance figure show', 'figure show example', 'show example importance', 'example importance distribution', 'importance distribution topic', 'distribution topic work', 'topic work inflection', 'work inflection point', 'inflection point occurs', 'point occurs importance']",,,,,,,
https://dl.acm.org/doi/abs/10.1145/2556288.2557214,0,A key challenge of this research was to identify the different health conditions on which people seek and share information via search engines and Twitter respectively. We identified four broad categories of conditions based on their severity and types: (1) symptoms of major diseases (2) benign explanations (non-life-threatening illnesses) (3) serious illnesses and (4) disabilities. We also characterized each condition by the degree of perceived social stigma provided by third-party judges. Our final list contained 165 conditions.,a key challenge of this research wa to identify the different health condition on which people seek and share information via search engine and twitter respectively we identified four broad category of condition based on their severity and type symptom of major disease benign explanation nonlifethreatening illness serious illness and disability we also characterized each condition by the degree of perceived social stigma provided by thirdparty judge our final list contained condition,"['key', 'challenge', 'research', 'wa', 'identify', 'different', 'health', 'condition', 'people', 'seek', 'share', 'information', 'via', 'search', 'engine', 'twitter', 'respectively', 'identified', 'four', 'broad', 'category', 'condition', 'based', 'severity', 'type', 'symptom', 'major', 'disease', 'benign', 'explanation', 'nonlifethreatening', 'illness', 'serious', 'illness', 'disability', 'also', 'characterized', 'condition', 'degree', 'perceived', 'social', 'stigma', 'provided', 'thirdparty', 'judge', 'final', 'list', 'contained', 'condition']","['key challenge', 'challenge research', 'research wa', 'wa identify', 'identify different', 'different health', 'health condition', 'condition people', 'people seek', 'seek share', 'share information', 'information via', 'via search', 'search engine', 'engine twitter', 'twitter respectively', 'respectively identified', 'identified four', 'four broad', 'broad category', 'category condition', 'condition based', 'based severity', 'severity type', 'type symptom', 'symptom major', 'major disease', 'disease benign', 'benign explanation', 'explanation nonlifethreatening', 'nonlifethreatening illness', 'illness serious', 'serious illness', 'illness disability', 'disability also', 'also characterized', 'characterized condition', 'condition degree', 'degree perceived', 'perceived social', 'social stigma', 'stigma provided', 'provided thirdparty', 'thirdparty judge', 'judge final', 'final list', 'list contained', 'contained condition']","['key challenge research', 'challenge research wa', 'research wa identify', 'wa identify different', 'identify different health', 'different health condition', 'health condition people', 'condition people seek', 'people seek share', 'seek share information', 'share information via', 'information via search', 'via search engine', 'search engine twitter', 'engine twitter respectively', 'twitter respectively identified', 'respectively identified four', 'identified four broad', 'four broad category', 'broad category condition', 'category condition based', 'condition based severity', 'based severity type', 'severity type symptom', 'type symptom major', 'symptom major disease', 'major disease benign', 'disease benign explanation', 'benign explanation nonlifethreatening', 'explanation nonlifethreatening illness', 'nonlifethreatening illness serious', 'illness serious illness', 'serious illness disability', 'illness disability also', 'disability also characterized', 'also characterized condition', 'characterized condition degree', 'condition degree perceived', 'degree perceived social', 'perceived social stigma', 'social stigma provided', 'stigma provided thirdparty', 'provided thirdparty judge', 'thirdparty judge final', 'judge final list', 'final list contained', 'list contained condition']",,,,,,,
https://www.aaai.org/ocs/index.php/ICWSM/ICWSM14/paper/viewPaper/8075,0,reddit is a social news website where registered users submit content in the form of links or text posts. Users also known as “redditors” can then vote each submission “up” or “down” to rank the post and determine its position or prominence on the site’s pages. These two attributes associated with a post are referred to as “upvotes” and “downvotes”. Redditors can also comment on posts and respond back in a conversation tree of comments. Content entries that is the posts are organized by areas of interest or sub-communities called “subreddits” such as politics programming or science. As of 2013 reddit’s official statistics included 56 billion page views 731 million unique visitors 40855032 posts and 404603286 comments (http://blog.reddit.com/2013/ 12/top-posts-of-2013-stats-and-snoo-years.html). We used of reddit’s official API (http://www.reddit.com/ dev /api) to collect posts comments and associated metadata from several mental health subreddits: specifically using a Python wrapper PRAW (https://praw.readthedocs.org/en/ latest/index.html). The subreddits we crawled were: alcoholism anxiety bipolarreddit depression mentalhealth MMFB (Make Me Feel Better) socialanxiety SuicideWatch. All of these subreddits host public content. In order to arrive at a comprehensive list of subreddits to focus on we utilized reddit’s native subreddit search feature (http://www.reddit.com/reddits) and searched for subreddits on “mental health”. Two researchers familiar with reddit employed an initial filtering step on the search results returned so that we focus on high precision subreddits discussing mental health concerns and issues. Thereafter we focused on a snowball approach in which starting with a few seed subreddits (mentalhealth depression) we compiled a second list of “related” or “similar” subreddits that are listed in the profile pages of the seed subreddits. Following a second filtering step we arrived at the list of subreddits listed above. For each of these subreddits we obtained daily crawls of their posts in the New category. Corresponding to each post we collected information on the title of the post the body or textual content id timestamp when the post was made author id and the number of upvotes and downvotes it obtained. Since posts gather comments over a period of time following the time of sharing we crawled all of the comments per post that were shared over a three day period after the post was made. Qualitative examinations of the subreddits of interest revealed that 90% or more of the comments to any post were typically made in a three day window following the time the post is made—hence the choice. The crawl of the subreddits used in this paper We present some descriptive statistics of our crawled data. Our dataset contained 20411 posts with at least one comment and 97661 comments in all with 27102 unique users who made posts comments or both. A set of 7823 users (28.79%) were found to write both at least one post and comment. CDF of the user distribution over posts and comments is given in Figure 1. The figure shows the expected heavy tail trend observed in several social phenomena. Also see Figure 2 for the distribution of comments over time following post share. It illustrates the quick responsivity culture in the communities we study (peak at 3 hours). Some of the additional statistics of our dataset are given in Table 1. Further example titles of a few,reddit is a social news website where registered user submit content in the form of link or text post user also known a redditors can then vote each submission up or down to rank the post and determine it position or prominence on the site page these two attribute associated with a post are referred to a upvotes and downvotes redditors can also comment on post and respond back in a conversation tree of comment content entry that is the post are organized by area of interest or subcommunities called subreddits such a politics programming or science a of reddits official statistic included billion page view million unique visitor post and comment httpblogredditcom toppostsofstatsandsnooyearshtml we used of reddits official api httpwwwredditcom dev api to collect post comment and associated metadata from several mental health subreddits specifically using a python wrapper praw httpsprawreadthedocsorgen latestindexhtml the subreddits we crawled were alcoholism anxiety bipolarreddit depression mentalhealth mmfb make me feel better socialanxiety suicidewatch all of these subreddits host public content in order to arrive at a comprehensive list of subreddits to focus on we utilized reddits native subreddit search feature httpwwwredditcomreddits and searched for subreddits on mental health two researcher familiar with reddit employed an initial filtering step on the search result returned so that we focus on high precision subreddits discussing mental health concern and issue thereafter we focused on a snowball approach in which starting with a few seed subreddits mentalhealth depression we compiled a second list of related or similar subreddits that are listed in the profile page of the seed subreddits following a second filtering step we arrived at the list of subreddits listed above for each of these subreddits we obtained daily crawl of their post in the new category corresponding to each post we collected information on the title of the post the body or textual content id timestamp when the post wa made author id and the number of upvotes and downvotes it obtained since post gather comment over a period of time following the time of sharing we crawled all of the comment per post that were shared over a three day period after the post wa made qualitative examination of the subreddits of interest revealed that or more of the comment to any post were typically made in a three day window following the time the post is madehence the choice the crawl of the subreddits used in this paper we present some descriptive statistic of our crawled data our dataset contained post with at least one comment and comment in all with unique user who made post comment or both a set of user were found to write both at least one post and comment cdf of the user distribution over post and comment is given in figure the figure show the expected heavy tail trend observed in several social phenomenon also see figure for the distribution of comment over time following post share it illustrates the quick responsivity culture in the community we study peak at hour some of the additional statistic of our dataset are given in table further example title of a few,"['reddit', 'social', 'news', 'website', 'registered', 'user', 'submit', 'content', 'form', 'link', 'text', 'post', 'user', 'also', 'known', 'redditors', 'vote', 'submission', 'rank', 'post', 'determine', 'position', 'prominence', 'site', 'page', 'two', 'attribute', 'associated', 'post', 'referred', 'upvotes', 'downvotes', 'redditors', 'also', 'comment', 'post', 'respond', 'back', 'conversation', 'tree', 'comment', 'content', 'entry', 'post', 'organized', 'area', 'interest', 'subcommunities', 'called', 'subreddits', 'politics', 'programming', 'science', 'reddits', 'official', 'statistic', 'included', 'billion', 'page', 'view', 'million', 'unique', 'visitor', 'post', 'comment', 'httpblogredditcom', 'toppostsofstatsandsnooyearshtml', 'used', 'reddits', 'official', 'api', 'httpwwwredditcom', 'dev', 'api', 'collect', 'post', 'comment', 'associated', 'metadata', 'several', 'mental', 'health', 'subreddits', 'specifically', 'using', 'python', 'wrapper', 'praw', 'httpsprawreadthedocsorgen', 'latestindexhtml', 'subreddits', 'crawled', 'alcoholism', 'anxiety', 'bipolarreddit', 'depression', 'mentalhealth', 'mmfb', 'make', 'feel', 'better', 'socialanxiety', 'suicidewatch', 'subreddits', 'host', 'public', 'content', 'order', 'arrive', 'comprehensive', 'list', 'subreddits', 'focus', 'utilized', 'reddits', 'native', 'subreddit', 'search', 'feature', 'httpwwwredditcomreddits', 'searched', 'subreddits', 'mental', 'health', 'two', 'researcher', 'familiar', 'reddit', 'employed', 'initial', 'filtering', 'step', 'search', 'result', 'returned', 'focus', 'high', 'precision', 'subreddits', 'discussing', 'mental', 'health', 'concern', 'issue', 'thereafter', 'focused', 'snowball', 'approach', 'starting', 'seed', 'subreddits', 'mentalhealth', 'depression', 'compiled', 'second', 'list', 'related', 'similar', 'subreddits', 'listed', 'profile', 'page', 'seed', 'subreddits', 'following', 'second', 'filtering', 'step', 'arrived', 'list', 'subreddits', 'listed', 'subreddits', 'obtained', 'daily', 'crawl', 'post', 'new', 'category', 'corresponding', 'post', 'collected', 'information', 'title', 'post', 'body', 'textual', 'content', 'id', 'timestamp', 'post', 'wa', 'made', 'author', 'id', 'number', 'upvotes', 'downvotes', 'obtained', 'since', 'post', 'gather', 'comment', 'period', 'time', 'following', 'time', 'sharing', 'crawled', 'comment', 'per', 'post', 'shared', 'three', 'day', 'period', 'post', 'wa', 'made', 'qualitative', 'examination', 'subreddits', 'interest', 'revealed', 'comment', 'post', 'typically', 'made', 'three', 'day', 'window', 'following', 'time', 'post', 'madehence', 'choice', 'crawl', 'subreddits', 'used', 'paper', 'present', 'descriptive', 'statistic', 'crawled', 'data', 'dataset', 'contained', 'post', 'least', 'one', 'comment', 'comment', 'unique', 'user', 'made', 'post', 'comment', 'set', 'user', 'found', 'write', 'least', 'one', 'post', 'comment', 'cdf', 'user', 'distribution', 'post', 'comment', 'given', 'figure', 'figure', 'show', 'expected', 'heavy', 'tail', 'trend', 'observed', 'several', 'social', 'phenomenon', 'also', 'see', 'figure', 'distribution', 'comment', 'time', 'following', 'post', 'share', 'illustrates', 'quick', 'responsivity', 'culture', 'community', 'study', 'peak', 'hour', 'additional', 'statistic', 'dataset', 'given', 'table', 'example', 'title']","['reddit social', 'social news', 'news website', 'website registered', 'registered user', 'user submit', 'submit content', 'content form', 'form link', 'link text', 'text post', 'post user', 'user also', 'also known', 'known redditors', 'redditors vote', 'vote submission', 'submission rank', 'rank post', 'post determine', 'determine position', 'position prominence', 'prominence site', 'site page', 'page two', 'two attribute', 'attribute associated', 'associated post', 'post referred', 'referred upvotes', 'upvotes downvotes', 'downvotes redditors', 'redditors also', 'also comment', 'comment post', 'post respond', 'respond back', 'back conversation', 'conversation tree', 'tree comment', 'comment content', 'content entry', 'entry post', 'post organized', 'organized area', 'area interest', 'interest subcommunities', 'subcommunities called', 'called subreddits', 'subreddits politics', 'politics programming', 'programming science', 'science reddits', 'reddits official', 'official statistic', 'statistic included', 'included billion', 'billion page', 'page view', 'view million', 'million unique', 'unique visitor', 'visitor post', 'post comment', 'comment httpblogredditcom', 'httpblogredditcom toppostsofstatsandsnooyearshtml', 'toppostsofstatsandsnooyearshtml used', 'used reddits', 'reddits official', 'official api', 'api httpwwwredditcom', 'httpwwwredditcom dev', 'dev api', 'api collect', 'collect post', 'post comment', 'comment associated', 'associated metadata', 'metadata several', 'several mental', 'mental health', 'health subreddits', 'subreddits specifically', 'specifically using', 'using python', 'python wrapper', 'wrapper praw', 'praw httpsprawreadthedocsorgen', 'httpsprawreadthedocsorgen latestindexhtml', 'latestindexhtml subreddits', 'subreddits crawled', 'crawled alcoholism', 'alcoholism anxiety', 'anxiety bipolarreddit', 'bipolarreddit depression', 'depression mentalhealth', 'mentalhealth mmfb', 'mmfb make', 'make feel', 'feel better', 'better socialanxiety', 'socialanxiety suicidewatch', 'suicidewatch subreddits', 'subreddits host', 'host public', 'public content', 'content order', 'order arrive', 'arrive comprehensive', 'comprehensive list', 'list subreddits', 'subreddits focus', 'focus utilized', 'utilized reddits', 'reddits native', 'native subreddit', 'subreddit search', 'search feature', 'feature httpwwwredditcomreddits', 'httpwwwredditcomreddits searched', 'searched subreddits', 'subreddits mental', 'mental health', 'health two', 'two researcher', 'researcher familiar', 'familiar reddit', 'reddit employed', 'employed initial', 'initial filtering', 'filtering step', 'step search', 'search result', 'result returned', 'returned focus', 'focus high', 'high precision', 'precision subreddits', 'subreddits discussing', 'discussing mental', 'mental health', 'health concern', 'concern issue', 'issue thereafter', 'thereafter focused', 'focused snowball', 'snowball approach', 'approach starting', 'starting seed', 'seed subreddits', 'subreddits mentalhealth', 'mentalhealth depression', 'depression compiled', 'compiled second', 'second list', 'list related', 'related similar', 'similar subreddits', 'subreddits listed', 'listed profile', 'profile page', 'page seed', 'seed subreddits', 'subreddits following', 'following second', 'second filtering', 'filtering step', 'step arrived', 'arrived list', 'list subreddits', 'subreddits listed', 'listed subreddits', 'subreddits obtained', 'obtained daily', 'daily crawl', 'crawl post', 'post new', 'new category', 'category corresponding', 'corresponding post', 'post collected', 'collected information', 'information title', 'title post', 'post body', 'body textual', 'textual content', 'content id', 'id timestamp', 'timestamp post', 'post wa', 'wa made', 'made author', 'author id', 'id number', 'number upvotes', 'upvotes downvotes', 'downvotes obtained', 'obtained since', 'since post', 'post gather', 'gather comment', 'comment period', 'period time', 'time following', 'following time', 'time sharing', 'sharing crawled', 'crawled comment', 'comment per', 'per post', 'post shared', 'shared three', 'three day', 'day period', 'period post', 'post wa', 'wa made', 'made qualitative', 'qualitative examination', 'examination subreddits', 'subreddits interest', 'interest revealed', 'revealed comment', 'comment post', 'post typically', 'typically made', 'made three', 'three day', 'day window', 'window following', 'following time', 'time post', 'post madehence', 'madehence choice', 'choice crawl', 'crawl subreddits', 'subreddits used', 'used paper', 'paper present', 'present descriptive', 'descriptive statistic', 'statistic crawled', 'crawled data', 'data dataset', 'dataset contained', 'contained post', 'post least', 'least one', 'one comment', 'comment comment', 'comment unique', 'unique user', 'user made', 'made post', 'post comment', 'comment set', 'set user', 'user found', 'found write', 'write least', 'least one', 'one post', 'post comment', 'comment cdf', 'cdf user', 'user distribution', 'distribution post', 'post comment', 'comment given', 'given figure', 'figure figure', 'figure show', 'show expected', 'expected heavy', 'heavy tail', 'tail trend', 'trend observed', 'observed several', 'several social', 'social phenomenon', 'phenomenon also', 'also see', 'see figure', 'figure distribution', 'distribution comment', 'comment time', 'time following', 'following post', 'post share', 'share illustrates', 'illustrates quick', 'quick responsivity', 'responsivity culture', 'culture community', 'community study', 'study peak', 'peak hour', 'hour additional', 'additional statistic', 'statistic dataset', 'dataset given', 'given table', 'table example', 'example title']","['reddit social news', 'social news website', 'news website registered', 'website registered user', 'registered user submit', 'user submit content', 'submit content form', 'content form link', 'form link text', 'link text post', 'text post user', 'post user also', 'user also known', 'also known redditors', 'known redditors vote', 'redditors vote submission', 'vote submission rank', 'submission rank post', 'rank post determine', 'post determine position', 'determine position prominence', 'position prominence site', 'prominence site page', 'site page two', 'page two attribute', 'two attribute associated', 'attribute associated post', 'associated post referred', 'post referred upvotes', 'referred upvotes downvotes', 'upvotes downvotes redditors', 'downvotes redditors also', 'redditors also comment', 'also comment post', 'comment post respond', 'post respond back', 'respond back conversation', 'back conversation tree', 'conversation tree comment', 'tree comment content', 'comment content entry', 'content entry post', 'entry post organized', 'post organized area', 'organized area interest', 'area interest subcommunities', 'interest subcommunities called', 'subcommunities called subreddits', 'called subreddits politics', 'subreddits politics programming', 'politics programming science', 'programming science reddits', 'science reddits official', 'reddits official statistic', 'official statistic included', 'statistic included billion', 'included billion page', 'billion page view', 'page view million', 'view million unique', 'million unique visitor', 'unique visitor post', 'visitor post comment', 'post comment httpblogredditcom', 'comment httpblogredditcom toppostsofstatsandsnooyearshtml', 'httpblogredditcom toppostsofstatsandsnooyearshtml used', 'toppostsofstatsandsnooyearshtml used reddits', 'used reddits official', 'reddits official api', 'official api httpwwwredditcom', 'api httpwwwredditcom dev', 'httpwwwredditcom dev api', 'dev api collect', 'api collect post', 'collect post comment', 'post comment associated', 'comment associated metadata', 'associated metadata several', 'metadata several mental', 'several mental health', 'mental health subreddits', 'health subreddits specifically', 'subreddits specifically using', 'specifically using python', 'using python wrapper', 'python wrapper praw', 'wrapper praw httpsprawreadthedocsorgen', 'praw httpsprawreadthedocsorgen latestindexhtml', 'httpsprawreadthedocsorgen latestindexhtml subreddits', 'latestindexhtml subreddits crawled', 'subreddits crawled alcoholism', 'crawled alcoholism anxiety', 'alcoholism anxiety bipolarreddit', 'anxiety bipolarreddit depression', 'bipolarreddit depression mentalhealth', 'depression mentalhealth mmfb', 'mentalhealth mmfb make', 'mmfb make feel', 'make feel better', 'feel better socialanxiety', 'better socialanxiety suicidewatch', 'socialanxiety suicidewatch subreddits', 'suicidewatch subreddits host', 'subreddits host public', 'host public content', 'public content order', 'content order arrive', 'order arrive comprehensive', 'arrive comprehensive list', 'comprehensive list subreddits', 'list subreddits focus', 'subreddits focus utilized', 'focus utilized reddits', 'utilized reddits native', 'reddits native subreddit', 'native subreddit search', 'subreddit search feature', 'search feature httpwwwredditcomreddits', 'feature httpwwwredditcomreddits searched', 'httpwwwredditcomreddits searched subreddits', 'searched subreddits mental', 'subreddits mental health', 'mental health two', 'health two researcher', 'two researcher familiar', 'researcher familiar reddit', 'familiar reddit employed', 'reddit employed initial', 'employed initial filtering', 'initial filtering step', 'filtering step search', 'step search result', 'search result returned', 'result returned focus', 'returned focus high', 'focus high precision', 'high precision subreddits', 'precision subreddits discussing', 'subreddits discussing mental', 'discussing mental health', 'mental health concern', 'health concern issue', 'concern issue thereafter', 'issue thereafter focused', 'thereafter focused snowball', 'focused snowball approach', 'snowball approach starting', 'approach starting seed', 'starting seed subreddits', 'seed subreddits mentalhealth', 'subreddits mentalhealth depression', 'mentalhealth depression compiled', 'depression compiled second', 'compiled second list', 'second list related', 'list related similar', 'related similar subreddits', 'similar subreddits listed', 'subreddits listed profile', 'listed profile page', 'profile page seed', 'page seed subreddits', 'seed subreddits following', 'subreddits following second', 'following second filtering', 'second filtering step', 'filtering step arrived', 'step arrived list', 'arrived list subreddits', 'list subreddits listed', 'subreddits listed subreddits', 'listed subreddits obtained', 'subreddits obtained daily', 'obtained daily crawl', 'daily crawl post', 'crawl post new', 'post new category', 'new category corresponding', 'category corresponding post', 'corresponding post collected', 'post collected information', 'collected information title', 'information title post', 'title post body', 'post body textual', 'body textual content', 'textual content id', 'content id timestamp', 'id timestamp post', 'timestamp post wa', 'post wa made', 'wa made author', 'made author id', 'author id number', 'id number upvotes', 'number upvotes downvotes', 'upvotes downvotes obtained', 'downvotes obtained since', 'obtained since post', 'since post gather', 'post gather comment', 'gather comment period', 'comment period time', 'period time following', 'time following time', 'following time sharing', 'time sharing crawled', 'sharing crawled comment', 'crawled comment per', 'comment per post', 'per post shared', 'post shared three', 'shared three day', 'three day period', 'day period post', 'period post wa', 'post wa made', 'wa made qualitative', 'made qualitative examination', 'qualitative examination subreddits', 'examination subreddits interest', 'subreddits interest revealed', 'interest revealed comment', 'revealed comment post', 'comment post typically', 'post typically made', 'typically made three', 'made three day', 'three day window', 'day window following', 'window following time', 'following time post', 'time post madehence', 'post madehence choice', 'madehence choice crawl', 'choice crawl subreddits', 'crawl subreddits used', 'subreddits used paper', 'used paper present', 'paper present descriptive', 'present descriptive statistic', 'descriptive statistic crawled', 'statistic crawled data', 'crawled data dataset', 'data dataset contained', 'dataset contained post', 'contained post least', 'post least one', 'least one comment', 'one comment comment', 'comment comment unique', 'comment unique user', 'unique user made', 'user made post', 'made post comment', 'post comment set', 'comment set user', 'set user found', 'user found write', 'found write least', 'write least one', 'least one post', 'one post comment', 'post comment cdf', 'comment cdf user', 'cdf user distribution', 'user distribution post', 'distribution post comment', 'post comment given', 'comment given figure', 'given figure figure', 'figure figure show', 'figure show expected', 'show expected heavy', 'expected heavy tail', 'heavy tail trend', 'tail trend observed', 'trend observed several', 'observed several social', 'several social phenomenon', 'social phenomenon also', 'phenomenon also see', 'also see figure', 'see figure distribution', 'figure distribution comment', 'distribution comment time', 'comment time following', 'time following post', 'following post share', 'post share illustrates', 'share illustrates quick', 'illustrates quick responsivity', 'quick responsivity culture', 'responsivity culture community', 'culture community study', 'community study peak', 'study peak hour', 'peak hour additional', 'hour additional statistic', 'additional statistic dataset', 'statistic dataset given', 'dataset given table', 'given table example', 'table example title']",,,,,,,
https://dl.acm.org/doi/abs/10.1145/3025453.3025932,0,Next we assessed the suitability and reliability of our collected corpus of Instagram posts and users for our later analyses. For the purpose we extracted n-grams (n=3) from the profile biographies of users. The top 10 uni- bi- and trigrams are shown in Table 3. They show that users are appropriating Instagram to seek and provide social and emotional support around different mental health concerns (“need someone talk” “feel free dm”). There are also explicit mentions of specific psychological challenges around mental health (“depression anxiety” “telling suicidal kids”) including warnings for profile visitors (“trigger warning”) and personal experiences of the condition (“alone alone alone”). We corroborated these observations with a licensed psychiatrist and concluded that the users in our dataset are engaging in genuine mental health disclosures tend to demonstrate disinhibition towards sharing their mental health experiences and are appropriating the platform specifically for this purpose via the chosen account.,next we assessed the suitability and reliability of our collected corpus of instagram post and user for our later analysis for the purpose we extracted ngrams n from the profile biography of user the top uni bi and trigram are shown in table they show that user are appropriating instagram to seek and provide social and emotional support around different mental health concern need someone talk feel free dm there are also explicit mention of specific psychological challenge around mental health depression anxiety telling suicidal kid including warning for profile visitor trigger warning and personal experience of the condition alone alone alone we corroborated these observation with a licensed psychiatrist and concluded that the user in our dataset are engaging in genuine mental health disclosure tend to demonstrate disinhibition towards sharing their mental health experience and are appropriating the platform specifically for this purpose via the chosen account,"['next', 'assessed', 'suitability', 'reliability', 'collected', 'corpus', 'instagram', 'post', 'user', 'later', 'analysis', 'purpose', 'extracted', 'ngrams', 'n', 'profile', 'biography', 'user', 'top', 'uni', 'bi', 'trigram', 'shown', 'table', 'show', 'user', 'appropriating', 'instagram', 'seek', 'provide', 'social', 'emotional', 'support', 'around', 'different', 'mental', 'health', 'concern', 'need', 'someone', 'talk', 'feel', 'free', 'dm', 'also', 'explicit', 'mention', 'specific', 'psychological', 'challenge', 'around', 'mental', 'health', 'depression', 'anxiety', 'telling', 'suicidal', 'kid', 'including', 'warning', 'profile', 'visitor', 'trigger', 'warning', 'personal', 'experience', 'condition', 'alone', 'alone', 'alone', 'corroborated', 'observation', 'licensed', 'psychiatrist', 'concluded', 'user', 'dataset', 'engaging', 'genuine', 'mental', 'health', 'disclosure', 'tend', 'demonstrate', 'disinhibition', 'towards', 'sharing', 'mental', 'health', 'experience', 'appropriating', 'platform', 'specifically', 'purpose', 'via', 'chosen', 'account']","['next assessed', 'assessed suitability', 'suitability reliability', 'reliability collected', 'collected corpus', 'corpus instagram', 'instagram post', 'post user', 'user later', 'later analysis', 'analysis purpose', 'purpose extracted', 'extracted ngrams', 'ngrams n', 'n profile', 'profile biography', 'biography user', 'user top', 'top uni', 'uni bi', 'bi trigram', 'trigram shown', 'shown table', 'table show', 'show user', 'user appropriating', 'appropriating instagram', 'instagram seek', 'seek provide', 'provide social', 'social emotional', 'emotional support', 'support around', 'around different', 'different mental', 'mental health', 'health concern', 'concern need', 'need someone', 'someone talk', 'talk feel', 'feel free', 'free dm', 'dm also', 'also explicit', 'explicit mention', 'mention specific', 'specific psychological', 'psychological challenge', 'challenge around', 'around mental', 'mental health', 'health depression', 'depression anxiety', 'anxiety telling', 'telling suicidal', 'suicidal kid', 'kid including', 'including warning', 'warning profile', 'profile visitor', 'visitor trigger', 'trigger warning', 'warning personal', 'personal experience', 'experience condition', 'condition alone', 'alone alone', 'alone alone', 'alone corroborated', 'corroborated observation', 'observation licensed', 'licensed psychiatrist', 'psychiatrist concluded', 'concluded user', 'user dataset', 'dataset engaging', 'engaging genuine', 'genuine mental', 'mental health', 'health disclosure', 'disclosure tend', 'tend demonstrate', 'demonstrate disinhibition', 'disinhibition towards', 'towards sharing', 'sharing mental', 'mental health', 'health experience', 'experience appropriating', 'appropriating platform', 'platform specifically', 'specifically purpose', 'purpose via', 'via chosen', 'chosen account']","['next assessed suitability', 'assessed suitability reliability', 'suitability reliability collected', 'reliability collected corpus', 'collected corpus instagram', 'corpus instagram post', 'instagram post user', 'post user later', 'user later analysis', 'later analysis purpose', 'analysis purpose extracted', 'purpose extracted ngrams', 'extracted ngrams n', 'ngrams n profile', 'n profile biography', 'profile biography user', 'biography user top', 'user top uni', 'top uni bi', 'uni bi trigram', 'bi trigram shown', 'trigram shown table', 'shown table show', 'table show user', 'show user appropriating', 'user appropriating instagram', 'appropriating instagram seek', 'instagram seek provide', 'seek provide social', 'provide social emotional', 'social emotional support', 'emotional support around', 'support around different', 'around different mental', 'different mental health', 'mental health concern', 'health concern need', 'concern need someone', 'need someone talk', 'someone talk feel', 'talk feel free', 'feel free dm', 'free dm also', 'dm also explicit', 'also explicit mention', 'explicit mention specific', 'mention specific psychological', 'specific psychological challenge', 'psychological challenge around', 'challenge around mental', 'around mental health', 'mental health depression', 'health depression anxiety', 'depression anxiety telling', 'anxiety telling suicidal', 'telling suicidal kid', 'suicidal kid including', 'kid including warning', 'including warning profile', 'warning profile visitor', 'profile visitor trigger', 'visitor trigger warning', 'trigger warning personal', 'warning personal experience', 'personal experience condition', 'experience condition alone', 'condition alone alone', 'alone alone alone', 'alone alone corroborated', 'alone corroborated observation', 'corroborated observation licensed', 'observation licensed psychiatrist', 'licensed psychiatrist concluded', 'psychiatrist concluded user', 'concluded user dataset', 'user dataset engaging', 'dataset engaging genuine', 'engaging genuine mental', 'genuine mental health', 'mental health disclosure', 'health disclosure tend', 'disclosure tend demonstrate', 'tend demonstrate disinhibition', 'demonstrate disinhibition towards', 'disinhibition towards sharing', 'towards sharing mental', 'sharing mental health', 'mental health experience', 'health experience appropriating', 'experience appropriating platform', 'appropriating platform specifically', 'platform specifically purpose', 'specifically purpose via', 'purpose via chosen', 'via chosen account']",,,,,,,
https://www.sciencedirect.com/science/article/pii/S0747563215300996,0,Tweets about depression were collected by Simply Measured a company that specializes in social media measurement and analytics (Simply Measured 2014). Simply Measured has access to the Twitter “firehose” (or full volume of tweets) via Gnip a licensed company that can retrieve the full Twitter data stream. All tweets in the English language that contained at least either “depressed” “#depressed” “depression” or “#depression” were collected between April 11 and May 4 2014. We scanned a random sample of the tweets to identify common phrases that included our keywords of interest but were not about mental health. In SAS version 9.3 (SAS Institute Inc. Cary NC) we used the index function which searches a character expression (in this case the text of the tweet) for a specific string of characters to locate and remove such tweets from our sample. We removed tweets that included the following terms regardless of capitalization: “Great Depression” “economic depression” “during the depression” “depression era” “tropical depression” and “depressed real estate”. The popularity and influence of the Tweeters was described using the distribution of followers and Klout Scores. While number of followers is a measure of popularity Klout Score is a measure of influence. Klout Scores range from 0 to 100 with a higher score indicating higher influence. Klout Score is calculated based on an algorithm that considers over 400 signals from eight different online networks. Examples of signals include the amount of retweets a person generates in relation to the amount of tweets shared and the amount of engagement a user drives from unique individuals (e.g. lots of retweets from different individuals as opposed to lots of retweets from one person) (Klout Inc. 2014).,tweet about depression were collected by simply measured a company that specializes in social medium measurement and analytics simply measured simply measured ha access to the twitter firehose or full volume of tweet via gnip a licensed company that can retrieve the full twitter data stream all tweet in the english language that contained at least either depressed depressed depression or depression were collected between april and may we scanned a random sample of the tweet to identify common phrase that included our keywords of interest but were not about mental health in sa version sa institute inc cary nc we used the index function which search a character expression in this case the text of the tweet for a specific string of character to locate and remove such tweet from our sample we removed tweet that included the following term regardless of capitalization great depression economic depression during the depression depression era tropical depression and depressed real estate the popularity and influence of the tweeter wa described using the distribution of follower and klout score while number of follower is a measure of popularity klout score is a measure of influence klout score range from to with a higher score indicating higher influence klout score is calculated based on an algorithm that considers over signal from eight different online network example of signal include the amount of retweets a person generates in relation to the amount of tweet shared and the amount of engagement a user drive from unique individual eg lot of retweets from different individual a opposed to lot of retweets from one person klout inc,"['tweet', 'depression', 'collected', 'simply', 'measured', 'company', 'specializes', 'social', 'medium', 'measurement', 'analytics', 'simply', 'measured', 'simply', 'measured', 'ha', 'access', 'twitter', 'firehose', 'full', 'volume', 'tweet', 'via', 'gnip', 'licensed', 'company', 'retrieve', 'full', 'twitter', 'data', 'stream', 'tweet', 'english', 'language', 'contained', 'least', 'either', 'depressed', 'depressed', 'depression', 'depression', 'collected', 'april', 'may', 'scanned', 'random', 'sample', 'tweet', 'identify', 'common', 'phrase', 'included', 'keywords', 'interest', 'mental', 'health', 'sa', 'version', 'sa', 'institute', 'inc', 'cary', 'nc', 'used', 'index', 'function', 'search', 'character', 'expression', 'case', 'text', 'tweet', 'specific', 'string', 'character', 'locate', 'remove', 'tweet', 'sample', 'removed', 'tweet', 'included', 'following', 'term', 'regardless', 'capitalization', 'great', 'depression', 'economic', 'depression', 'depression', 'depression', 'era', 'tropical', 'depression', 'depressed', 'real', 'estate', 'popularity', 'influence', 'tweeter', 'wa', 'described', 'using', 'distribution', 'follower', 'klout', 'score', 'number', 'follower', 'measure', 'popularity', 'klout', 'score', 'measure', 'influence', 'klout', 'score', 'range', 'higher', 'score', 'indicating', 'higher', 'influence', 'klout', 'score', 'calculated', 'based', 'algorithm', 'considers', 'signal', 'eight', 'different', 'online', 'network', 'example', 'signal', 'include', 'amount', 'retweets', 'person', 'generates', 'relation', 'amount', 'tweet', 'shared', 'amount', 'engagement', 'user', 'drive', 'unique', 'individual', 'eg', 'lot', 'retweets', 'different', 'individual', 'opposed', 'lot', 'retweets', 'one', 'person', 'klout', 'inc']","['tweet depression', 'depression collected', 'collected simply', 'simply measured', 'measured company', 'company specializes', 'specializes social', 'social medium', 'medium measurement', 'measurement analytics', 'analytics simply', 'simply measured', 'measured simply', 'simply measured', 'measured ha', 'ha access', 'access twitter', 'twitter firehose', 'firehose full', 'full volume', 'volume tweet', 'tweet via', 'via gnip', 'gnip licensed', 'licensed company', 'company retrieve', 'retrieve full', 'full twitter', 'twitter data', 'data stream', 'stream tweet', 'tweet english', 'english language', 'language contained', 'contained least', 'least either', 'either depressed', 'depressed depressed', 'depressed depression', 'depression depression', 'depression collected', 'collected april', 'april may', 'may scanned', 'scanned random', 'random sample', 'sample tweet', 'tweet identify', 'identify common', 'common phrase', 'phrase included', 'included keywords', 'keywords interest', 'interest mental', 'mental health', 'health sa', 'sa version', 'version sa', 'sa institute', 'institute inc', 'inc cary', 'cary nc', 'nc used', 'used index', 'index function', 'function search', 'search character', 'character expression', 'expression case', 'case text', 'text tweet', 'tweet specific', 'specific string', 'string character', 'character locate', 'locate remove', 'remove tweet', 'tweet sample', 'sample removed', 'removed tweet', 'tweet included', 'included following', 'following term', 'term regardless', 'regardless capitalization', 'capitalization great', 'great depression', 'depression economic', 'economic depression', 'depression depression', 'depression depression', 'depression era', 'era tropical', 'tropical depression', 'depression depressed', 'depressed real', 'real estate', 'estate popularity', 'popularity influence', 'influence tweeter', 'tweeter wa', 'wa described', 'described using', 'using distribution', 'distribution follower', 'follower klout', 'klout score', 'score number', 'number follower', 'follower measure', 'measure popularity', 'popularity klout', 'klout score', 'score measure', 'measure influence', 'influence klout', 'klout score', 'score range', 'range higher', 'higher score', 'score indicating', 'indicating higher', 'higher influence', 'influence klout', 'klout score', 'score calculated', 'calculated based', 'based algorithm', 'algorithm considers', 'considers signal', 'signal eight', 'eight different', 'different online', 'online network', 'network example', 'example signal', 'signal include', 'include amount', 'amount retweets', 'retweets person', 'person generates', 'generates relation', 'relation amount', 'amount tweet', 'tweet shared', 'shared amount', 'amount engagement', 'engagement user', 'user drive', 'drive unique', 'unique individual', 'individual eg', 'eg lot', 'lot retweets', 'retweets different', 'different individual', 'individual opposed', 'opposed lot', 'lot retweets', 'retweets one', 'one person', 'person klout', 'klout inc']","['tweet depression collected', 'depression collected simply', 'collected simply measured', 'simply measured company', 'measured company specializes', 'company specializes social', 'specializes social medium', 'social medium measurement', 'medium measurement analytics', 'measurement analytics simply', 'analytics simply measured', 'simply measured simply', 'measured simply measured', 'simply measured ha', 'measured ha access', 'ha access twitter', 'access twitter firehose', 'twitter firehose full', 'firehose full volume', 'full volume tweet', 'volume tweet via', 'tweet via gnip', 'via gnip licensed', 'gnip licensed company', 'licensed company retrieve', 'company retrieve full', 'retrieve full twitter', 'full twitter data', 'twitter data stream', 'data stream tweet', 'stream tweet english', 'tweet english language', 'english language contained', 'language contained least', 'contained least either', 'least either depressed', 'either depressed depressed', 'depressed depressed depression', 'depressed depression depression', 'depression depression collected', 'depression collected april', 'collected april may', 'april may scanned', 'may scanned random', 'scanned random sample', 'random sample tweet', 'sample tweet identify', 'tweet identify common', 'identify common phrase', 'common phrase included', 'phrase included keywords', 'included keywords interest', 'keywords interest mental', 'interest mental health', 'mental health sa', 'health sa version', 'sa version sa', 'version sa institute', 'sa institute inc', 'institute inc cary', 'inc cary nc', 'cary nc used', 'nc used index', 'used index function', 'index function search', 'function search character', 'search character expression', 'character expression case', 'expression case text', 'case text tweet', 'text tweet specific', 'tweet specific string', 'specific string character', 'string character locate', 'character locate remove', 'locate remove tweet', 'remove tweet sample', 'tweet sample removed', 'sample removed tweet', 'removed tweet included', 'tweet included following', 'included following term', 'following term regardless', 'term regardless capitalization', 'regardless capitalization great', 'capitalization great depression', 'great depression economic', 'depression economic depression', 'economic depression depression', 'depression depression depression', 'depression depression era', 'depression era tropical', 'era tropical depression', 'tropical depression depressed', 'depression depressed real', 'depressed real estate', 'real estate popularity', 'estate popularity influence', 'popularity influence tweeter', 'influence tweeter wa', 'tweeter wa described', 'wa described using', 'described using distribution', 'using distribution follower', 'distribution follower klout', 'follower klout score', 'klout score number', 'score number follower', 'number follower measure', 'follower measure popularity', 'measure popularity klout', 'popularity klout score', 'klout score measure', 'score measure influence', 'measure influence klout', 'influence klout score', 'klout score range', 'score range higher', 'range higher score', 'higher score indicating', 'score indicating higher', 'indicating higher influence', 'higher influence klout', 'influence klout score', 'klout score calculated', 'score calculated based', 'calculated based algorithm', 'based algorithm considers', 'algorithm considers signal', 'considers signal eight', 'signal eight different', 'eight different online', 'different online network', 'online network example', 'network example signal', 'example signal include', 'signal include amount', 'include amount retweets', 'amount retweets person', 'retweets person generates', 'person generates relation', 'generates relation amount', 'relation amount tweet', 'amount tweet shared', 'tweet shared amount', 'shared amount engagement', 'amount engagement user', 'engagement user drive', 'user drive unique', 'drive unique individual', 'unique individual eg', 'individual eg lot', 'eg lot retweets', 'lot retweets different', 'retweets different individual', 'different individual opposed', 'individual opposed lot', 'opposed lot retweets', 'lot retweets one', 'retweets one person', 'one person klout', 'person klout inc']",,,,,,,
https://aclanthology.org/W15-1202.pdf,1,Since mental health conditions including schizophrenia have different prevalence rates depending on age and gender (among other demographic variables) controlling for these will be important when examining systematic differences between schizophrenic users and community controls. In particular we would like to be able to attribute any quantifiable signals we observe to the presence or absence of schizophrenia rather than to a confounding age or gender divergence between the populations (Dos Reis and Culotta 2015). To that end we estimated the age and gender of all our users (from their language usage) via the tools graciously made available by the World Well-Being Project (Sap et al. 2014). For each user we applied a hard threshold to the gender prediction to obtain a binary ‘Female’ or ‘Male’ label. Then in order to select the best match for each schizophrenia user we selected the community control that had the same gender label and was closest in age (without replacement).,since mental health condition including schizophrenia have different prevalence rate depending on age and gender among other demographic variable controlling for these will be important when examining systematic difference between schizophrenic user and community control in particular we would like to be able to attribute any quantifiable signal we observe to the presence or absence of schizophrenia rather than to a confounding age or gender divergence between the population do real and culotta to that end we estimated the age and gender of all our user from their language usage via the tool graciously made available by the world wellbeing project sap et al for each user we applied a hard threshold to the gender prediction to obtain a binary female or male label then in order to select the best match for each schizophrenia user we selected the community control that had the same gender label and wa closest in age without replacement,"['since', 'mental', 'health', 'condition', 'including', 'schizophrenia', 'different', 'prevalence', 'rate', 'depending', 'age', 'gender', 'among', 'demographic', 'variable', 'controlling', 'important', 'examining', 'systematic', 'difference', 'schizophrenic', 'user', 'community', 'control', 'particular', 'would', 'like', 'able', 'attribute', 'quantifiable', 'signal', 'observe', 'presence', 'absence', 'schizophrenia', 'rather', 'confounding', 'age', 'gender', 'divergence', 'population', 'real', 'culotta', 'end', 'estimated', 'age', 'gender', 'user', 'language', 'usage', 'via', 'tool', 'graciously', 'made', 'available', 'world', 'wellbeing', 'project', 'sap', 'et', 'al', 'user', 'applied', 'hard', 'threshold', 'gender', 'prediction', 'obtain', 'binary', 'female', 'male', 'label', 'order', 'select', 'best', 'match', 'schizophrenia', 'user', 'selected', 'community', 'control', 'gender', 'label', 'wa', 'closest', 'age', 'without', 'replacement']","['since mental', 'mental health', 'health condition', 'condition including', 'including schizophrenia', 'schizophrenia different', 'different prevalence', 'prevalence rate', 'rate depending', 'depending age', 'age gender', 'gender among', 'among demographic', 'demographic variable', 'variable controlling', 'controlling important', 'important examining', 'examining systematic', 'systematic difference', 'difference schizophrenic', 'schizophrenic user', 'user community', 'community control', 'control particular', 'particular would', 'would like', 'like able', 'able attribute', 'attribute quantifiable', 'quantifiable signal', 'signal observe', 'observe presence', 'presence absence', 'absence schizophrenia', 'schizophrenia rather', 'rather confounding', 'confounding age', 'age gender', 'gender divergence', 'divergence population', 'population real', 'real culotta', 'culotta end', 'end estimated', 'estimated age', 'age gender', 'gender user', 'user language', 'language usage', 'usage via', 'via tool', 'tool graciously', 'graciously made', 'made available', 'available world', 'world wellbeing', 'wellbeing project', 'project sap', 'sap et', 'et al', 'al user', 'user applied', 'applied hard', 'hard threshold', 'threshold gender', 'gender prediction', 'prediction obtain', 'obtain binary', 'binary female', 'female male', 'male label', 'label order', 'order select', 'select best', 'best match', 'match schizophrenia', 'schizophrenia user', 'user selected', 'selected community', 'community control', 'control gender', 'gender label', 'label wa', 'wa closest', 'closest age', 'age without', 'without replacement']","['since mental health', 'mental health condition', 'health condition including', 'condition including schizophrenia', 'including schizophrenia different', 'schizophrenia different prevalence', 'different prevalence rate', 'prevalence rate depending', 'rate depending age', 'depending age gender', 'age gender among', 'gender among demographic', 'among demographic variable', 'demographic variable controlling', 'variable controlling important', 'controlling important examining', 'important examining systematic', 'examining systematic difference', 'systematic difference schizophrenic', 'difference schizophrenic user', 'schizophrenic user community', 'user community control', 'community control particular', 'control particular would', 'particular would like', 'would like able', 'like able attribute', 'able attribute quantifiable', 'attribute quantifiable signal', 'quantifiable signal observe', 'signal observe presence', 'observe presence absence', 'presence absence schizophrenia', 'absence schizophrenia rather', 'schizophrenia rather confounding', 'rather confounding age', 'confounding age gender', 'age gender divergence', 'gender divergence population', 'divergence population real', 'population real culotta', 'real culotta end', 'culotta end estimated', 'end estimated age', 'estimated age gender', 'age gender user', 'gender user language', 'user language usage', 'language usage via', 'usage via tool', 'via tool graciously', 'tool graciously made', 'graciously made available', 'made available world', 'available world wellbeing', 'world wellbeing project', 'wellbeing project sap', 'project sap et', 'sap et al', 'et al user', 'al user applied', 'user applied hard', 'applied hard threshold', 'hard threshold gender', 'threshold gender prediction', 'gender prediction obtain', 'prediction obtain binary', 'obtain binary female', 'binary female male', 'female male label', 'male label order', 'label order select', 'order select best', 'select best match', 'best match schizophrenia', 'match schizophrenia user', 'schizophrenia user selected', 'user selected community', 'selected community control', 'community control gender', 'control gender label', 'gender label wa', 'label wa closest', 'wa closest age', 'closest age without', 'age without replacement']",,,,,,,
https://dl.acm.org/doi/abs/10.1145/2700171.2791026,0,Next we compiled a list of reported celebrity suicides which fell within the time range of our Reddit data. Defining who is a “celebrity” is nontrivial so we refer to the Wikipedia page listing celebrity suicides7 as a way to measure who has sufficient celebrity status for inclusion. We obtained 10 reported celebrity suicides in the same period as our Reddit data; their names and reported suicides are shown in Table 2. We measure the prominence of a celebrity’s death by measuring the change in Wikipedia page views for the celebrity’s Wikipedia page. Wikipedia provides daily page view statistics for each page.8 We compare the number of page-views in the two weeks prior to their death with the two weeks following their death in terms of z-score (Figure 1). Here z-scores are computed by converting the page views to standard normal variable with 0-mean and standard deviation of 1. For 9/10 of the cases we see a notable spike in number of views showing that the suicides of these individuals were well-known enough to be viewable on such a macro scale and for examining the presence of Werther Effect in social media. We note two aspects related to the above analysis and which will be used through the rest of this paper. First since we are focusing on different types of data sources—Wikipedia and Reddit we use z-score conversion as a normalization technique for the Wikipedia page views and Reddit’s SW posting activity volume. Further the above observation in Wikipedia data and the analyses that ensue focus on observing changes over a two week window preceding and succeeding a celebrity suicide; this choice is motivated by our initial analyses and from the literature on Werther Effect [17].As mentioned earlier we examine data from Reddit. We provide a description of the features of this social media platform which are important to understand the context of our research problem. Reddit allows users to submit content in the form of links or text posts organized by areas of interest or sub-communities called “subreddits” (e.g. politics programming science). Users can voice their opinion on the post via a voting mechanism which allows more popular submissions to be featured more prominently according to their score: the difference between the “upvotes” and “downvotes” cast on each post (also known as “score”). Users can also engage with each other via a comment thread attached to each post. In 2014 Reddit had 71 billion page views over 8 000 active communities 55 million posts and 535 million comments5 . In this paper we focus specifically on the subreddit called “SuicideWatch” a forum for users contemplating suicide and who seek help advice and support. It is a strong support community with (currently) about 35K subscribers. The community is highly moderated with many of its moderators and active subscribers adopting prominent roles in providing support to individuals showing vulnerability. In this subreddit votes on posts are used as a proxy for support and to increase or decrease a post’s prominence rather than as a statement of agreement/disagreement. We used Reddit’s official API6 to collect posts comments and associated metadata from r/SuicideWatch (hereafter SW). Our analysis in this paper is based on all posts made to SW between October 16 2013 and December 19 2014 – 66059 posts from 19159 unique users. Example (paraphrased) titles of posts from r/SuicideWatch are given in Table 1. We collected the title of the post the body or textual content ID timestamp author ID the number of upvotes and downvotes the post obtained including the difference between upvotes and downvotes on the post (i.e. score.),next we compiled a list of reported celebrity suicide which fell within the time range of our reddit data defining who is a celebrity is nontrivial so we refer to the wikipedia page listing celebrity suicide a a way to measure who ha sufficient celebrity status for inclusion we obtained reported celebrity suicide in the same period a our reddit data their name and reported suicide are shown in table we measure the prominence of a celebrity death by measuring the change in wikipedia page view for the celebrity wikipedia page wikipedia provides daily page view statistic for each page we compare the number of pageviews in the two week prior to their death with the two week following their death in term of zscore figure here zscores are computed by converting the page view to standard normal variable with mean and standard deviation of for of the case we see a notable spike in number of view showing that the suicide of these individual were wellknown enough to be viewable on such a macro scale and for examining the presence of werther effect in social medium we note two aspect related to the above analysis and which will be used through the rest of this paper first since we are focusing on different type of data sourceswikipedia and reddit we use zscore conversion a a normalization technique for the wikipedia page view and reddits sw posting activity volume further the above observation in wikipedia data and the analysis that ensue focus on observing change over a two week window preceding and succeeding a celebrity suicide this choice is motivated by our initial analysis and from the literature on werther effect a mentioned earlier we examine data from reddit we provide a description of the feature of this social medium platform which are important to understand the context of our research problem reddit allows user to submit content in the form of link or text post organized by area of interest or subcommunities called subreddits eg politics programming science user can voice their opinion on the post via a voting mechanism which allows more popular submission to be featured more prominently according to their score the difference between the upvotes and downvotes cast on each post also known a score user can also engage with each other via a comment thread attached to each post in reddit had billion page view over active community million post and million comment in this paper we focus specifically on the subreddit called suicidewatch a forum for user contemplating suicide and who seek help advice and support it is a strong support community with currently about k subscriber the community is highly moderated with many of it moderator and active subscriber adopting prominent role in providing support to individual showing vulnerability in this subreddit vote on post are used a a proxy for support and to increase or decrease a post prominence rather than a a statement of agreementdisagreement we used reddits official api to collect post comment and associated metadata from rsuicidewatch hereafter sw our analysis in this paper is based on all post made to sw between october and december post from unique user example paraphrased title of post from rsuicidewatch are given in table we collected the title of the post the body or textual content id timestamp author id the number of upvotes and downvotes the post obtained including the difference between upvotes and downvotes on the post ie score,"['next', 'compiled', 'list', 'reported', 'celebrity', 'suicide', 'fell', 'within', 'time', 'range', 'reddit', 'data', 'defining', 'celebrity', 'nontrivial', 'refer', 'wikipedia', 'page', 'listing', 'celebrity', 'suicide', 'way', 'measure', 'ha', 'sufficient', 'celebrity', 'status', 'inclusion', 'obtained', 'reported', 'celebrity', 'suicide', 'period', 'reddit', 'data', 'name', 'reported', 'suicide', 'shown', 'table', 'measure', 'prominence', 'celebrity', 'death', 'measuring', 'change', 'wikipedia', 'page', 'view', 'celebrity', 'wikipedia', 'page', 'wikipedia', 'provides', 'daily', 'page', 'view', 'statistic', 'page', 'compare', 'number', 'pageviews', 'two', 'week', 'prior', 'death', 'two', 'week', 'following', 'death', 'term', 'zscore', 'figure', 'zscores', 'computed', 'converting', 'page', 'view', 'standard', 'normal', 'variable', 'mean', 'standard', 'deviation', 'case', 'see', 'notable', 'spike', 'number', 'view', 'showing', 'suicide', 'individual', 'wellknown', 'enough', 'viewable', 'macro', 'scale', 'examining', 'presence', 'werther', 'effect', 'social', 'medium', 'note', 'two', 'aspect', 'related', 'analysis', 'used', 'rest', 'paper', 'first', 'since', 'focusing', 'different', 'type', 'data', 'sourceswikipedia', 'reddit', 'use', 'zscore', 'conversion', 'normalization', 'technique', 'wikipedia', 'page', 'view', 'reddits', 'sw', 'posting', 'activity', 'volume', 'observation', 'wikipedia', 'data', 'analysis', 'ensue', 'focus', 'observing', 'change', 'two', 'week', 'window', 'preceding', 'succeeding', 'celebrity', 'suicide', 'choice', 'motivated', 'initial', 'analysis', 'literature', 'werther', 'effect', 'mentioned', 'earlier', 'examine', 'data', 'reddit', 'provide', 'description', 'feature', 'social', 'medium', 'platform', 'important', 'understand', 'context', 'research', 'problem', 'reddit', 'allows', 'user', 'submit', 'content', 'form', 'link', 'text', 'post', 'organized', 'area', 'interest', 'subcommunities', 'called', 'subreddits', 'eg', 'politics', 'programming', 'science', 'user', 'voice', 'opinion', 'post', 'via', 'voting', 'mechanism', 'allows', 'popular', 'submission', 'featured', 'prominently', 'according', 'score', 'difference', 'upvotes', 'downvotes', 'cast', 'post', 'also', 'known', 'score', 'user', 'also', 'engage', 'via', 'comment', 'thread', 'attached', 'post', 'reddit', 'billion', 'page', 'view', 'active', 'community', 'million', 'post', 'million', 'comment', 'paper', 'focus', 'specifically', 'subreddit', 'called', 'suicidewatch', 'forum', 'user', 'contemplating', 'suicide', 'seek', 'help', 'advice', 'support', 'strong', 'support', 'community', 'currently', 'k', 'subscriber', 'community', 'highly', 'moderated', 'many', 'moderator', 'active', 'subscriber', 'adopting', 'prominent', 'role', 'providing', 'support', 'individual', 'showing', 'vulnerability', 'subreddit', 'vote', 'post', 'used', 'proxy', 'support', 'increase', 'decrease', 'post', 'prominence', 'rather', 'statement', 'agreementdisagreement', 'used', 'reddits', 'official', 'api', 'collect', 'post', 'comment', 'associated', 'metadata', 'rsuicidewatch', 'hereafter', 'sw', 'analysis', 'paper', 'based', 'post', 'made', 'sw', 'october', 'december', 'post', 'unique', 'user', 'example', 'paraphrased', 'title', 'post', 'rsuicidewatch', 'given', 'table', 'collected', 'title', 'post', 'body', 'textual', 'content', 'id', 'timestamp', 'author', 'id', 'number', 'upvotes', 'downvotes', 'post', 'obtained', 'including', 'difference', 'upvotes', 'downvotes', 'post', 'ie', 'score']","['next compiled', 'compiled list', 'list reported', 'reported celebrity', 'celebrity suicide', 'suicide fell', 'fell within', 'within time', 'time range', 'range reddit', 'reddit data', 'data defining', 'defining celebrity', 'celebrity nontrivial', 'nontrivial refer', 'refer wikipedia', 'wikipedia page', 'page listing', 'listing celebrity', 'celebrity suicide', 'suicide way', 'way measure', 'measure ha', 'ha sufficient', 'sufficient celebrity', 'celebrity status', 'status inclusion', 'inclusion obtained', 'obtained reported', 'reported celebrity', 'celebrity suicide', 'suicide period', 'period reddit', 'reddit data', 'data name', 'name reported', 'reported suicide', 'suicide shown', 'shown table', 'table measure', 'measure prominence', 'prominence celebrity', 'celebrity death', 'death measuring', 'measuring change', 'change wikipedia', 'wikipedia page', 'page view', 'view celebrity', 'celebrity wikipedia', 'wikipedia page', 'page wikipedia', 'wikipedia provides', 'provides daily', 'daily page', 'page view', 'view statistic', 'statistic page', 'page compare', 'compare number', 'number pageviews', 'pageviews two', 'two week', 'week prior', 'prior death', 'death two', 'two week', 'week following', 'following death', 'death term', 'term zscore', 'zscore figure', 'figure zscores', 'zscores computed', 'computed converting', 'converting page', 'page view', 'view standard', 'standard normal', 'normal variable', 'variable mean', 'mean standard', 'standard deviation', 'deviation case', 'case see', 'see notable', 'notable spike', 'spike number', 'number view', 'view showing', 'showing suicide', 'suicide individual', 'individual wellknown', 'wellknown enough', 'enough viewable', 'viewable macro', 'macro scale', 'scale examining', 'examining presence', 'presence werther', 'werther effect', 'effect social', 'social medium', 'medium note', 'note two', 'two aspect', 'aspect related', 'related analysis', 'analysis used', 'used rest', 'rest paper', 'paper first', 'first since', 'since focusing', 'focusing different', 'different type', 'type data', 'data sourceswikipedia', 'sourceswikipedia reddit', 'reddit use', 'use zscore', 'zscore conversion', 'conversion normalization', 'normalization technique', 'technique wikipedia', 'wikipedia page', 'page view', 'view reddits', 'reddits sw', 'sw posting', 'posting activity', 'activity volume', 'volume observation', 'observation wikipedia', 'wikipedia data', 'data analysis', 'analysis ensue', 'ensue focus', 'focus observing', 'observing change', 'change two', 'two week', 'week window', 'window preceding', 'preceding succeeding', 'succeeding celebrity', 'celebrity suicide', 'suicide choice', 'choice motivated', 'motivated initial', 'initial analysis', 'analysis literature', 'literature werther', 'werther effect', 'effect mentioned', 'mentioned earlier', 'earlier examine', 'examine data', 'data reddit', 'reddit provide', 'provide description', 'description feature', 'feature social', 'social medium', 'medium platform', 'platform important', 'important understand', 'understand context', 'context research', 'research problem', 'problem reddit', 'reddit allows', 'allows user', 'user submit', 'submit content', 'content form', 'form link', 'link text', 'text post', 'post organized', 'organized area', 'area interest', 'interest subcommunities', 'subcommunities called', 'called subreddits', 'subreddits eg', 'eg politics', 'politics programming', 'programming science', 'science user', 'user voice', 'voice opinion', 'opinion post', 'post via', 'via voting', 'voting mechanism', 'mechanism allows', 'allows popular', 'popular submission', 'submission featured', 'featured prominently', 'prominently according', 'according score', 'score difference', 'difference upvotes', 'upvotes downvotes', 'downvotes cast', 'cast post', 'post also', 'also known', 'known score', 'score user', 'user also', 'also engage', 'engage via', 'via comment', 'comment thread', 'thread attached', 'attached post', 'post reddit', 'reddit billion', 'billion page', 'page view', 'view active', 'active community', 'community million', 'million post', 'post million', 'million comment', 'comment paper', 'paper focus', 'focus specifically', 'specifically subreddit', 'subreddit called', 'called suicidewatch', 'suicidewatch forum', 'forum user', 'user contemplating', 'contemplating suicide', 'suicide seek', 'seek help', 'help advice', 'advice support', 'support strong', 'strong support', 'support community', 'community currently', 'currently k', 'k subscriber', 'subscriber community', 'community highly', 'highly moderated', 'moderated many', 'many moderator', 'moderator active', 'active subscriber', 'subscriber adopting', 'adopting prominent', 'prominent role', 'role providing', 'providing support', 'support individual', 'individual showing', 'showing vulnerability', 'vulnerability subreddit', 'subreddit vote', 'vote post', 'post used', 'used proxy', 'proxy support', 'support increase', 'increase decrease', 'decrease post', 'post prominence', 'prominence rather', 'rather statement', 'statement agreementdisagreement', 'agreementdisagreement used', 'used reddits', 'reddits official', 'official api', 'api collect', 'collect post', 'post comment', 'comment associated', 'associated metadata', 'metadata rsuicidewatch', 'rsuicidewatch hereafter', 'hereafter sw', 'sw analysis', 'analysis paper', 'paper based', 'based post', 'post made', 'made sw', 'sw october', 'october december', 'december post', 'post unique', 'unique user', 'user example', 'example paraphrased', 'paraphrased title', 'title post', 'post rsuicidewatch', 'rsuicidewatch given', 'given table', 'table collected', 'collected title', 'title post', 'post body', 'body textual', 'textual content', 'content id', 'id timestamp', 'timestamp author', 'author id', 'id number', 'number upvotes', 'upvotes downvotes', 'downvotes post', 'post obtained', 'obtained including', 'including difference', 'difference upvotes', 'upvotes downvotes', 'downvotes post', 'post ie', 'ie score']","['next compiled list', 'compiled list reported', 'list reported celebrity', 'reported celebrity suicide', 'celebrity suicide fell', 'suicide fell within', 'fell within time', 'within time range', 'time range reddit', 'range reddit data', 'reddit data defining', 'data defining celebrity', 'defining celebrity nontrivial', 'celebrity nontrivial refer', 'nontrivial refer wikipedia', 'refer wikipedia page', 'wikipedia page listing', 'page listing celebrity', 'listing celebrity suicide', 'celebrity suicide way', 'suicide way measure', 'way measure ha', 'measure ha sufficient', 'ha sufficient celebrity', 'sufficient celebrity status', 'celebrity status inclusion', 'status inclusion obtained', 'inclusion obtained reported', 'obtained reported celebrity', 'reported celebrity suicide', 'celebrity suicide period', 'suicide period reddit', 'period reddit data', 'reddit data name', 'data name reported', 'name reported suicide', 'reported suicide shown', 'suicide shown table', 'shown table measure', 'table measure prominence', 'measure prominence celebrity', 'prominence celebrity death', 'celebrity death measuring', 'death measuring change', 'measuring change wikipedia', 'change wikipedia page', 'wikipedia page view', 'page view celebrity', 'view celebrity wikipedia', 'celebrity wikipedia page', 'wikipedia page wikipedia', 'page wikipedia provides', 'wikipedia provides daily', 'provides daily page', 'daily page view', 'page view statistic', 'view statistic page', 'statistic page compare', 'page compare number', 'compare number pageviews', 'number pageviews two', 'pageviews two week', 'two week prior', 'week prior death', 'prior death two', 'death two week', 'two week following', 'week following death', 'following death term', 'death term zscore', 'term zscore figure', 'zscore figure zscores', 'figure zscores computed', 'zscores computed converting', 'computed converting page', 'converting page view', 'page view standard', 'view standard normal', 'standard normal variable', 'normal variable mean', 'variable mean standard', 'mean standard deviation', 'standard deviation case', 'deviation case see', 'case see notable', 'see notable spike', 'notable spike number', 'spike number view', 'number view showing', 'view showing suicide', 'showing suicide individual', 'suicide individual wellknown', 'individual wellknown enough', 'wellknown enough viewable', 'enough viewable macro', 'viewable macro scale', 'macro scale examining', 'scale examining presence', 'examining presence werther', 'presence werther effect', 'werther effect social', 'effect social medium', 'social medium note', 'medium note two', 'note two aspect', 'two aspect related', 'aspect related analysis', 'related analysis used', 'analysis used rest', 'used rest paper', 'rest paper first', 'paper first since', 'first since focusing', 'since focusing different', 'focusing different type', 'different type data', 'type data sourceswikipedia', 'data sourceswikipedia reddit', 'sourceswikipedia reddit use', 'reddit use zscore', 'use zscore conversion', 'zscore conversion normalization', 'conversion normalization technique', 'normalization technique wikipedia', 'technique wikipedia page', 'wikipedia page view', 'page view reddits', 'view reddits sw', 'reddits sw posting', 'sw posting activity', 'posting activity volume', 'activity volume observation', 'volume observation wikipedia', 'observation wikipedia data', 'wikipedia data analysis', 'data analysis ensue', 'analysis ensue focus', 'ensue focus observing', 'focus observing change', 'observing change two', 'change two week', 'two week window', 'week window preceding', 'window preceding succeeding', 'preceding succeeding celebrity', 'succeeding celebrity suicide', 'celebrity suicide choice', 'suicide choice motivated', 'choice motivated initial', 'motivated initial analysis', 'initial analysis literature', 'analysis literature werther', 'literature werther effect', 'werther effect mentioned', 'effect mentioned earlier', 'mentioned earlier examine', 'earlier examine data', 'examine data reddit', 'data reddit provide', 'reddit provide description', 'provide description feature', 'description feature social', 'feature social medium', 'social medium platform', 'medium platform important', 'platform important understand', 'important understand context', 'understand context research', 'context research problem', 'research problem reddit', 'problem reddit allows', 'reddit allows user', 'allows user submit', 'user submit content', 'submit content form', 'content form link', 'form link text', 'link text post', 'text post organized', 'post organized area', 'organized area interest', 'area interest subcommunities', 'interest subcommunities called', 'subcommunities called subreddits', 'called subreddits eg', 'subreddits eg politics', 'eg politics programming', 'politics programming science', 'programming science user', 'science user voice', 'user voice opinion', 'voice opinion post', 'opinion post via', 'post via voting', 'via voting mechanism', 'voting mechanism allows', 'mechanism allows popular', 'allows popular submission', 'popular submission featured', 'submission featured prominently', 'featured prominently according', 'prominently according score', 'according score difference', 'score difference upvotes', 'difference upvotes downvotes', 'upvotes downvotes cast', 'downvotes cast post', 'cast post also', 'post also known', 'also known score', 'known score user', 'score user also', 'user also engage', 'also engage via', 'engage via comment', 'via comment thread', 'comment thread attached', 'thread attached post', 'attached post reddit', 'post reddit billion', 'reddit billion page', 'billion page view', 'page view active', 'view active community', 'active community million', 'community million post', 'million post million', 'post million comment', 'million comment paper', 'comment paper focus', 'paper focus specifically', 'focus specifically subreddit', 'specifically subreddit called', 'subreddit called suicidewatch', 'called suicidewatch forum', 'suicidewatch forum user', 'forum user contemplating', 'user contemplating suicide', 'contemplating suicide seek', 'suicide seek help', 'seek help advice', 'help advice support', 'advice support strong', 'support strong support', 'strong support community', 'support community currently', 'community currently k', 'currently k subscriber', 'k subscriber community', 'subscriber community highly', 'community highly moderated', 'highly moderated many', 'moderated many moderator', 'many moderator active', 'moderator active subscriber', 'active subscriber adopting', 'subscriber adopting prominent', 'adopting prominent role', 'prominent role providing', 'role providing support', 'providing support individual', 'support individual showing', 'individual showing vulnerability', 'showing vulnerability subreddit', 'vulnerability subreddit vote', 'subreddit vote post', 'vote post used', 'post used proxy', 'used proxy support', 'proxy support increase', 'support increase decrease', 'increase decrease post', 'decrease post prominence', 'post prominence rather', 'prominence rather statement', 'rather statement agreementdisagreement', 'statement agreementdisagreement used', 'agreementdisagreement used reddits', 'used reddits official', 'reddits official api', 'official api collect', 'api collect post', 'collect post comment', 'post comment associated', 'comment associated metadata', 'associated metadata rsuicidewatch', 'metadata rsuicidewatch hereafter', 'rsuicidewatch hereafter sw', 'hereafter sw analysis', 'sw analysis paper', 'analysis paper based', 'paper based post', 'based post made', 'post made sw', 'made sw october', 'sw october december', 'october december post', 'december post unique', 'post unique user', 'unique user example', 'user example paraphrased', 'example paraphrased title', 'paraphrased title post', 'title post rsuicidewatch', 'post rsuicidewatch given', 'rsuicidewatch given table', 'given table collected', 'table collected title', 'collected title post', 'title post body', 'post body textual', 'body textual content', 'textual content id', 'content id timestamp', 'id timestamp author', 'timestamp author id', 'author id number', 'id number upvotes', 'number upvotes downvotes', 'upvotes downvotes post', 'downvotes post obtained', 'post obtained including', 'obtained including difference', 'including difference upvotes', 'difference upvotes downvotes', 'upvotes downvotes post', 'downvotes post ie', 'post ie score']",,,,,,,
https://aclanthology.org/W17-3110.pdf,0,We briefly explain the data collection method here but we refer the interested reader with further questions on the methodology to Coppersmith et al. (2016) for the suicide attempt data and Coppersmith et al. (2014a) for all other conditions. The data for these analyses are Twitter posts collected via two methods. Most of the data come from users who have publicly discussed their mental health conditions. These users are frequently referred to as “self-stated diagnosis” users as they state publicly something like “I was diagnosed with schizophrenia” or “I’m so thankful to have survived my suicide attempt last year”. The data for users with a suicide attempt was supplemented by data from OurDataHelps.org a data donation site where people provide access to their public posts and fill out a short questionnaire about their mental health history. Data are then deidentified and made available to researchers addressing questions of interest to the mental health community. Donors provide consent for their data to be used in mental health research upon signup. Of the users who attempted suicide 146 came from OurDataHelps.org. Specifically we examine generalized anxiety disorder eating disorders panic attacks schizophrenia and attempted suicides. These conditions were selected based on the theory that there are important timing aspects to their symptoms – ebbing and flowing of symptoms as treatment is effective (especially schizophrenia) onset and exacerbation of symptoms by external events and stress and punctuated events in time of psychological symptoms (suicide attempts panic attacks and binging/purging behavior with eating disorders). We use the Twitter streaming API to collect a sample of users who used a series of mental health words or phrases in their tweet text (e.g. ‘schizophrenia‘ or ‘suicide attempt‘). Each tweet that uses one of these phrases is examined via regular expression to indicate that the user is talking about themselves. Finally those tweets that pass the regular expression are examined by a human to confirm (to the best of our ability) that their selfstatement of diagnosis appears to be genuine. This results in a dataset with users that have a self-stated diagnosis of generalized anxiety disorder (n = 2408) an eating disorder (749) panic attacks (263) schizophrenia (350) or someone who would go on to attempt suicide (423). Some of these users do not exhibit the sort of posting behavior required to create micropatterns (i.e. they rarely post multiple times within a 3 hour time window). We exclude these users from our analysis which is 5-9% of users for most conditions with the exception of those with a suicide attempt where a little over half the users do not exhibit this posting behavior. The resultant dataset used for analyses is: generalized anxiety disorder (n = 2271) eating disorders (687) panic attacks (247) schizophrenia (318) suicide attempts (157). In order to allow comparisons of each condition to control users we gather a random sample of 10000 Twitter users for whom at least 75% of their posts are identified by Twitter as English. All the users with a self-stated diagnoses and all members of this control population have their age and gender estimated according to Sap et al. (2014). For each user with a self-stated diagnosis we find a matched control through the following procedure: create a pool of users where the estimated gender matches and the estimated age is within the same 10-year bracket (the suggested accuracy of the age estimator). From that pool of age- and gender- matched users we select the user whose tweets start and end over the most similar timeframe. We will refer to these age- gender- and time-matched controls simply as “matched controls” throughout the rest of this paper. All tweets were publicly posted by their author (i.e. no users marked at “protected” or “private” were included). On average users had 2949 tweets. The distribution of estimated age and genders for users with each self-stated condition can be seen in Figure 1. For most conditions the population skews female though for schizophrenia the genders are roughly balanced. The average age tends to be in the early-to-mid 20s.,we briefly explain the data collection method here but we refer the interested reader with further question on the methodology to coppersmith et al for the suicide attempt data and coppersmith et al a for all other condition the data for these analysis are twitter post collected via two method most of the data come from user who have publicly discussed their mental health condition these user are frequently referred to a selfstated diagnosis user a they state publicly something like i wa diagnosed with schizophrenia or im so thankful to have survived my suicide attempt last year the data for user with a suicide attempt wa supplemented by data from ourdatahelpsorg a data donation site where people provide access to their public post and fill out a short questionnaire about their mental health history data are then deidentified and made available to researcher addressing question of interest to the mental health community donor provide consent for their data to be used in mental health research upon signup of the user who attempted suicide came from ourdatahelpsorg specifically we examine generalized anxiety disorder eating disorder panic attack schizophrenia and attempted suicide these condition were selected based on the theory that there are important timing aspect to their symptom ebbing and flowing of symptom a treatment is effective especially schizophrenia onset and exacerbation of symptom by external event and stress and punctuated event in time of psychological symptom suicide attempt panic attack and bingingpurging behavior with eating disorder we use the twitter streaming api to collect a sample of user who used a series of mental health word or phrase in their tweet text eg schizophrenia or suicide attempt each tweet that us one of these phrase is examined via regular expression to indicate that the user is talking about themselves finally those tweet that pas the regular expression are examined by a human to confirm to the best of our ability that their selfstatement of diagnosis appears to be genuine this result in a dataset with user that have a selfstated diagnosis of generalized anxiety disorder n an eating disorder panic attack schizophrenia or someone who would go on to attempt suicide some of these user do not exhibit the sort of posting behavior required to create micropatterns ie they rarely post multiple time within a hour time window we exclude these user from our analysis which is of user for most condition with the exception of those with a suicide attempt where a little over half the user do not exhibit this posting behavior the resultant dataset used for analysis is generalized anxiety disorder n eating disorder panic attack schizophrenia suicide attempt in order to allow comparison of each condition to control user we gather a random sample of twitter user for whom at least of their post are identified by twitter a english all the user with a selfstated diagnosis and all member of this control population have their age and gender estimated according to sap et al for each user with a selfstated diagnosis we find a matched control through the following procedure create a pool of user where the estimated gender match and the estimated age is within the same year bracket the suggested accuracy of the age estimator from that pool of age and gender matched user we select the user whose tweet start and end over the most similar timeframe we will refer to these age gender and timematched control simply a matched control throughout the rest of this paper all tweet were publicly posted by their author ie no user marked at protected or private were included on average user had tweet the distribution of estimated age and gender for user with each selfstated condition can be seen in figure for most condition the population skews female though for schizophrenia the gender are roughly balanced the average age tends to be in the earlytomid s,"['briefly', 'explain', 'data', 'collection', 'method', 'refer', 'interested', 'reader', 'question', 'methodology', 'coppersmith', 'et', 'al', 'suicide', 'attempt', 'data', 'coppersmith', 'et', 'al', 'condition', 'data', 'analysis', 'twitter', 'post', 'collected', 'via', 'two', 'method', 'data', 'come', 'user', 'publicly', 'discussed', 'mental', 'health', 'condition', 'user', 'frequently', 'referred', 'selfstated', 'diagnosis', 'user', 'state', 'publicly', 'something', 'like', 'wa', 'diagnosed', 'schizophrenia', 'im', 'thankful', 'survived', 'suicide', 'attempt', 'last', 'year', 'data', 'user', 'suicide', 'attempt', 'wa', 'supplemented', 'data', 'ourdatahelpsorg', 'data', 'donation', 'site', 'people', 'provide', 'access', 'public', 'post', 'fill', 'short', 'questionnaire', 'mental', 'health', 'history', 'data', 'deidentified', 'made', 'available', 'researcher', 'addressing', 'question', 'interest', 'mental', 'health', 'community', 'donor', 'provide', 'consent', 'data', 'used', 'mental', 'health', 'research', 'upon', 'signup', 'user', 'attempted', 'suicide', 'came', 'ourdatahelpsorg', 'specifically', 'examine', 'generalized', 'anxiety', 'disorder', 'eating', 'disorder', 'panic', 'attack', 'schizophrenia', 'attempted', 'suicide', 'condition', 'selected', 'based', 'theory', 'important', 'timing', 'aspect', 'symptom', 'ebbing', 'flowing', 'symptom', 'treatment', 'effective', 'especially', 'schizophrenia', 'onset', 'exacerbation', 'symptom', 'external', 'event', 'stress', 'punctuated', 'event', 'time', 'psychological', 'symptom', 'suicide', 'attempt', 'panic', 'attack', 'bingingpurging', 'behavior', 'eating', 'disorder', 'use', 'twitter', 'streaming', 'api', 'collect', 'sample', 'user', 'used', 'series', 'mental', 'health', 'word', 'phrase', 'tweet', 'text', 'eg', 'schizophrenia', 'suicide', 'attempt', 'tweet', 'us', 'one', 'phrase', 'examined', 'via', 'regular', 'expression', 'indicate', 'user', 'talking', 'finally', 'tweet', 'pas', 'regular', 'expression', 'examined', 'human', 'confirm', 'best', 'ability', 'selfstatement', 'diagnosis', 'appears', 'genuine', 'result', 'dataset', 'user', 'selfstated', 'diagnosis', 'generalized', 'anxiety', 'disorder', 'n', 'eating', 'disorder', 'panic', 'attack', 'schizophrenia', 'someone', 'would', 'go', 'attempt', 'suicide', 'user', 'exhibit', 'sort', 'posting', 'behavior', 'required', 'create', 'micropatterns', 'ie', 'rarely', 'post', 'multiple', 'time', 'within', 'hour', 'time', 'window', 'exclude', 'user', 'analysis', 'user', 'condition', 'exception', 'suicide', 'attempt', 'little', 'half', 'user', 'exhibit', 'posting', 'behavior', 'resultant', 'dataset', 'used', 'analysis', 'generalized', 'anxiety', 'disorder', 'n', 'eating', 'disorder', 'panic', 'attack', 'schizophrenia', 'suicide', 'attempt', 'order', 'allow', 'comparison', 'condition', 'control', 'user', 'gather', 'random', 'sample', 'twitter', 'user', 'least', 'post', 'identified', 'twitter', 'english', 'user', 'selfstated', 'diagnosis', 'member', 'control', 'population', 'age', 'gender', 'estimated', 'according', 'sap', 'et', 'al', 'user', 'selfstated', 'diagnosis', 'find', 'matched', 'control', 'following', 'procedure', 'create', 'pool', 'user', 'estimated', 'gender', 'match', 'estimated', 'age', 'within', 'year', 'bracket', 'suggested', 'accuracy', 'age', 'estimator', 'pool', 'age', 'gender', 'matched', 'user', 'select', 'user', 'whose', 'tweet', 'start', 'end', 'similar', 'timeframe', 'refer', 'age', 'gender', 'timematched', 'control', 'simply', 'matched', 'control', 'throughout', 'rest', 'paper', 'tweet', 'publicly', 'posted', 'author', 'ie', 'user', 'marked', 'protected', 'private', 'included', 'average', 'user', 'tweet', 'distribution', 'estimated', 'age', 'gender', 'user', 'selfstated', 'condition', 'seen', 'figure', 'condition', 'population', 'skews', 'female', 'though', 'schizophrenia', 'gender', 'roughly', 'balanced', 'average', 'age', 'tends', 'earlytomid']","['briefly explain', 'explain data', 'data collection', 'collection method', 'method refer', 'refer interested', 'interested reader', 'reader question', 'question methodology', 'methodology coppersmith', 'coppersmith et', 'et al', 'al suicide', 'suicide attempt', 'attempt data', 'data coppersmith', 'coppersmith et', 'et al', 'al condition', 'condition data', 'data analysis', 'analysis twitter', 'twitter post', 'post collected', 'collected via', 'via two', 'two method', 'method data', 'data come', 'come user', 'user publicly', 'publicly discussed', 'discussed mental', 'mental health', 'health condition', 'condition user', 'user frequently', 'frequently referred', 'referred selfstated', 'selfstated diagnosis', 'diagnosis user', 'user state', 'state publicly', 'publicly something', 'something like', 'like wa', 'wa diagnosed', 'diagnosed schizophrenia', 'schizophrenia im', 'im thankful', 'thankful survived', 'survived suicide', 'suicide attempt', 'attempt last', 'last year', 'year data', 'data user', 'user suicide', 'suicide attempt', 'attempt wa', 'wa supplemented', 'supplemented data', 'data ourdatahelpsorg', 'ourdatahelpsorg data', 'data donation', 'donation site', 'site people', 'people provide', 'provide access', 'access public', 'public post', 'post fill', 'fill short', 'short questionnaire', 'questionnaire mental', 'mental health', 'health history', 'history data', 'data deidentified', 'deidentified made', 'made available', 'available researcher', 'researcher addressing', 'addressing question', 'question interest', 'interest mental', 'mental health', 'health community', 'community donor', 'donor provide', 'provide consent', 'consent data', 'data used', 'used mental', 'mental health', 'health research', 'research upon', 'upon signup', 'signup user', 'user attempted', 'attempted suicide', 'suicide came', 'came ourdatahelpsorg', 'ourdatahelpsorg specifically', 'specifically examine', 'examine generalized', 'generalized anxiety', 'anxiety disorder', 'disorder eating', 'eating disorder', 'disorder panic', 'panic attack', 'attack schizophrenia', 'schizophrenia attempted', 'attempted suicide', 'suicide condition', 'condition selected', 'selected based', 'based theory', 'theory important', 'important timing', 'timing aspect', 'aspect symptom', 'symptom ebbing', 'ebbing flowing', 'flowing symptom', 'symptom treatment', 'treatment effective', 'effective especially', 'especially schizophrenia', 'schizophrenia onset', 'onset exacerbation', 'exacerbation symptom', 'symptom external', 'external event', 'event stress', 'stress punctuated', 'punctuated event', 'event time', 'time psychological', 'psychological symptom', 'symptom suicide', 'suicide attempt', 'attempt panic', 'panic attack', 'attack bingingpurging', 'bingingpurging behavior', 'behavior eating', 'eating disorder', 'disorder use', 'use twitter', 'twitter streaming', 'streaming api', 'api collect', 'collect sample', 'sample user', 'user used', 'used series', 'series mental', 'mental health', 'health word', 'word phrase', 'phrase tweet', 'tweet text', 'text eg', 'eg schizophrenia', 'schizophrenia suicide', 'suicide attempt', 'attempt tweet', 'tweet us', 'us one', 'one phrase', 'phrase examined', 'examined via', 'via regular', 'regular expression', 'expression indicate', 'indicate user', 'user talking', 'talking finally', 'finally tweet', 'tweet pas', 'pas regular', 'regular expression', 'expression examined', 'examined human', 'human confirm', 'confirm best', 'best ability', 'ability selfstatement', 'selfstatement diagnosis', 'diagnosis appears', 'appears genuine', 'genuine result', 'result dataset', 'dataset user', 'user selfstated', 'selfstated diagnosis', 'diagnosis generalized', 'generalized anxiety', 'anxiety disorder', 'disorder n', 'n eating', 'eating disorder', 'disorder panic', 'panic attack', 'attack schizophrenia', 'schizophrenia someone', 'someone would', 'would go', 'go attempt', 'attempt suicide', 'suicide user', 'user exhibit', 'exhibit sort', 'sort posting', 'posting behavior', 'behavior required', 'required create', 'create micropatterns', 'micropatterns ie', 'ie rarely', 'rarely post', 'post multiple', 'multiple time', 'time within', 'within hour', 'hour time', 'time window', 'window exclude', 'exclude user', 'user analysis', 'analysis user', 'user condition', 'condition exception', 'exception suicide', 'suicide attempt', 'attempt little', 'little half', 'half user', 'user exhibit', 'exhibit posting', 'posting behavior', 'behavior resultant', 'resultant dataset', 'dataset used', 'used analysis', 'analysis generalized', 'generalized anxiety', 'anxiety disorder', 'disorder n', 'n eating', 'eating disorder', 'disorder panic', 'panic attack', 'attack schizophrenia', 'schizophrenia suicide', 'suicide attempt', 'attempt order', 'order allow', 'allow comparison', 'comparison condition', 'condition control', 'control user', 'user gather', 'gather random', 'random sample', 'sample twitter', 'twitter user', 'user least', 'least post', 'post identified', 'identified twitter', 'twitter english', 'english user', 'user selfstated', 'selfstated diagnosis', 'diagnosis member', 'member control', 'control population', 'population age', 'age gender', 'gender estimated', 'estimated according', 'according sap', 'sap et', 'et al', 'al user', 'user selfstated', 'selfstated diagnosis', 'diagnosis find', 'find matched', 'matched control', 'control following', 'following procedure', 'procedure create', 'create pool', 'pool user', 'user estimated', 'estimated gender', 'gender match', 'match estimated', 'estimated age', 'age within', 'within year', 'year bracket', 'bracket suggested', 'suggested accuracy', 'accuracy age', 'age estimator', 'estimator pool', 'pool age', 'age gender', 'gender matched', 'matched user', 'user select', 'select user', 'user whose', 'whose tweet', 'tweet start', 'start end', 'end similar', 'similar timeframe', 'timeframe refer', 'refer age', 'age gender', 'gender timematched', 'timematched control', 'control simply', 'simply matched', 'matched control', 'control throughout', 'throughout rest', 'rest paper', 'paper tweet', 'tweet publicly', 'publicly posted', 'posted author', 'author ie', 'ie user', 'user marked', 'marked protected', 'protected private', 'private included', 'included average', 'average user', 'user tweet', 'tweet distribution', 'distribution estimated', 'estimated age', 'age gender', 'gender user', 'user selfstated', 'selfstated condition', 'condition seen', 'seen figure', 'figure condition', 'condition population', 'population skews', 'skews female', 'female though', 'though schizophrenia', 'schizophrenia gender', 'gender roughly', 'roughly balanced', 'balanced average', 'average age', 'age tends', 'tends earlytomid']","['briefly explain data', 'explain data collection', 'data collection method', 'collection method refer', 'method refer interested', 'refer interested reader', 'interested reader question', 'reader question methodology', 'question methodology coppersmith', 'methodology coppersmith et', 'coppersmith et al', 'et al suicide', 'al suicide attempt', 'suicide attempt data', 'attempt data coppersmith', 'data coppersmith et', 'coppersmith et al', 'et al condition', 'al condition data', 'condition data analysis', 'data analysis twitter', 'analysis twitter post', 'twitter post collected', 'post collected via', 'collected via two', 'via two method', 'two method data', 'method data come', 'data come user', 'come user publicly', 'user publicly discussed', 'publicly discussed mental', 'discussed mental health', 'mental health condition', 'health condition user', 'condition user frequently', 'user frequently referred', 'frequently referred selfstated', 'referred selfstated diagnosis', 'selfstated diagnosis user', 'diagnosis user state', 'user state publicly', 'state publicly something', 'publicly something like', 'something like wa', 'like wa diagnosed', 'wa diagnosed schizophrenia', 'diagnosed schizophrenia im', 'schizophrenia im thankful', 'im thankful survived', 'thankful survived suicide', 'survived suicide attempt', 'suicide attempt last', 'attempt last year', 'last year data', 'year data user', 'data user suicide', 'user suicide attempt', 'suicide attempt wa', 'attempt wa supplemented', 'wa supplemented data', 'supplemented data ourdatahelpsorg', 'data ourdatahelpsorg data', 'ourdatahelpsorg data donation', 'data donation site', 'donation site people', 'site people provide', 'people provide access', 'provide access public', 'access public post', 'public post fill', 'post fill short', 'fill short questionnaire', 'short questionnaire mental', 'questionnaire mental health', 'mental health history', 'health history data', 'history data deidentified', 'data deidentified made', 'deidentified made available', 'made available researcher', 'available researcher addressing', 'researcher addressing question', 'addressing question interest', 'question interest mental', 'interest mental health', 'mental health community', 'health community donor', 'community donor provide', 'donor provide consent', 'provide consent data', 'consent data used', 'data used mental', 'used mental health', 'mental health research', 'health research upon', 'research upon signup', 'upon signup user', 'signup user attempted', 'user attempted suicide', 'attempted suicide came', 'suicide came ourdatahelpsorg', 'came ourdatahelpsorg specifically', 'ourdatahelpsorg specifically examine', 'specifically examine generalized', 'examine generalized anxiety', 'generalized anxiety disorder', 'anxiety disorder eating', 'disorder eating disorder', 'eating disorder panic', 'disorder panic attack', 'panic attack schizophrenia', 'attack schizophrenia attempted', 'schizophrenia attempted suicide', 'attempted suicide condition', 'suicide condition selected', 'condition selected based', 'selected based theory', 'based theory important', 'theory important timing', 'important timing aspect', 'timing aspect symptom', 'aspect symptom ebbing', 'symptom ebbing flowing', 'ebbing flowing symptom', 'flowing symptom treatment', 'symptom treatment effective', 'treatment effective especially', 'effective especially schizophrenia', 'especially schizophrenia onset', 'schizophrenia onset exacerbation', 'onset exacerbation symptom', 'exacerbation symptom external', 'symptom external event', 'external event stress', 'event stress punctuated', 'stress punctuated event', 'punctuated event time', 'event time psychological', 'time psychological symptom', 'psychological symptom suicide', 'symptom suicide attempt', 'suicide attempt panic', 'attempt panic attack', 'panic attack bingingpurging', 'attack bingingpurging behavior', 'bingingpurging behavior eating', 'behavior eating disorder', 'eating disorder use', 'disorder use twitter', 'use twitter streaming', 'twitter streaming api', 'streaming api collect', 'api collect sample', 'collect sample user', 'sample user used', 'user used series', 'used series mental', 'series mental health', 'mental health word', 'health word phrase', 'word phrase tweet', 'phrase tweet text', 'tweet text eg', 'text eg schizophrenia', 'eg schizophrenia suicide', 'schizophrenia suicide attempt', 'suicide attempt tweet', 'attempt tweet us', 'tweet us one', 'us one phrase', 'one phrase examined', 'phrase examined via', 'examined via regular', 'via regular expression', 'regular expression indicate', 'expression indicate user', 'indicate user talking', 'user talking finally', 'talking finally tweet', 'finally tweet pas', 'tweet pas regular', 'pas regular expression', 'regular expression examined', 'expression examined human', 'examined human confirm', 'human confirm best', 'confirm best ability', 'best ability selfstatement', 'ability selfstatement diagnosis', 'selfstatement diagnosis appears', 'diagnosis appears genuine', 'appears genuine result', 'genuine result dataset', 'result dataset user', 'dataset user selfstated', 'user selfstated diagnosis', 'selfstated diagnosis generalized', 'diagnosis generalized anxiety', 'generalized anxiety disorder', 'anxiety disorder n', 'disorder n eating', 'n eating disorder', 'eating disorder panic', 'disorder panic attack', 'panic attack schizophrenia', 'attack schizophrenia someone', 'schizophrenia someone would', 'someone would go', 'would go attempt', 'go attempt suicide', 'attempt suicide user', 'suicide user exhibit', 'user exhibit sort', 'exhibit sort posting', 'sort posting behavior', 'posting behavior required', 'behavior required create', 'required create micropatterns', 'create micropatterns ie', 'micropatterns ie rarely', 'ie rarely post', 'rarely post multiple', 'post multiple time', 'multiple time within', 'time within hour', 'within hour time', 'hour time window', 'time window exclude', 'window exclude user', 'exclude user analysis', 'user analysis user', 'analysis user condition', 'user condition exception', 'condition exception suicide', 'exception suicide attempt', 'suicide attempt little', 'attempt little half', 'little half user', 'half user exhibit', 'user exhibit posting', 'exhibit posting behavior', 'posting behavior resultant', 'behavior resultant dataset', 'resultant dataset used', 'dataset used analysis', 'used analysis generalized', 'analysis generalized anxiety', 'generalized anxiety disorder', 'anxiety disorder n', 'disorder n eating', 'n eating disorder', 'eating disorder panic', 'disorder panic attack', 'panic attack schizophrenia', 'attack schizophrenia suicide', 'schizophrenia suicide attempt', 'suicide attempt order', 'attempt order allow', 'order allow comparison', 'allow comparison condition', 'comparison condition control', 'condition control user', 'control user gather', 'user gather random', 'gather random sample', 'random sample twitter', 'sample twitter user', 'twitter user least', 'user least post', 'least post identified', 'post identified twitter', 'identified twitter english', 'twitter english user', 'english user selfstated', 'user selfstated diagnosis', 'selfstated diagnosis member', 'diagnosis member control', 'member control population', 'control population age', 'population age gender', 'age gender estimated', 'gender estimated according', 'estimated according sap', 'according sap et', 'sap et al', 'et al user', 'al user selfstated', 'user selfstated diagnosis', 'selfstated diagnosis find', 'diagnosis find matched', 'find matched control', 'matched control following', 'control following procedure', 'following procedure create', 'procedure create pool', 'create pool user', 'pool user estimated', 'user estimated gender', 'estimated gender match', 'gender match estimated', 'match estimated age', 'estimated age within', 'age within year', 'within year bracket', 'year bracket suggested', 'bracket suggested accuracy', 'suggested accuracy age', 'accuracy age estimator', 'age estimator pool', 'estimator pool age', 'pool age gender', 'age gender matched', 'gender matched user', 'matched user select', 'user select user', 'select user whose', 'user whose tweet', 'whose tweet start', 'tweet start end', 'start end similar', 'end similar timeframe', 'similar timeframe refer', 'timeframe refer age', 'refer age gender', 'age gender timematched', 'gender timematched control', 'timematched control simply', 'control simply matched', 'simply matched control', 'matched control throughout', 'control throughout rest', 'throughout rest paper', 'rest paper tweet', 'paper tweet publicly', 'tweet publicly posted', 'publicly posted author', 'posted author ie', 'author ie user', 'ie user marked', 'user marked protected', 'marked protected private', 'protected private included', 'private included average', 'included average user', 'average user tweet', 'user tweet distribution', 'tweet distribution estimated', 'distribution estimated age', 'estimated age gender', 'age gender user', 'gender user selfstated', 'user selfstated condition', 'selfstated condition seen', 'condition seen figure', 'seen figure condition', 'figure condition population', 'condition population skews', 'population skews female', 'skews female though', 'female though schizophrenia', 'though schizophrenia gender', 'schizophrenia gender roughly', 'gender roughly balanced', 'roughly balanced average', 'balanced average age', 'average age tends', 'age tends earlytomid']",,,,,,,
https://dl.acm.org/doi/abs/10.1145/2998181.2998220,1,For inferring gender of a user in our two datasets we compared account names to existing name databases. First of all we started cleaning the account names and subsequently identifying the first and last name on the basis of a 1-gram lookup. Thereafter we compared the names to country-specific name databases. For this the country origin of a Twitter user was firstly retrieved using the Country Name Inference giving the user’s specified location. If the gender could not be retrieved using the previous method it would look up the name over all the country-specific lookup tables. For analytical simplicity we only consider binary gender (female/male) in this paper.,for inferring gender of a user in our two datasets we compared account name to existing name database first of all we started cleaning the account name and subsequently identifying the first and last name on the basis of a gram lookup thereafter we compared the name to countryspecific name database for this the country origin of a twitter user wa firstly retrieved using the country name inference giving the user specified location if the gender could not be retrieved using the previous method it would look up the name over all the countryspecific lookup table for analytical simplicity we only consider binary gender femalemale in this paper,"['inferring', 'gender', 'user', 'two', 'datasets', 'compared', 'account', 'name', 'existing', 'name', 'database', 'first', 'started', 'cleaning', 'account', 'name', 'subsequently', 'identifying', 'first', 'last', 'name', 'basis', 'gram', 'lookup', 'thereafter', 'compared', 'name', 'countryspecific', 'name', 'database', 'country', 'origin', 'twitter', 'user', 'wa', 'firstly', 'retrieved', 'using', 'country', 'name', 'inference', 'giving', 'user', 'specified', 'location', 'gender', 'could', 'retrieved', 'using', 'previous', 'method', 'would', 'look', 'name', 'countryspecific', 'lookup', 'table', 'analytical', 'simplicity', 'consider', 'binary', 'gender', 'femalemale', 'paper']","['inferring gender', 'gender user', 'user two', 'two datasets', 'datasets compared', 'compared account', 'account name', 'name existing', 'existing name', 'name database', 'database first', 'first started', 'started cleaning', 'cleaning account', 'account name', 'name subsequently', 'subsequently identifying', 'identifying first', 'first last', 'last name', 'name basis', 'basis gram', 'gram lookup', 'lookup thereafter', 'thereafter compared', 'compared name', 'name countryspecific', 'countryspecific name', 'name database', 'database country', 'country origin', 'origin twitter', 'twitter user', 'user wa', 'wa firstly', 'firstly retrieved', 'retrieved using', 'using country', 'country name', 'name inference', 'inference giving', 'giving user', 'user specified', 'specified location', 'location gender', 'gender could', 'could retrieved', 'retrieved using', 'using previous', 'previous method', 'method would', 'would look', 'look name', 'name countryspecific', 'countryspecific lookup', 'lookup table', 'table analytical', 'analytical simplicity', 'simplicity consider', 'consider binary', 'binary gender', 'gender femalemale', 'femalemale paper']","['inferring gender user', 'gender user two', 'user two datasets', 'two datasets compared', 'datasets compared account', 'compared account name', 'account name existing', 'name existing name', 'existing name database', 'name database first', 'database first started', 'first started cleaning', 'started cleaning account', 'cleaning account name', 'account name subsequently', 'name subsequently identifying', 'subsequently identifying first', 'identifying first last', 'first last name', 'last name basis', 'name basis gram', 'basis gram lookup', 'gram lookup thereafter', 'lookup thereafter compared', 'thereafter compared name', 'compared name countryspecific', 'name countryspecific name', 'countryspecific name database', 'name database country', 'database country origin', 'country origin twitter', 'origin twitter user', 'twitter user wa', 'user wa firstly', 'wa firstly retrieved', 'firstly retrieved using', 'retrieved using country', 'using country name', 'country name inference', 'name inference giving', 'inference giving user', 'giving user specified', 'user specified location', 'specified location gender', 'location gender could', 'gender could retrieved', 'could retrieved using', 'retrieved using previous', 'using previous method', 'previous method would', 'method would look', 'would look name', 'look name countryspecific', 'name countryspecific lookup', 'countryspecific lookup table', 'lookup table analytical', 'table analytical simplicity', 'analytical simplicity consider', 'simplicity consider binary', 'consider binary gender', 'binary gender femalemale', 'gender femalemale paper']",,,,,,,
https://www.jmir.org/2019/6/e14199/,0,The selection of the tweets and their users was based on the filtered real-time streaming support provided by the Twitter API. In the first step we selected the users who showed potential signs of depression on Twitter on the basis of the 20 most frequent words in Spanish expressed by patients suffering from depression in clinical settings. These words were jointly identified and selected by a psychologist and a family physician with clinical experience and were based on the definition and general features of depression according to the Diagnostic and Statistical Manual of Mental Disorders [42]. The list of words used and their English translations are shown in Textbox 1. During June 2018 1470000 tweets including 1 or more occurrences of the words listed in Textbox 1 were collected. From this collection of tweets and to select the users who publicly stated in the textual description associated to their profile that they suffered from depression all the profile descriptions including 1 or more occurrences of the word “depr” and all the possible derivations related to the word depression in Spanish such as “depre” “depresión” “depresivo” “depresiva” “deprimido” and “deprimida” were considered. From the 720 users who included 1 or more of these words in their description profile 90 users who stated they suffered from depression or were receiving treatment for depression were selected for the analysis. This selection was performed by a psychologist verifying that the statements were related to real expressions of depression excluding quotes jokes or fake ones. For each of these depressed Twitter users we collected all the most recent tweets from their timeline up to a maximum of about 3200 tweets. Thus a total of 189669 tweets were collected a figure that was reduced to 140946 after discarding the retweets. These 140946 tweets constituted the depressive users dataset. Examples of sentences appearing in the user profiles that were used for selecting the depressive users are: “Paciente psiquiátrico con depresión crónica” (Psychiatric patient with chronic depression; example of a profile sentence that indicates depression). “Colecciono errores traducidos a tweets depresivos y a uno que otro impulso de amor” (I gather errors translated into depressing tweets and into one or another love impulse; example of a profile sentence that does not indicate depression). Once the users with profile sentences indicating depression had been retrieved their Twitter timelines were collected. Only those users having in their timeline at least 10 tweets that suggested signs of depression were retained for further analyses. For each user the selection of these tweets was performed by manually inspecting the tweets of the user’s complete timeline in reverse temporal order starting from the most recent one to the oldest tweet of the timeline retrieved by means of the Twitter API . Finally a total number of 1000 tweets issued by the 90 depressive users suggesting signs of depression were detected and used for the analysis. This set of tweets provided us with the depressive tweets dataset which was used to analyze linguistic features of tweets showing signs of depression. It has to be mentioned that these 1000 tweets were not to be included in the depressive users dataset (see Figure 1). At the same time more than 97500000 tweets were also collected in June 2018: such tweets were gathered by listening to the public Twitter stream during this time span by only considering tweets with Spanish textual contents (as detected by Twitter language identification support). Given that Twitter requires more restrictive filters than just the language of the tweets we used a list of the most frequently used Spanish words (stopwords) to retrieve all tweets that included 1 or more of these words. The vast majority of Spanish tweets should match this criterion. A sample of 450 users who did not mention in their profile the word depression and its derivations were selected randomly from the 97500000 tweets. The complete timelines of these users were compiled (1141021 tweets) which were reduced to 712589 once retweets were removed. These 712589 tweets constituted the control dataset. To identify the language of a tweet we relied on the language automatically identified by Twitter for each tweet selecting tweets in Spanish. It has to be noted that these data can contain some tweets from unidentified depressive users.,the selection of the tweet and their user wa based on the filtered realtime streaming support provided by the twitter api in the first step we selected the user who showed potential sign of depression on twitter on the basis of the most frequent word in spanish expressed by patient suffering from depression in clinical setting these word were jointly identified and selected by a psychologist and a family physician with clinical experience and were based on the definition and general feature of depression according to the diagnostic and statistical manual of mental disorder the list of word used and their english translation are shown in textbox during june tweet including or more occurrence of the word listed in textbox were collected from this collection of tweet and to select the user who publicly stated in the textual description associated to their profile that they suffered from depression all the profile description including or more occurrence of the word depr and all the possible derivation related to the word depression in spanish such a depre depresin depresivo depresiva deprimido and deprimida were considered from the user who included or more of these word in their description profile user who stated they suffered from depression or were receiving treatment for depression were selected for the analysis this selection wa performed by a psychologist verifying that the statement were related to real expression of depression excluding quote joke or fake one for each of these depressed twitter user we collected all the most recent tweet from their timeline up to a maximum of about tweet thus a total of tweet were collected a figure that wa reduced to after discarding the retweets these tweet constituted the depressive user dataset example of sentence appearing in the user profile that were used for selecting the depressive user are paciente psiquitrico con depresin crnica psychiatric patient with chronic depression example of a profile sentence that indicates depression colecciono errores traducidos a tweet depresivos y a uno que otro impulso de amor i gather error translated into depressing tweet and into one or another love impulse example of a profile sentence that doe not indicate depression once the user with profile sentence indicating depression had been retrieved their twitter timeline were collected only those user having in their timeline at least tweet that suggested sign of depression were retained for further analysis for each user the selection of these tweet wa performed by manually inspecting the tweet of the user complete timeline in reverse temporal order starting from the most recent one to the oldest tweet of the timeline retrieved by mean of the twitter api finally a total number of tweet issued by the depressive user suggesting sign of depression were detected and used for the analysis this set of tweet provided u with the depressive tweet dataset which wa used to analyze linguistic feature of tweet showing sign of depression it ha to be mentioned that these tweet were not to be included in the depressive user dataset see figure at the same time more than tweet were also collected in june such tweet were gathered by listening to the public twitter stream during this time span by only considering tweet with spanish textual content a detected by twitter language identification support given that twitter requires more restrictive filter than just the language of the tweet we used a list of the most frequently used spanish word stopwords to retrieve all tweet that included or more of these word the vast majority of spanish tweet should match this criterion a sample of user who did not mention in their profile the word depression and it derivation were selected randomly from the tweet the complete timeline of these user were compiled tweet which were reduced to once retweets were removed these tweet constituted the control dataset to identify the language of a tweet we relied on the language automatically identified by twitter for each tweet selecting tweet in spanish it ha to be noted that these data can contain some tweet from unidentified depressive user,"['selection', 'tweet', 'user', 'wa', 'based', 'filtered', 'realtime', 'streaming', 'support', 'provided', 'twitter', 'api', 'first', 'step', 'selected', 'user', 'showed', 'potential', 'sign', 'depression', 'twitter', 'basis', 'frequent', 'word', 'spanish', 'expressed', 'patient', 'suffering', 'depression', 'clinical', 'setting', 'word', 'jointly', 'identified', 'selected', 'psychologist', 'family', 'physician', 'clinical', 'experience', 'based', 'definition', 'general', 'feature', 'depression', 'according', 'diagnostic', 'statistical', 'manual', 'mental', 'disorder', 'list', 'word', 'used', 'english', 'translation', 'shown', 'textbox', 'june', 'tweet', 'including', 'occurrence', 'word', 'listed', 'textbox', 'collected', 'collection', 'tweet', 'select', 'user', 'publicly', 'stated', 'textual', 'description', 'associated', 'profile', 'suffered', 'depression', 'profile', 'description', 'including', 'occurrence', 'word', 'depr', 'possible', 'derivation', 'related', 'word', 'depression', 'spanish', 'depre', 'depresin', 'depresivo', 'depresiva', 'deprimido', 'deprimida', 'considered', 'user', 'included', 'word', 'description', 'profile', 'user', 'stated', 'suffered', 'depression', 'receiving', 'treatment', 'depression', 'selected', 'analysis', 'selection', 'wa', 'performed', 'psychologist', 'verifying', 'statement', 'related', 'real', 'expression', 'depression', 'excluding', 'quote', 'joke', 'fake', 'one', 'depressed', 'twitter', 'user', 'collected', 'recent', 'tweet', 'timeline', 'maximum', 'tweet', 'thus', 'total', 'tweet', 'collected', 'figure', 'wa', 'reduced', 'discarding', 'retweets', 'tweet', 'constituted', 'depressive', 'user', 'dataset', 'example', 'sentence', 'appearing', 'user', 'profile', 'used', 'selecting', 'depressive', 'user', 'paciente', 'psiquitrico', 'con', 'depresin', 'crnica', 'psychiatric', 'patient', 'chronic', 'depression', 'example', 'profile', 'sentence', 'indicates', 'depression', 'colecciono', 'errores', 'traducidos', 'tweet', 'depresivos', 'uno', 'que', 'otro', 'impulso', 'de', 'amor', 'gather', 'error', 'translated', 'depressing', 'tweet', 'one', 'another', 'love', 'impulse', 'example', 'profile', 'sentence', 'doe', 'indicate', 'depression', 'user', 'profile', 'sentence', 'indicating', 'depression', 'retrieved', 'twitter', 'timeline', 'collected', 'user', 'timeline', 'least', 'tweet', 'suggested', 'sign', 'depression', 'retained', 'analysis', 'user', 'selection', 'tweet', 'wa', 'performed', 'manually', 'inspecting', 'tweet', 'user', 'complete', 'timeline', 'reverse', 'temporal', 'order', 'starting', 'recent', 'one', 'oldest', 'tweet', 'timeline', 'retrieved', 'mean', 'twitter', 'api', 'finally', 'total', 'number', 'tweet', 'issued', 'depressive', 'user', 'suggesting', 'sign', 'depression', 'detected', 'used', 'analysis', 'set', 'tweet', 'provided', 'u', 'depressive', 'tweet', 'dataset', 'wa', 'used', 'analyze', 'linguistic', 'feature', 'tweet', 'showing', 'sign', 'depression', 'ha', 'mentioned', 'tweet', 'included', 'depressive', 'user', 'dataset', 'see', 'figure', 'time', 'tweet', 'also', 'collected', 'june', 'tweet', 'gathered', 'listening', 'public', 'twitter', 'stream', 'time', 'span', 'considering', 'tweet', 'spanish', 'textual', 'content', 'detected', 'twitter', 'language', 'identification', 'support', 'given', 'twitter', 'requires', 'restrictive', 'filter', 'language', 'tweet', 'used', 'list', 'frequently', 'used', 'spanish', 'word', 'stopwords', 'retrieve', 'tweet', 'included', 'word', 'vast', 'majority', 'spanish', 'tweet', 'match', 'criterion', 'sample', 'user', 'mention', 'profile', 'word', 'depression', 'derivation', 'selected', 'randomly', 'tweet', 'complete', 'timeline', 'user', 'compiled', 'tweet', 'reduced', 'retweets', 'removed', 'tweet', 'constituted', 'control', 'dataset', 'identify', 'language', 'tweet', 'relied', 'language', 'automatically', 'identified', 'twitter', 'tweet', 'selecting', 'tweet', 'spanish', 'ha', 'noted', 'data', 'contain', 'tweet', 'unidentified', 'depressive', 'user']","['selection tweet', 'tweet user', 'user wa', 'wa based', 'based filtered', 'filtered realtime', 'realtime streaming', 'streaming support', 'support provided', 'provided twitter', 'twitter api', 'api first', 'first step', 'step selected', 'selected user', 'user showed', 'showed potential', 'potential sign', 'sign depression', 'depression twitter', 'twitter basis', 'basis frequent', 'frequent word', 'word spanish', 'spanish expressed', 'expressed patient', 'patient suffering', 'suffering depression', 'depression clinical', 'clinical setting', 'setting word', 'word jointly', 'jointly identified', 'identified selected', 'selected psychologist', 'psychologist family', 'family physician', 'physician clinical', 'clinical experience', 'experience based', 'based definition', 'definition general', 'general feature', 'feature depression', 'depression according', 'according diagnostic', 'diagnostic statistical', 'statistical manual', 'manual mental', 'mental disorder', 'disorder list', 'list word', 'word used', 'used english', 'english translation', 'translation shown', 'shown textbox', 'textbox june', 'june tweet', 'tweet including', 'including occurrence', 'occurrence word', 'word listed', 'listed textbox', 'textbox collected', 'collected collection', 'collection tweet', 'tweet select', 'select user', 'user publicly', 'publicly stated', 'stated textual', 'textual description', 'description associated', 'associated profile', 'profile suffered', 'suffered depression', 'depression profile', 'profile description', 'description including', 'including occurrence', 'occurrence word', 'word depr', 'depr possible', 'possible derivation', 'derivation related', 'related word', 'word depression', 'depression spanish', 'spanish depre', 'depre depresin', 'depresin depresivo', 'depresivo depresiva', 'depresiva deprimido', 'deprimido deprimida', 'deprimida considered', 'considered user', 'user included', 'included word', 'word description', 'description profile', 'profile user', 'user stated', 'stated suffered', 'suffered depression', 'depression receiving', 'receiving treatment', 'treatment depression', 'depression selected', 'selected analysis', 'analysis selection', 'selection wa', 'wa performed', 'performed psychologist', 'psychologist verifying', 'verifying statement', 'statement related', 'related real', 'real expression', 'expression depression', 'depression excluding', 'excluding quote', 'quote joke', 'joke fake', 'fake one', 'one depressed', 'depressed twitter', 'twitter user', 'user collected', 'collected recent', 'recent tweet', 'tweet timeline', 'timeline maximum', 'maximum tweet', 'tweet thus', 'thus total', 'total tweet', 'tweet collected', 'collected figure', 'figure wa', 'wa reduced', 'reduced discarding', 'discarding retweets', 'retweets tweet', 'tweet constituted', 'constituted depressive', 'depressive user', 'user dataset', 'dataset example', 'example sentence', 'sentence appearing', 'appearing user', 'user profile', 'profile used', 'used selecting', 'selecting depressive', 'depressive user', 'user paciente', 'paciente psiquitrico', 'psiquitrico con', 'con depresin', 'depresin crnica', 'crnica psychiatric', 'psychiatric patient', 'patient chronic', 'chronic depression', 'depression example', 'example profile', 'profile sentence', 'sentence indicates', 'indicates depression', 'depression colecciono', 'colecciono errores', 'errores traducidos', 'traducidos tweet', 'tweet depresivos', 'depresivos uno', 'uno que', 'que otro', 'otro impulso', 'impulso de', 'de amor', 'amor gather', 'gather error', 'error translated', 'translated depressing', 'depressing tweet', 'tweet one', 'one another', 'another love', 'love impulse', 'impulse example', 'example profile', 'profile sentence', 'sentence doe', 'doe indicate', 'indicate depression', 'depression user', 'user profile', 'profile sentence', 'sentence indicating', 'indicating depression', 'depression retrieved', 'retrieved twitter', 'twitter timeline', 'timeline collected', 'collected user', 'user timeline', 'timeline least', 'least tweet', 'tweet suggested', 'suggested sign', 'sign depression', 'depression retained', 'retained analysis', 'analysis user', 'user selection', 'selection tweet', 'tweet wa', 'wa performed', 'performed manually', 'manually inspecting', 'inspecting tweet', 'tweet user', 'user complete', 'complete timeline', 'timeline reverse', 'reverse temporal', 'temporal order', 'order starting', 'starting recent', 'recent one', 'one oldest', 'oldest tweet', 'tweet timeline', 'timeline retrieved', 'retrieved mean', 'mean twitter', 'twitter api', 'api finally', 'finally total', 'total number', 'number tweet', 'tweet issued', 'issued depressive', 'depressive user', 'user suggesting', 'suggesting sign', 'sign depression', 'depression detected', 'detected used', 'used analysis', 'analysis set', 'set tweet', 'tweet provided', 'provided u', 'u depressive', 'depressive tweet', 'tweet dataset', 'dataset wa', 'wa used', 'used analyze', 'analyze linguistic', 'linguistic feature', 'feature tweet', 'tweet showing', 'showing sign', 'sign depression', 'depression ha', 'ha mentioned', 'mentioned tweet', 'tweet included', 'included depressive', 'depressive user', 'user dataset', 'dataset see', 'see figure', 'figure time', 'time tweet', 'tweet also', 'also collected', 'collected june', 'june tweet', 'tweet gathered', 'gathered listening', 'listening public', 'public twitter', 'twitter stream', 'stream time', 'time span', 'span considering', 'considering tweet', 'tweet spanish', 'spanish textual', 'textual content', 'content detected', 'detected twitter', 'twitter language', 'language identification', 'identification support', 'support given', 'given twitter', 'twitter requires', 'requires restrictive', 'restrictive filter', 'filter language', 'language tweet', 'tweet used', 'used list', 'list frequently', 'frequently used', 'used spanish', 'spanish word', 'word stopwords', 'stopwords retrieve', 'retrieve tweet', 'tweet included', 'included word', 'word vast', 'vast majority', 'majority spanish', 'spanish tweet', 'tweet match', 'match criterion', 'criterion sample', 'sample user', 'user mention', 'mention profile', 'profile word', 'word depression', 'depression derivation', 'derivation selected', 'selected randomly', 'randomly tweet', 'tweet complete', 'complete timeline', 'timeline user', 'user compiled', 'compiled tweet', 'tweet reduced', 'reduced retweets', 'retweets removed', 'removed tweet', 'tweet constituted', 'constituted control', 'control dataset', 'dataset identify', 'identify language', 'language tweet', 'tweet relied', 'relied language', 'language automatically', 'automatically identified', 'identified twitter', 'twitter tweet', 'tweet selecting', 'selecting tweet', 'tweet spanish', 'spanish ha', 'ha noted', 'noted data', 'data contain', 'contain tweet', 'tweet unidentified', 'unidentified depressive', 'depressive user']","['selection tweet user', 'tweet user wa', 'user wa based', 'wa based filtered', 'based filtered realtime', 'filtered realtime streaming', 'realtime streaming support', 'streaming support provided', 'support provided twitter', 'provided twitter api', 'twitter api first', 'api first step', 'first step selected', 'step selected user', 'selected user showed', 'user showed potential', 'showed potential sign', 'potential sign depression', 'sign depression twitter', 'depression twitter basis', 'twitter basis frequent', 'basis frequent word', 'frequent word spanish', 'word spanish expressed', 'spanish expressed patient', 'expressed patient suffering', 'patient suffering depression', 'suffering depression clinical', 'depression clinical setting', 'clinical setting word', 'setting word jointly', 'word jointly identified', 'jointly identified selected', 'identified selected psychologist', 'selected psychologist family', 'psychologist family physician', 'family physician clinical', 'physician clinical experience', 'clinical experience based', 'experience based definition', 'based definition general', 'definition general feature', 'general feature depression', 'feature depression according', 'depression according diagnostic', 'according diagnostic statistical', 'diagnostic statistical manual', 'statistical manual mental', 'manual mental disorder', 'mental disorder list', 'disorder list word', 'list word used', 'word used english', 'used english translation', 'english translation shown', 'translation shown textbox', 'shown textbox june', 'textbox june tweet', 'june tweet including', 'tweet including occurrence', 'including occurrence word', 'occurrence word listed', 'word listed textbox', 'listed textbox collected', 'textbox collected collection', 'collected collection tweet', 'collection tweet select', 'tweet select user', 'select user publicly', 'user publicly stated', 'publicly stated textual', 'stated textual description', 'textual description associated', 'description associated profile', 'associated profile suffered', 'profile suffered depression', 'suffered depression profile', 'depression profile description', 'profile description including', 'description including occurrence', 'including occurrence word', 'occurrence word depr', 'word depr possible', 'depr possible derivation', 'possible derivation related', 'derivation related word', 'related word depression', 'word depression spanish', 'depression spanish depre', 'spanish depre depresin', 'depre depresin depresivo', 'depresin depresivo depresiva', 'depresivo depresiva deprimido', 'depresiva deprimido deprimida', 'deprimido deprimida considered', 'deprimida considered user', 'considered user included', 'user included word', 'included word description', 'word description profile', 'description profile user', 'profile user stated', 'user stated suffered', 'stated suffered depression', 'suffered depression receiving', 'depression receiving treatment', 'receiving treatment depression', 'treatment depression selected', 'depression selected analysis', 'selected analysis selection', 'analysis selection wa', 'selection wa performed', 'wa performed psychologist', 'performed psychologist verifying', 'psychologist verifying statement', 'verifying statement related', 'statement related real', 'related real expression', 'real expression depression', 'expression depression excluding', 'depression excluding quote', 'excluding quote joke', 'quote joke fake', 'joke fake one', 'fake one depressed', 'one depressed twitter', 'depressed twitter user', 'twitter user collected', 'user collected recent', 'collected recent tweet', 'recent tweet timeline', 'tweet timeline maximum', 'timeline maximum tweet', 'maximum tweet thus', 'tweet thus total', 'thus total tweet', 'total tweet collected', 'tweet collected figure', 'collected figure wa', 'figure wa reduced', 'wa reduced discarding', 'reduced discarding retweets', 'discarding retweets tweet', 'retweets tweet constituted', 'tweet constituted depressive', 'constituted depressive user', 'depressive user dataset', 'user dataset example', 'dataset example sentence', 'example sentence appearing', 'sentence appearing user', 'appearing user profile', 'user profile used', 'profile used selecting', 'used selecting depressive', 'selecting depressive user', 'depressive user paciente', 'user paciente psiquitrico', 'paciente psiquitrico con', 'psiquitrico con depresin', 'con depresin crnica', 'depresin crnica psychiatric', 'crnica psychiatric patient', 'psychiatric patient chronic', 'patient chronic depression', 'chronic depression example', 'depression example profile', 'example profile sentence', 'profile sentence indicates', 'sentence indicates depression', 'indicates depression colecciono', 'depression colecciono errores', 'colecciono errores traducidos', 'errores traducidos tweet', 'traducidos tweet depresivos', 'tweet depresivos uno', 'depresivos uno que', 'uno que otro', 'que otro impulso', 'otro impulso de', 'impulso de amor', 'de amor gather', 'amor gather error', 'gather error translated', 'error translated depressing', 'translated depressing tweet', 'depressing tweet one', 'tweet one another', 'one another love', 'another love impulse', 'love impulse example', 'impulse example profile', 'example profile sentence', 'profile sentence doe', 'sentence doe indicate', 'doe indicate depression', 'indicate depression user', 'depression user profile', 'user profile sentence', 'profile sentence indicating', 'sentence indicating depression', 'indicating depression retrieved', 'depression retrieved twitter', 'retrieved twitter timeline', 'twitter timeline collected', 'timeline collected user', 'collected user timeline', 'user timeline least', 'timeline least tweet', 'least tweet suggested', 'tweet suggested sign', 'suggested sign depression', 'sign depression retained', 'depression retained analysis', 'retained analysis user', 'analysis user selection', 'user selection tweet', 'selection tweet wa', 'tweet wa performed', 'wa performed manually', 'performed manually inspecting', 'manually inspecting tweet', 'inspecting tweet user', 'tweet user complete', 'user complete timeline', 'complete timeline reverse', 'timeline reverse temporal', 'reverse temporal order', 'temporal order starting', 'order starting recent', 'starting recent one', 'recent one oldest', 'one oldest tweet', 'oldest tweet timeline', 'tweet timeline retrieved', 'timeline retrieved mean', 'retrieved mean twitter', 'mean twitter api', 'twitter api finally', 'api finally total', 'finally total number', 'total number tweet', 'number tweet issued', 'tweet issued depressive', 'issued depressive user', 'depressive user suggesting', 'user suggesting sign', 'suggesting sign depression', 'sign depression detected', 'depression detected used', 'detected used analysis', 'used analysis set', 'analysis set tweet', 'set tweet provided', 'tweet provided u', 'provided u depressive', 'u depressive tweet', 'depressive tweet dataset', 'tweet dataset wa', 'dataset wa used', 'wa used analyze', 'used analyze linguistic', 'analyze linguistic feature', 'linguistic feature tweet', 'feature tweet showing', 'tweet showing sign', 'showing sign depression', 'sign depression ha', 'depression ha mentioned', 'ha mentioned tweet', 'mentioned tweet included', 'tweet included depressive', 'included depressive user', 'depressive user dataset', 'user dataset see', 'dataset see figure', 'see figure time', 'figure time tweet', 'time tweet also', 'tweet also collected', 'also collected june', 'collected june tweet', 'june tweet gathered', 'tweet gathered listening', 'gathered listening public', 'listening public twitter', 'public twitter stream', 'twitter stream time', 'stream time span', 'time span considering', 'span considering tweet', 'considering tweet spanish', 'tweet spanish textual', 'spanish textual content', 'textual content detected', 'content detected twitter', 'detected twitter language', 'twitter language identification', 'language identification support', 'identification support given', 'support given twitter', 'given twitter requires', 'twitter requires restrictive', 'requires restrictive filter', 'restrictive filter language', 'filter language tweet', 'language tweet used', 'tweet used list', 'used list frequently', 'list frequently used', 'frequently used spanish', 'used spanish word', 'spanish word stopwords', 'word stopwords retrieve', 'stopwords retrieve tweet', 'retrieve tweet included', 'tweet included word', 'included word vast', 'word vast majority', 'vast majority spanish', 'majority spanish tweet', 'spanish tweet match', 'tweet match criterion', 'match criterion sample', 'criterion sample user', 'sample user mention', 'user mention profile', 'mention profile word', 'profile word depression', 'word depression derivation', 'depression derivation selected', 'derivation selected randomly', 'selected randomly tweet', 'randomly tweet complete', 'tweet complete timeline', 'complete timeline user', 'timeline user compiled', 'user compiled tweet', 'compiled tweet reduced', 'tweet reduced retweets', 'reduced retweets removed', 'retweets removed tweet', 'removed tweet constituted', 'tweet constituted control', 'constituted control dataset', 'control dataset identify', 'dataset identify language', 'identify language tweet', 'language tweet relied', 'tweet relied language', 'relied language automatically', 'language automatically identified', 'automatically identified twitter', 'identified twitter tweet', 'twitter tweet selecting', 'tweet selecting tweet', 'selecting tweet spanish', 'tweet spanish ha', 'spanish ha noted', 'ha noted data', 'noted data contain', 'data contain tweet', 'contain tweet unidentified', 'tweet unidentified depressive', 'unidentified depressive user']",,,,,,,
https://aclanthology.org/W18-0608.pdf,0,Data was collected from 7 Cups of Tea an anonymous online chat-based peer support community for emotional distress1 . Users agree at signup that their data may be used for the purposes of research. All the data used for the current study was anonymous and securely stored. This research was performed in line with the ethical and privacy protocols outlined in detail in (Benton et al. 2017). Data from 7 Cups takes the form of written dialogue between users of the service and volunteers who are trained as “active listeners”. A fragment of an exchange between the user of the service (U) and the volunteer (V) might go as follows: For the analyses reported in this paper we used only text generated by users of the service not the volunteers providing peer support. Users who reported depression as their primary concern at sign up were eligible for inclusion in analyses. Our original sample was comprised of 23048 conversations involving 1937 unique users. Users were excluded from the sample if they did not indicate their culture or if they selected ‘Other’. This resulted in the exclusion of 199 and 130 users respectively. The original sample also included users identifying as Native American or American Indian. This group was excluded from analyses since the majority of the data among these users was not English. This resulted in the removal of 15 users leaving a total sample size of 1593.,data wa collected from cup of tea an anonymous online chatbased peer support community for emotional distress user agree at signup that their data may be used for the purpose of research all the data used for the current study wa anonymous and securely stored this research wa performed in line with the ethical and privacy protocol outlined in detail in benton et al data from cup take the form of written dialogue between user of the service and volunteer who are trained a active listener a fragment of an exchange between the user of the service u and the volunteer v might go a follows for the analysis reported in this paper we used only text generated by user of the service not the volunteer providing peer support user who reported depression a their primary concern at sign up were eligible for inclusion in analysis our original sample wa comprised of conversation involving unique user user were excluded from the sample if they did not indicate their culture or if they selected other this resulted in the exclusion of and user respectively the original sample also included user identifying a native american or american indian this group wa excluded from analysis since the majority of the data among these user wa not english this resulted in the removal of user leaving a total sample size of,"['data', 'wa', 'collected', 'cup', 'tea', 'anonymous', 'online', 'chatbased', 'peer', 'support', 'community', 'emotional', 'distress', 'user', 'agree', 'signup', 'data', 'may', 'used', 'purpose', 'research', 'data', 'used', 'current', 'study', 'wa', 'anonymous', 'securely', 'stored', 'research', 'wa', 'performed', 'line', 'ethical', 'privacy', 'protocol', 'outlined', 'detail', 'benton', 'et', 'al', 'data', 'cup', 'take', 'form', 'written', 'dialogue', 'user', 'service', 'volunteer', 'trained', 'active', 'listener', 'fragment', 'exchange', 'user', 'service', 'u', 'volunteer', 'v', 'might', 'go', 'follows', 'analysis', 'reported', 'paper', 'used', 'text', 'generated', 'user', 'service', 'volunteer', 'providing', 'peer', 'support', 'user', 'reported', 'depression', 'primary', 'concern', 'sign', 'eligible', 'inclusion', 'analysis', 'original', 'sample', 'wa', 'comprised', 'conversation', 'involving', 'unique', 'user', 'user', 'excluded', 'sample', 'indicate', 'culture', 'selected', 'resulted', 'exclusion', 'user', 'respectively', 'original', 'sample', 'also', 'included', 'user', 'identifying', 'native', 'american', 'american', 'indian', 'group', 'wa', 'excluded', 'analysis', 'since', 'majority', 'data', 'among', 'user', 'wa', 'english', 'resulted', 'removal', 'user', 'leaving', 'total', 'sample', 'size']","['data wa', 'wa collected', 'collected cup', 'cup tea', 'tea anonymous', 'anonymous online', 'online chatbased', 'chatbased peer', 'peer support', 'support community', 'community emotional', 'emotional distress', 'distress user', 'user agree', 'agree signup', 'signup data', 'data may', 'may used', 'used purpose', 'purpose research', 'research data', 'data used', 'used current', 'current study', 'study wa', 'wa anonymous', 'anonymous securely', 'securely stored', 'stored research', 'research wa', 'wa performed', 'performed line', 'line ethical', 'ethical privacy', 'privacy protocol', 'protocol outlined', 'outlined detail', 'detail benton', 'benton et', 'et al', 'al data', 'data cup', 'cup take', 'take form', 'form written', 'written dialogue', 'dialogue user', 'user service', 'service volunteer', 'volunteer trained', 'trained active', 'active listener', 'listener fragment', 'fragment exchange', 'exchange user', 'user service', 'service u', 'u volunteer', 'volunteer v', 'v might', 'might go', 'go follows', 'follows analysis', 'analysis reported', 'reported paper', 'paper used', 'used text', 'text generated', 'generated user', 'user service', 'service volunteer', 'volunteer providing', 'providing peer', 'peer support', 'support user', 'user reported', 'reported depression', 'depression primary', 'primary concern', 'concern sign', 'sign eligible', 'eligible inclusion', 'inclusion analysis', 'analysis original', 'original sample', 'sample wa', 'wa comprised', 'comprised conversation', 'conversation involving', 'involving unique', 'unique user', 'user user', 'user excluded', 'excluded sample', 'sample indicate', 'indicate culture', 'culture selected', 'selected resulted', 'resulted exclusion', 'exclusion user', 'user respectively', 'respectively original', 'original sample', 'sample also', 'also included', 'included user', 'user identifying', 'identifying native', 'native american', 'american american', 'american indian', 'indian group', 'group wa', 'wa excluded', 'excluded analysis', 'analysis since', 'since majority', 'majority data', 'data among', 'among user', 'user wa', 'wa english', 'english resulted', 'resulted removal', 'removal user', 'user leaving', 'leaving total', 'total sample', 'sample size']","['data wa collected', 'wa collected cup', 'collected cup tea', 'cup tea anonymous', 'tea anonymous online', 'anonymous online chatbased', 'online chatbased peer', 'chatbased peer support', 'peer support community', 'support community emotional', 'community emotional distress', 'emotional distress user', 'distress user agree', 'user agree signup', 'agree signup data', 'signup data may', 'data may used', 'may used purpose', 'used purpose research', 'purpose research data', 'research data used', 'data used current', 'used current study', 'current study wa', 'study wa anonymous', 'wa anonymous securely', 'anonymous securely stored', 'securely stored research', 'stored research wa', 'research wa performed', 'wa performed line', 'performed line ethical', 'line ethical privacy', 'ethical privacy protocol', 'privacy protocol outlined', 'protocol outlined detail', 'outlined detail benton', 'detail benton et', 'benton et al', 'et al data', 'al data cup', 'data cup take', 'cup take form', 'take form written', 'form written dialogue', 'written dialogue user', 'dialogue user service', 'user service volunteer', 'service volunteer trained', 'volunteer trained active', 'trained active listener', 'active listener fragment', 'listener fragment exchange', 'fragment exchange user', 'exchange user service', 'user service u', 'service u volunteer', 'u volunteer v', 'volunteer v might', 'v might go', 'might go follows', 'go follows analysis', 'follows analysis reported', 'analysis reported paper', 'reported paper used', 'paper used text', 'used text generated', 'text generated user', 'generated user service', 'user service volunteer', 'service volunteer providing', 'volunteer providing peer', 'providing peer support', 'peer support user', 'support user reported', 'user reported depression', 'reported depression primary', 'depression primary concern', 'primary concern sign', 'concern sign eligible', 'sign eligible inclusion', 'eligible inclusion analysis', 'inclusion analysis original', 'analysis original sample', 'original sample wa', 'sample wa comprised', 'wa comprised conversation', 'comprised conversation involving', 'conversation involving unique', 'involving unique user', 'unique user user', 'user user excluded', 'user excluded sample', 'excluded sample indicate', 'sample indicate culture', 'indicate culture selected', 'culture selected resulted', 'selected resulted exclusion', 'resulted exclusion user', 'exclusion user respectively', 'user respectively original', 'respectively original sample', 'original sample also', 'sample also included', 'also included user', 'included user identifying', 'user identifying native', 'identifying native american', 'native american american', 'american american indian', 'american indian group', 'indian group wa', 'group wa excluded', 'wa excluded analysis', 'excluded analysis since', 'analysis since majority', 'since majority data', 'majority data among', 'data among user', 'among user wa', 'user wa english', 'wa english resulted', 'english resulted removal', 'resulted removal user', 'removal user leaving', 'user leaving total', 'leaving total sample', 'total sample size']",,,,,,,
https://dl.acm.org/doi/pdf/10.1145/3359169,0,"Selection Criteria and Data Scope. To understand the impact of cultural differences on how individuals use online mental health platforms we begin our analysis by creating a dataset of users from different national communities on Talklife a support platform with over half a million users [91]. For this analysis due to the fact that most research in CSCW on mental health online has been done either agnostic of cultural context [12 34] or in a Western context [60 67 88] we choose to focus on users from non-Western countries following Zhang et al. [103]. As researchers located in the Global South and with lived experience interacting with the health system and diverse explanatory models [52] of mental illness we believe that moving the focus of CSCW and CSCWadjacent mental health research away from the West is crucial to better meet the needs of people often underserved by the medical system [70]. To create these subgroups of users we choose the three non-Western countries with the highest user populations on Talklife or India Malaysia and the Philippines. Guided by the rich amount of literature on the unique nuances to mental health expression for each country [35 62 77 80] we examine the national identity linguistic and behavior-based differences of use between each user subgroup. In particular this research notes that as a result of cultural norms around the sharing of distress and alternative conceptualizations of mental illness in India Malaysia and the Philippines symptoms are often expressed in somatic and religious terms as opposed to traditionally clinical or psychiatric terms. We choose to analyze each subgroup at the national level for both theoretical and practical reasons. On a theoretical level in past work in the medical anthropology of mental health national identity has commonly been used for a approximate level of analysis for cultural identity [31 33 52]. Additionally on a more practical level each user’s country was determined using their IP address by Talklife and shared with us in an user-anonymized dataset. Inferring a more precise location could potentially compromise user anonymity as discussed in past work [47] and did not seem to have any more significant value for our analysis of cultural differences than analysis at the national level. We analyze data from 10532 Indian users 3370 Malaysian users and 3370 Filipino users as shown in Table 2. Collectively we refer to these countries as the minority sample. As a comparison set we construct a random sample of all threads on Talklife and refer to it as the majority sample. Due to the relative prevalence of users from Western English-speaking countries in Talklife most of the threads in the majority sample include posts from countries such as the USA UK and Canada. Indians are the largest non-Western minority subgroup on Talklife. Data was sampled from May 2012 to June 2018. Following this cross-national analysis to see if our broader results on Talklife generalize to a differently structured online mental health community we picked the largest Western country (the United States) and the largest non-Western country (India) represented on 7Cups a similar support platform with more than 15000 users actively using the platform each week [7]. Using 7Cups data we repeat our analysis testing for the same cultural differences we found in our Talklife sample. For this analysis we were provided a sample of data on activity from 6055 Indian users and 18581 American users as shown in Table 2. Unlike our sample of Talklife users this dataset is not a random sample. There is an upsampling of Indian users to ensure that we have data from a sufficient number of Indians in the dataset. Like on Talklife Indians are the largest non-Western minority subgroup on 7Cups. We focus on Indian users due to a lack of sufficient data on users from Malaysia or the Philippines. Data was sampled from March 2014 - August 2018. 3.1.2 Defining Cultural Identity and Use of Clinical Language. In this work we examine the relationship between cultural identity and use of online mental health support forums. To do so we leverage Tomlinson’s definition of cultural identity as “self and communal definitions based around specific usually politically inflected differentiations: gender sexuality class religion race and ethnicity nationality"" [94] particularly looking at the aspect that of modern cultural identity that runs along national lines as delineated by Hall et al. [41]. As a diverse and amorphous form of identity cultural identity can often intersect and interact with other forms of identity including religious or ethnic identity. However in the absence of direct information about religious or ethnic identity based on the data available we use national identity as a proxy for cultural identity. Additionally following Schlesinger et al’s [83] call for more intersectional analyses and methods within HCI we also include analyses of adjacent and intersecting identities when relevant including religious identity. To analyze clinical language we use a broader definition of clinical language than just specific medical diagnoses. Following methods used in past work to analyze antidepressant related language [30] we create a dataset of clinical mental health language including unigrams bigrams and trigrams from a list of mental disorders as defined by the International Classification of Diseases (ICD-10) and Diagnostic and Statistical Manual of Mental Disorders (DSM-5) [100]. We also included all unigrams from the MacMillan Dictionary list of words used to describe illnesses and diseases both specifically for mental illness and general illness [1–3]. As a result we include unigrams like “night"" (from night terrors) or sleep (from “sleep disorder"") as these are often correlated with specific symptoms of mental illness or distress such as sleep issues or being awake at night [30]. This included any clinically common abbreviations for mental disorders such as OCD for “obsessive compulsive disorder"" or BPD for “borderline personality disorder."" Shorthand for disorders commonly used by online communities such as “pro-ana” (as used in pro-eating disorder communities) [22] were not included due to the difficulty in finding an exhaustive list of these terms across disorders. We choose to use terms from and associated with DSM and ICD categorized disorders as a result of the common usage of these frameworks globally [99]. Throughout our analysis of these varied factors we use µ to represent means and σ to represent standard deviations. 3.1.3 Constraints Limitations and Tradeoffs. Cultural identity can exist at many different and intersecting levels including subcultures and subcommunities within the larger umbrella of a cultural identity. As a result for the purpose of this analysis we had to adopt some constraints in order to do a meaningful and specific analysis. One large limiting constraint that we chose for this study is to use national identity at the state level as a proxy for cultural identity. Though a major and formative part of modern cultural identity as argued by both Hall [41] and Tomlinson [94] each country we analyze is incredibly diverse with many individual cultural identities that both intersect and diverge from a greater national identity [54 64 89]. A more rich analysis of these other forms of cultural identity is beyond the scope of this work but could lead to richer conclusions about the nature of cultural identity in online mental health support communities particularly with regard to cultural differences between users with the same national identity. Additionally to stay consistent between analyses as a result of a lack of data on users from Malaysia and the Philippines we only analyze users in India on 7Cups and extend these findings to the experience of being part of a minority group on an online mental health forum. We draw validity for these exploratory findings from similar consistent patterns we observe between Indian Malaysian and Filipino users but a deeper analysis with a larger dataset is likely necessary to determine when and for which minority communities these conclusions do not hold true. Additionally while we construct clinical language through use of the commonly used DSM and ICD both frameworks of illness categorization have significant limitations particularly in the countries we have selected. For example there are both mental health disorders that are culturebound [74] as well as mental health language that is used in different ways within the specific countries we analyze such as depression often being an umbrella term for all mental illnesses [53]. Additionally it is clear that online support communities often develop their own cultural norms and language around mental health [21 72] and a deeper understanding of how this plays out on Talklife and 7Cups is neither the focus nor within the scope of this work. In this work we intentionally use standard clinical and medical terms for mental health disorders in our analysis of clinical language. As detailed in past anthropological research [52] it is theorized that the use of medical and clinical language is representative of a medicalized explanatory model of illness and we frame use of this language across cultures as a approximate signifier of a greater awareness of the presence of a mental disorder as opposed to conceptualizing distress as “stress"" “tension"" or “depression"" [25 53 98]. For our analysis we strictly analyzed posts that were in the Latin alphabet with almost all posts on both Talklife and 7Cups being in English. However as both Malay [8] and Tagalog [82] are most commonly written in the Latin script and since it is common for users from India speakers to use romanized versions of Indian languages online [79] it is possible that a small minority of posts in our analysis were text in a different language. However as confirmed by only seeing English words used in our analysis of the top n-grams among each user subgroup it is clear that English is the predominant language on both platforms. Though beyond the immediate scope of this work a greater analysis of non-English code-switching on these platforms could lead to a deeper understanding of the impact of interactions on expression between users with the same national identity but different language preferences.",selection criterion and data scope to understand the impact of cultural difference on how individual use online mental health platform we begin our analysis by creating a dataset of user from different national community on talklife a support platform with over half a million user for this analysis due to the fact that most research in cscw on mental health online ha been done either agnostic of cultural context or in a western context we choose to focus on user from nonwestern country following zhang et al a researcher located in the global south and with lived experience interacting with the health system and diverse explanatory model of mental illness we believe that moving the focus of cscw and cscwadjacent mental health research away from the west is crucial to better meet the need of people often underserved by the medical system to create these subgroup of user we choose the three nonwestern country with the highest user population on talklife or india malaysia and the philippine guided by the rich amount of literature on the unique nuance to mental health expression for each country we examine the national identity linguistic and behaviorbased difference of use between each user subgroup in particular this research note that a a result of cultural norm around the sharing of distress and alternative conceptualization of mental illness in india malaysia and the philippine symptom are often expressed in somatic and religious term a opposed to traditionally clinical or psychiatric term we choose to analyze each subgroup at the national level for both theoretical and practical reason on a theoretical level in past work in the medical anthropology of mental health national identity ha commonly been used for a approximate level of analysis for cultural identity additionally on a more practical level each user country wa determined using their ip address by talklife and shared with u in an useranonymized dataset inferring a more precise location could potentially compromise user anonymity a discussed in past work and did not seem to have any more significant value for our analysis of cultural difference than analysis at the national level we analyze data from indian user malaysian user and filipino user a shown in table collectively we refer to these country a the minority sample a a comparison set we construct a random sample of all thread on talklife and refer to it a the majority sample due to the relative prevalence of user from western englishspeaking country in talklife most of the thread in the majority sample include post from country such a the usa uk and canada indian are the largest nonwestern minority subgroup on talklife data wa sampled from may to june following this crossnational analysis to see if our broader result on talklife generalize to a differently structured online mental health community we picked the largest western country the united state and the largest nonwestern country india represented on cup a similar support platform with more than user actively using the platform each week using cup data we repeat our analysis testing for the same cultural difference we found in our talklife sample for this analysis we were provided a sample of data on activity from indian user and american user a shown in table unlike our sample of talklife user this dataset is not a random sample there is an upsampling of indian user to ensure that we have data from a sufficient number of indian in the dataset like on talklife indian are the largest nonwestern minority subgroup on cup we focus on indian user due to a lack of sufficient data on user from malaysia or the philippine data wa sampled from march august defining cultural identity and use of clinical language in this work we examine the relationship between cultural identity and use of online mental health support forum to do so we leverage tomlinsons definition of cultural identity a self and communal definition based around specific usually politically inflected differentiation gender sexuality class religion race and ethnicity nationality particularly looking at the aspect that of modern cultural identity that run along national line a delineated by hall et al a a diverse and amorphous form of identity cultural identity can often intersect and interact with other form of identity including religious or ethnic identity however in the absence of direct information about religious or ethnic identity based on the data available we use national identity a a proxy for cultural identity additionally following schlesinger et al call for more intersectional analysis and method within hci we also include analysis of adjacent and intersecting identity when relevant including religious identity to analyze clinical language we use a broader definition of clinical language than just specific medical diagnosis following method used in past work to analyze antidepressant related language we create a dataset of clinical mental health language including unigrams bigram and trigram from a list of mental disorder a defined by the international classification of disease icd and diagnostic and statistical manual of mental disorder dsm we also included all unigrams from the macmillan dictionary list of word used to describe illness and disease both specifically for mental illness and general illness a a result we include unigrams like night from night terror or sleep from sleep disorder a these are often correlated with specific symptom of mental illness or distress such a sleep issue or being awake at night this included any clinically common abbreviation for mental disorder such a ocd for obsessive compulsive disorder or bpd for borderline personality disorder shorthand for disorder commonly used by online community such a proana a used in proeating disorder community were not included due to the difficulty in finding an exhaustive list of these term across disorder we choose to use term from and associated with dsm and icd categorized disorder a a result of the common usage of these framework globally throughout our analysis of these varied factor we use to represent mean and to represent standard deviation constraint limitation and tradeoff cultural identity can exist at many different and intersecting level including subculture and subcommunities within the larger umbrella of a cultural identity a a result for the purpose of this analysis we had to adopt some constraint in order to do a meaningful and specific analysis one large limiting constraint that we chose for this study is to use national identity at the state level a a proxy for cultural identity though a major and formative part of modern cultural identity a argued by both hall and tomlinson each country we analyze is incredibly diverse with many individual cultural identity that both intersect and diverge from a greater national identity a more rich analysis of these other form of cultural identity is beyond the scope of this work but could lead to richer conclusion about the nature of cultural identity in online mental health support community particularly with regard to cultural difference between user with the same national identity additionally to stay consistent between analysis a a result of a lack of data on user from malaysia and the philippine we only analyze user in india on cup and extend these finding to the experience of being part of a minority group on an online mental health forum we draw validity for these exploratory finding from similar consistent pattern we observe between indian malaysian and filipino user but a deeper analysis with a larger dataset is likely necessary to determine when and for which minority community these conclusion do not hold true additionally while we construct clinical language through use of the commonly used dsm and icd both framework of illness categorization have significant limitation particularly in the country we have selected for example there are both mental health disorder that are culturebound a well a mental health language that is used in different way within the specific country we analyze such a depression often being an umbrella term for all mental illness additionally it is clear that online support community often develop their own cultural norm and language around mental health and a deeper understanding of how this play out on talklife and cup is neither the focus nor within the scope of this work in this work we intentionally use standard clinical and medical term for mental health disorder in our analysis of clinical language a detailed in past anthropological research it is theorized that the use of medical and clinical language is representative of a medicalized explanatory model of illness and we frame use of this language across culture a a approximate signifier of a greater awareness of the presence of a mental disorder a opposed to conceptualizing distress a stress tension or depression for our analysis we strictly analyzed post that were in the latin alphabet with almost all post on both talklife and cup being in english however a both malay and tagalog are most commonly written in the latin script and since it is common for user from india speaker to use romanized version of indian language online it is possible that a small minority of post in our analysis were text in a different language however a confirmed by only seeing english word used in our analysis of the top ngrams among each user subgroup it is clear that english is the predominant language on both platform though beyond the immediate scope of this work a greater analysis of nonenglish codeswitching on these platform could lead to a deeper understanding of the impact of interaction on expression between user with the same national identity but different language preference,"['selection', 'criterion', 'data', 'scope', 'understand', 'impact', 'cultural', 'difference', 'individual', 'use', 'online', 'mental', 'health', 'platform', 'begin', 'analysis', 'creating', 'dataset', 'user', 'different', 'national', 'community', 'talklife', 'support', 'platform', 'half', 'million', 'user', 'analysis', 'due', 'fact', 'research', 'cscw', 'mental', 'health', 'online', 'ha', 'done', 'either', 'agnostic', 'cultural', 'context', 'western', 'context', 'choose', 'focus', 'user', 'nonwestern', 'country', 'following', 'zhang', 'et', 'al', 'researcher', 'located', 'global', 'south', 'lived', 'experience', 'interacting', 'health', 'system', 'diverse', 'explanatory', 'model', 'mental', 'illness', 'believe', 'moving', 'focus', 'cscw', 'cscwadjacent', 'mental', 'health', 'research', 'away', 'west', 'crucial', 'better', 'meet', 'need', 'people', 'often', 'underserved', 'medical', 'system', 'create', 'subgroup', 'user', 'choose', 'three', 'nonwestern', 'country', 'highest', 'user', 'population', 'talklife', 'india', 'malaysia', 'philippine', 'guided', 'rich', 'amount', 'literature', 'unique', 'nuance', 'mental', 'health', 'expression', 'country', 'examine', 'national', 'identity', 'linguistic', 'behaviorbased', 'difference', 'use', 'user', 'subgroup', 'particular', 'research', 'note', 'result', 'cultural', 'norm', 'around', 'sharing', 'distress', 'alternative', 'conceptualization', 'mental', 'illness', 'india', 'malaysia', 'philippine', 'symptom', 'often', 'expressed', 'somatic', 'religious', 'term', 'opposed', 'traditionally', 'clinical', 'psychiatric', 'term', 'choose', 'analyze', 'subgroup', 'national', 'level', 'theoretical', 'practical', 'reason', 'theoretical', 'level', 'past', 'work', 'medical', 'anthropology', 'mental', 'health', 'national', 'identity', 'ha', 'commonly', 'used', 'approximate', 'level', 'analysis', 'cultural', 'identity', 'additionally', 'practical', 'level', 'user', 'country', 'wa', 'determined', 'using', 'ip', 'address', 'talklife', 'shared', 'u', 'useranonymized', 'dataset', 'inferring', 'precise', 'location', 'could', 'potentially', 'compromise', 'user', 'anonymity', 'discussed', 'past', 'work', 'seem', 'significant', 'value', 'analysis', 'cultural', 'difference', 'analysis', 'national', 'level', 'analyze', 'data', 'indian', 'user', 'malaysian', 'user', 'filipino', 'user', 'shown', 'table', 'collectively', 'refer', 'country', 'minority', 'sample', 'comparison', 'set', 'construct', 'random', 'sample', 'thread', 'talklife', 'refer', 'majority', 'sample', 'due', 'relative', 'prevalence', 'user', 'western', 'englishspeaking', 'country', 'talklife', 'thread', 'majority', 'sample', 'include', 'post', 'country', 'usa', 'uk', 'canada', 'indian', 'largest', 'nonwestern', 'minority', 'subgroup', 'talklife', 'data', 'wa', 'sampled', 'may', 'june', 'following', 'crossnational', 'analysis', 'see', 'broader', 'result', 'talklife', 'generalize', 'differently', 'structured', 'online', 'mental', 'health', 'community', 'picked', 'largest', 'western', 'country', 'united', 'state', 'largest', 'nonwestern', 'country', 'india', 'represented', 'cup', 'similar', 'support', 'platform', 'user', 'actively', 'using', 'platform', 'week', 'using', 'cup', 'data', 'repeat', 'analysis', 'testing', 'cultural', 'difference', 'found', 'talklife', 'sample', 'analysis', 'provided', 'sample', 'data', 'activity', 'indian', 'user', 'american', 'user', 'shown', 'table', 'unlike', 'sample', 'talklife', 'user', 'dataset', 'random', 'sample', 'upsampling', 'indian', 'user', 'ensure', 'data', 'sufficient', 'number', 'indian', 'dataset', 'like', 'talklife', 'indian', 'largest', 'nonwestern', 'minority', 'subgroup', 'cup', 'focus', 'indian', 'user', 'due', 'lack', 'sufficient', 'data', 'user', 'malaysia', 'philippine', 'data', 'wa', 'sampled', 'march', 'august', 'defining', 'cultural', 'identity', 'use', 'clinical', 'language', 'work', 'examine', 'relationship', 'cultural', 'identity', 'use', 'online', 'mental', 'health', 'support', 'forum', 'leverage', 'tomlinsons', 'definition', 'cultural', 'identity', 'self', 'communal', 'definition', 'based', 'around', 'specific', 'usually', 'politically', 'inflected', 'differentiation', 'gender', 'sexuality', 'class', 'religion', 'race', 'ethnicity', 'nationality', 'particularly', 'looking', 'aspect', 'modern', 'cultural', 'identity', 'run', 'along', 'national', 'line', 'delineated', 'hall', 'et', 'al', 'diverse', 'amorphous', 'form', 'identity', 'cultural', 'identity', 'often', 'intersect', 'interact', 'form', 'identity', 'including', 'religious', 'ethnic', 'identity', 'however', 'absence', 'direct', 'information', 'religious', 'ethnic', 'identity', 'based', 'data', 'available', 'use', 'national', 'identity', 'proxy', 'cultural', 'identity', 'additionally', 'following', 'schlesinger', 'et', 'al', 'call', 'intersectional', 'analysis', 'method', 'within', 'hci', 'also', 'include', 'analysis', 'adjacent', 'intersecting', 'identity', 'relevant', 'including', 'religious', 'identity', 'analyze', 'clinical', 'language', 'use', 'broader', 'definition', 'clinical', 'language', 'specific', 'medical', 'diagnosis', 'following', 'method', 'used', 'past', 'work', 'analyze', 'antidepressant', 'related', 'language', 'create', 'dataset', 'clinical', 'mental', 'health', 'language', 'including', 'unigrams', 'bigram', 'trigram', 'list', 'mental', 'disorder', 'defined', 'international', 'classification', 'disease', 'icd', 'diagnostic', 'statistical', 'manual', 'mental', 'disorder', 'dsm', 'also', 'included', 'unigrams', 'macmillan', 'dictionary', 'list', 'word', 'used', 'describe', 'illness', 'disease', 'specifically', 'mental', 'illness', 'general', 'illness', 'result', 'include', 'unigrams', 'like', 'night', 'night', 'terror', 'sleep', 'sleep', 'disorder', 'often', 'correlated', 'specific', 'symptom', 'mental', 'illness', 'distress', 'sleep', 'issue', 'awake', 'night', 'included', 'clinically', 'common', 'abbreviation', 'mental', 'disorder', 'ocd', 'obsessive', 'compulsive', 'disorder', 'bpd', 'borderline', 'personality', 'disorder', 'shorthand', 'disorder', 'commonly', 'used', 'online', 'community', 'proana', 'used', 'proeating', 'disorder', 'community', 'included', 'due', 'difficulty', 'finding', 'exhaustive', 'list', 'term', 'across', 'disorder', 'choose', 'use', 'term', 'associated', 'dsm', 'icd', 'categorized', 'disorder', 'result', 'common', 'usage', 'framework', 'globally', 'throughout', 'analysis', 'varied', 'factor', 'use', 'represent', 'mean', 'represent', 'standard', 'deviation', 'constraint', 'limitation', 'tradeoff', 'cultural', 'identity', 'exist', 'many', 'different', 'intersecting', 'level', 'including', 'subculture', 'subcommunities', 'within', 'larger', 'umbrella', 'cultural', 'identity', 'result', 'purpose', 'analysis', 'adopt', 'constraint', 'order', 'meaningful', 'specific', 'analysis', 'one', 'large', 'limiting', 'constraint', 'chose', 'study', 'use', 'national', 'identity', 'state', 'level', 'proxy', 'cultural', 'identity', 'though', 'major', 'formative', 'part', 'modern', 'cultural', 'identity', 'argued', 'hall', 'tomlinson', 'country', 'analyze', 'incredibly', 'diverse', 'many', 'individual', 'cultural', 'identity', 'intersect', 'diverge', 'greater', 'national', 'identity', 'rich', 'analysis', 'form', 'cultural', 'identity', 'beyond', 'scope', 'work', 'could', 'lead', 'richer', 'conclusion', 'nature', 'cultural', 'identity', 'online', 'mental', 'health', 'support', 'community', 'particularly', 'regard', 'cultural', 'difference', 'user', 'national', 'identity', 'additionally', 'stay', 'consistent', 'analysis', 'result', 'lack', 'data', 'user', 'malaysia', 'philippine', 'analyze', 'user', 'india', 'cup', 'extend', 'finding', 'experience', 'part', 'minority', 'group', 'online', 'mental', 'health', 'forum', 'draw', 'validity', 'exploratory', 'finding', 'similar', 'consistent', 'pattern', 'observe', 'indian', 'malaysian', 'filipino', 'user', 'deeper', 'analysis', 'larger', 'dataset', 'likely', 'necessary', 'determine', 'minority', 'community', 'conclusion', 'hold', 'true', 'additionally', 'construct', 'clinical', 'language', 'use', 'commonly', 'used', 'dsm', 'icd', 'framework', 'illness', 'categorization', 'significant', 'limitation', 'particularly', 'country', 'selected', 'example', 'mental', 'health', 'disorder', 'culturebound', 'well', 'mental', 'health', 'language', 'used', 'different', 'way', 'within', 'specific', 'country', 'analyze', 'depression', 'often', 'umbrella', 'term', 'mental', 'illness', 'additionally', 'clear', 'online', 'support', 'community', 'often', 'develop', 'cultural', 'norm', 'language', 'around', 'mental', 'health', 'deeper', 'understanding', 'play', 'talklife', 'cup', 'neither', 'focus', 'within', 'scope', 'work', 'work', 'intentionally', 'use', 'standard', 'clinical', 'medical', 'term', 'mental', 'health', 'disorder', 'analysis', 'clinical', 'language', 'detailed', 'past', 'anthropological', 'research', 'theorized', 'use', 'medical', 'clinical', 'language', 'representative', 'medicalized', 'explanatory', 'model', 'illness', 'frame', 'use', 'language', 'across', 'culture', 'approximate', 'signifier', 'greater', 'awareness', 'presence', 'mental', 'disorder', 'opposed', 'conceptualizing', 'distress', 'stress', 'tension', 'depression', 'analysis', 'strictly', 'analyzed', 'post', 'latin', 'alphabet', 'almost', 'post', 'talklife', 'cup', 'english', 'however', 'malay', 'tagalog', 'commonly', 'written', 'latin', 'script', 'since', 'common', 'user', 'india', 'speaker', 'use', 'romanized', 'version', 'indian', 'language', 'online', 'possible', 'small', 'minority', 'post', 'analysis', 'text', 'different', 'language', 'however', 'confirmed', 'seeing', 'english', 'word', 'used', 'analysis', 'top', 'ngrams', 'among', 'user', 'subgroup', 'clear', 'english', 'predominant', 'language', 'platform', 'though', 'beyond', 'immediate', 'scope', 'work', 'greater', 'analysis', 'nonenglish', 'codeswitching', 'platform', 'could', 'lead', 'deeper', 'understanding', 'impact', 'interaction', 'expression', 'user', 'national', 'identity', 'different', 'language', 'preference']","['selection criterion', 'criterion data', 'data scope', 'scope understand', 'understand impact', 'impact cultural', 'cultural difference', 'difference individual', 'individual use', 'use online', 'online mental', 'mental health', 'health platform', 'platform begin', 'begin analysis', 'analysis creating', 'creating dataset', 'dataset user', 'user different', 'different national', 'national community', 'community talklife', 'talklife support', 'support platform', 'platform half', 'half million', 'million user', 'user analysis', 'analysis due', 'due fact', 'fact research', 'research cscw', 'cscw mental', 'mental health', 'health online', 'online ha', 'ha done', 'done either', 'either agnostic', 'agnostic cultural', 'cultural context', 'context western', 'western context', 'context choose', 'choose focus', 'focus user', 'user nonwestern', 'nonwestern country', 'country following', 'following zhang', 'zhang et', 'et al', 'al researcher', 'researcher located', 'located global', 'global south', 'south lived', 'lived experience', 'experience interacting', 'interacting health', 'health system', 'system diverse', 'diverse explanatory', 'explanatory model', 'model mental', 'mental illness', 'illness believe', 'believe moving', 'moving focus', 'focus cscw', 'cscw cscwadjacent', 'cscwadjacent mental', 'mental health', 'health research', 'research away', 'away west', 'west crucial', 'crucial better', 'better meet', 'meet need', 'need people', 'people often', 'often underserved', 'underserved medical', 'medical system', 'system create', 'create subgroup', 'subgroup user', 'user choose', 'choose three', 'three nonwestern', 'nonwestern country', 'country highest', 'highest user', 'user population', 'population talklife', 'talklife india', 'india malaysia', 'malaysia philippine', 'philippine guided', 'guided rich', 'rich amount', 'amount literature', 'literature unique', 'unique nuance', 'nuance mental', 'mental health', 'health expression', 'expression country', 'country examine', 'examine national', 'national identity', 'identity linguistic', 'linguistic behaviorbased', 'behaviorbased difference', 'difference use', 'use user', 'user subgroup', 'subgroup particular', 'particular research', 'research note', 'note result', 'result cultural', 'cultural norm', 'norm around', 'around sharing', 'sharing distress', 'distress alternative', 'alternative conceptualization', 'conceptualization mental', 'mental illness', 'illness india', 'india malaysia', 'malaysia philippine', 'philippine symptom', 'symptom often', 'often expressed', 'expressed somatic', 'somatic religious', 'religious term', 'term opposed', 'opposed traditionally', 'traditionally clinical', 'clinical psychiatric', 'psychiatric term', 'term choose', 'choose analyze', 'analyze subgroup', 'subgroup national', 'national level', 'level theoretical', 'theoretical practical', 'practical reason', 'reason theoretical', 'theoretical level', 'level past', 'past work', 'work medical', 'medical anthropology', 'anthropology mental', 'mental health', 'health national', 'national identity', 'identity ha', 'ha commonly', 'commonly used', 'used approximate', 'approximate level', 'level analysis', 'analysis cultural', 'cultural identity', 'identity additionally', 'additionally practical', 'practical level', 'level user', 'user country', 'country wa', 'wa determined', 'determined using', 'using ip', 'ip address', 'address talklife', 'talklife shared', 'shared u', 'u useranonymized', 'useranonymized dataset', 'dataset inferring', 'inferring precise', 'precise location', 'location could', 'could potentially', 'potentially compromise', 'compromise user', 'user anonymity', 'anonymity discussed', 'discussed past', 'past work', 'work seem', 'seem significant', 'significant value', 'value analysis', 'analysis cultural', 'cultural difference', 'difference analysis', 'analysis national', 'national level', 'level analyze', 'analyze data', 'data indian', 'indian user', 'user malaysian', 'malaysian user', 'user filipino', 'filipino user', 'user shown', 'shown table', 'table collectively', 'collectively refer', 'refer country', 'country minority', 'minority sample', 'sample comparison', 'comparison set', 'set construct', 'construct random', 'random sample', 'sample thread', 'thread talklife', 'talklife refer', 'refer majority', 'majority sample', 'sample due', 'due relative', 'relative prevalence', 'prevalence user', 'user western', 'western englishspeaking', 'englishspeaking country', 'country talklife', 'talklife thread', 'thread majority', 'majority sample', 'sample include', 'include post', 'post country', 'country usa', 'usa uk', 'uk canada', 'canada indian', 'indian largest', 'largest nonwestern', 'nonwestern minority', 'minority subgroup', 'subgroup talklife', 'talklife data', 'data wa', 'wa sampled', 'sampled may', 'may june', 'june following', 'following crossnational', 'crossnational analysis', 'analysis see', 'see broader', 'broader result', 'result talklife', 'talklife generalize', 'generalize differently', 'differently structured', 'structured online', 'online mental', 'mental health', 'health community', 'community picked', 'picked largest', 'largest western', 'western country', 'country united', 'united state', 'state largest', 'largest nonwestern', 'nonwestern country', 'country india', 'india represented', 'represented cup', 'cup similar', 'similar support', 'support platform', 'platform user', 'user actively', 'actively using', 'using platform', 'platform week', 'week using', 'using cup', 'cup data', 'data repeat', 'repeat analysis', 'analysis testing', 'testing cultural', 'cultural difference', 'difference found', 'found talklife', 'talklife sample', 'sample analysis', 'analysis provided', 'provided sample', 'sample data', 'data activity', 'activity indian', 'indian user', 'user american', 'american user', 'user shown', 'shown table', 'table unlike', 'unlike sample', 'sample talklife', 'talklife user', 'user dataset', 'dataset random', 'random sample', 'sample upsampling', 'upsampling indian', 'indian user', 'user ensure', 'ensure data', 'data sufficient', 'sufficient number', 'number indian', 'indian dataset', 'dataset like', 'like talklife', 'talklife indian', 'indian largest', 'largest nonwestern', 'nonwestern minority', 'minority subgroup', 'subgroup cup', 'cup focus', 'focus indian', 'indian user', 'user due', 'due lack', 'lack sufficient', 'sufficient data', 'data user', 'user malaysia', 'malaysia philippine', 'philippine data', 'data wa', 'wa sampled', 'sampled march', 'march august', 'august defining', 'defining cultural', 'cultural identity', 'identity use', 'use clinical', 'clinical language', 'language work', 'work examine', 'examine relationship', 'relationship cultural', 'cultural identity', 'identity use', 'use online', 'online mental', 'mental health', 'health support', 'support forum', 'forum leverage', 'leverage tomlinsons', 'tomlinsons definition', 'definition cultural', 'cultural identity', 'identity self', 'self communal', 'communal definition', 'definition based', 'based around', 'around specific', 'specific usually', 'usually politically', 'politically inflected', 'inflected differentiation', 'differentiation gender', 'gender sexuality', 'sexuality class', 'class religion', 'religion race', 'race ethnicity', 'ethnicity nationality', 'nationality particularly', 'particularly looking', 'looking aspect', 'aspect modern', 'modern cultural', 'cultural identity', 'identity run', 'run along', 'along national', 'national line', 'line delineated', 'delineated hall', 'hall et', 'et al', 'al diverse', 'diverse amorphous', 'amorphous form', 'form identity', 'identity cultural', 'cultural identity', 'identity often', 'often intersect', 'intersect interact', 'interact form', 'form identity', 'identity including', 'including religious', 'religious ethnic', 'ethnic identity', 'identity however', 'however absence', 'absence direct', 'direct information', 'information religious', 'religious ethnic', 'ethnic identity', 'identity based', 'based data', 'data available', 'available use', 'use national', 'national identity', 'identity proxy', 'proxy cultural', 'cultural identity', 'identity additionally', 'additionally following', 'following schlesinger', 'schlesinger et', 'et al', 'al call', 'call intersectional', 'intersectional analysis', 'analysis method', 'method within', 'within hci', 'hci also', 'also include', 'include analysis', 'analysis adjacent', 'adjacent intersecting', 'intersecting identity', 'identity relevant', 'relevant including', 'including religious', 'religious identity', 'identity analyze', 'analyze clinical', 'clinical language', 'language use', 'use broader', 'broader definition', 'definition clinical', 'clinical language', 'language specific', 'specific medical', 'medical diagnosis', 'diagnosis following', 'following method', 'method used', 'used past', 'past work', 'work analyze', 'analyze antidepressant', 'antidepressant related', 'related language', 'language create', 'create dataset', 'dataset clinical', 'clinical mental', 'mental health', 'health language', 'language including', 'including unigrams', 'unigrams bigram', 'bigram trigram', 'trigram list', 'list mental', 'mental disorder', 'disorder defined', 'defined international', 'international classification', 'classification disease', 'disease icd', 'icd diagnostic', 'diagnostic statistical', 'statistical manual', 'manual mental', 'mental disorder', 'disorder dsm', 'dsm also', 'also included', 'included unigrams', 'unigrams macmillan', 'macmillan dictionary', 'dictionary list', 'list word', 'word used', 'used describe', 'describe illness', 'illness disease', 'disease specifically', 'specifically mental', 'mental illness', 'illness general', 'general illness', 'illness result', 'result include', 'include unigrams', 'unigrams like', 'like night', 'night night', 'night terror', 'terror sleep', 'sleep sleep', 'sleep disorder', 'disorder often', 'often correlated', 'correlated specific', 'specific symptom', 'symptom mental', 'mental illness', 'illness distress', 'distress sleep', 'sleep issue', 'issue awake', 'awake night', 'night included', 'included clinically', 'clinically common', 'common abbreviation', 'abbreviation mental', 'mental disorder', 'disorder ocd', 'ocd obsessive', 'obsessive compulsive', 'compulsive disorder', 'disorder bpd', 'bpd borderline', 'borderline personality', 'personality disorder', 'disorder shorthand', 'shorthand disorder', 'disorder commonly', 'commonly used', 'used online', 'online community', 'community proana', 'proana used', 'used proeating', 'proeating disorder', 'disorder community', 'community included', 'included due', 'due difficulty', 'difficulty finding', 'finding exhaustive', 'exhaustive list', 'list term', 'term across', 'across disorder', 'disorder choose', 'choose use', 'use term', 'term associated', 'associated dsm', 'dsm icd', 'icd categorized', 'categorized disorder', 'disorder result', 'result common', 'common usage', 'usage framework', 'framework globally', 'globally throughout', 'throughout analysis', 'analysis varied', 'varied factor', 'factor use', 'use represent', 'represent mean', 'mean represent', 'represent standard', 'standard deviation', 'deviation constraint', 'constraint limitation', 'limitation tradeoff', 'tradeoff cultural', 'cultural identity', 'identity exist', 'exist many', 'many different', 'different intersecting', 'intersecting level', 'level including', 'including subculture', 'subculture subcommunities', 'subcommunities within', 'within larger', 'larger umbrella', 'umbrella cultural', 'cultural identity', 'identity result', 'result purpose', 'purpose analysis', 'analysis adopt', 'adopt constraint', 'constraint order', 'order meaningful', 'meaningful specific', 'specific analysis', 'analysis one', 'one large', 'large limiting', 'limiting constraint', 'constraint chose', 'chose study', 'study use', 'use national', 'national identity', 'identity state', 'state level', 'level proxy', 'proxy cultural', 'cultural identity', 'identity though', 'though major', 'major formative', 'formative part', 'part modern', 'modern cultural', 'cultural identity', 'identity argued', 'argued hall', 'hall tomlinson', 'tomlinson country', 'country analyze', 'analyze incredibly', 'incredibly diverse', 'diverse many', 'many individual', 'individual cultural', 'cultural identity', 'identity intersect', 'intersect diverge', 'diverge greater', 'greater national', 'national identity', 'identity rich', 'rich analysis', 'analysis form', 'form cultural', 'cultural identity', 'identity beyond', 'beyond scope', 'scope work', 'work could', 'could lead', 'lead richer', 'richer conclusion', 'conclusion nature', 'nature cultural', 'cultural identity', 'identity online', 'online mental', 'mental health', 'health support', 'support community', 'community particularly', 'particularly regard', 'regard cultural', 'cultural difference', 'difference user', 'user national', 'national identity', 'identity additionally', 'additionally stay', 'stay consistent', 'consistent analysis', 'analysis result', 'result lack', 'lack data', 'data user', 'user malaysia', 'malaysia philippine', 'philippine analyze', 'analyze user', 'user india', 'india cup', 'cup extend', 'extend finding', 'finding experience', 'experience part', 'part minority', 'minority group', 'group online', 'online mental', 'mental health', 'health forum', 'forum draw', 'draw validity', 'validity exploratory', 'exploratory finding', 'finding similar', 'similar consistent', 'consistent pattern', 'pattern observe', 'observe indian', 'indian malaysian', 'malaysian filipino', 'filipino user', 'user deeper', 'deeper analysis', 'analysis larger', 'larger dataset', 'dataset likely', 'likely necessary', 'necessary determine', 'determine minority', 'minority community', 'community conclusion', 'conclusion hold', 'hold true', 'true additionally', 'additionally construct', 'construct clinical', 'clinical language', 'language use', 'use commonly', 'commonly used', 'used dsm', 'dsm icd', 'icd framework', 'framework illness', 'illness categorization', 'categorization significant', 'significant limitation', 'limitation particularly', 'particularly country', 'country selected', 'selected example', 'example mental', 'mental health', 'health disorder', 'disorder culturebound', 'culturebound well', 'well mental', 'mental health', 'health language', 'language used', 'used different', 'different way', 'way within', 'within specific', 'specific country', 'country analyze', 'analyze depression', 'depression often', 'often umbrella', 'umbrella term', 'term mental', 'mental illness', 'illness additionally', 'additionally clear', 'clear online', 'online support', 'support community', 'community often', 'often develop', 'develop cultural', 'cultural norm', 'norm language', 'language around', 'around mental', 'mental health', 'health deeper', 'deeper understanding', 'understanding play', 'play talklife', 'talklife cup', 'cup neither', 'neither focus', 'focus within', 'within scope', 'scope work', 'work work', 'work intentionally', 'intentionally use', 'use standard', 'standard clinical', 'clinical medical', 'medical term', 'term mental', 'mental health', 'health disorder', 'disorder analysis', 'analysis clinical', 'clinical language', 'language detailed', 'detailed past', 'past anthropological', 'anthropological research', 'research theorized', 'theorized use', 'use medical', 'medical clinical', 'clinical language', 'language representative', 'representative medicalized', 'medicalized explanatory', 'explanatory model', 'model illness', 'illness frame', 'frame use', 'use language', 'language across', 'across culture', 'culture approximate', 'approximate signifier', 'signifier greater', 'greater awareness', 'awareness presence', 'presence mental', 'mental disorder', 'disorder opposed', 'opposed conceptualizing', 'conceptualizing distress', 'distress stress', 'stress tension', 'tension depression', 'depression analysis', 'analysis strictly', 'strictly analyzed', 'analyzed post', 'post latin', 'latin alphabet', 'alphabet almost', 'almost post', 'post talklife', 'talklife cup', 'cup english', 'english however', 'however malay', 'malay tagalog', 'tagalog commonly', 'commonly written', 'written latin', 'latin script', 'script since', 'since common', 'common user', 'user india', 'india speaker', 'speaker use', 'use romanized', 'romanized version', 'version indian', 'indian language', 'language online', 'online possible', 'possible small', 'small minority', 'minority post', 'post analysis', 'analysis text', 'text different', 'different language', 'language however', 'however confirmed', 'confirmed seeing', 'seeing english', 'english word', 'word used', 'used analysis', 'analysis top', 'top ngrams', 'ngrams among', 'among user', 'user subgroup', 'subgroup clear', 'clear english', 'english predominant', 'predominant language', 'language platform', 'platform though', 'though beyond', 'beyond immediate', 'immediate scope', 'scope work', 'work greater', 'greater analysis', 'analysis nonenglish', 'nonenglish codeswitching', 'codeswitching platform', 'platform could', 'could lead', 'lead deeper', 'deeper understanding', 'understanding impact', 'impact interaction', 'interaction expression', 'expression user', 'user national', 'national identity', 'identity different', 'different language', 'language preference']","['selection criterion data', 'criterion data scope', 'data scope understand', 'scope understand impact', 'understand impact cultural', 'impact cultural difference', 'cultural difference individual', 'difference individual use', 'individual use online', 'use online mental', 'online mental health', 'mental health platform', 'health platform begin', 'platform begin analysis', 'begin analysis creating', 'analysis creating dataset', 'creating dataset user', 'dataset user different', 'user different national', 'different national community', 'national community talklife', 'community talklife support', 'talklife support platform', 'support platform half', 'platform half million', 'half million user', 'million user analysis', 'user analysis due', 'analysis due fact', 'due fact research', 'fact research cscw', 'research cscw mental', 'cscw mental health', 'mental health online', 'health online ha', 'online ha done', 'ha done either', 'done either agnostic', 'either agnostic cultural', 'agnostic cultural context', 'cultural context western', 'context western context', 'western context choose', 'context choose focus', 'choose focus user', 'focus user nonwestern', 'user nonwestern country', 'nonwestern country following', 'country following zhang', 'following zhang et', 'zhang et al', 'et al researcher', 'al researcher located', 'researcher located global', 'located global south', 'global south lived', 'south lived experience', 'lived experience interacting', 'experience interacting health', 'interacting health system', 'health system diverse', 'system diverse explanatory', 'diverse explanatory model', 'explanatory model mental', 'model mental illness', 'mental illness believe', 'illness believe moving', 'believe moving focus', 'moving focus cscw', 'focus cscw cscwadjacent', 'cscw cscwadjacent mental', 'cscwadjacent mental health', 'mental health research', 'health research away', 'research away west', 'away west crucial', 'west crucial better', 'crucial better meet', 'better meet need', 'meet need people', 'need people often', 'people often underserved', 'often underserved medical', 'underserved medical system', 'medical system create', 'system create subgroup', 'create subgroup user', 'subgroup user choose', 'user choose three', 'choose three nonwestern', 'three nonwestern country', 'nonwestern country highest', 'country highest user', 'highest user population', 'user population talklife', 'population talklife india', 'talklife india malaysia', 'india malaysia philippine', 'malaysia philippine guided', 'philippine guided rich', 'guided rich amount', 'rich amount literature', 'amount literature unique', 'literature unique nuance', 'unique nuance mental', 'nuance mental health', 'mental health expression', 'health expression country', 'expression country examine', 'country examine national', 'examine national identity', 'national identity linguistic', 'identity linguistic behaviorbased', 'linguistic behaviorbased difference', 'behaviorbased difference use', 'difference use user', 'use user subgroup', 'user subgroup particular', 'subgroup particular research', 'particular research note', 'research note result', 'note result cultural', 'result cultural norm', 'cultural norm around', 'norm around sharing', 'around sharing distress', 'sharing distress alternative', 'distress alternative conceptualization', 'alternative conceptualization mental', 'conceptualization mental illness', 'mental illness india', 'illness india malaysia', 'india malaysia philippine', 'malaysia philippine symptom', 'philippine symptom often', 'symptom often expressed', 'often expressed somatic', 'expressed somatic religious', 'somatic religious term', 'religious term opposed', 'term opposed traditionally', 'opposed traditionally clinical', 'traditionally clinical psychiatric', 'clinical psychiatric term', 'psychiatric term choose', 'term choose analyze', 'choose analyze subgroup', 'analyze subgroup national', 'subgroup national level', 'national level theoretical', 'level theoretical practical', 'theoretical practical reason', 'practical reason theoretical', 'reason theoretical level', 'theoretical level past', 'level past work', 'past work medical', 'work medical anthropology', 'medical anthropology mental', 'anthropology mental health', 'mental health national', 'health national identity', 'national identity ha', 'identity ha commonly', 'ha commonly used', 'commonly used approximate', 'used approximate level', 'approximate level analysis', 'level analysis cultural', 'analysis cultural identity', 'cultural identity additionally', 'identity additionally practical', 'additionally practical level', 'practical level user', 'level user country', 'user country wa', 'country wa determined', 'wa determined using', 'determined using ip', 'using ip address', 'ip address talklife', 'address talklife shared', 'talklife shared u', 'shared u useranonymized', 'u useranonymized dataset', 'useranonymized dataset inferring', 'dataset inferring precise', 'inferring precise location', 'precise location could', 'location could potentially', 'could potentially compromise', 'potentially compromise user', 'compromise user anonymity', 'user anonymity discussed', 'anonymity discussed past', 'discussed past work', 'past work seem', 'work seem significant', 'seem significant value', 'significant value analysis', 'value analysis cultural', 'analysis cultural difference', 'cultural difference analysis', 'difference analysis national', 'analysis national level', 'national level analyze', 'level analyze data', 'analyze data indian', 'data indian user', 'indian user malaysian', 'user malaysian user', 'malaysian user filipino', 'user filipino user', 'filipino user shown', 'user shown table', 'shown table collectively', 'table collectively refer', 'collectively refer country', 'refer country minority', 'country minority sample', 'minority sample comparison', 'sample comparison set', 'comparison set construct', 'set construct random', 'construct random sample', 'random sample thread', 'sample thread talklife', 'thread talklife refer', 'talklife refer majority', 'refer majority sample', 'majority sample due', 'sample due relative', 'due relative prevalence', 'relative prevalence user', 'prevalence user western', 'user western englishspeaking', 'western englishspeaking country', 'englishspeaking country talklife', 'country talklife thread', 'talklife thread majority', 'thread majority sample', 'majority sample include', 'sample include post', 'include post country', 'post country usa', 'country usa uk', 'usa uk canada', 'uk canada indian', 'canada indian largest', 'indian largest nonwestern', 'largest nonwestern minority', 'nonwestern minority subgroup', 'minority subgroup talklife', 'subgroup talklife data', 'talklife data wa', 'data wa sampled', 'wa sampled may', 'sampled may june', 'may june following', 'june following crossnational', 'following crossnational analysis', 'crossnational analysis see', 'analysis see broader', 'see broader result', 'broader result talklife', 'result talklife generalize', 'talklife generalize differently', 'generalize differently structured', 'differently structured online', 'structured online mental', 'online mental health', 'mental health community', 'health community picked', 'community picked largest', 'picked largest western', 'largest western country', 'western country united', 'country united state', 'united state largest', 'state largest nonwestern', 'largest nonwestern country', 'nonwestern country india', 'country india represented', 'india represented cup', 'represented cup similar', 'cup similar support', 'similar support platform', 'support platform user', 'platform user actively', 'user actively using', 'actively using platform', 'using platform week', 'platform week using', 'week using cup', 'using cup data', 'cup data repeat', 'data repeat analysis', 'repeat analysis testing', 'analysis testing cultural', 'testing cultural difference', 'cultural difference found', 'difference found talklife', 'found talklife sample', 'talklife sample analysis', 'sample analysis provided', 'analysis provided sample', 'provided sample data', 'sample data activity', 'data activity indian', 'activity indian user', 'indian user american', 'user american user', 'american user shown', 'user shown table', 'shown table unlike', 'table unlike sample', 'unlike sample talklife', 'sample talklife user', 'talklife user dataset', 'user dataset random', 'dataset random sample', 'random sample upsampling', 'sample upsampling indian', 'upsampling indian user', 'indian user ensure', 'user ensure data', 'ensure data sufficient', 'data sufficient number', 'sufficient number indian', 'number indian dataset', 'indian dataset like', 'dataset like talklife', 'like talklife indian', 'talklife indian largest', 'indian largest nonwestern', 'largest nonwestern minority', 'nonwestern minority subgroup', 'minority subgroup cup', 'subgroup cup focus', 'cup focus indian', 'focus indian user', 'indian user due', 'user due lack', 'due lack sufficient', 'lack sufficient data', 'sufficient data user', 'data user malaysia', 'user malaysia philippine', 'malaysia philippine data', 'philippine data wa', 'data wa sampled', 'wa sampled march', 'sampled march august', 'march august defining', 'august defining cultural', 'defining cultural identity', 'cultural identity use', 'identity use clinical', 'use clinical language', 'clinical language work', 'language work examine', 'work examine relationship', 'examine relationship cultural', 'relationship cultural identity', 'cultural identity use', 'identity use online', 'use online mental', 'online mental health', 'mental health support', 'health support forum', 'support forum leverage', 'forum leverage tomlinsons', 'leverage tomlinsons definition', 'tomlinsons definition cultural', 'definition cultural identity', 'cultural identity self', 'identity self communal', 'self communal definition', 'communal definition based', 'definition based around', 'based around specific', 'around specific usually', 'specific usually politically', 'usually politically inflected', 'politically inflected differentiation', 'inflected differentiation gender', 'differentiation gender sexuality', 'gender sexuality class', 'sexuality class religion', 'class religion race', 'religion race ethnicity', 'race ethnicity nationality', 'ethnicity nationality particularly', 'nationality particularly looking', 'particularly looking aspect', 'looking aspect modern', 'aspect modern cultural', 'modern cultural identity', 'cultural identity run', 'identity run along', 'run along national', 'along national line', 'national line delineated', 'line delineated hall', 'delineated hall et', 'hall et al', 'et al diverse', 'al diverse amorphous', 'diverse amorphous form', 'amorphous form identity', 'form identity cultural', 'identity cultural identity', 'cultural identity often', 'identity often intersect', 'often intersect interact', 'intersect interact form', 'interact form identity', 'form identity including', 'identity including religious', 'including religious ethnic', 'religious ethnic identity', 'ethnic identity however', 'identity however absence', 'however absence direct', 'absence direct information', 'direct information religious', 'information religious ethnic', 'religious ethnic identity', 'ethnic identity based', 'identity based data', 'based data available', 'data available use', 'available use national', 'use national identity', 'national identity proxy', 'identity proxy cultural', 'proxy cultural identity', 'cultural identity additionally', 'identity additionally following', 'additionally following schlesinger', 'following schlesinger et', 'schlesinger et al', 'et al call', 'al call intersectional', 'call intersectional analysis', 'intersectional analysis method', 'analysis method within', 'method within hci', 'within hci also', 'hci also include', 'also include analysis', 'include analysis adjacent', 'analysis adjacent intersecting', 'adjacent intersecting identity', 'intersecting identity relevant', 'identity relevant including', 'relevant including religious', 'including religious identity', 'religious identity analyze', 'identity analyze clinical', 'analyze clinical language', 'clinical language use', 'language use broader', 'use broader definition', 'broader definition clinical', 'definition clinical language', 'clinical language specific', 'language specific medical', 'specific medical diagnosis', 'medical diagnosis following', 'diagnosis following method', 'following method used', 'method used past', 'used past work', 'past work analyze', 'work analyze antidepressant', 'analyze antidepressant related', 'antidepressant related language', 'related language create', 'language create dataset', 'create dataset clinical', 'dataset clinical mental', 'clinical mental health', 'mental health language', 'health language including', 'language including unigrams', 'including unigrams bigram', 'unigrams bigram trigram', 'bigram trigram list', 'trigram list mental', 'list mental disorder', 'mental disorder defined', 'disorder defined international', 'defined international classification', 'international classification disease', 'classification disease icd', 'disease icd diagnostic', 'icd diagnostic statistical', 'diagnostic statistical manual', 'statistical manual mental', 'manual mental disorder', 'mental disorder dsm', 'disorder dsm also', 'dsm also included', 'also included unigrams', 'included unigrams macmillan', 'unigrams macmillan dictionary', 'macmillan dictionary list', 'dictionary list word', 'list word used', 'word used describe', 'used describe illness', 'describe illness disease', 'illness disease specifically', 'disease specifically mental', 'specifically mental illness', 'mental illness general', 'illness general illness', 'general illness result', 'illness result include', 'result include unigrams', 'include unigrams like', 'unigrams like night', 'like night night', 'night night terror', 'night terror sleep', 'terror sleep sleep', 'sleep sleep disorder', 'sleep disorder often', 'disorder often correlated', 'often correlated specific', 'correlated specific symptom', 'specific symptom mental', 'symptom mental illness', 'mental illness distress', 'illness distress sleep', 'distress sleep issue', 'sleep issue awake', 'issue awake night', 'awake night included', 'night included clinically', 'included clinically common', 'clinically common abbreviation', 'common abbreviation mental', 'abbreviation mental disorder', 'mental disorder ocd', 'disorder ocd obsessive', 'ocd obsessive compulsive', 'obsessive compulsive disorder', 'compulsive disorder bpd', 'disorder bpd borderline', 'bpd borderline personality', 'borderline personality disorder', 'personality disorder shorthand', 'disorder shorthand disorder', 'shorthand disorder commonly', 'disorder commonly used', 'commonly used online', 'used online community', 'online community proana', 'community proana used', 'proana used proeating', 'used proeating disorder', 'proeating disorder community', 'disorder community included', 'community included due', 'included due difficulty', 'due difficulty finding', 'difficulty finding exhaustive', 'finding exhaustive list', 'exhaustive list term', 'list term across', 'term across disorder', 'across disorder choose', 'disorder choose use', 'choose use term', 'use term associated', 'term associated dsm', 'associated dsm icd', 'dsm icd categorized', 'icd categorized disorder', 'categorized disorder result', 'disorder result common', 'result common usage', 'common usage framework', 'usage framework globally', 'framework globally throughout', 'globally throughout analysis', 'throughout analysis varied', 'analysis varied factor', 'varied factor use', 'factor use represent', 'use represent mean', 'represent mean represent', 'mean represent standard', 'represent standard deviation', 'standard deviation constraint', 'deviation constraint limitation', 'constraint limitation tradeoff', 'limitation tradeoff cultural', 'tradeoff cultural identity', 'cultural identity exist', 'identity exist many', 'exist many different', 'many different intersecting', 'different intersecting level', 'intersecting level including', 'level including subculture', 'including subculture subcommunities', 'subculture subcommunities within', 'subcommunities within larger', 'within larger umbrella', 'larger umbrella cultural', 'umbrella cultural identity', 'cultural identity result', 'identity result purpose', 'result purpose analysis', 'purpose analysis adopt', 'analysis adopt constraint', 'adopt constraint order', 'constraint order meaningful', 'order meaningful specific', 'meaningful specific analysis', 'specific analysis one', 'analysis one large', 'one large limiting', 'large limiting constraint', 'limiting constraint chose', 'constraint chose study', 'chose study use', 'study use national', 'use national identity', 'national identity state', 'identity state level', 'state level proxy', 'level proxy cultural', 'proxy cultural identity', 'cultural identity though', 'identity though major', 'though major formative', 'major formative part', 'formative part modern', 'part modern cultural', 'modern cultural identity', 'cultural identity argued', 'identity argued hall', 'argued hall tomlinson', 'hall tomlinson country', 'tomlinson country analyze', 'country analyze incredibly', 'analyze incredibly diverse', 'incredibly diverse many', 'diverse many individual', 'many individual cultural', 'individual cultural identity', 'cultural identity intersect', 'identity intersect diverge', 'intersect diverge greater', 'diverge greater national', 'greater national identity', 'national identity rich', 'identity rich analysis', 'rich analysis form', 'analysis form cultural', 'form cultural identity', 'cultural identity beyond', 'identity beyond scope', 'beyond scope work', 'scope work could', 'work could lead', 'could lead richer', 'lead richer conclusion', 'richer conclusion nature', 'conclusion nature cultural', 'nature cultural identity', 'cultural identity online', 'identity online mental', 'online mental health', 'mental health support', 'health support community', 'support community particularly', 'community particularly regard', 'particularly regard cultural', 'regard cultural difference', 'cultural difference user', 'difference user national', 'user national identity', 'national identity additionally', 'identity additionally stay', 'additionally stay consistent', 'stay consistent analysis', 'consistent analysis result', 'analysis result lack', 'result lack data', 'lack data user', 'data user malaysia', 'user malaysia philippine', 'malaysia philippine analyze', 'philippine analyze user', 'analyze user india', 'user india cup', 'india cup extend', 'cup extend finding', 'extend finding experience', 'finding experience part', 'experience part minority', 'part minority group', 'minority group online', 'group online mental', 'online mental health', 'mental health forum', 'health forum draw', 'forum draw validity', 'draw validity exploratory', 'validity exploratory finding', 'exploratory finding similar', 'finding similar consistent', 'similar consistent pattern', 'consistent pattern observe', 'pattern observe indian', 'observe indian malaysian', 'indian malaysian filipino', 'malaysian filipino user', 'filipino user deeper', 'user deeper analysis', 'deeper analysis larger', 'analysis larger dataset', 'larger dataset likely', 'dataset likely necessary', 'likely necessary determine', 'necessary determine minority', 'determine minority community', 'minority community conclusion', 'community conclusion hold', 'conclusion hold true', 'hold true additionally', 'true additionally construct', 'additionally construct clinical', 'construct clinical language', 'clinical language use', 'language use commonly', 'use commonly used', 'commonly used dsm', 'used dsm icd', 'dsm icd framework', 'icd framework illness', 'framework illness categorization', 'illness categorization significant', 'categorization significant limitation', 'significant limitation particularly', 'limitation particularly country', 'particularly country selected', 'country selected example', 'selected example mental', 'example mental health', 'mental health disorder', 'health disorder culturebound', 'disorder culturebound well', 'culturebound well mental', 'well mental health', 'mental health language', 'health language used', 'language used different', 'used different way', 'different way within', 'way within specific', 'within specific country', 'specific country analyze', 'country analyze depression', 'analyze depression often', 'depression often umbrella', 'often umbrella term', 'umbrella term mental', 'term mental illness', 'mental illness additionally', 'illness additionally clear', 'additionally clear online', 'clear online support', 'online support community', 'support community often', 'community often develop', 'often develop cultural', 'develop cultural norm', 'cultural norm language', 'norm language around', 'language around mental', 'around mental health', 'mental health deeper', 'health deeper understanding', 'deeper understanding play', 'understanding play talklife', 'play talklife cup', 'talklife cup neither', 'cup neither focus', 'neither focus within', 'focus within scope', 'within scope work', 'scope work work', 'work work intentionally', 'work intentionally use', 'intentionally use standard', 'use standard clinical', 'standard clinical medical', 'clinical medical term', 'medical term mental', 'term mental health', 'mental health disorder', 'health disorder analysis', 'disorder analysis clinical', 'analysis clinical language', 'clinical language detailed', 'language detailed past', 'detailed past anthropological', 'past anthropological research', 'anthropological research theorized', 'research theorized use', 'theorized use medical', 'use medical clinical', 'medical clinical language', 'clinical language representative', 'language representative medicalized', 'representative medicalized explanatory', 'medicalized explanatory model', 'explanatory model illness', 'model illness frame', 'illness frame use', 'frame use language', 'use language across', 'language across culture', 'across culture approximate', 'culture approximate signifier', 'approximate signifier greater', 'signifier greater awareness', 'greater awareness presence', 'awareness presence mental', 'presence mental disorder', 'mental disorder opposed', 'disorder opposed conceptualizing', 'opposed conceptualizing distress', 'conceptualizing distress stress', 'distress stress tension', 'stress tension depression', 'tension depression analysis', 'depression analysis strictly', 'analysis strictly analyzed', 'strictly analyzed post', 'analyzed post latin', 'post latin alphabet', 'latin alphabet almost', 'alphabet almost post', 'almost post talklife', 'post talklife cup', 'talklife cup english', 'cup english however', 'english however malay', 'however malay tagalog', 'malay tagalog commonly', 'tagalog commonly written', 'commonly written latin', 'written latin script', 'latin script since', 'script since common', 'since common user', 'common user india', 'user india speaker', 'india speaker use', 'speaker use romanized', 'use romanized version', 'romanized version indian', 'version indian language', 'indian language online', 'language online possible', 'online possible small', 'possible small minority', 'small minority post', 'minority post analysis', 'post analysis text', 'analysis text different', 'text different language', 'different language however', 'language however confirmed', 'however confirmed seeing', 'confirmed seeing english', 'seeing english word', 'english word used', 'word used analysis', 'used analysis top', 'analysis top ngrams', 'top ngrams among', 'ngrams among user', 'among user subgroup', 'user subgroup clear', 'subgroup clear english', 'clear english predominant', 'english predominant language', 'predominant language platform', 'language platform though', 'platform though beyond', 'though beyond immediate', 'beyond immediate scope', 'immediate scope work', 'scope work greater', 'work greater analysis', 'greater analysis nonenglish', 'analysis nonenglish codeswitching', 'nonenglish codeswitching platform', 'codeswitching platform could', 'platform could lead', 'could lead deeper', 'lead deeper understanding', 'deeper understanding impact', 'understanding impact interaction', 'impact interaction expression', 'interaction expression user', 'expression user national', 'user national identity', 'national identity different', 'identity different language', 'different language preference']",,,,,,,
https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-018-2197-z,0,In this section we first present the data gathered and used in our analysis. Researchers interested in the code and the data are invited to contact the authors. Reddit is a website which enables users to aggregate rate and discuss news entertainment politics and many other topics. According to Alexa it is the 8th most popular website in the world. It was estimated by the Pew research center that 6% of online adults use Reddit [26]. The site is organized into a collection of “subreddits” each focused on a particular topic and administered by a collection of moderators. The subreddit r/SuicideWatch is a forum in which online users are encouraged to post their thoughts regarding suicide. At the time of our data collection it had over 58000 subscribers. Sometimes users express a preoccupation with the thought of suicide. Other times users discuss immediate plans to take their own life. These posts often contain a description of their mental state including depression reaction to stress their feelings of being alone and having a low self-esteem. While most online sources of data are notoriously noisy this particular subreddit is remarkably clean. Given the serious nature of the subreddit individuals are less likely to post harassing comments or off-topic remarks. When users post such comments the moderators of the subreddit quickly remove them. We collected all posts from its inception in 2008 to 2016. Each post is often commented on by other individuals. In this work we focused on the original post as it most often represents the suicidal ideation of a user and comments often represent emotional support from other users. We cleaned this data. First we removed empty posts in which the content had been deleted. Second we removed links and replaced them with the word “link”. Third we concatenated the text of the post to the title as many users begin their post in the title and continue in the body of the post. Finally we removed punctuation and other special characters. After cleaning this data we had 131728 posts with 27978246 words of which 84607 words were unique posted by 63252 unique users.,in this section we first present the data gathered and used in our analysis researcher interested in the code and the data are invited to contact the author reddit is a website which enables user to aggregate rate and discus news entertainment politics and many other topic according to alexa it is the th most popular website in the world it wa estimated by the pew research center that of online adult use reddit the site is organized into a collection of subreddits each focused on a particular topic and administered by a collection of moderator the subreddit rsuicidewatch is a forum in which online user are encouraged to post their thought regarding suicide at the time of our data collection it had over subscriber sometimes user express a preoccupation with the thought of suicide other time user discus immediate plan to take their own life these post often contain a description of their mental state including depression reaction to stress their feeling of being alone and having a low selfesteem while most online source of data are notoriously noisy this particular subreddit is remarkably clean given the serious nature of the subreddit individual are le likely to post harassing comment or offtopic remark when user post such comment the moderator of the subreddit quickly remove them we collected all post from it inception in to each post is often commented on by other individual in this work we focused on the original post a it most often represents the suicidal ideation of a user and comment often represent emotional support from other user we cleaned this data first we removed empty post in which the content had been deleted second we removed link and replaced them with the word link third we concatenated the text of the post to the title a many user begin their post in the title and continue in the body of the post finally we removed punctuation and other special character after cleaning this data we had post with word of which word were unique posted by unique user,"['section', 'first', 'present', 'data', 'gathered', 'used', 'analysis', 'researcher', 'interested', 'code', 'data', 'invited', 'contact', 'author', 'reddit', 'website', 'enables', 'user', 'aggregate', 'rate', 'discus', 'news', 'entertainment', 'politics', 'many', 'topic', 'according', 'alexa', 'th', 'popular', 'website', 'world', 'wa', 'estimated', 'pew', 'research', 'center', 'online', 'adult', 'use', 'reddit', 'site', 'organized', 'collection', 'subreddits', 'focused', 'particular', 'topic', 'administered', 'collection', 'moderator', 'subreddit', 'rsuicidewatch', 'forum', 'online', 'user', 'encouraged', 'post', 'thought', 'regarding', 'suicide', 'time', 'data', 'collection', 'subscriber', 'sometimes', 'user', 'express', 'preoccupation', 'thought', 'suicide', 'time', 'user', 'discus', 'immediate', 'plan', 'take', 'life', 'post', 'often', 'contain', 'description', 'mental', 'state', 'including', 'depression', 'reaction', 'stress', 'feeling', 'alone', 'low', 'selfesteem', 'online', 'source', 'data', 'notoriously', 'noisy', 'particular', 'subreddit', 'remarkably', 'clean', 'given', 'serious', 'nature', 'subreddit', 'individual', 'le', 'likely', 'post', 'harassing', 'comment', 'offtopic', 'remark', 'user', 'post', 'comment', 'moderator', 'subreddit', 'quickly', 'remove', 'collected', 'post', 'inception', 'post', 'often', 'commented', 'individual', 'work', 'focused', 'original', 'post', 'often', 'represents', 'suicidal', 'ideation', 'user', 'comment', 'often', 'represent', 'emotional', 'support', 'user', 'cleaned', 'data', 'first', 'removed', 'empty', 'post', 'content', 'deleted', 'second', 'removed', 'link', 'replaced', 'word', 'link', 'third', 'concatenated', 'text', 'post', 'title', 'many', 'user', 'begin', 'post', 'title', 'continue', 'body', 'post', 'finally', 'removed', 'punctuation', 'special', 'character', 'cleaning', 'data', 'post', 'word', 'word', 'unique', 'posted', 'unique', 'user']","['section first', 'first present', 'present data', 'data gathered', 'gathered used', 'used analysis', 'analysis researcher', 'researcher interested', 'interested code', 'code data', 'data invited', 'invited contact', 'contact author', 'author reddit', 'reddit website', 'website enables', 'enables user', 'user aggregate', 'aggregate rate', 'rate discus', 'discus news', 'news entertainment', 'entertainment politics', 'politics many', 'many topic', 'topic according', 'according alexa', 'alexa th', 'th popular', 'popular website', 'website world', 'world wa', 'wa estimated', 'estimated pew', 'pew research', 'research center', 'center online', 'online adult', 'adult use', 'use reddit', 'reddit site', 'site organized', 'organized collection', 'collection subreddits', 'subreddits focused', 'focused particular', 'particular topic', 'topic administered', 'administered collection', 'collection moderator', 'moderator subreddit', 'subreddit rsuicidewatch', 'rsuicidewatch forum', 'forum online', 'online user', 'user encouraged', 'encouraged post', 'post thought', 'thought regarding', 'regarding suicide', 'suicide time', 'time data', 'data collection', 'collection subscriber', 'subscriber sometimes', 'sometimes user', 'user express', 'express preoccupation', 'preoccupation thought', 'thought suicide', 'suicide time', 'time user', 'user discus', 'discus immediate', 'immediate plan', 'plan take', 'take life', 'life post', 'post often', 'often contain', 'contain description', 'description mental', 'mental state', 'state including', 'including depression', 'depression reaction', 'reaction stress', 'stress feeling', 'feeling alone', 'alone low', 'low selfesteem', 'selfesteem online', 'online source', 'source data', 'data notoriously', 'notoriously noisy', 'noisy particular', 'particular subreddit', 'subreddit remarkably', 'remarkably clean', 'clean given', 'given serious', 'serious nature', 'nature subreddit', 'subreddit individual', 'individual le', 'le likely', 'likely post', 'post harassing', 'harassing comment', 'comment offtopic', 'offtopic remark', 'remark user', 'user post', 'post comment', 'comment moderator', 'moderator subreddit', 'subreddit quickly', 'quickly remove', 'remove collected', 'collected post', 'post inception', 'inception post', 'post often', 'often commented', 'commented individual', 'individual work', 'work focused', 'focused original', 'original post', 'post often', 'often represents', 'represents suicidal', 'suicidal ideation', 'ideation user', 'user comment', 'comment often', 'often represent', 'represent emotional', 'emotional support', 'support user', 'user cleaned', 'cleaned data', 'data first', 'first removed', 'removed empty', 'empty post', 'post content', 'content deleted', 'deleted second', 'second removed', 'removed link', 'link replaced', 'replaced word', 'word link', 'link third', 'third concatenated', 'concatenated text', 'text post', 'post title', 'title many', 'many user', 'user begin', 'begin post', 'post title', 'title continue', 'continue body', 'body post', 'post finally', 'finally removed', 'removed punctuation', 'punctuation special', 'special character', 'character cleaning', 'cleaning data', 'data post', 'post word', 'word word', 'word unique', 'unique posted', 'posted unique', 'unique user']","['section first present', 'first present data', 'present data gathered', 'data gathered used', 'gathered used analysis', 'used analysis researcher', 'analysis researcher interested', 'researcher interested code', 'interested code data', 'code data invited', 'data invited contact', 'invited contact author', 'contact author reddit', 'author reddit website', 'reddit website enables', 'website enables user', 'enables user aggregate', 'user aggregate rate', 'aggregate rate discus', 'rate discus news', 'discus news entertainment', 'news entertainment politics', 'entertainment politics many', 'politics many topic', 'many topic according', 'topic according alexa', 'according alexa th', 'alexa th popular', 'th popular website', 'popular website world', 'website world wa', 'world wa estimated', 'wa estimated pew', 'estimated pew research', 'pew research center', 'research center online', 'center online adult', 'online adult use', 'adult use reddit', 'use reddit site', 'reddit site organized', 'site organized collection', 'organized collection subreddits', 'collection subreddits focused', 'subreddits focused particular', 'focused particular topic', 'particular topic administered', 'topic administered collection', 'administered collection moderator', 'collection moderator subreddit', 'moderator subreddit rsuicidewatch', 'subreddit rsuicidewatch forum', 'rsuicidewatch forum online', 'forum online user', 'online user encouraged', 'user encouraged post', 'encouraged post thought', 'post thought regarding', 'thought regarding suicide', 'regarding suicide time', 'suicide time data', 'time data collection', 'data collection subscriber', 'collection subscriber sometimes', 'subscriber sometimes user', 'sometimes user express', 'user express preoccupation', 'express preoccupation thought', 'preoccupation thought suicide', 'thought suicide time', 'suicide time user', 'time user discus', 'user discus immediate', 'discus immediate plan', 'immediate plan take', 'plan take life', 'take life post', 'life post often', 'post often contain', 'often contain description', 'contain description mental', 'description mental state', 'mental state including', 'state including depression', 'including depression reaction', 'depression reaction stress', 'reaction stress feeling', 'stress feeling alone', 'feeling alone low', 'alone low selfesteem', 'low selfesteem online', 'selfesteem online source', 'online source data', 'source data notoriously', 'data notoriously noisy', 'notoriously noisy particular', 'noisy particular subreddit', 'particular subreddit remarkably', 'subreddit remarkably clean', 'remarkably clean given', 'clean given serious', 'given serious nature', 'serious nature subreddit', 'nature subreddit individual', 'subreddit individual le', 'individual le likely', 'le likely post', 'likely post harassing', 'post harassing comment', 'harassing comment offtopic', 'comment offtopic remark', 'offtopic remark user', 'remark user post', 'user post comment', 'post comment moderator', 'comment moderator subreddit', 'moderator subreddit quickly', 'subreddit quickly remove', 'quickly remove collected', 'remove collected post', 'collected post inception', 'post inception post', 'inception post often', 'post often commented', 'often commented individual', 'commented individual work', 'individual work focused', 'work focused original', 'focused original post', 'original post often', 'post often represents', 'often represents suicidal', 'represents suicidal ideation', 'suicidal ideation user', 'ideation user comment', 'user comment often', 'comment often represent', 'often represent emotional', 'represent emotional support', 'emotional support user', 'support user cleaned', 'user cleaned data', 'cleaned data first', 'data first removed', 'first removed empty', 'removed empty post', 'empty post content', 'post content deleted', 'content deleted second', 'deleted second removed', 'second removed link', 'removed link replaced', 'link replaced word', 'replaced word link', 'word link third', 'link third concatenated', 'third concatenated text', 'concatenated text post', 'text post title', 'post title many', 'title many user', 'many user begin', 'user begin post', 'begin post title', 'post title continue', 'title continue body', 'continue body post', 'body post finally', 'post finally removed', 'finally removed punctuation', 'removed punctuation special', 'punctuation special character', 'special character cleaning', 'character cleaning data', 'cleaning data post', 'data post word', 'post word word', 'word word unique', 'word unique posted', 'unique posted unique', 'posted unique user']",,,,,,,
https://ieeexplore.ieee.org/abstract/document/8609647,0,Reddit is a multilingual Online Social Network founded in 2005 and organized in subcommunities by areas of interest called subreddits. We obtained data from the Reddit's data repository4 focusing on four subreddits where people discuss issues related to mental heath disorders: Depression (/r/depression) Suicide Watch (/r/Suicide Watch) Anxiety (/r/anxiety) and Bipolar (/r/bipolar). Our dataset is comprised of user activities (posts and comments) that took place between 2011 and 201 7. Here we focus on data from January 2017 to December 2017. In total we obtained 261511 posts and 1256669 comments from 184708 unique users. Table I shows the total number of users posts and comments per subreddit. The total number of comments in each community is at least 4.2 times larger than the number of posts which suggests a supportive behavior among users.,reddit is a multilingual online social network founded in and organized in subcommunities by area of interest called subreddits we obtained data from the reddits data repository focusing on four subreddits where people discus issue related to mental heath disorder depression rdepression suicide watch rsuicide watch anxiety ranxiety and bipolar rbipolar our dataset is comprised of user activity post and comment that took place between and here we focus on data from january to december in total we obtained post and comment from unique user table i show the total number of user post and comment per subreddit the total number of comment in each community is at least time larger than the number of post which suggests a supportive behavior among user,"['reddit', 'multilingual', 'online', 'social', 'network', 'founded', 'organized', 'subcommunities', 'area', 'interest', 'called', 'subreddits', 'obtained', 'data', 'reddits', 'data', 'repository', 'focusing', 'four', 'subreddits', 'people', 'discus', 'issue', 'related', 'mental', 'heath', 'disorder', 'depression', 'rdepression', 'suicide', 'watch', 'rsuicide', 'watch', 'anxiety', 'ranxiety', 'bipolar', 'rbipolar', 'dataset', 'comprised', 'user', 'activity', 'post', 'comment', 'took', 'place', 'focus', 'data', 'january', 'december', 'total', 'obtained', 'post', 'comment', 'unique', 'user', 'table', 'show', 'total', 'number', 'user', 'post', 'comment', 'per', 'subreddit', 'total', 'number', 'comment', 'community', 'least', 'time', 'larger', 'number', 'post', 'suggests', 'supportive', 'behavior', 'among', 'user']","['reddit multilingual', 'multilingual online', 'online social', 'social network', 'network founded', 'founded organized', 'organized subcommunities', 'subcommunities area', 'area interest', 'interest called', 'called subreddits', 'subreddits obtained', 'obtained data', 'data reddits', 'reddits data', 'data repository', 'repository focusing', 'focusing four', 'four subreddits', 'subreddits people', 'people discus', 'discus issue', 'issue related', 'related mental', 'mental heath', 'heath disorder', 'disorder depression', 'depression rdepression', 'rdepression suicide', 'suicide watch', 'watch rsuicide', 'rsuicide watch', 'watch anxiety', 'anxiety ranxiety', 'ranxiety bipolar', 'bipolar rbipolar', 'rbipolar dataset', 'dataset comprised', 'comprised user', 'user activity', 'activity post', 'post comment', 'comment took', 'took place', 'place focus', 'focus data', 'data january', 'january december', 'december total', 'total obtained', 'obtained post', 'post comment', 'comment unique', 'unique user', 'user table', 'table show', 'show total', 'total number', 'number user', 'user post', 'post comment', 'comment per', 'per subreddit', 'subreddit total', 'total number', 'number comment', 'comment community', 'community least', 'least time', 'time larger', 'larger number', 'number post', 'post suggests', 'suggests supportive', 'supportive behavior', 'behavior among', 'among user']","['reddit multilingual online', 'multilingual online social', 'online social network', 'social network founded', 'network founded organized', 'founded organized subcommunities', 'organized subcommunities area', 'subcommunities area interest', 'area interest called', 'interest called subreddits', 'called subreddits obtained', 'subreddits obtained data', 'obtained data reddits', 'data reddits data', 'reddits data repository', 'data repository focusing', 'repository focusing four', 'focusing four subreddits', 'four subreddits people', 'subreddits people discus', 'people discus issue', 'discus issue related', 'issue related mental', 'related mental heath', 'mental heath disorder', 'heath disorder depression', 'disorder depression rdepression', 'depression rdepression suicide', 'rdepression suicide watch', 'suicide watch rsuicide', 'watch rsuicide watch', 'rsuicide watch anxiety', 'watch anxiety ranxiety', 'anxiety ranxiety bipolar', 'ranxiety bipolar rbipolar', 'bipolar rbipolar dataset', 'rbipolar dataset comprised', 'dataset comprised user', 'comprised user activity', 'user activity post', 'activity post comment', 'post comment took', 'comment took place', 'took place focus', 'place focus data', 'focus data january', 'data january december', 'january december total', 'december total obtained', 'total obtained post', 'obtained post comment', 'post comment unique', 'comment unique user', 'unique user table', 'user table show', 'table show total', 'show total number', 'total number user', 'number user post', 'user post comment', 'post comment per', 'comment per subreddit', 'per subreddit total', 'subreddit total number', 'total number comment', 'number comment community', 'comment community least', 'community least time', 'least time larger', 'time larger number', 'larger number post', 'number post suggests', 'post suggests supportive', 'suggests supportive behavior', 'supportive behavior among', 'behavior among user']",,,,,,,
