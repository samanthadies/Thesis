Link to paper,Score,Text,Cleaned,unigrams,bigrams,trigrams,topic1,topic2,topic3,topic4,topic5,topic6,topic7,topic8
https://link.springer.com/content/pdf/10.1140/epjds/s13688-017-0110-z.pdf,1,Data collection was crowdsourced using Amazon’s Mechanical Turk (MTurk) crowdwork platform. Separate surveys were created for depressed and healthy individuals. In the depressed survey participants were invited to complete a survey that involved passing a series of inclusion criteria responding to a standardized clinical depression survey answering questions related to demographics and history of depression and sharing social media history. We used the CES-D (Center for Epidemiologic Studies Depression Scale) questionnaire to screen participant depression levels []. CES-D assessment quality has been demonstrated as on-par with other depression inventories including the Beck Depression Inventory and the Kellner Symptom Questionnaire [ ]. Healthy participants were screened to ensure no history of depression and active Instagram use. See Additional file  for actual survey text. Qualified participants were asked to share their Instagram usernames and history. An app embedded in the survey allowed participants to securely log into their Instagram accounts and agree to share their data.b Upon securing consent we made a one-time collection of participants’ entire Instagram posting history. In total we collected  photographs from  Instagram users  of whom had a history of depression. We asked a different set of MTurk crowdworkers to rate the Instagram photographs collected. This new task asked participants to rate a random selection of  photos from the data we collected. Raters were asked to judge how interesting likable happy and sad each photo seemed on a continuous - scale. Each photo was rated by at least three different raters and ratings were averaged across raters. Raters were not informed that photos were from Instagram nor were they given any information about the study participants who provided the photos including mental health status. Each ratings category showed good inter-rater agreement. Only a subset of participant Instagram photos were rated (N = ). We limited ratings data to a subset because this task was time-consuming for crowdworkers and so proved a costly form of data collection. For the depressed sample ratings were only made for photos posted within a year in either direction of the date of first depression diagnosis. Within this subset for each user the nearest  posts prior to the diagnosis date were rated. For the control population the most recent  photos from each user’s date of participation in this study were rated.,data collection wa crowdsourced using amazon mechanical turk mturk crowdwork platform separate survey were created for depressed and healthy individual in the depressed survey participant were invited to complete a survey that involved passing a series of inclusion criterion responding to a standardized clinical depression survey answering question related to demographic and history of depression and sharing social medium history we used the cesd center for epidemiologic study depression scale questionnaire to screen participant depression level cesd assessment quality ha been demonstrated a onpar with other depression inventory including the beck depression inventory and the kellner symptom questionnaire healthy participant were screened to ensure no history of depression and active instagram use see additional file for actual survey text qualified participant were asked to share their instagram usernames and history an app embedded in the survey allowed participant to securely log into their instagram account and agree to share their datab upon securing consent we made a onetime collection of participant entire instagram posting history in total we collected photograph from instagram user of whom had a history of depression we asked a different set of mturk crowdworkers to rate the instagram photograph collected this new task asked participant to rate a random selection of photo from the data we collected raters were asked to judge how interesting likable happy and sad each photo seemed on a continuous scale each photo wa rated by at least three different raters and rating were averaged across raters raters were not informed that photo were from instagram nor were they given any information about the study participant who provided the photo including mental health status each rating category showed good interrater agreement only a subset of participant instagram photo were rated n we limited rating data to a subset because this task wa timeconsuming for crowdworkers and so proved a costly form of data collection for the depressed sample rating were only made for photo posted within a year in either direction of the date of first depression diagnosis within this subset for each user the nearest post prior to the diagnosis date were rated for the control population the most recent photo from each user date of participation in this study were rated,"['data', 'collection', 'wa', 'crowdsourced', 'using', 'amazon', 'mechanical', 'turk', 'mturk', 'crowdwork', 'platform', 'separate', 'survey', 'created', 'depressed', 'healthy', 'individual', 'depressed', 'survey', 'participant', 'invited', 'complete', 'survey', 'involved', 'passing', 'series', 'inclusion', 'criterion', 'responding', 'standardized', 'clinical', 'depression', 'survey', 'answering', 'question', 'related', 'demographic', 'history', 'depression', 'sharing', 'social', 'medium', 'history', 'used', 'cesd', 'center', 'epidemiologic', 'study', 'depression', 'scale', 'questionnaire', 'screen', 'participant', 'depression', 'level', 'cesd', 'assessment', 'quality', 'ha', 'demonstrated', 'onpar', 'depression', 'inventory', 'including', 'beck', 'depression', 'inventory', 'kellner', 'symptom', 'questionnaire', 'healthy', 'participant', 'screened', 'ensure', 'history', 'depression', 'active', 'instagram', 'use', 'see', 'additional', 'file', 'actual', 'survey', 'text', 'qualified', 'participant', 'asked', 'share', 'instagram', 'usernames', 'history', 'app', 'embedded', 'survey', 'allowed', 'participant', 'securely', 'log', 'instagram', 'account', 'agree', 'share', 'datab', 'upon', 'securing', 'consent', 'made', 'onetime', 'collection', 'participant', 'entire', 'instagram', 'posting', 'history', 'total', 'collected', 'photograph', 'instagram', 'user', 'history', 'depression', 'asked', 'different', 'set', 'mturk', 'crowdworkers', 'rate', 'instagram', 'photograph', 'collected', 'new', 'task', 'asked', 'participant', 'rate', 'random', 'selection', 'photo', 'data', 'collected', 'raters', 'asked', 'judge', 'interesting', 'likable', 'happy', 'sad', 'photo', 'seemed', 'continuous', 'scale', 'photo', 'wa', 'rated', 'least', 'three', 'different', 'raters', 'rating', 'averaged', 'across', 'raters', 'raters', 'informed', 'photo', 'instagram', 'given', 'information', 'study', 'participant', 'provided', 'photo', 'including', 'mental', 'health', 'status', 'rating', 'category', 'showed', 'good', 'interrater', 'agreement', 'subset', 'participant', 'instagram', 'photo', 'rated', 'n', 'limited', 'rating', 'data', 'subset', 'task', 'wa', 'timeconsuming', 'crowdworkers', 'proved', 'costly', 'form', 'data', 'collection', 'depressed', 'sample', 'rating', 'made', 'photo', 'posted', 'within', 'year', 'either', 'direction', 'date', 'first', 'depression', 'diagnosis', 'within', 'subset', 'user', 'nearest', 'post', 'prior', 'diagnosis', 'date', 'rated', 'control', 'population', 'recent', 'photo', 'user', 'date', 'participation', 'study', 'rated']","['data collection', 'collection wa', 'wa crowdsourced', 'crowdsourced using', 'using amazon', 'amazon mechanical', 'mechanical turk', 'turk mturk', 'mturk crowdwork', 'crowdwork platform', 'platform separate', 'separate survey', 'survey created', 'created depressed', 'depressed healthy', 'healthy individual', 'individual depressed', 'depressed survey', 'survey participant', 'participant invited', 'invited complete', 'complete survey', 'survey involved', 'involved passing', 'passing series', 'series inclusion', 'inclusion criterion', 'criterion responding', 'responding standardized', 'standardized clinical', 'clinical depression', 'depression survey', 'survey answering', 'answering question', 'question related', 'related demographic', 'demographic history', 'history depression', 'depression sharing', 'sharing social', 'social medium', 'medium history', 'history used', 'used cesd', 'cesd center', 'center epidemiologic', 'epidemiologic study', 'study depression', 'depression scale', 'scale questionnaire', 'questionnaire screen', 'screen participant', 'participant depression', 'depression level', 'level cesd', 'cesd assessment', 'assessment quality', 'quality ha', 'ha demonstrated', 'demonstrated onpar', 'onpar depression', 'depression inventory', 'inventory including', 'including beck', 'beck depression', 'depression inventory', 'inventory kellner', 'kellner symptom', 'symptom questionnaire', 'questionnaire healthy', 'healthy participant', 'participant screened', 'screened ensure', 'ensure history', 'history depression', 'depression active', 'active instagram', 'instagram use', 'use see', 'see additional', 'additional file', 'file actual', 'actual survey', 'survey text', 'text qualified', 'qualified participant', 'participant asked', 'asked share', 'share instagram', 'instagram usernames', 'usernames history', 'history app', 'app embedded', 'embedded survey', 'survey allowed', 'allowed participant', 'participant securely', 'securely log', 'log instagram', 'instagram account', 'account agree', 'agree share', 'share datab', 'datab upon', 'upon securing', 'securing consent', 'consent made', 'made onetime', 'onetime collection', 'collection participant', 'participant entire', 'entire instagram', 'instagram posting', 'posting history', 'history total', 'total collected', 'collected photograph', 'photograph instagram', 'instagram user', 'user history', 'history depression', 'depression asked', 'asked different', 'different set', 'set mturk', 'mturk crowdworkers', 'crowdworkers rate', 'rate instagram', 'instagram photograph', 'photograph collected', 'collected new', 'new task', 'task asked', 'asked participant', 'participant rate', 'rate random', 'random selection', 'selection photo', 'photo data', 'data collected', 'collected raters', 'raters asked', 'asked judge', 'judge interesting', 'interesting likable', 'likable happy', 'happy sad', 'sad photo', 'photo seemed', 'seemed continuous', 'continuous scale', 'scale photo', 'photo wa', 'wa rated', 'rated least', 'least three', 'three different', 'different raters', 'raters rating', 'rating averaged', 'averaged across', 'across raters', 'raters raters', 'raters informed', 'informed photo', 'photo instagram', 'instagram given', 'given information', 'information study', 'study participant', 'participant provided', 'provided photo', 'photo including', 'including mental', 'mental health', 'health status', 'status rating', 'rating category', 'category showed', 'showed good', 'good interrater', 'interrater agreement', 'agreement subset', 'subset participant', 'participant instagram', 'instagram photo', 'photo rated', 'rated n', 'n limited', 'limited rating', 'rating data', 'data subset', 'subset task', 'task wa', 'wa timeconsuming', 'timeconsuming crowdworkers', 'crowdworkers proved', 'proved costly', 'costly form', 'form data', 'data collection', 'collection depressed', 'depressed sample', 'sample rating', 'rating made', 'made photo', 'photo posted', 'posted within', 'within year', 'year either', 'either direction', 'direction date', 'date first', 'first depression', 'depression diagnosis', 'diagnosis within', 'within subset', 'subset user', 'user nearest', 'nearest post', 'post prior', 'prior diagnosis', 'diagnosis date', 'date rated', 'rated control', 'control population', 'population recent', 'recent photo', 'photo user', 'user date', 'date participation', 'participation study', 'study rated']","['data collection wa', 'collection wa crowdsourced', 'wa crowdsourced using', 'crowdsourced using amazon', 'using amazon mechanical', 'amazon mechanical turk', 'mechanical turk mturk', 'turk mturk crowdwork', 'mturk crowdwork platform', 'crowdwork platform separate', 'platform separate survey', 'separate survey created', 'survey created depressed', 'created depressed healthy', 'depressed healthy individual', 'healthy individual depressed', 'individual depressed survey', 'depressed survey participant', 'survey participant invited', 'participant invited complete', 'invited complete survey', 'complete survey involved', 'survey involved passing', 'involved passing series', 'passing series inclusion', 'series inclusion criterion', 'inclusion criterion responding', 'criterion responding standardized', 'responding standardized clinical', 'standardized clinical depression', 'clinical depression survey', 'depression survey answering', 'survey answering question', 'answering question related', 'question related demographic', 'related demographic history', 'demographic history depression', 'history depression sharing', 'depression sharing social', 'sharing social medium', 'social medium history', 'medium history used', 'history used cesd', 'used cesd center', 'cesd center epidemiologic', 'center epidemiologic study', 'epidemiologic study depression', 'study depression scale', 'depression scale questionnaire', 'scale questionnaire screen', 'questionnaire screen participant', 'screen participant depression', 'participant depression level', 'depression level cesd', 'level cesd assessment', 'cesd assessment quality', 'assessment quality ha', 'quality ha demonstrated', 'ha demonstrated onpar', 'demonstrated onpar depression', 'onpar depression inventory', 'depression inventory including', 'inventory including beck', 'including beck depression', 'beck depression inventory', 'depression inventory kellner', 'inventory kellner symptom', 'kellner symptom questionnaire', 'symptom questionnaire healthy', 'questionnaire healthy participant', 'healthy participant screened', 'participant screened ensure', 'screened ensure history', 'ensure history depression', 'history depression active', 'depression active instagram', 'active instagram use', 'instagram use see', 'use see additional', 'see additional file', 'additional file actual', 'file actual survey', 'actual survey text', 'survey text qualified', 'text qualified participant', 'qualified participant asked', 'participant asked share', 'asked share instagram', 'share instagram usernames', 'instagram usernames history', 'usernames history app', 'history app embedded', 'app embedded survey', 'embedded survey allowed', 'survey allowed participant', 'allowed participant securely', 'participant securely log', 'securely log instagram', 'log instagram account', 'instagram account agree', 'account agree share', 'agree share datab', 'share datab upon', 'datab upon securing', 'upon securing consent', 'securing consent made', 'consent made onetime', 'made onetime collection', 'onetime collection participant', 'collection participant entire', 'participant entire instagram', 'entire instagram posting', 'instagram posting history', 'posting history total', 'history total collected', 'total collected photograph', 'collected photograph instagram', 'photograph instagram user', 'instagram user history', 'user history depression', 'history depression asked', 'depression asked different', 'asked different set', 'different set mturk', 'set mturk crowdworkers', 'mturk crowdworkers rate', 'crowdworkers rate instagram', 'rate instagram photograph', 'instagram photograph collected', 'photograph collected new', 'collected new task', 'new task asked', 'task asked participant', 'asked participant rate', 'participant rate random', 'rate random selection', 'random selection photo', 'selection photo data', 'photo data collected', 'data collected raters', 'collected raters asked', 'raters asked judge', 'asked judge interesting', 'judge interesting likable', 'interesting likable happy', 'likable happy sad', 'happy sad photo', 'sad photo seemed', 'photo seemed continuous', 'seemed continuous scale', 'continuous scale photo', 'scale photo wa', 'photo wa rated', 'wa rated least', 'rated least three', 'least three different', 'three different raters', 'different raters rating', 'raters rating averaged', 'rating averaged across', 'averaged across raters', 'across raters raters', 'raters raters informed', 'raters informed photo', 'informed photo instagram', 'photo instagram given', 'instagram given information', 'given information study', 'information study participant', 'study participant provided', 'participant provided photo', 'provided photo including', 'photo including mental', 'including mental health', 'mental health status', 'health status rating', 'status rating category', 'rating category showed', 'category showed good', 'showed good interrater', 'good interrater agreement', 'interrater agreement subset', 'agreement subset participant', 'subset participant instagram', 'participant instagram photo', 'instagram photo rated', 'photo rated n', 'rated n limited', 'n limited rating', 'limited rating data', 'rating data subset', 'data subset task', 'subset task wa', 'task wa timeconsuming', 'wa timeconsuming crowdworkers', 'timeconsuming crowdworkers proved', 'crowdworkers proved costly', 'proved costly form', 'costly form data', 'form data collection', 'data collection depressed', 'collection depressed sample', 'depressed sample rating', 'sample rating made', 'rating made photo', 'made photo posted', 'photo posted within', 'posted within year', 'within year either', 'year either direction', 'either direction date', 'direction date first', 'date first depression', 'first depression diagnosis', 'depression diagnosis within', 'diagnosis within subset', 'within subset user', 'subset user nearest', 'user nearest post', 'nearest post prior', 'post prior diagnosis', 'prior diagnosis date', 'diagnosis date rated', 'date rated control', 'rated control population', 'control population recent', 'population recent photo', 'recent photo user', 'photo user date', 'user date participation', 'date participation study', 'participation study rated']",0.996274471282959,0.0,0.0,0.0,0.0,0.0,0,0.0
https://dl.acm.org/doi/abs/10.1145/2858036.2858207 ,1,Following our data collection we focused on verifying whether MHs and SW subreddit content actually relate to discussion of mental health concerns and suicidal ideation. The MHs have been previously examined for understanding mental health discourse on Reddit [51 39]. For SW we consulted (1) a licensed clinical psychologist/suicide prevention expert and (2) two active moderators of SW to obtain qualitative grounding that the content in SW indeed related to expressions of suicidal ideation. Example (paraphrased) titles of posts from one of the MHs and SW are given in Table 1.,following our data collection we focused on verifying whether mhs and sw subreddit content actually relate to discussion of mental health concern and suicidal ideation the mhs have been previously examined for understanding mental health discourse on reddit for sw we consulted a licensed clinical psychologistsuicide prevention expert and two active moderator of sw to obtain qualitative grounding that the content in sw indeed related to expression of suicidal ideation example paraphrased title of post from one of the mhs and sw are given in table,"['following', 'data', 'collection', 'focused', 'verifying', 'whether', 'mhs', 'sw', 'subreddit', 'content', 'actually', 'relate', 'discussion', 'mental', 'health', 'concern', 'suicidal', 'ideation', 'mhs', 'previously', 'examined', 'understanding', 'mental', 'health', 'discourse', 'reddit', 'sw', 'consulted', 'licensed', 'clinical', 'psychologistsuicide', 'prevention', 'expert', 'two', 'active', 'moderator', 'sw', 'obtain', 'qualitative', 'grounding', 'content', 'sw', 'indeed', 'related', 'expression', 'suicidal', 'ideation', 'example', 'paraphrased', 'title', 'post', 'one', 'mhs', 'sw', 'given', 'table']","['following data', 'data collection', 'collection focused', 'focused verifying', 'verifying whether', 'whether mhs', 'mhs sw', 'sw subreddit', 'subreddit content', 'content actually', 'actually relate', 'relate discussion', 'discussion mental', 'mental health', 'health concern', 'concern suicidal', 'suicidal ideation', 'ideation mhs', 'mhs previously', 'previously examined', 'examined understanding', 'understanding mental', 'mental health', 'health discourse', 'discourse reddit', 'reddit sw', 'sw consulted', 'consulted licensed', 'licensed clinical', 'clinical psychologistsuicide', 'psychologistsuicide prevention', 'prevention expert', 'expert two', 'two active', 'active moderator', 'moderator sw', 'sw obtain', 'obtain qualitative', 'qualitative grounding', 'grounding content', 'content sw', 'sw indeed', 'indeed related', 'related expression', 'expression suicidal', 'suicidal ideation', 'ideation example', 'example paraphrased', 'paraphrased title', 'title post', 'post one', 'one mhs', 'mhs sw', 'sw given', 'given table']","['following data collection', 'data collection focused', 'collection focused verifying', 'focused verifying whether', 'verifying whether mhs', 'whether mhs sw', 'mhs sw subreddit', 'sw subreddit content', 'subreddit content actually', 'content actually relate', 'actually relate discussion', 'relate discussion mental', 'discussion mental health', 'mental health concern', 'health concern suicidal', 'concern suicidal ideation', 'suicidal ideation mhs', 'ideation mhs previously', 'mhs previously examined', 'previously examined understanding', 'examined understanding mental', 'understanding mental health', 'mental health discourse', 'health discourse reddit', 'discourse reddit sw', 'reddit sw consulted', 'sw consulted licensed', 'consulted licensed clinical', 'licensed clinical psychologistsuicide', 'clinical psychologistsuicide prevention', 'psychologistsuicide prevention expert', 'prevention expert two', 'expert two active', 'two active moderator', 'active moderator sw', 'moderator sw obtain', 'sw obtain qualitative', 'obtain qualitative grounding', 'qualitative grounding content', 'grounding content sw', 'content sw indeed', 'sw indeed related', 'indeed related expression', 'related expression suicidal', 'expression suicidal ideation', 'suicidal ideation example', 'ideation example paraphrased', 'example paraphrased title', 'paraphrased title post', 'title post one', 'post one mhs', 'one mhs sw', 'mhs sw given', 'sw given table']",0.9846349358558655,0.0,0.0,0.0,0.0,0.0,0,0.0
https://dl.acm.org/doi/abs/10.1145/2702613.2732733,1,Automatic detection of self-disclosure levels in posts necessitates obtaining gold standard labels on self-disclosure in essence “ground truth”. For the purpose two raters familiar with Reddit and its mental health communities in particular independently rated a small random sample (50 posts) with equal proportions from mental health and control subreddits for three levels of self-disclosure – no selfdisclosure low and high self-disclosure. These three classes of self-disclosure were chosen based on categorization by Bak et al in [10]. The raters mutually discussed their labels thereafter and thus came up with a set of rules for rating. The rules were further aligned with observations in prior work [9 10 11]. Per the rules: Posts that either reveal personal information (e.g. age location gender etc.) or divulge sensitive or vulnerable thoughts beliefs or embarrassing/confessional experiences were to be considered to be indicative of high self-disclosure. Joinson [10] characterized sensitive disclosure in terms of the extent of “revealed vulnerability”. Posts about self but not disclosing any personal or emotionally vulnerable content was to be considered of low self-disclosure. No self-disclosure posts were those which were about people or things other than the posting author and which divulged information unrelated to the self. Following these mutually agreed upon rules the previous two raters and an additional rater familiar with Reddit independently coded a larger sample of 800 posts to create a training set for the purposes of classification. The raters had good agreement in their ratings: Fleiss’ Kappa was found to be .73. However given the subjective nature of characterization of self-disclosure we considered only those posts in the training set for which we had agreement across all three raters – this gave us 627 posts. Across the three categories the coded set consisted of 38% posts of high selfdisclosure 35% posts of low self-disclosure and 27% with no self-disclosure. Table 3 gives examples of mental health post excerpts with high self-disclosure while Table 4 and 5 provide examples of low and no self-disclosure posts. Note that including non-mental health posts in the training set was essential so as to let the detector learn on posts of low and no self-disclosure and on those not mental health related.,automatic detection of selfdisclosure level in post necessitates obtaining gold standard label on selfdisclosure in essence ground truth for the purpose two raters familiar with reddit and it mental health community in particular independently rated a small random sample post with equal proportion from mental health and control subreddits for three level of selfdisclosure no selfdisclosure low and high selfdisclosure these three class of selfdisclosure were chosen based on categorization by bak et al in the raters mutually discussed their label thereafter and thus came up with a set of rule for rating the rule were further aligned with observation in prior work per the rule post that either reveal personal information eg age location gender etc or divulge sensitive or vulnerable thought belief or embarrassingconfessional experience were to be considered to be indicative of high selfdisclosure joinson characterized sensitive disclosure in term of the extent of revealed vulnerability post about self but not disclosing any personal or emotionally vulnerable content wa to be considered of low selfdisclosure no selfdisclosure post were those which were about people or thing other than the posting author and which divulged information unrelated to the self following these mutually agreed upon rule the previous two raters and an additional rater familiar with reddit independently coded a larger sample of post to create a training set for the purpose of classification the raters had good agreement in their rating fleiss kappa wa found to be however given the subjective nature of characterization of selfdisclosure we considered only those post in the training set for which we had agreement across all three raters this gave u post across the three category the coded set consisted of post of high selfdisclosure post of low selfdisclosure and with no selfdisclosure table give example of mental health post excerpt with high selfdisclosure while table and provide example of low and no selfdisclosure post note that including nonmental health post in the training set wa essential so a to let the detector learn on post of low and no selfdisclosure and on those not mental health related,"['automatic', 'detection', 'selfdisclosure', 'level', 'post', 'necessitates', 'obtaining', 'gold', 'standard', 'label', 'selfdisclosure', 'essence', 'ground', 'truth', 'purpose', 'two', 'raters', 'familiar', 'reddit', 'mental', 'health', 'community', 'particular', 'independently', 'rated', 'small', 'random', 'sample', 'post', 'equal', 'proportion', 'mental', 'health', 'control', 'subreddits', 'three', 'level', 'selfdisclosure', 'selfdisclosure', 'low', 'high', 'selfdisclosure', 'three', 'class', 'selfdisclosure', 'chosen', 'based', 'categorization', 'bak', 'et', 'al', 'raters', 'mutually', 'discussed', 'label', 'thereafter', 'thus', 'came', 'set', 'rule', 'rating', 'rule', 'aligned', 'observation', 'prior', 'work', 'per', 'rule', 'post', 'either', 'reveal', 'personal', 'information', 'eg', 'age', 'location', 'gender', 'etc', 'divulge', 'sensitive', 'vulnerable', 'thought', 'belief', 'embarrassingconfessional', 'experience', 'considered', 'indicative', 'high', 'selfdisclosure', 'joinson', 'characterized', 'sensitive', 'disclosure', 'term', 'extent', 'revealed', 'vulnerability', 'post', 'self', 'disclosing', 'personal', 'emotionally', 'vulnerable', 'content', 'wa', 'considered', 'low', 'selfdisclosure', 'selfdisclosure', 'post', 'people', 'thing', 'posting', 'author', 'divulged', 'information', 'unrelated', 'self', 'following', 'mutually', 'agreed', 'upon', 'rule', 'previous', 'two', 'raters', 'additional', 'rater', 'familiar', 'reddit', 'independently', 'coded', 'larger', 'sample', 'post', 'create', 'training', 'set', 'purpose', 'classification', 'raters', 'good', 'agreement', 'rating', 'fleiss', 'kappa', 'wa', 'found', 'however', 'given', 'subjective', 'nature', 'characterization', 'selfdisclosure', 'considered', 'post', 'training', 'set', 'agreement', 'across', 'three', 'raters', 'gave', 'u', 'post', 'across', 'three', 'category', 'coded', 'set', 'consisted', 'post', 'high', 'selfdisclosure', 'post', 'low', 'selfdisclosure', 'selfdisclosure', 'table', 'give', 'example', 'mental', 'health', 'post', 'excerpt', 'high', 'selfdisclosure', 'table', 'provide', 'example', 'low', 'selfdisclosure', 'post', 'note', 'including', 'nonmental', 'health', 'post', 'training', 'set', 'wa', 'essential', 'let', 'detector', 'learn', 'post', 'low', 'selfdisclosure', 'mental', 'health', 'related']","['automatic detection', 'detection selfdisclosure', 'selfdisclosure level', 'level post', 'post necessitates', 'necessitates obtaining', 'obtaining gold', 'gold standard', 'standard label', 'label selfdisclosure', 'selfdisclosure essence', 'essence ground', 'ground truth', 'truth purpose', 'purpose two', 'two raters', 'raters familiar', 'familiar reddit', 'reddit mental', 'mental health', 'health community', 'community particular', 'particular independently', 'independently rated', 'rated small', 'small random', 'random sample', 'sample post', 'post equal', 'equal proportion', 'proportion mental', 'mental health', 'health control', 'control subreddits', 'subreddits three', 'three level', 'level selfdisclosure', 'selfdisclosure selfdisclosure', 'selfdisclosure low', 'low high', 'high selfdisclosure', 'selfdisclosure three', 'three class', 'class selfdisclosure', 'selfdisclosure chosen', 'chosen based', 'based categorization', 'categorization bak', 'bak et', 'et al', 'al raters', 'raters mutually', 'mutually discussed', 'discussed label', 'label thereafter', 'thereafter thus', 'thus came', 'came set', 'set rule', 'rule rating', 'rating rule', 'rule aligned', 'aligned observation', 'observation prior', 'prior work', 'work per', 'per rule', 'rule post', 'post either', 'either reveal', 'reveal personal', 'personal information', 'information eg', 'eg age', 'age location', 'location gender', 'gender etc', 'etc divulge', 'divulge sensitive', 'sensitive vulnerable', 'vulnerable thought', 'thought belief', 'belief embarrassingconfessional', 'embarrassingconfessional experience', 'experience considered', 'considered indicative', 'indicative high', 'high selfdisclosure', 'selfdisclosure joinson', 'joinson characterized', 'characterized sensitive', 'sensitive disclosure', 'disclosure term', 'term extent', 'extent revealed', 'revealed vulnerability', 'vulnerability post', 'post self', 'self disclosing', 'disclosing personal', 'personal emotionally', 'emotionally vulnerable', 'vulnerable content', 'content wa', 'wa considered', 'considered low', 'low selfdisclosure', 'selfdisclosure selfdisclosure', 'selfdisclosure post', 'post people', 'people thing', 'thing posting', 'posting author', 'author divulged', 'divulged information', 'information unrelated', 'unrelated self', 'self following', 'following mutually', 'mutually agreed', 'agreed upon', 'upon rule', 'rule previous', 'previous two', 'two raters', 'raters additional', 'additional rater', 'rater familiar', 'familiar reddit', 'reddit independently', 'independently coded', 'coded larger', 'larger sample', 'sample post', 'post create', 'create training', 'training set', 'set purpose', 'purpose classification', 'classification raters', 'raters good', 'good agreement', 'agreement rating', 'rating fleiss', 'fleiss kappa', 'kappa wa', 'wa found', 'found however', 'however given', 'given subjective', 'subjective nature', 'nature characterization', 'characterization selfdisclosure', 'selfdisclosure considered', 'considered post', 'post training', 'training set', 'set agreement', 'agreement across', 'across three', 'three raters', 'raters gave', 'gave u', 'u post', 'post across', 'across three', 'three category', 'category coded', 'coded set', 'set consisted', 'consisted post', 'post high', 'high selfdisclosure', 'selfdisclosure post', 'post low', 'low selfdisclosure', 'selfdisclosure selfdisclosure', 'selfdisclosure table', 'table give', 'give example', 'example mental', 'mental health', 'health post', 'post excerpt', 'excerpt high', 'high selfdisclosure', 'selfdisclosure table', 'table provide', 'provide example', 'example low', 'low selfdisclosure', 'selfdisclosure post', 'post note', 'note including', 'including nonmental', 'nonmental health', 'health post', 'post training', 'training set', 'set wa', 'wa essential', 'essential let', 'let detector', 'detector learn', 'learn post', 'post low', 'low selfdisclosure', 'selfdisclosure mental', 'mental health', 'health related']","['automatic detection selfdisclosure', 'detection selfdisclosure level', 'selfdisclosure level post', 'level post necessitates', 'post necessitates obtaining', 'necessitates obtaining gold', 'obtaining gold standard', 'gold standard label', 'standard label selfdisclosure', 'label selfdisclosure essence', 'selfdisclosure essence ground', 'essence ground truth', 'ground truth purpose', 'truth purpose two', 'purpose two raters', 'two raters familiar', 'raters familiar reddit', 'familiar reddit mental', 'reddit mental health', 'mental health community', 'health community particular', 'community particular independently', 'particular independently rated', 'independently rated small', 'rated small random', 'small random sample', 'random sample post', 'sample post equal', 'post equal proportion', 'equal proportion mental', 'proportion mental health', 'mental health control', 'health control subreddits', 'control subreddits three', 'subreddits three level', 'three level selfdisclosure', 'level selfdisclosure selfdisclosure', 'selfdisclosure selfdisclosure low', 'selfdisclosure low high', 'low high selfdisclosure', 'high selfdisclosure three', 'selfdisclosure three class', 'three class selfdisclosure', 'class selfdisclosure chosen', 'selfdisclosure chosen based', 'chosen based categorization', 'based categorization bak', 'categorization bak et', 'bak et al', 'et al raters', 'al raters mutually', 'raters mutually discussed', 'mutually discussed label', 'discussed label thereafter', 'label thereafter thus', 'thereafter thus came', 'thus came set', 'came set rule', 'set rule rating', 'rule rating rule', 'rating rule aligned', 'rule aligned observation', 'aligned observation prior', 'observation prior work', 'prior work per', 'work per rule', 'per rule post', 'rule post either', 'post either reveal', 'either reveal personal', 'reveal personal information', 'personal information eg', 'information eg age', 'eg age location', 'age location gender', 'location gender etc', 'gender etc divulge', 'etc divulge sensitive', 'divulge sensitive vulnerable', 'sensitive vulnerable thought', 'vulnerable thought belief', 'thought belief embarrassingconfessional', 'belief embarrassingconfessional experience', 'embarrassingconfessional experience considered', 'experience considered indicative', 'considered indicative high', 'indicative high selfdisclosure', 'high selfdisclosure joinson', 'selfdisclosure joinson characterized', 'joinson characterized sensitive', 'characterized sensitive disclosure', 'sensitive disclosure term', 'disclosure term extent', 'term extent revealed', 'extent revealed vulnerability', 'revealed vulnerability post', 'vulnerability post self', 'post self disclosing', 'self disclosing personal', 'disclosing personal emotionally', 'personal emotionally vulnerable', 'emotionally vulnerable content', 'vulnerable content wa', 'content wa considered', 'wa considered low', 'considered low selfdisclosure', 'low selfdisclosure selfdisclosure', 'selfdisclosure selfdisclosure post', 'selfdisclosure post people', 'post people thing', 'people thing posting', 'thing posting author', 'posting author divulged', 'author divulged information', 'divulged information unrelated', 'information unrelated self', 'unrelated self following', 'self following mutually', 'following mutually agreed', 'mutually agreed upon', 'agreed upon rule', 'upon rule previous', 'rule previous two', 'previous two raters', 'two raters additional', 'raters additional rater', 'additional rater familiar', 'rater familiar reddit', 'familiar reddit independently', 'reddit independently coded', 'independently coded larger', 'coded larger sample', 'larger sample post', 'sample post create', 'post create training', 'create training set', 'training set purpose', 'set purpose classification', 'purpose classification raters', 'classification raters good', 'raters good agreement', 'good agreement rating', 'agreement rating fleiss', 'rating fleiss kappa', 'fleiss kappa wa', 'kappa wa found', 'wa found however', 'found however given', 'however given subjective', 'given subjective nature', 'subjective nature characterization', 'nature characterization selfdisclosure', 'characterization selfdisclosure considered', 'selfdisclosure considered post', 'considered post training', 'post training set', 'training set agreement', 'set agreement across', 'agreement across three', 'across three raters', 'three raters gave', 'raters gave u', 'gave u post', 'u post across', 'post across three', 'across three category', 'three category coded', 'category coded set', 'coded set consisted', 'set consisted post', 'consisted post high', 'post high selfdisclosure', 'high selfdisclosure post', 'selfdisclosure post low', 'post low selfdisclosure', 'low selfdisclosure selfdisclosure', 'selfdisclosure selfdisclosure table', 'selfdisclosure table give', 'table give example', 'give example mental', 'example mental health', 'mental health post', 'health post excerpt', 'post excerpt high', 'excerpt high selfdisclosure', 'high selfdisclosure table', 'selfdisclosure table provide', 'table provide example', 'provide example low', 'example low selfdisclosure', 'low selfdisclosure post', 'selfdisclosure post note', 'post note including', 'note including nonmental', 'including nonmental health', 'nonmental health post', 'health post training', 'post training set', 'training set wa', 'set wa essential', 'wa essential let', 'essential let detector', 'let detector learn', 'detector learn post', 'learn post low', 'post low selfdisclosure', 'low selfdisclosure mental', 'selfdisclosure mental health', 'mental health related']",0.0,0.0,0.0,0.0,0.0,0.9958696961402893,0,0.0
https://dl.acm.org/doi/abs/10.1145/2702123.2702280,1,In this study we gathered information on depression levels of Twitter users and their activity histories. To do this we published a website to administer a questionnaire and disseminated information about the website over Twitter1. In contrast to De Choudhury et al. [14] who collected data from Englishspeaking users through crowdsourcing this study collected data from Japanese-speaking volunteers. This approach was used to investigate the extent to which depression risk can be estimated for a population different from the population considered by the prior research [14]. Figure 1 shows a screenshot of our website. The website collected the responses to a questionnaire to evaluate the degree of depression of the Twitter users who participated (hereinafter the participants) and to collect the histories of participants activities on Twitter. The activity histories of participants were collected through the Twitter application programming interface (API)2 and the questionnaires to determine degree of depression were completed by participants through their web browsers. Before data collection visitors to the website were presented with a written explanation of the aims of the experiment the information that would be collected and how that information would be handled. Those who consented to become participants after receiving the explanation logged into their individual Twitter accounts through the OAuth authorization process. Next participants were surveyed on gender age occupation and history of depression following which they answered a questionnaire designed to evaluate degree of depression. A message called the “kokoro score” (“kokoro” is a Japanese word meaning “heart”) determined on the basis of answers to the questionnaire and information in the collected tweets was displayed to participants after completion of the questionnaire (Fig. 2). Experiment participants were able to tweet the message displayed which made it possible to promote the website over Twitter by word-of-mouth in a type of snowball sampling. The CES-D questionnaire was used to evaluate the degree of depression [30]. In the CES-D test participants answered 20 questions on a Likert-type 4-point scale. Each answer was assigned a score of 0-3 points with the sum of the points from all answers used as the score to estimate likelihood of depression. Several standards exist by which to determine the appropriate cutoff score for identifying depression. In this research we regarded a score of 22 points or higher as indicating active depression and a score of 21 points or lower as indicating no active depression; these are the same values as used in [14] and give a cutoff score of 22. In addition answers to BDI [2] a depression scale used with characteristics similar to CESD were collected to ensure the reliability of data. For each participant scores were calculated on both scales with poor correlation regarded as indicating unreliable answers. The time taken to answer the questionnaires was also recorded and those completed in too brief a time were excluded. After each participant answered the questionnaire the activity history of that participant on Twitter was collected from Twitter by using the API. At most 3200 tweets were collected for each participant and the number of users following the participant and being followed by the participant were recorded. Tweets published after the questionnaire was taken were discarded. The website was opened to the public on 4 December 2013 at which time the authors publicized it on their Twitter accounts. Between 4 December 2013 and 8 February 2014 219 people participated in the experiment. After eliminating participants who did not tweet and participants who answered the questionnaire in fewer than 30 seconds (as previously mentioned to ensure the reliability of the questionnaire answers) 214 sets of answers remained. Only the first set of answers was used for participants who completed the questionnaire more than once. As a result data about 209 experiment participants (male: 121; female: 88) aged 16 to 55 (mean: 28.8 years; standard deviation: 8.2 years) were analyzed. The correlations between CES-D score and BDI score for these participants were high 0.87 and there were no participants with uncorrelated scores so the data for all 209 participants were used; excluded datasets are not discussed any further. Figure 3 shows the histogram of CES-D scores of 209 participants. Among the participants 81 (resp. 128) were estimated to have (resp. not have) active depression for an incidence of approximately 39%. This incidence is similar to that found by De Choudhury et al. [14] who identified depression in approximately 36% of participants. Table 1 gives statistics on the activity histories of participants.,in this study we gathered information on depression level of twitter user and their activity history to do this we published a website to administer a questionnaire and disseminated information about the website over twitter in contrast to de choudhury et al who collected data from englishspeaking user through crowdsourcing this study collected data from japanesespeaking volunteer this approach wa used to investigate the extent to which depression risk can be estimated for a population different from the population considered by the prior research figure show a screenshot of our website the website collected the response to a questionnaire to evaluate the degree of depression of the twitter user who participated hereinafter the participant and to collect the history of participant activity on twitter the activity history of participant were collected through the twitter application programming interface api and the questionnaire to determine degree of depression were completed by participant through their web browser before data collection visitor to the website were presented with a written explanation of the aim of the experiment the information that would be collected and how that information would be handled those who consented to become participant after receiving the explanation logged into their individual twitter account through the oauth authorization process next participant were surveyed on gender age occupation and history of depression following which they answered a questionnaire designed to evaluate degree of depression a message called the kokoro score kokoro is a japanese word meaning heart determined on the basis of answer to the questionnaire and information in the collected tweet wa displayed to participant after completion of the questionnaire fig experiment participant were able to tweet the message displayed which made it possible to promote the website over twitter by wordofmouth in a type of snowball sampling the cesd questionnaire wa used to evaluate the degree of depression in the cesd test participant answered question on a likerttype point scale each answer wa assigned a score of point with the sum of the point from all answer used a the score to estimate likelihood of depression several standard exist by which to determine the appropriate cutoff score for identifying depression in this research we regarded a score of point or higher a indicating active depression and a score of point or lower a indicating no active depression these are the same value a used in and give a cutoff score of in addition answer to bdi a depression scale used with characteristic similar to cesd were collected to ensure the reliability of data for each participant score were calculated on both scale with poor correlation regarded a indicating unreliable answer the time taken to answer the questionnaire wa also recorded and those completed in too brief a time were excluded after each participant answered the questionnaire the activity history of that participant on twitter wa collected from twitter by using the api at most tweet were collected for each participant and the number of user following the participant and being followed by the participant were recorded tweet published after the questionnaire wa taken were discarded the website wa opened to the public on december at which time the author publicized it on their twitter account between december and february people participated in the experiment after eliminating participant who did not tweet and participant who answered the questionnaire in fewer than second a previously mentioned to ensure the reliability of the questionnaire answer set of answer remained only the first set of answer wa used for participant who completed the questionnaire more than once a a result data about experiment participant male female aged to mean year standard deviation year were analyzed the correlation between cesd score and bdi score for these participant were high and there were no participant with uncorrelated score so the data for all participant were used excluded datasets are not discussed any further figure show the histogram of cesd score of participant among the participant resp were estimated to have resp not have active depression for an incidence of approximately this incidence is similar to that found by de choudhury et al who identified depression in approximately of participant table give statistic on the activity history of participant,"['study', 'gathered', 'information', 'depression', 'level', 'twitter', 'user', 'activity', 'history', 'published', 'website', 'administer', 'questionnaire', 'disseminated', 'information', 'website', 'twitter', 'contrast', 'de', 'choudhury', 'et', 'al', 'collected', 'data', 'englishspeaking', 'user', 'crowdsourcing', 'study', 'collected', 'data', 'japanesespeaking', 'volunteer', 'approach', 'wa', 'used', 'investigate', 'extent', 'depression', 'risk', 'estimated', 'population', 'different', 'population', 'considered', 'prior', 'research', 'figure', 'show', 'screenshot', 'website', 'website', 'collected', 'response', 'questionnaire', 'evaluate', 'degree', 'depression', 'twitter', 'user', 'participated', 'hereinafter', 'participant', 'collect', 'history', 'participant', 'activity', 'twitter', 'activity', 'history', 'participant', 'collected', 'twitter', 'application', 'programming', 'interface', 'api', 'questionnaire', 'determine', 'degree', 'depression', 'completed', 'participant', 'web', 'browser', 'data', 'collection', 'visitor', 'website', 'presented', 'written', 'explanation', 'aim', 'experiment', 'information', 'would', 'collected', 'information', 'would', 'handled', 'consented', 'become', 'participant', 'receiving', 'explanation', 'logged', 'individual', 'twitter', 'account', 'oauth', 'authorization', 'process', 'next', 'participant', 'surveyed', 'gender', 'age', 'occupation', 'history', 'depression', 'following', 'answered', 'questionnaire', 'designed', 'evaluate', 'degree', 'depression', 'message', 'called', 'kokoro', 'score', 'kokoro', 'japanese', 'word', 'meaning', 'heart', 'determined', 'basis', 'answer', 'questionnaire', 'information', 'collected', 'tweet', 'wa', 'displayed', 'participant', 'completion', 'questionnaire', 'fig', 'experiment', 'participant', 'able', 'tweet', 'message', 'displayed', 'made', 'possible', 'promote', 'website', 'twitter', 'wordofmouth', 'type', 'snowball', 'sampling', 'cesd', 'questionnaire', 'wa', 'used', 'evaluate', 'degree', 'depression', 'cesd', 'test', 'participant', 'answered', 'question', 'likerttype', 'point', 'scale', 'answer', 'wa', 'assigned', 'score', 'point', 'sum', 'point', 'answer', 'used', 'score', 'estimate', 'likelihood', 'depression', 'several', 'standard', 'exist', 'determine', 'appropriate', 'cutoff', 'score', 'identifying', 'depression', 'research', 'regarded', 'score', 'point', 'higher', 'indicating', 'active', 'depression', 'score', 'point', 'lower', 'indicating', 'active', 'depression', 'value', 'used', 'give', 'cutoff', 'score', 'addition', 'answer', 'bdi', 'depression', 'scale', 'used', 'characteristic', 'similar', 'cesd', 'collected', 'ensure', 'reliability', 'data', 'participant', 'score', 'calculated', 'scale', 'poor', 'correlation', 'regarded', 'indicating', 'unreliable', 'answer', 'time', 'taken', 'answer', 'questionnaire', 'wa', 'also', 'recorded', 'completed', 'brief', 'time', 'excluded', 'participant', 'answered', 'questionnaire', 'activity', 'history', 'participant', 'twitter', 'wa', 'collected', 'twitter', 'using', 'api', 'tweet', 'collected', 'participant', 'number', 'user', 'following', 'participant', 'followed', 'participant', 'recorded', 'tweet', 'published', 'questionnaire', 'wa', 'taken', 'discarded', 'website', 'wa', 'opened', 'public', 'december', 'time', 'author', 'publicized', 'twitter', 'account', 'december', 'february', 'people', 'participated', 'experiment', 'eliminating', 'participant', 'tweet', 'participant', 'answered', 'questionnaire', 'fewer', 'second', 'previously', 'mentioned', 'ensure', 'reliability', 'questionnaire', 'answer', 'set', 'answer', 'remained', 'first', 'set', 'answer', 'wa', 'used', 'participant', 'completed', 'questionnaire', 'result', 'data', 'experiment', 'participant', 'male', 'female', 'aged', 'mean', 'year', 'standard', 'deviation', 'year', 'analyzed', 'correlation', 'cesd', 'score', 'bdi', 'score', 'participant', 'high', 'participant', 'uncorrelated', 'score', 'data', 'participant', 'used', 'excluded', 'datasets', 'discussed', 'figure', 'show', 'histogram', 'cesd', 'score', 'participant', 'among', 'participant', 'resp', 'estimated', 'resp', 'active', 'depression', 'incidence', 'approximately', 'incidence', 'similar', 'found', 'de', 'choudhury', 'et', 'al', 'identified', 'depression', 'approximately', 'participant', 'table', 'give', 'statistic', 'activity', 'history', 'participant']","['study gathered', 'gathered information', 'information depression', 'depression level', 'level twitter', 'twitter user', 'user activity', 'activity history', 'history published', 'published website', 'website administer', 'administer questionnaire', 'questionnaire disseminated', 'disseminated information', 'information website', 'website twitter', 'twitter contrast', 'contrast de', 'de choudhury', 'choudhury et', 'et al', 'al collected', 'collected data', 'data englishspeaking', 'englishspeaking user', 'user crowdsourcing', 'crowdsourcing study', 'study collected', 'collected data', 'data japanesespeaking', 'japanesespeaking volunteer', 'volunteer approach', 'approach wa', 'wa used', 'used investigate', 'investigate extent', 'extent depression', 'depression risk', 'risk estimated', 'estimated population', 'population different', 'different population', 'population considered', 'considered prior', 'prior research', 'research figure', 'figure show', 'show screenshot', 'screenshot website', 'website website', 'website collected', 'collected response', 'response questionnaire', 'questionnaire evaluate', 'evaluate degree', 'degree depression', 'depression twitter', 'twitter user', 'user participated', 'participated hereinafter', 'hereinafter participant', 'participant collect', 'collect history', 'history participant', 'participant activity', 'activity twitter', 'twitter activity', 'activity history', 'history participant', 'participant collected', 'collected twitter', 'twitter application', 'application programming', 'programming interface', 'interface api', 'api questionnaire', 'questionnaire determine', 'determine degree', 'degree depression', 'depression completed', 'completed participant', 'participant web', 'web browser', 'browser data', 'data collection', 'collection visitor', 'visitor website', 'website presented', 'presented written', 'written explanation', 'explanation aim', 'aim experiment', 'experiment information', 'information would', 'would collected', 'collected information', 'information would', 'would handled', 'handled consented', 'consented become', 'become participant', 'participant receiving', 'receiving explanation', 'explanation logged', 'logged individual', 'individual twitter', 'twitter account', 'account oauth', 'oauth authorization', 'authorization process', 'process next', 'next participant', 'participant surveyed', 'surveyed gender', 'gender age', 'age occupation', 'occupation history', 'history depression', 'depression following', 'following answered', 'answered questionnaire', 'questionnaire designed', 'designed evaluate', 'evaluate degree', 'degree depression', 'depression message', 'message called', 'called kokoro', 'kokoro score', 'score kokoro', 'kokoro japanese', 'japanese word', 'word meaning', 'meaning heart', 'heart determined', 'determined basis', 'basis answer', 'answer questionnaire', 'questionnaire information', 'information collected', 'collected tweet', 'tweet wa', 'wa displayed', 'displayed participant', 'participant completion', 'completion questionnaire', 'questionnaire fig', 'fig experiment', 'experiment participant', 'participant able', 'able tweet', 'tweet message', 'message displayed', 'displayed made', 'made possible', 'possible promote', 'promote website', 'website twitter', 'twitter wordofmouth', 'wordofmouth type', 'type snowball', 'snowball sampling', 'sampling cesd', 'cesd questionnaire', 'questionnaire wa', 'wa used', 'used evaluate', 'evaluate degree', 'degree depression', 'depression cesd', 'cesd test', 'test participant', 'participant answered', 'answered question', 'question likerttype', 'likerttype point', 'point scale', 'scale answer', 'answer wa', 'wa assigned', 'assigned score', 'score point', 'point sum', 'sum point', 'point answer', 'answer used', 'used score', 'score estimate', 'estimate likelihood', 'likelihood depression', 'depression several', 'several standard', 'standard exist', 'exist determine', 'determine appropriate', 'appropriate cutoff', 'cutoff score', 'score identifying', 'identifying depression', 'depression research', 'research regarded', 'regarded score', 'score point', 'point higher', 'higher indicating', 'indicating active', 'active depression', 'depression score', 'score point', 'point lower', 'lower indicating', 'indicating active', 'active depression', 'depression value', 'value used', 'used give', 'give cutoff', 'cutoff score', 'score addition', 'addition answer', 'answer bdi', 'bdi depression', 'depression scale', 'scale used', 'used characteristic', 'characteristic similar', 'similar cesd', 'cesd collected', 'collected ensure', 'ensure reliability', 'reliability data', 'data participant', 'participant score', 'score calculated', 'calculated scale', 'scale poor', 'poor correlation', 'correlation regarded', 'regarded indicating', 'indicating unreliable', 'unreliable answer', 'answer time', 'time taken', 'taken answer', 'answer questionnaire', 'questionnaire wa', 'wa also', 'also recorded', 'recorded completed', 'completed brief', 'brief time', 'time excluded', 'excluded participant', 'participant answered', 'answered questionnaire', 'questionnaire activity', 'activity history', 'history participant', 'participant twitter', 'twitter wa', 'wa collected', 'collected twitter', 'twitter using', 'using api', 'api tweet', 'tweet collected', 'collected participant', 'participant number', 'number user', 'user following', 'following participant', 'participant followed', 'followed participant', 'participant recorded', 'recorded tweet', 'tweet published', 'published questionnaire', 'questionnaire wa', 'wa taken', 'taken discarded', 'discarded website', 'website wa', 'wa opened', 'opened public', 'public december', 'december time', 'time author', 'author publicized', 'publicized twitter', 'twitter account', 'account december', 'december february', 'february people', 'people participated', 'participated experiment', 'experiment eliminating', 'eliminating participant', 'participant tweet', 'tweet participant', 'participant answered', 'answered questionnaire', 'questionnaire fewer', 'fewer second', 'second previously', 'previously mentioned', 'mentioned ensure', 'ensure reliability', 'reliability questionnaire', 'questionnaire answer', 'answer set', 'set answer', 'answer remained', 'remained first', 'first set', 'set answer', 'answer wa', 'wa used', 'used participant', 'participant completed', 'completed questionnaire', 'questionnaire result', 'result data', 'data experiment', 'experiment participant', 'participant male', 'male female', 'female aged', 'aged mean', 'mean year', 'year standard', 'standard deviation', 'deviation year', 'year analyzed', 'analyzed correlation', 'correlation cesd', 'cesd score', 'score bdi', 'bdi score', 'score participant', 'participant high', 'high participant', 'participant uncorrelated', 'uncorrelated score', 'score data', 'data participant', 'participant used', 'used excluded', 'excluded datasets', 'datasets discussed', 'discussed figure', 'figure show', 'show histogram', 'histogram cesd', 'cesd score', 'score participant', 'participant among', 'among participant', 'participant resp', 'resp estimated', 'estimated resp', 'resp active', 'active depression', 'depression incidence', 'incidence approximately', 'approximately incidence', 'incidence similar', 'similar found', 'found de', 'de choudhury', 'choudhury et', 'et al', 'al identified', 'identified depression', 'depression approximately', 'approximately participant', 'participant table', 'table give', 'give statistic', 'statistic activity', 'activity history', 'history participant']","['study gathered information', 'gathered information depression', 'information depression level', 'depression level twitter', 'level twitter user', 'twitter user activity', 'user activity history', 'activity history published', 'history published website', 'published website administer', 'website administer questionnaire', 'administer questionnaire disseminated', 'questionnaire disseminated information', 'disseminated information website', 'information website twitter', 'website twitter contrast', 'twitter contrast de', 'contrast de choudhury', 'de choudhury et', 'choudhury et al', 'et al collected', 'al collected data', 'collected data englishspeaking', 'data englishspeaking user', 'englishspeaking user crowdsourcing', 'user crowdsourcing study', 'crowdsourcing study collected', 'study collected data', 'collected data japanesespeaking', 'data japanesespeaking volunteer', 'japanesespeaking volunteer approach', 'volunteer approach wa', 'approach wa used', 'wa used investigate', 'used investigate extent', 'investigate extent depression', 'extent depression risk', 'depression risk estimated', 'risk estimated population', 'estimated population different', 'population different population', 'different population considered', 'population considered prior', 'considered prior research', 'prior research figure', 'research figure show', 'figure show screenshot', 'show screenshot website', 'screenshot website website', 'website website collected', 'website collected response', 'collected response questionnaire', 'response questionnaire evaluate', 'questionnaire evaluate degree', 'evaluate degree depression', 'degree depression twitter', 'depression twitter user', 'twitter user participated', 'user participated hereinafter', 'participated hereinafter participant', 'hereinafter participant collect', 'participant collect history', 'collect history participant', 'history participant activity', 'participant activity twitter', 'activity twitter activity', 'twitter activity history', 'activity history participant', 'history participant collected', 'participant collected twitter', 'collected twitter application', 'twitter application programming', 'application programming interface', 'programming interface api', 'interface api questionnaire', 'api questionnaire determine', 'questionnaire determine degree', 'determine degree depression', 'degree depression completed', 'depression completed participant', 'completed participant web', 'participant web browser', 'web browser data', 'browser data collection', 'data collection visitor', 'collection visitor website', 'visitor website presented', 'website presented written', 'presented written explanation', 'written explanation aim', 'explanation aim experiment', 'aim experiment information', 'experiment information would', 'information would collected', 'would collected information', 'collected information would', 'information would handled', 'would handled consented', 'handled consented become', 'consented become participant', 'become participant receiving', 'participant receiving explanation', 'receiving explanation logged', 'explanation logged individual', 'logged individual twitter', 'individual twitter account', 'twitter account oauth', 'account oauth authorization', 'oauth authorization process', 'authorization process next', 'process next participant', 'next participant surveyed', 'participant surveyed gender', 'surveyed gender age', 'gender age occupation', 'age occupation history', 'occupation history depression', 'history depression following', 'depression following answered', 'following answered questionnaire', 'answered questionnaire designed', 'questionnaire designed evaluate', 'designed evaluate degree', 'evaluate degree depression', 'degree depression message', 'depression message called', 'message called kokoro', 'called kokoro score', 'kokoro score kokoro', 'score kokoro japanese', 'kokoro japanese word', 'japanese word meaning', 'word meaning heart', 'meaning heart determined', 'heart determined basis', 'determined basis answer', 'basis answer questionnaire', 'answer questionnaire information', 'questionnaire information collected', 'information collected tweet', 'collected tweet wa', 'tweet wa displayed', 'wa displayed participant', 'displayed participant completion', 'participant completion questionnaire', 'completion questionnaire fig', 'questionnaire fig experiment', 'fig experiment participant', 'experiment participant able', 'participant able tweet', 'able tweet message', 'tweet message displayed', 'message displayed made', 'displayed made possible', 'made possible promote', 'possible promote website', 'promote website twitter', 'website twitter wordofmouth', 'twitter wordofmouth type', 'wordofmouth type snowball', 'type snowball sampling', 'snowball sampling cesd', 'sampling cesd questionnaire', 'cesd questionnaire wa', 'questionnaire wa used', 'wa used evaluate', 'used evaluate degree', 'evaluate degree depression', 'degree depression cesd', 'depression cesd test', 'cesd test participant', 'test participant answered', 'participant answered question', 'answered question likerttype', 'question likerttype point', 'likerttype point scale', 'point scale answer', 'scale answer wa', 'answer wa assigned', 'wa assigned score', 'assigned score point', 'score point sum', 'point sum point', 'sum point answer', 'point answer used', 'answer used score', 'used score estimate', 'score estimate likelihood', 'estimate likelihood depression', 'likelihood depression several', 'depression several standard', 'several standard exist', 'standard exist determine', 'exist determine appropriate', 'determine appropriate cutoff', 'appropriate cutoff score', 'cutoff score identifying', 'score identifying depression', 'identifying depression research', 'depression research regarded', 'research regarded score', 'regarded score point', 'score point higher', 'point higher indicating', 'higher indicating active', 'indicating active depression', 'active depression score', 'depression score point', 'score point lower', 'point lower indicating', 'lower indicating active', 'indicating active depression', 'active depression value', 'depression value used', 'value used give', 'used give cutoff', 'give cutoff score', 'cutoff score addition', 'score addition answer', 'addition answer bdi', 'answer bdi depression', 'bdi depression scale', 'depression scale used', 'scale used characteristic', 'used characteristic similar', 'characteristic similar cesd', 'similar cesd collected', 'cesd collected ensure', 'collected ensure reliability', 'ensure reliability data', 'reliability data participant', 'data participant score', 'participant score calculated', 'score calculated scale', 'calculated scale poor', 'scale poor correlation', 'poor correlation regarded', 'correlation regarded indicating', 'regarded indicating unreliable', 'indicating unreliable answer', 'unreliable answer time', 'answer time taken', 'time taken answer', 'taken answer questionnaire', 'answer questionnaire wa', 'questionnaire wa also', 'wa also recorded', 'also recorded completed', 'recorded completed brief', 'completed brief time', 'brief time excluded', 'time excluded participant', 'excluded participant answered', 'participant answered questionnaire', 'answered questionnaire activity', 'questionnaire activity history', 'activity history participant', 'history participant twitter', 'participant twitter wa', 'twitter wa collected', 'wa collected twitter', 'collected twitter using', 'twitter using api', 'using api tweet', 'api tweet collected', 'tweet collected participant', 'collected participant number', 'participant number user', 'number user following', 'user following participant', 'following participant followed', 'participant followed participant', 'followed participant recorded', 'participant recorded tweet', 'recorded tweet published', 'tweet published questionnaire', 'published questionnaire wa', 'questionnaire wa taken', 'wa taken discarded', 'taken discarded website', 'discarded website wa', 'website wa opened', 'wa opened public', 'opened public december', 'public december time', 'december time author', 'time author publicized', 'author publicized twitter', 'publicized twitter account', 'twitter account december', 'account december february', 'december february people', 'february people participated', 'people participated experiment', 'participated experiment eliminating', 'experiment eliminating participant', 'eliminating participant tweet', 'participant tweet participant', 'tweet participant answered', 'participant answered questionnaire', 'answered questionnaire fewer', 'questionnaire fewer second', 'fewer second previously', 'second previously mentioned', 'previously mentioned ensure', 'mentioned ensure reliability', 'ensure reliability questionnaire', 'reliability questionnaire answer', 'questionnaire answer set', 'answer set answer', 'set answer remained', 'answer remained first', 'remained first set', 'first set answer', 'set answer wa', 'answer wa used', 'wa used participant', 'used participant completed', 'participant completed questionnaire', 'completed questionnaire result', 'questionnaire result data', 'result data experiment', 'data experiment participant', 'experiment participant male', 'participant male female', 'male female aged', 'female aged mean', 'aged mean year', 'mean year standard', 'year standard deviation', 'standard deviation year', 'deviation year analyzed', 'year analyzed correlation', 'analyzed correlation cesd', 'correlation cesd score', 'cesd score bdi', 'score bdi score', 'bdi score participant', 'score participant high', 'participant high participant', 'high participant uncorrelated', 'participant uncorrelated score', 'uncorrelated score data', 'score data participant', 'data participant used', 'participant used excluded', 'used excluded datasets', 'excluded datasets discussed', 'datasets discussed figure', 'discussed figure show', 'figure show histogram', 'show histogram cesd', 'histogram cesd score', 'cesd score participant', 'score participant among', 'participant among participant', 'among participant resp', 'participant resp estimated', 'resp estimated resp', 'estimated resp active', 'resp active depression', 'active depression incidence', 'depression incidence approximately', 'incidence approximately incidence', 'approximately incidence similar', 'incidence similar found', 'similar found de', 'found de choudhury', 'de choudhury et', 'choudhury et al', 'et al identified', 'al identified depression', 'identified depression approximately', 'depression approximately participant', 'approximately participant table', 'participant table give', 'table give statistic', 'give statistic activity', 'statistic activity history', 'activity history participant']",0.0,0.0,0.9977142214775085,0.0,0.0,0.0,0,0.0
https://www.nature.com/articles/s41598-017-12961-9,1,Participants were recruited using Amazon’s Mechanical Turk (MTurk) crowdwork platform and we collected user data from both the survey on MTurk and participants’ Twitter history. Recruitment and data collection procedures were identical for depression and PTSD samples with the exception of the condition-specific questionnaire used for screening. Separate surveys were created for affected and healthy samples. The term “affected” here refers to participants affected by either depression or PTSD respectively. In the affected sample surveys participants were invited to complete a questionnaire that involved passing a series of inclusion criteria responding to a standardized clinical assessment survey answering questions related to demographics and mental health history and sharing social media history. We used the CES-D (Center for Epidemiologic Studies Depression Scale) questionnaire to screen participant depression levels29. CES-D assessment quality has been demonstrated as on-par with other depression inventories including the Beck Depression Inventory and the Kellner Symptom Questionnaire3031. The Trauma Screening Questionnaire (TSQ) was used to screen for PTSD32. A comparison cohort of healthy participants were screened to ensure no history of depression or PTSD respectively and for active Twitter use. Qualified participants were asked to share their Twitter usernames and history. An app embedded in the survey allowed participants to securely log into their Twitter accounts and agree to share their data. Upon securing consent we made a one-time collection of participants’ Twitter posting history up to the most recent 3200 tweets (this limit is imposed by the Twitter API). In total we collected 279951 tweets from 204 Twitter users for the depression analysis and 243775 tweets from 174 Twitter users for the PTSD analysis. Details on participant data protection measures are outlined below.,participant were recruited using amazon mechanical turk mturk crowdwork platform and we collected user data from both the survey on mturk and participant twitter history recruitment and data collection procedure were identical for depression and ptsd sample with the exception of the conditionspecific questionnaire used for screening separate survey were created for affected and healthy sample the term affected here refers to participant affected by either depression or ptsd respectively in the affected sample survey participant were invited to complete a questionnaire that involved passing a series of inclusion criterion responding to a standardized clinical assessment survey answering question related to demographic and mental health history and sharing social medium history we used the cesd center for epidemiologic study depression scale questionnaire to screen participant depression level cesd assessment quality ha been demonstrated a onpar with other depression inventory including the beck depression inventory and the kellner symptom questionnaire the trauma screening questionnaire tsq wa used to screen for ptsd a comparison cohort of healthy participant were screened to ensure no history of depression or ptsd respectively and for active twitter use qualified participant were asked to share their twitter usernames and history an app embedded in the survey allowed participant to securely log into their twitter account and agree to share their data upon securing consent we made a onetime collection of participant twitter posting history up to the most recent tweet this limit is imposed by the twitter api in total we collected tweet from twitter user for the depression analysis and tweet from twitter user for the ptsd analysis detail on participant data protection measure are outlined below,"['participant', 'recruited', 'using', 'amazon', 'mechanical', 'turk', 'mturk', 'crowdwork', 'platform', 'collected', 'user', 'data', 'survey', 'mturk', 'participant', 'twitter', 'history', 'recruitment', 'data', 'collection', 'procedure', 'identical', 'depression', 'ptsd', 'sample', 'exception', 'conditionspecific', 'questionnaire', 'used', 'screening', 'separate', 'survey', 'created', 'affected', 'healthy', 'sample', 'term', 'affected', 'refers', 'participant', 'affected', 'either', 'depression', 'ptsd', 'respectively', 'affected', 'sample', 'survey', 'participant', 'invited', 'complete', 'questionnaire', 'involved', 'passing', 'series', 'inclusion', 'criterion', 'responding', 'standardized', 'clinical', 'assessment', 'survey', 'answering', 'question', 'related', 'demographic', 'mental', 'health', 'history', 'sharing', 'social', 'medium', 'history', 'used', 'cesd', 'center', 'epidemiologic', 'study', 'depression', 'scale', 'questionnaire', 'screen', 'participant', 'depression', 'level', 'cesd', 'assessment', 'quality', 'ha', 'demonstrated', 'onpar', 'depression', 'inventory', 'including', 'beck', 'depression', 'inventory', 'kellner', 'symptom', 'questionnaire', 'trauma', 'screening', 'questionnaire', 'tsq', 'wa', 'used', 'screen', 'ptsd', 'comparison', 'cohort', 'healthy', 'participant', 'screened', 'ensure', 'history', 'depression', 'ptsd', 'respectively', 'active', 'twitter', 'use', 'qualified', 'participant', 'asked', 'share', 'twitter', 'usernames', 'history', 'app', 'embedded', 'survey', 'allowed', 'participant', 'securely', 'log', 'twitter', 'account', 'agree', 'share', 'data', 'upon', 'securing', 'consent', 'made', 'onetime', 'collection', 'participant', 'twitter', 'posting', 'history', 'recent', 'tweet', 'limit', 'imposed', 'twitter', 'api', 'total', 'collected', 'tweet', 'twitter', 'user', 'depression', 'analysis', 'tweet', 'twitter', 'user', 'ptsd', 'analysis', 'detail', 'participant', 'data', 'protection', 'measure', 'outlined']","['participant recruited', 'recruited using', 'using amazon', 'amazon mechanical', 'mechanical turk', 'turk mturk', 'mturk crowdwork', 'crowdwork platform', 'platform collected', 'collected user', 'user data', 'data survey', 'survey mturk', 'mturk participant', 'participant twitter', 'twitter history', 'history recruitment', 'recruitment data', 'data collection', 'collection procedure', 'procedure identical', 'identical depression', 'depression ptsd', 'ptsd sample', 'sample exception', 'exception conditionspecific', 'conditionspecific questionnaire', 'questionnaire used', 'used screening', 'screening separate', 'separate survey', 'survey created', 'created affected', 'affected healthy', 'healthy sample', 'sample term', 'term affected', 'affected refers', 'refers participant', 'participant affected', 'affected either', 'either depression', 'depression ptsd', 'ptsd respectively', 'respectively affected', 'affected sample', 'sample survey', 'survey participant', 'participant invited', 'invited complete', 'complete questionnaire', 'questionnaire involved', 'involved passing', 'passing series', 'series inclusion', 'inclusion criterion', 'criterion responding', 'responding standardized', 'standardized clinical', 'clinical assessment', 'assessment survey', 'survey answering', 'answering question', 'question related', 'related demographic', 'demographic mental', 'mental health', 'health history', 'history sharing', 'sharing social', 'social medium', 'medium history', 'history used', 'used cesd', 'cesd center', 'center epidemiologic', 'epidemiologic study', 'study depression', 'depression scale', 'scale questionnaire', 'questionnaire screen', 'screen participant', 'participant depression', 'depression level', 'level cesd', 'cesd assessment', 'assessment quality', 'quality ha', 'ha demonstrated', 'demonstrated onpar', 'onpar depression', 'depression inventory', 'inventory including', 'including beck', 'beck depression', 'depression inventory', 'inventory kellner', 'kellner symptom', 'symptom questionnaire', 'questionnaire trauma', 'trauma screening', 'screening questionnaire', 'questionnaire tsq', 'tsq wa', 'wa used', 'used screen', 'screen ptsd', 'ptsd comparison', 'comparison cohort', 'cohort healthy', 'healthy participant', 'participant screened', 'screened ensure', 'ensure history', 'history depression', 'depression ptsd', 'ptsd respectively', 'respectively active', 'active twitter', 'twitter use', 'use qualified', 'qualified participant', 'participant asked', 'asked share', 'share twitter', 'twitter usernames', 'usernames history', 'history app', 'app embedded', 'embedded survey', 'survey allowed', 'allowed participant', 'participant securely', 'securely log', 'log twitter', 'twitter account', 'account agree', 'agree share', 'share data', 'data upon', 'upon securing', 'securing consent', 'consent made', 'made onetime', 'onetime collection', 'collection participant', 'participant twitter', 'twitter posting', 'posting history', 'history recent', 'recent tweet', 'tweet limit', 'limit imposed', 'imposed twitter', 'twitter api', 'api total', 'total collected', 'collected tweet', 'tweet twitter', 'twitter user', 'user depression', 'depression analysis', 'analysis tweet', 'tweet twitter', 'twitter user', 'user ptsd', 'ptsd analysis', 'analysis detail', 'detail participant', 'participant data', 'data protection', 'protection measure', 'measure outlined']","['participant recruited using', 'recruited using amazon', 'using amazon mechanical', 'amazon mechanical turk', 'mechanical turk mturk', 'turk mturk crowdwork', 'mturk crowdwork platform', 'crowdwork platform collected', 'platform collected user', 'collected user data', 'user data survey', 'data survey mturk', 'survey mturk participant', 'mturk participant twitter', 'participant twitter history', 'twitter history recruitment', 'history recruitment data', 'recruitment data collection', 'data collection procedure', 'collection procedure identical', 'procedure identical depression', 'identical depression ptsd', 'depression ptsd sample', 'ptsd sample exception', 'sample exception conditionspecific', 'exception conditionspecific questionnaire', 'conditionspecific questionnaire used', 'questionnaire used screening', 'used screening separate', 'screening separate survey', 'separate survey created', 'survey created affected', 'created affected healthy', 'affected healthy sample', 'healthy sample term', 'sample term affected', 'term affected refers', 'affected refers participant', 'refers participant affected', 'participant affected either', 'affected either depression', 'either depression ptsd', 'depression ptsd respectively', 'ptsd respectively affected', 'respectively affected sample', 'affected sample survey', 'sample survey participant', 'survey participant invited', 'participant invited complete', 'invited complete questionnaire', 'complete questionnaire involved', 'questionnaire involved passing', 'involved passing series', 'passing series inclusion', 'series inclusion criterion', 'inclusion criterion responding', 'criterion responding standardized', 'responding standardized clinical', 'standardized clinical assessment', 'clinical assessment survey', 'assessment survey answering', 'survey answering question', 'answering question related', 'question related demographic', 'related demographic mental', 'demographic mental health', 'mental health history', 'health history sharing', 'history sharing social', 'sharing social medium', 'social medium history', 'medium history used', 'history used cesd', 'used cesd center', 'cesd center epidemiologic', 'center epidemiologic study', 'epidemiologic study depression', 'study depression scale', 'depression scale questionnaire', 'scale questionnaire screen', 'questionnaire screen participant', 'screen participant depression', 'participant depression level', 'depression level cesd', 'level cesd assessment', 'cesd assessment quality', 'assessment quality ha', 'quality ha demonstrated', 'ha demonstrated onpar', 'demonstrated onpar depression', 'onpar depression inventory', 'depression inventory including', 'inventory including beck', 'including beck depression', 'beck depression inventory', 'depression inventory kellner', 'inventory kellner symptom', 'kellner symptom questionnaire', 'symptom questionnaire trauma', 'questionnaire trauma screening', 'trauma screening questionnaire', 'screening questionnaire tsq', 'questionnaire tsq wa', 'tsq wa used', 'wa used screen', 'used screen ptsd', 'screen ptsd comparison', 'ptsd comparison cohort', 'comparison cohort healthy', 'cohort healthy participant', 'healthy participant screened', 'participant screened ensure', 'screened ensure history', 'ensure history depression', 'history depression ptsd', 'depression ptsd respectively', 'ptsd respectively active', 'respectively active twitter', 'active twitter use', 'twitter use qualified', 'use qualified participant', 'qualified participant asked', 'participant asked share', 'asked share twitter', 'share twitter usernames', 'twitter usernames history', 'usernames history app', 'history app embedded', 'app embedded survey', 'embedded survey allowed', 'survey allowed participant', 'allowed participant securely', 'participant securely log', 'securely log twitter', 'log twitter account', 'twitter account agree', 'account agree share', 'agree share data', 'share data upon', 'data upon securing', 'upon securing consent', 'securing consent made', 'consent made onetime', 'made onetime collection', 'onetime collection participant', 'collection participant twitter', 'participant twitter posting', 'twitter posting history', 'posting history recent', 'history recent tweet', 'recent tweet limit', 'tweet limit imposed', 'limit imposed twitter', 'imposed twitter api', 'twitter api total', 'api total collected', 'total collected tweet', 'collected tweet twitter', 'tweet twitter user', 'twitter user depression', 'user depression analysis', 'depression analysis tweet', 'analysis tweet twitter', 'tweet twitter user', 'twitter user ptsd', 'user ptsd analysis', 'ptsd analysis detail', 'analysis detail participant', 'detail participant data', 'participant data protection', 'data protection measure', 'protection measure outlined']",0.9949967861175537,0.0,0.0,0.0,0.0,0.0,0,0.0
https://aclanthology.org/W14-3214.pdf,1,We estimated user-level degree of depression (DDep) as the average response to seven depression facet items which are nested within the larger Neuroticism item pool. For each item users indicated how accurately short phrases described themselves (e.g. “often feel blue” “dislike myself”; responses ranged from 1 = very inaccurate to 5 = very accurate). Figure 1a shows the distribution of surveyassessed DDep (standardized). The items can be seen in Table 1. Figure 2 shows the daily averages of surveyassessed DDep collapsed across years. A LOESS smoother over the daily averages illustrates a seasonal trend with depression rising over the winter months and dropping during the summer.,we estimated userlevel degree of depression ddep a the average response to seven depression facet item which are nested within the larger neuroticism item pool for each item user indicated how accurately short phrase described themselves eg often feel blue dislike myself response ranged from very inaccurate to very accurate figure a show the distribution of surveyassessed ddep standardized the item can be seen in table figure show the daily average of surveyassessed ddep collapsed across year a loess smoother over the daily average illustrates a seasonal trend with depression rising over the winter month and dropping during the summer,"['estimated', 'userlevel', 'degree', 'depression', 'ddep', 'average', 'response', 'seven', 'depression', 'facet', 'item', 'nested', 'within', 'larger', 'neuroticism', 'item', 'pool', 'item', 'user', 'indicated', 'accurately', 'short', 'phrase', 'described', 'eg', 'often', 'feel', 'blue', 'dislike', 'response', 'ranged', 'inaccurate', 'accurate', 'figure', 'show', 'distribution', 'surveyassessed', 'ddep', 'standardized', 'item', 'seen', 'table', 'figure', 'show', 'daily', 'average', 'surveyassessed', 'ddep', 'collapsed', 'across', 'year', 'loess', 'smoother', 'daily', 'average', 'illustrates', 'seasonal', 'trend', 'depression', 'rising', 'winter', 'month', 'dropping', 'summer']","['estimated userlevel', 'userlevel degree', 'degree depression', 'depression ddep', 'ddep average', 'average response', 'response seven', 'seven depression', 'depression facet', 'facet item', 'item nested', 'nested within', 'within larger', 'larger neuroticism', 'neuroticism item', 'item pool', 'pool item', 'item user', 'user indicated', 'indicated accurately', 'accurately short', 'short phrase', 'phrase described', 'described eg', 'eg often', 'often feel', 'feel blue', 'blue dislike', 'dislike response', 'response ranged', 'ranged inaccurate', 'inaccurate accurate', 'accurate figure', 'figure show', 'show distribution', 'distribution surveyassessed', 'surveyassessed ddep', 'ddep standardized', 'standardized item', 'item seen', 'seen table', 'table figure', 'figure show', 'show daily', 'daily average', 'average surveyassessed', 'surveyassessed ddep', 'ddep collapsed', 'collapsed across', 'across year', 'year loess', 'loess smoother', 'smoother daily', 'daily average', 'average illustrates', 'illustrates seasonal', 'seasonal trend', 'trend depression', 'depression rising', 'rising winter', 'winter month', 'month dropping', 'dropping summer']","['estimated userlevel degree', 'userlevel degree depression', 'degree depression ddep', 'depression ddep average', 'ddep average response', 'average response seven', 'response seven depression', 'seven depression facet', 'depression facet item', 'facet item nested', 'item nested within', 'nested within larger', 'within larger neuroticism', 'larger neuroticism item', 'neuroticism item pool', 'item pool item', 'pool item user', 'item user indicated', 'user indicated accurately', 'indicated accurately short', 'accurately short phrase', 'short phrase described', 'phrase described eg', 'described eg often', 'eg often feel', 'often feel blue', 'feel blue dislike', 'blue dislike response', 'dislike response ranged', 'response ranged inaccurate', 'ranged inaccurate accurate', 'inaccurate accurate figure', 'accurate figure show', 'figure show distribution', 'show distribution surveyassessed', 'distribution surveyassessed ddep', 'surveyassessed ddep standardized', 'ddep standardized item', 'standardized item seen', 'item seen table', 'seen table figure', 'table figure show', 'figure show daily', 'show daily average', 'daily average surveyassessed', 'average surveyassessed ddep', 'surveyassessed ddep collapsed', 'ddep collapsed across', 'collapsed across year', 'across year loess', 'year loess smoother', 'loess smoother daily', 'smoother daily average', 'daily average illustrates', 'average illustrates seasonal', 'illustrates seasonal trend', 'seasonal trend depression', 'trend depression rising', 'depression rising winter', 'rising winter month', 'winter month dropping', 'month dropping summer']",0.0,0.0,0.0,0.0,0.9865265488624573,0.0,0,0.0
https://ieeexplore.ieee.org/abstract/document/6784326,1,CLINICAL Communities: Communities who are interested in ‘depression’ and with at least 200 posts are extracted from LiveJournal. This is identified through the ‘Search communities by interest’2 provided by LiveJournal and results in 24 communities with 38401 posts. The CLINICAL communities are grouped based on name and description of the individual community: depression bipolar self-harm attachment/separation and suicide (See Table 1 for statistics). The earliest community creation date was in 2001 thus our data set spans over 10 years. b) CONTROL communities: We constructed a CONTROL data set using five popular categories of communities in the LiveJournal Directory.3 We select communities who have at least 200 posts resulting in 23 communities with 229563 posts. This set is called CONTROL and the statistics of these 23 communities and their description are shown in Table 2.,clinical community community who are interested in depression and with at least post are extracted from livejournal this is identified through the search community by interest provided by livejournal and result in community with post the clinical community are grouped based on name and description of the individual community depression bipolar selfharm attachmentseparation and suicide see table for statistic the earliest community creation date wa in thus our data set span over year b control community we constructed a control data set using five popular category of community in the livejournal directory we select community who have at least post resulting in community with post this set is called control and the statistic of these community and their description are shown in table,"['clinical', 'community', 'community', 'interested', 'depression', 'least', 'post', 'extracted', 'livejournal', 'identified', 'search', 'community', 'interest', 'provided', 'livejournal', 'result', 'community', 'post', 'clinical', 'community', 'grouped', 'based', 'name', 'description', 'individual', 'community', 'depression', 'bipolar', 'selfharm', 'attachmentseparation', 'suicide', 'see', 'table', 'statistic', 'earliest', 'community', 'creation', 'date', 'wa', 'thus', 'data', 'set', 'span', 'year', 'b', 'control', 'community', 'constructed', 'control', 'data', 'set', 'using', 'five', 'popular', 'category', 'community', 'livejournal', 'directory', 'select', 'community', 'least', 'post', 'resulting', 'community', 'post', 'set', 'called', 'control', 'statistic', 'community', 'description', 'shown', 'table']","['clinical community', 'community community', 'community interested', 'interested depression', 'depression least', 'least post', 'post extracted', 'extracted livejournal', 'livejournal identified', 'identified search', 'search community', 'community interest', 'interest provided', 'provided livejournal', 'livejournal result', 'result community', 'community post', 'post clinical', 'clinical community', 'community grouped', 'grouped based', 'based name', 'name description', 'description individual', 'individual community', 'community depression', 'depression bipolar', 'bipolar selfharm', 'selfharm attachmentseparation', 'attachmentseparation suicide', 'suicide see', 'see table', 'table statistic', 'statistic earliest', 'earliest community', 'community creation', 'creation date', 'date wa', 'wa thus', 'thus data', 'data set', 'set span', 'span year', 'year b', 'b control', 'control community', 'community constructed', 'constructed control', 'control data', 'data set', 'set using', 'using five', 'five popular', 'popular category', 'category community', 'community livejournal', 'livejournal directory', 'directory select', 'select community', 'community least', 'least post', 'post resulting', 'resulting community', 'community post', 'post set', 'set called', 'called control', 'control statistic', 'statistic community', 'community description', 'description shown', 'shown table']","['clinical community community', 'community community interested', 'community interested depression', 'interested depression least', 'depression least post', 'least post extracted', 'post extracted livejournal', 'extracted livejournal identified', 'livejournal identified search', 'identified search community', 'search community interest', 'community interest provided', 'interest provided livejournal', 'provided livejournal result', 'livejournal result community', 'result community post', 'community post clinical', 'post clinical community', 'clinical community grouped', 'community grouped based', 'grouped based name', 'based name description', 'name description individual', 'description individual community', 'individual community depression', 'community depression bipolar', 'depression bipolar selfharm', 'bipolar selfharm attachmentseparation', 'selfharm attachmentseparation suicide', 'attachmentseparation suicide see', 'suicide see table', 'see table statistic', 'table statistic earliest', 'statistic earliest community', 'earliest community creation', 'community creation date', 'creation date wa', 'date wa thus', 'wa thus data', 'thus data set', 'data set span', 'set span year', 'span year b', 'year b control', 'b control community', 'control community constructed', 'community constructed control', 'constructed control data', 'control data set', 'data set using', 'set using five', 'using five popular', 'five popular category', 'popular category community', 'category community livejournal', 'community livejournal directory', 'livejournal directory select', 'directory select community', 'select community least', 'community least post', 'least post resulting', 'post resulting community', 'resulting community post', 'community post set', 'post set called', 'set called control', 'called control statistic', 'control statistic community', 'statistic community description', 'community description shown', 'description shown table']",0.0,0.9881629943847656,0.0,0.0,0.0,0.0,0,0.0
https://www.jmir.org/2017/7/e243/,1,A Web-based survey of Weibo users was conducted to assess the respondents’ suicide risk and emotional distress (ie depression anxiety and stress). The invitation letter to participate in this survey was widely sent out to general Weibo users by various promotion activities. For a Weibo user to be eligible for the study she or he had to be 18 years or older (by self-report). A 30 Renminbi incentive for each complete survey was provided to boost the respond rate. With the respondents’ consent their Weibo posts that were posted in the public domain during the 12 months before the survey were downloaded by calling Weibo API. The survey fulfilled the Checklist for Reporting Results of Internet E-Surveys (CHERRIES) checklist and details of the procedure have been reported in previous publications [2232]. In addition when multiple survey feedback were submitted from the same Internet protocol addresses only the first submission was used to avoid duplicate participation. In contrast to a previous study [32] this study excluded those who posted nothing throughout the 12 months but not those who posted fewer than 100 posts. Eventually data provided by 974 respondents remained for further analyses. The study has obtained ethical approvals from the Human Research Ethical Review Committee at the University of Hong Kong and the Institute Review Board of the Institute of Psychology at the Chinese Academy of Sciences. The survey measured respondents’ suicide probability score depression anxiety stress and Weibo suicide communication (WSC) as the outcome variables. In addition the respondents’ Weibo posts language features were extracted as independent variables or features for machine learning. The details of how those data were obtained are elaborated in the following subsections.The Chinese version of the SPS was adopted to assess the respondents’ suicide probability. The SPS was originally developed in the United States and then translated and validated in China [3637]. The Cronbach alpha coefficient of the scale in our study was .749.,a webbased survey of weibo user wa conducted to ass the respondent suicide risk and emotional distress ie depression anxiety and stress the invitation letter to participate in this survey wa widely sent out to general weibo user by various promotion activity for a weibo user to be eligible for the study she or he had to be year or older by selfreport a renminbi incentive for each complete survey wa provided to boost the respond rate with the respondent consent their weibo post that were posted in the public domain during the month before the survey were downloaded by calling weibo api the survey fulfilled the checklist for reporting result of internet esurveys cherry checklist and detail of the procedure have been reported in previous publication in addition when multiple survey feedback were submitted from the same internet protocol address only the first submission wa used to avoid duplicate participation in contrast to a previous study this study excluded those who posted nothing throughout the month but not those who posted fewer than post eventually data provided by respondent remained for further analysis the study ha obtained ethical approval from the human research ethical review committee at the university of hong kong and the institute review board of the institute of psychology at the chinese academy of science the survey measured respondent suicide probability score depression anxiety stress and weibo suicide communication wsc a the outcome variable in addition the respondent weibo post language feature were extracted a independent variable or feature for machine learning the detail of how those data were obtained are elaborated in the following subsectionsthe chinese version of the sps wa adopted to ass the respondent suicide probability the sps wa originally developed in the united state and then translated and validated in china the cronbach alpha coefficient of the scale in our study wa,"['webbased', 'survey', 'weibo', 'user', 'wa', 'conducted', 'ass', 'respondent', 'suicide', 'risk', 'emotional', 'distress', 'ie', 'depression', 'anxiety', 'stress', 'invitation', 'letter', 'participate', 'survey', 'wa', 'widely', 'sent', 'general', 'weibo', 'user', 'various', 'promotion', 'activity', 'weibo', 'user', 'eligible', 'study', 'year', 'older', 'selfreport', 'renminbi', 'incentive', 'complete', 'survey', 'wa', 'provided', 'boost', 'respond', 'rate', 'respondent', 'consent', 'weibo', 'post', 'posted', 'public', 'domain', 'month', 'survey', 'downloaded', 'calling', 'weibo', 'api', 'survey', 'fulfilled', 'checklist', 'reporting', 'result', 'internet', 'esurveys', 'cherry', 'checklist', 'detail', 'procedure', 'reported', 'previous', 'publication', 'addition', 'multiple', 'survey', 'feedback', 'submitted', 'internet', 'protocol', 'address', 'first', 'submission', 'wa', 'used', 'avoid', 'duplicate', 'participation', 'contrast', 'previous', 'study', 'study', 'excluded', 'posted', 'nothing', 'throughout', 'month', 'posted', 'fewer', 'post', 'eventually', 'data', 'provided', 'respondent', 'remained', 'analysis', 'study', 'ha', 'obtained', 'ethical', 'approval', 'human', 'research', 'ethical', 'review', 'committee', 'university', 'hong', 'kong', 'institute', 'review', 'board', 'institute', 'psychology', 'chinese', 'academy', 'science', 'survey', 'measured', 'respondent', 'suicide', 'probability', 'score', 'depression', 'anxiety', 'stress', 'weibo', 'suicide', 'communication', 'wsc', 'outcome', 'variable', 'addition', 'respondent', 'weibo', 'post', 'language', 'feature', 'extracted', 'independent', 'variable', 'feature', 'machine', 'learning', 'detail', 'data', 'obtained', 'elaborated', 'following', 'subsectionsthe', 'chinese', 'version', 'sps', 'wa', 'adopted', 'ass', 'respondent', 'suicide', 'probability', 'sps', 'wa', 'originally', 'developed', 'united', 'state', 'translated', 'validated', 'china', 'cronbach', 'alpha', 'coefficient', 'scale', 'study', 'wa']","['webbased survey', 'survey weibo', 'weibo user', 'user wa', 'wa conducted', 'conducted ass', 'ass respondent', 'respondent suicide', 'suicide risk', 'risk emotional', 'emotional distress', 'distress ie', 'ie depression', 'depression anxiety', 'anxiety stress', 'stress invitation', 'invitation letter', 'letter participate', 'participate survey', 'survey wa', 'wa widely', 'widely sent', 'sent general', 'general weibo', 'weibo user', 'user various', 'various promotion', 'promotion activity', 'activity weibo', 'weibo user', 'user eligible', 'eligible study', 'study year', 'year older', 'older selfreport', 'selfreport renminbi', 'renminbi incentive', 'incentive complete', 'complete survey', 'survey wa', 'wa provided', 'provided boost', 'boost respond', 'respond rate', 'rate respondent', 'respondent consent', 'consent weibo', 'weibo post', 'post posted', 'posted public', 'public domain', 'domain month', 'month survey', 'survey downloaded', 'downloaded calling', 'calling weibo', 'weibo api', 'api survey', 'survey fulfilled', 'fulfilled checklist', 'checklist reporting', 'reporting result', 'result internet', 'internet esurveys', 'esurveys cherry', 'cherry checklist', 'checklist detail', 'detail procedure', 'procedure reported', 'reported previous', 'previous publication', 'publication addition', 'addition multiple', 'multiple survey', 'survey feedback', 'feedback submitted', 'submitted internet', 'internet protocol', 'protocol address', 'address first', 'first submission', 'submission wa', 'wa used', 'used avoid', 'avoid duplicate', 'duplicate participation', 'participation contrast', 'contrast previous', 'previous study', 'study study', 'study excluded', 'excluded posted', 'posted nothing', 'nothing throughout', 'throughout month', 'month posted', 'posted fewer', 'fewer post', 'post eventually', 'eventually data', 'data provided', 'provided respondent', 'respondent remained', 'remained analysis', 'analysis study', 'study ha', 'ha obtained', 'obtained ethical', 'ethical approval', 'approval human', 'human research', 'research ethical', 'ethical review', 'review committee', 'committee university', 'university hong', 'hong kong', 'kong institute', 'institute review', 'review board', 'board institute', 'institute psychology', 'psychology chinese', 'chinese academy', 'academy science', 'science survey', 'survey measured', 'measured respondent', 'respondent suicide', 'suicide probability', 'probability score', 'score depression', 'depression anxiety', 'anxiety stress', 'stress weibo', 'weibo suicide', 'suicide communication', 'communication wsc', 'wsc outcome', 'outcome variable', 'variable addition', 'addition respondent', 'respondent weibo', 'weibo post', 'post language', 'language feature', 'feature extracted', 'extracted independent', 'independent variable', 'variable feature', 'feature machine', 'machine learning', 'learning detail', 'detail data', 'data obtained', 'obtained elaborated', 'elaborated following', 'following subsectionsthe', 'subsectionsthe chinese', 'chinese version', 'version sps', 'sps wa', 'wa adopted', 'adopted ass', 'ass respondent', 'respondent suicide', 'suicide probability', 'probability sps', 'sps wa', 'wa originally', 'originally developed', 'developed united', 'united state', 'state translated', 'translated validated', 'validated china', 'china cronbach', 'cronbach alpha', 'alpha coefficient', 'coefficient scale', 'scale study', 'study wa']","['webbased survey weibo', 'survey weibo user', 'weibo user wa', 'user wa conducted', 'wa conducted ass', 'conducted ass respondent', 'ass respondent suicide', 'respondent suicide risk', 'suicide risk emotional', 'risk emotional distress', 'emotional distress ie', 'distress ie depression', 'ie depression anxiety', 'depression anxiety stress', 'anxiety stress invitation', 'stress invitation letter', 'invitation letter participate', 'letter participate survey', 'participate survey wa', 'survey wa widely', 'wa widely sent', 'widely sent general', 'sent general weibo', 'general weibo user', 'weibo user various', 'user various promotion', 'various promotion activity', 'promotion activity weibo', 'activity weibo user', 'weibo user eligible', 'user eligible study', 'eligible study year', 'study year older', 'year older selfreport', 'older selfreport renminbi', 'selfreport renminbi incentive', 'renminbi incentive complete', 'incentive complete survey', 'complete survey wa', 'survey wa provided', 'wa provided boost', 'provided boost respond', 'boost respond rate', 'respond rate respondent', 'rate respondent consent', 'respondent consent weibo', 'consent weibo post', 'weibo post posted', 'post posted public', 'posted public domain', 'public domain month', 'domain month survey', 'month survey downloaded', 'survey downloaded calling', 'downloaded calling weibo', 'calling weibo api', 'weibo api survey', 'api survey fulfilled', 'survey fulfilled checklist', 'fulfilled checklist reporting', 'checklist reporting result', 'reporting result internet', 'result internet esurveys', 'internet esurveys cherry', 'esurveys cherry checklist', 'cherry checklist detail', 'checklist detail procedure', 'detail procedure reported', 'procedure reported previous', 'reported previous publication', 'previous publication addition', 'publication addition multiple', 'addition multiple survey', 'multiple survey feedback', 'survey feedback submitted', 'feedback submitted internet', 'submitted internet protocol', 'internet protocol address', 'protocol address first', 'address first submission', 'first submission wa', 'submission wa used', 'wa used avoid', 'used avoid duplicate', 'avoid duplicate participation', 'duplicate participation contrast', 'participation contrast previous', 'contrast previous study', 'previous study study', 'study study excluded', 'study excluded posted', 'excluded posted nothing', 'posted nothing throughout', 'nothing throughout month', 'throughout month posted', 'month posted fewer', 'posted fewer post', 'fewer post eventually', 'post eventually data', 'eventually data provided', 'data provided respondent', 'provided respondent remained', 'respondent remained analysis', 'remained analysis study', 'analysis study ha', 'study ha obtained', 'ha obtained ethical', 'obtained ethical approval', 'ethical approval human', 'approval human research', 'human research ethical', 'research ethical review', 'ethical review committee', 'review committee university', 'committee university hong', 'university hong kong', 'hong kong institute', 'kong institute review', 'institute review board', 'review board institute', 'board institute psychology', 'institute psychology chinese', 'psychology chinese academy', 'chinese academy science', 'academy science survey', 'science survey measured', 'survey measured respondent', 'measured respondent suicide', 'respondent suicide probability', 'suicide probability score', 'probability score depression', 'score depression anxiety', 'depression anxiety stress', 'anxiety stress weibo', 'stress weibo suicide', 'weibo suicide communication', 'suicide communication wsc', 'communication wsc outcome', 'wsc outcome variable', 'outcome variable addition', 'variable addition respondent', 'addition respondent weibo', 'respondent weibo post', 'weibo post language', 'post language feature', 'language feature extracted', 'feature extracted independent', 'extracted independent variable', 'independent variable feature', 'variable feature machine', 'feature machine learning', 'machine learning detail', 'learning detail data', 'detail data obtained', 'data obtained elaborated', 'obtained elaborated following', 'elaborated following subsectionsthe', 'following subsectionsthe chinese', 'subsectionsthe chinese version', 'chinese version sps', 'version sps wa', 'sps wa adopted', 'wa adopted ass', 'adopted ass respondent', 'ass respondent suicide', 'respondent suicide probability', 'suicide probability sps', 'probability sps wa', 'sps wa originally', 'wa originally developed', 'originally developed united', 'developed united state', 'united state translated', 'state translated validated', 'translated validated china', 'validated china cronbach', 'china cronbach alpha', 'cronbach alpha coefficient', 'alpha coefficient scale', 'coefficient scale study', 'scale study wa']",0.0,0.0,0.0,0.9952409863471985,0.0,0.0,0,0.0
https://dl.acm.org/doi/abs/10.1145/3025453.3025909,1,We first obtained a list of 150 ranked major universities in the United States by crawling the US News and World Report website [48]. This list is constructed based on the Carnegie classification employed extensively by higher education researchers and using a set of 16 indicators of academic excellence defined by US News. The list includes a variety of universities spread across the US in different settings (e.g. urban rural) and with a wide range of student enrollment sizes. Figure 1(a) shows their geographic distribution. As a part of this crawl we also obtained university metadata: gender distribution of students average tuition and fees and academic calendar (semester/quarter). To obtain further information about the nature of the student body we crawled the Wikipedia pages of all of the 150 universities. From these pages we extracted the size of student enrollment type (public/private) and setting (rural/suburban/urban/city) at every institution. These definitions come from a formal categorization scheme used by the US Department of Education. The student body enrollment sizes ranged from 2255 to 97494 with 98 public and 52 private universities. 50 universities were reported to be urban 47 city 39 suburban and 13 rural. Finally we obtained information on racial diversity of the universities from a website known as Priceonomics [58]. The website calculates the Herfindahl-Hirschman Index (HHI) by combining the race/ethnicity distribution of student bodies at different universities with data given from the Department of Education. HHI ranges from 1 (the least diverse: a population of all one type) to 1/N (the most diverse) where N is the number of different racial categories being analyzed. Social Media Data of Universities Next we obtained social media data of the above universities. Specifically we focused on the social media Reddit. Why Reddit? Reddit is known to be a widely used online forum and social media site among the college student demographic [23]. Due to its forum structure it is extensively used for both content sharing as well as for obtaining feedback and information from communities of interest. Reddit harbors a variety of communities known as “subreddits” including many dedicated to specific university campuses. This allows a large sample of posts shared by students of a university to be collected in one place. Our preliminary manual inspection of university subreddits (e.g. r/gatech or r/KState) revealed that these subreddits are appropriated by students to discuss college topics (Table 1). Focusing on these public Reddit communities also does not require explicit data collection efforts to be coordinated at each of the 150 university sites. Although more students are likely to use Facebook due to its largely privately shared content it is challenging to obtain access to a large dataset of a university’s students. Next while Twitter is also widely adopted without explicit self-reported information it is challenging to identify college student accounts. Finally prior work [2 18] notes that semianonymity of Reddit enables candid self disclosure around stigmatized topics like mental health. Initial Data Acquisition. We leveraged the archive of all of Reddit data made available on Google’s BigQuery [11]. BigQuery is a cloud based managed data warehouse that allows third parties to access large publicly available dataset through simple SQL-type queries. Our queries grabbed all posts ranging between June 2011 and February 2016 available in the Reddit data archive. This included 424984 posts from 153378 unique users across all of the 146 universities with a mean of 2910.8 posts ( = 4329.6) and 1050 unique users ( = 1407) per subreddit. Filling the Gaps in Subreddit Data. The second step of our data collection process focused on identifying subreddits with insufficient data and supplementing them through additional alternative data collection. Through Reddit’s official API (https://www.reddit.com/dev/api/) we obtained the most recent number of subscribers in the 146 university subreddits (as of July 2016). Then to investigate if and to what extent some subreddits may have had unusually low data as given in step 1 we determined the median unique user to subscriber ratio in each subreddit. This allows us to capture the subreddits where the subscriber count is high however the data obtained is not sufficiently representative. For subreddits with unique user to subscriber ratio under median (.42) (73 in all) we performed a one-time data collection using the Reddit API. This gave us a set of (at most) 1000 most recent posts for each subreddit with a total of 39824 posts added to the data obtained in step 1 following de-duplication. We note that this procedure did not skew the yearly distributions of data across the subreddits: The skew (yearly rate of change) before and after data filling were 4.86 and 5.05 respectively which were found to be statistically equivalent based on a two-sample equivalence test (p = .013 p = .025) a test that uses two one-sided t-tests on the before-after yearly rates of change from both sides of a chosen difference interval [1 1].We now present a methodology of identifying posts shared in university subreddits that that are likely to be mental health expressions. Note that our Reddit data does not contain any gold standard information around whether a post shared in a university subreddit is about one’s mental health experience or condition. Our proposed method overcomes this challenge by employing an inductive transfer learning approach [16]. First we include (as ground truth data) Reddit posts made on various mental health support communities. Prior work has established that in these communities individuals selfdisclose a variety of mental health challenges explicitly [50]. Parallelly we utilize another set of Reddit posts made on generic subreddits unrelated to mental health to be a control. Next we build a machine learning classifier to distinguish between these two types of posts. Then we learn features that could detect whether an post shared in a university subreddit could be an expression of some mental health concern. We discuss these steps in detail in the following subsections.,we first obtained a list of ranked major university in the united state by crawling the u news and world report website this list is constructed based on the carnegie classification employed extensively by higher education researcher and using a set of indicator of academic excellence defined by u news the list includes a variety of university spread across the u in different setting eg urban rural and with a wide range of student enrollment size figure a show their geographic distribution a a part of this crawl we also obtained university metadata gender distribution of student average tuition and fee and academic calendar semesterquarter to obtain further information about the nature of the student body we crawled the wikipedia page of all of the university from these page we extracted the size of student enrollment type publicprivate and setting ruralsuburbanurbancity at every institution these definition come from a formal categorization scheme used by the u department of education the student body enrollment size ranged from to with public and private university university were reported to be urban city suburban and rural finally we obtained information on racial diversity of the university from a website known a priceonomics the website calculates the herfindahlhirschman index hhi by combining the raceethnicity distribution of student body at different university with data given from the department of education hhi range from the least diverse a population of all one type to n the most diverse where n is the number of different racial category being analyzed social medium data of university next we obtained social medium data of the above university specifically we focused on the social medium reddit why reddit reddit is known to be a widely used online forum and social medium site among the college student demographic due to it forum structure it is extensively used for both content sharing a well a for obtaining feedback and information from community of interest reddit harbor a variety of community known a subreddits including many dedicated to specific university campus this allows a large sample of post shared by student of a university to be collected in one place our preliminary manual inspection of university subreddits eg rgatech or rkstate revealed that these subreddits are appropriated by student to discus college topic table focusing on these public reddit community also doe not require explicit data collection effort to be coordinated at each of the university site although more student are likely to use facebook due to it largely privately shared content it is challenging to obtain access to a large dataset of a university student next while twitter is also widely adopted without explicit selfreported information it is challenging to identify college student account finally prior work note that semianonymity of reddit enables candid self disclosure around stigmatized topic like mental health initial data acquisition we leveraged the archive of all of reddit data made available on google bigquery bigquery is a cloud based managed data warehouse that allows third party to access large publicly available dataset through simple sqltype query our query grabbed all post ranging between june and february available in the reddit data archive this included post from unique user across all of the university with a mean of post and unique user per subreddit filling the gap in subreddit data the second step of our data collection process focused on identifying subreddits with insufficient data and supplementing them through additional alternative data collection through reddits official api httpswwwredditcomdevapi we obtained the most recent number of subscriber in the university subreddits a of july then to investigate if and to what extent some subreddits may have had unusually low data a given in step we determined the median unique user to subscriber ratio in each subreddit this allows u to capture the subreddits where the subscriber count is high however the data obtained is not sufficiently representative for subreddits with unique user to subscriber ratio under median in all we performed a onetime data collection using the reddit api this gave u a set of at most most recent post for each subreddit with a total of post added to the data obtained in step following deduplication we note that this procedure did not skew the yearly distribution of data across the subreddits the skew yearly rate of change before and after data filling were and respectively which were found to be statistically equivalent based on a twosample equivalence test p p a test that us two onesided ttests on the beforeafter yearly rate of change from both side of a chosen difference interval we now present a methodology of identifying post shared in university subreddits that that are likely to be mental health expression note that our reddit data doe not contain any gold standard information around whether a post shared in a university subreddit is about one mental health experience or condition our proposed method overcomes this challenge by employing an inductive transfer learning approach first we include a ground truth data reddit post made on various mental health support community prior work ha established that in these community individual selfdisclose a variety of mental health challenge explicitly parallelly we utilize another set of reddit post made on generic subreddits unrelated to mental health to be a control next we build a machine learning classifier to distinguish between these two type of post then we learn feature that could detect whether an post shared in a university subreddit could be an expression of some mental health concern we discus these step in detail in the following subsection,"['first', 'obtained', 'list', 'ranked', 'major', 'university', 'united', 'state', 'crawling', 'u', 'news', 'world', 'report', 'website', 'list', 'constructed', 'based', 'carnegie', 'classification', 'employed', 'extensively', 'higher', 'education', 'researcher', 'using', 'set', 'indicator', 'academic', 'excellence', 'defined', 'u', 'news', 'list', 'includes', 'variety', 'university', 'spread', 'across', 'u', 'different', 'setting', 'eg', 'urban', 'rural', 'wide', 'range', 'student', 'enrollment', 'size', 'figure', 'show', 'geographic', 'distribution', 'part', 'crawl', 'also', 'obtained', 'university', 'metadata', 'gender', 'distribution', 'student', 'average', 'tuition', 'fee', 'academic', 'calendar', 'semesterquarter', 'obtain', 'information', 'nature', 'student', 'body', 'crawled', 'wikipedia', 'page', 'university', 'page', 'extracted', 'size', 'student', 'enrollment', 'type', 'publicprivate', 'setting', 'ruralsuburbanurbancity', 'every', 'institution', 'definition', 'come', 'formal', 'categorization', 'scheme', 'used', 'u', 'department', 'education', 'student', 'body', 'enrollment', 'size', 'ranged', 'public', 'private', 'university', 'university', 'reported', 'urban', 'city', 'suburban', 'rural', 'finally', 'obtained', 'information', 'racial', 'diversity', 'university', 'website', 'known', 'priceonomics', 'website', 'calculates', 'herfindahlhirschman', 'index', 'hhi', 'combining', 'raceethnicity', 'distribution', 'student', 'body', 'different', 'university', 'data', 'given', 'department', 'education', 'hhi', 'range', 'least', 'diverse', 'population', 'one', 'type', 'n', 'diverse', 'n', 'number', 'different', 'racial', 'category', 'analyzed', 'social', 'medium', 'data', 'university', 'next', 'obtained', 'social', 'medium', 'data', 'university', 'specifically', 'focused', 'social', 'medium', 'reddit', 'reddit', 'reddit', 'known', 'widely', 'used', 'online', 'forum', 'social', 'medium', 'site', 'among', 'college', 'student', 'demographic', 'due', 'forum', 'structure', 'extensively', 'used', 'content', 'sharing', 'well', 'obtaining', 'feedback', 'information', 'community', 'interest', 'reddit', 'harbor', 'variety', 'community', 'known', 'subreddits', 'including', 'many', 'dedicated', 'specific', 'university', 'campus', 'allows', 'large', 'sample', 'post', 'shared', 'student', 'university', 'collected', 'one', 'place', 'preliminary', 'manual', 'inspection', 'university', 'subreddits', 'eg', 'rgatech', 'rkstate', 'revealed', 'subreddits', 'appropriated', 'student', 'discus', 'college', 'topic', 'table', 'focusing', 'public', 'reddit', 'community', 'also', 'doe', 'require', 'explicit', 'data', 'collection', 'effort', 'coordinated', 'university', 'site', 'although', 'student', 'likely', 'use', 'facebook', 'due', 'largely', 'privately', 'shared', 'content', 'challenging', 'obtain', 'access', 'large', 'dataset', 'university', 'student', 'next', 'twitter', 'also', 'widely', 'adopted', 'without', 'explicit', 'selfreported', 'information', 'challenging', 'identify', 'college', 'student', 'account', 'finally', 'prior', 'work', 'note', 'semianonymity', 'reddit', 'enables', 'candid', 'self', 'disclosure', 'around', 'stigmatized', 'topic', 'like', 'mental', 'health', 'initial', 'data', 'acquisition', 'leveraged', 'archive', 'reddit', 'data', 'made', 'available', 'google', 'bigquery', 'bigquery', 'cloud', 'based', 'managed', 'data', 'warehouse', 'allows', 'third', 'party', 'access', 'large', 'publicly', 'available', 'dataset', 'simple', 'sqltype', 'query', 'query', 'grabbed', 'post', 'ranging', 'june', 'february', 'available', 'reddit', 'data', 'archive', 'included', 'post', 'unique', 'user', 'across', 'university', 'mean', 'post', 'unique', 'user', 'per', 'subreddit', 'filling', 'gap', 'subreddit', 'data', 'second', 'step', 'data', 'collection', 'process', 'focused', 'identifying', 'subreddits', 'insufficient', 'data', 'supplementing', 'additional', 'alternative', 'data', 'collection', 'reddits', 'official', 'api', 'httpswwwredditcomdevapi', 'obtained', 'recent', 'number', 'subscriber', 'university', 'subreddits', 'july', 'investigate', 'extent', 'subreddits', 'may', 'unusually', 'low', 'data', 'given', 'step', 'determined', 'median', 'unique', 'user', 'subscriber', 'ratio', 'subreddit', 'allows', 'u', 'capture', 'subreddits', 'subscriber', 'count', 'high', 'however', 'data', 'obtained', 'sufficiently', 'representative', 'subreddits', 'unique', 'user', 'subscriber', 'ratio', 'median', 'performed', 'onetime', 'data', 'collection', 'using', 'reddit', 'api', 'gave', 'u', 'set', 'recent', 'post', 'subreddit', 'total', 'post', 'added', 'data', 'obtained', 'step', 'following', 'deduplication', 'note', 'procedure', 'skew', 'yearly', 'distribution', 'data', 'across', 'subreddits', 'skew', 'yearly', 'rate', 'change', 'data', 'filling', 'respectively', 'found', 'statistically', 'equivalent', 'based', 'twosample', 'equivalence', 'test', 'p', 'p', 'test', 'us', 'two', 'onesided', 'ttests', 'beforeafter', 'yearly', 'rate', 'change', 'side', 'chosen', 'difference', 'interval', 'present', 'methodology', 'identifying', 'post', 'shared', 'university', 'subreddits', 'likely', 'mental', 'health', 'expression', 'note', 'reddit', 'data', 'doe', 'contain', 'gold', 'standard', 'information', 'around', 'whether', 'post', 'shared', 'university', 'subreddit', 'one', 'mental', 'health', 'experience', 'condition', 'proposed', 'method', 'overcomes', 'challenge', 'employing', 'inductive', 'transfer', 'learning', 'approach', 'first', 'include', 'ground', 'truth', 'data', 'reddit', 'post', 'made', 'various', 'mental', 'health', 'support', 'community', 'prior', 'work', 'ha', 'established', 'community', 'individual', 'selfdisclose', 'variety', 'mental', 'health', 'challenge', 'explicitly', 'parallelly', 'utilize', 'another', 'set', 'reddit', 'post', 'made', 'generic', 'subreddits', 'unrelated', 'mental', 'health', 'control', 'next', 'build', 'machine', 'learning', 'classifier', 'distinguish', 'two', 'type', 'post', 'learn', 'feature', 'could', 'detect', 'whether', 'post', 'shared', 'university', 'subreddit', 'could', 'expression', 'mental', 'health', 'concern', 'discus', 'step', 'detail', 'following', 'subsection']","['first obtained', 'obtained list', 'list ranked', 'ranked major', 'major university', 'university united', 'united state', 'state crawling', 'crawling u', 'u news', 'news world', 'world report', 'report website', 'website list', 'list constructed', 'constructed based', 'based carnegie', 'carnegie classification', 'classification employed', 'employed extensively', 'extensively higher', 'higher education', 'education researcher', 'researcher using', 'using set', 'set indicator', 'indicator academic', 'academic excellence', 'excellence defined', 'defined u', 'u news', 'news list', 'list includes', 'includes variety', 'variety university', 'university spread', 'spread across', 'across u', 'u different', 'different setting', 'setting eg', 'eg urban', 'urban rural', 'rural wide', 'wide range', 'range student', 'student enrollment', 'enrollment size', 'size figure', 'figure show', 'show geographic', 'geographic distribution', 'distribution part', 'part crawl', 'crawl also', 'also obtained', 'obtained university', 'university metadata', 'metadata gender', 'gender distribution', 'distribution student', 'student average', 'average tuition', 'tuition fee', 'fee academic', 'academic calendar', 'calendar semesterquarter', 'semesterquarter obtain', 'obtain information', 'information nature', 'nature student', 'student body', 'body crawled', 'crawled wikipedia', 'wikipedia page', 'page university', 'university page', 'page extracted', 'extracted size', 'size student', 'student enrollment', 'enrollment type', 'type publicprivate', 'publicprivate setting', 'setting ruralsuburbanurbancity', 'ruralsuburbanurbancity every', 'every institution', 'institution definition', 'definition come', 'come formal', 'formal categorization', 'categorization scheme', 'scheme used', 'used u', 'u department', 'department education', 'education student', 'student body', 'body enrollment', 'enrollment size', 'size ranged', 'ranged public', 'public private', 'private university', 'university university', 'university reported', 'reported urban', 'urban city', 'city suburban', 'suburban rural', 'rural finally', 'finally obtained', 'obtained information', 'information racial', 'racial diversity', 'diversity university', 'university website', 'website known', 'known priceonomics', 'priceonomics website', 'website calculates', 'calculates herfindahlhirschman', 'herfindahlhirschman index', 'index hhi', 'hhi combining', 'combining raceethnicity', 'raceethnicity distribution', 'distribution student', 'student body', 'body different', 'different university', 'university data', 'data given', 'given department', 'department education', 'education hhi', 'hhi range', 'range least', 'least diverse', 'diverse population', 'population one', 'one type', 'type n', 'n diverse', 'diverse n', 'n number', 'number different', 'different racial', 'racial category', 'category analyzed', 'analyzed social', 'social medium', 'medium data', 'data university', 'university next', 'next obtained', 'obtained social', 'social medium', 'medium data', 'data university', 'university specifically', 'specifically focused', 'focused social', 'social medium', 'medium reddit', 'reddit reddit', 'reddit reddit', 'reddit known', 'known widely', 'widely used', 'used online', 'online forum', 'forum social', 'social medium', 'medium site', 'site among', 'among college', 'college student', 'student demographic', 'demographic due', 'due forum', 'forum structure', 'structure extensively', 'extensively used', 'used content', 'content sharing', 'sharing well', 'well obtaining', 'obtaining feedback', 'feedback information', 'information community', 'community interest', 'interest reddit', 'reddit harbor', 'harbor variety', 'variety community', 'community known', 'known subreddits', 'subreddits including', 'including many', 'many dedicated', 'dedicated specific', 'specific university', 'university campus', 'campus allows', 'allows large', 'large sample', 'sample post', 'post shared', 'shared student', 'student university', 'university collected', 'collected one', 'one place', 'place preliminary', 'preliminary manual', 'manual inspection', 'inspection university', 'university subreddits', 'subreddits eg', 'eg rgatech', 'rgatech rkstate', 'rkstate revealed', 'revealed subreddits', 'subreddits appropriated', 'appropriated student', 'student discus', 'discus college', 'college topic', 'topic table', 'table focusing', 'focusing public', 'public reddit', 'reddit community', 'community also', 'also doe', 'doe require', 'require explicit', 'explicit data', 'data collection', 'collection effort', 'effort coordinated', 'coordinated university', 'university site', 'site although', 'although student', 'student likely', 'likely use', 'use facebook', 'facebook due', 'due largely', 'largely privately', 'privately shared', 'shared content', 'content challenging', 'challenging obtain', 'obtain access', 'access large', 'large dataset', 'dataset university', 'university student', 'student next', 'next twitter', 'twitter also', 'also widely', 'widely adopted', 'adopted without', 'without explicit', 'explicit selfreported', 'selfreported information', 'information challenging', 'challenging identify', 'identify college', 'college student', 'student account', 'account finally', 'finally prior', 'prior work', 'work note', 'note semianonymity', 'semianonymity reddit', 'reddit enables', 'enables candid', 'candid self', 'self disclosure', 'disclosure around', 'around stigmatized', 'stigmatized topic', 'topic like', 'like mental', 'mental health', 'health initial', 'initial data', 'data acquisition', 'acquisition leveraged', 'leveraged archive', 'archive reddit', 'reddit data', 'data made', 'made available', 'available google', 'google bigquery', 'bigquery bigquery', 'bigquery cloud', 'cloud based', 'based managed', 'managed data', 'data warehouse', 'warehouse allows', 'allows third', 'third party', 'party access', 'access large', 'large publicly', 'publicly available', 'available dataset', 'dataset simple', 'simple sqltype', 'sqltype query', 'query query', 'query grabbed', 'grabbed post', 'post ranging', 'ranging june', 'june february', 'february available', 'available reddit', 'reddit data', 'data archive', 'archive included', 'included post', 'post unique', 'unique user', 'user across', 'across university', 'university mean', 'mean post', 'post unique', 'unique user', 'user per', 'per subreddit', 'subreddit filling', 'filling gap', 'gap subreddit', 'subreddit data', 'data second', 'second step', 'step data', 'data collection', 'collection process', 'process focused', 'focused identifying', 'identifying subreddits', 'subreddits insufficient', 'insufficient data', 'data supplementing', 'supplementing additional', 'additional alternative', 'alternative data', 'data collection', 'collection reddits', 'reddits official', 'official api', 'api httpswwwredditcomdevapi', 'httpswwwredditcomdevapi obtained', 'obtained recent', 'recent number', 'number subscriber', 'subscriber university', 'university subreddits', 'subreddits july', 'july investigate', 'investigate extent', 'extent subreddits', 'subreddits may', 'may unusually', 'unusually low', 'low data', 'data given', 'given step', 'step determined', 'determined median', 'median unique', 'unique user', 'user subscriber', 'subscriber ratio', 'ratio subreddit', 'subreddit allows', 'allows u', 'u capture', 'capture subreddits', 'subreddits subscriber', 'subscriber count', 'count high', 'high however', 'however data', 'data obtained', 'obtained sufficiently', 'sufficiently representative', 'representative subreddits', 'subreddits unique', 'unique user', 'user subscriber', 'subscriber ratio', 'ratio median', 'median performed', 'performed onetime', 'onetime data', 'data collection', 'collection using', 'using reddit', 'reddit api', 'api gave', 'gave u', 'u set', 'set recent', 'recent post', 'post subreddit', 'subreddit total', 'total post', 'post added', 'added data', 'data obtained', 'obtained step', 'step following', 'following deduplication', 'deduplication note', 'note procedure', 'procedure skew', 'skew yearly', 'yearly distribution', 'distribution data', 'data across', 'across subreddits', 'subreddits skew', 'skew yearly', 'yearly rate', 'rate change', 'change data', 'data filling', 'filling respectively', 'respectively found', 'found statistically', 'statistically equivalent', 'equivalent based', 'based twosample', 'twosample equivalence', 'equivalence test', 'test p', 'p p', 'p test', 'test us', 'us two', 'two onesided', 'onesided ttests', 'ttests beforeafter', 'beforeafter yearly', 'yearly rate', 'rate change', 'change side', 'side chosen', 'chosen difference', 'difference interval', 'interval present', 'present methodology', 'methodology identifying', 'identifying post', 'post shared', 'shared university', 'university subreddits', 'subreddits likely', 'likely mental', 'mental health', 'health expression', 'expression note', 'note reddit', 'reddit data', 'data doe', 'doe contain', 'contain gold', 'gold standard', 'standard information', 'information around', 'around whether', 'whether post', 'post shared', 'shared university', 'university subreddit', 'subreddit one', 'one mental', 'mental health', 'health experience', 'experience condition', 'condition proposed', 'proposed method', 'method overcomes', 'overcomes challenge', 'challenge employing', 'employing inductive', 'inductive transfer', 'transfer learning', 'learning approach', 'approach first', 'first include', 'include ground', 'ground truth', 'truth data', 'data reddit', 'reddit post', 'post made', 'made various', 'various mental', 'mental health', 'health support', 'support community', 'community prior', 'prior work', 'work ha', 'ha established', 'established community', 'community individual', 'individual selfdisclose', 'selfdisclose variety', 'variety mental', 'mental health', 'health challenge', 'challenge explicitly', 'explicitly parallelly', 'parallelly utilize', 'utilize another', 'another set', 'set reddit', 'reddit post', 'post made', 'made generic', 'generic subreddits', 'subreddits unrelated', 'unrelated mental', 'mental health', 'health control', 'control next', 'next build', 'build machine', 'machine learning', 'learning classifier', 'classifier distinguish', 'distinguish two', 'two type', 'type post', 'post learn', 'learn feature', 'feature could', 'could detect', 'detect whether', 'whether post', 'post shared', 'shared university', 'university subreddit', 'subreddit could', 'could expression', 'expression mental', 'mental health', 'health concern', 'concern discus', 'discus step', 'step detail', 'detail following', 'following subsection']","['first obtained list', 'obtained list ranked', 'list ranked major', 'ranked major university', 'major university united', 'university united state', 'united state crawling', 'state crawling u', 'crawling u news', 'u news world', 'news world report', 'world report website', 'report website list', 'website list constructed', 'list constructed based', 'constructed based carnegie', 'based carnegie classification', 'carnegie classification employed', 'classification employed extensively', 'employed extensively higher', 'extensively higher education', 'higher education researcher', 'education researcher using', 'researcher using set', 'using set indicator', 'set indicator academic', 'indicator academic excellence', 'academic excellence defined', 'excellence defined u', 'defined u news', 'u news list', 'news list includes', 'list includes variety', 'includes variety university', 'variety university spread', 'university spread across', 'spread across u', 'across u different', 'u different setting', 'different setting eg', 'setting eg urban', 'eg urban rural', 'urban rural wide', 'rural wide range', 'wide range student', 'range student enrollment', 'student enrollment size', 'enrollment size figure', 'size figure show', 'figure show geographic', 'show geographic distribution', 'geographic distribution part', 'distribution part crawl', 'part crawl also', 'crawl also obtained', 'also obtained university', 'obtained university metadata', 'university metadata gender', 'metadata gender distribution', 'gender distribution student', 'distribution student average', 'student average tuition', 'average tuition fee', 'tuition fee academic', 'fee academic calendar', 'academic calendar semesterquarter', 'calendar semesterquarter obtain', 'semesterquarter obtain information', 'obtain information nature', 'information nature student', 'nature student body', 'student body crawled', 'body crawled wikipedia', 'crawled wikipedia page', 'wikipedia page university', 'page university page', 'university page extracted', 'page extracted size', 'extracted size student', 'size student enrollment', 'student enrollment type', 'enrollment type publicprivate', 'type publicprivate setting', 'publicprivate setting ruralsuburbanurbancity', 'setting ruralsuburbanurbancity every', 'ruralsuburbanurbancity every institution', 'every institution definition', 'institution definition come', 'definition come formal', 'come formal categorization', 'formal categorization scheme', 'categorization scheme used', 'scheme used u', 'used u department', 'u department education', 'department education student', 'education student body', 'student body enrollment', 'body enrollment size', 'enrollment size ranged', 'size ranged public', 'ranged public private', 'public private university', 'private university university', 'university university reported', 'university reported urban', 'reported urban city', 'urban city suburban', 'city suburban rural', 'suburban rural finally', 'rural finally obtained', 'finally obtained information', 'obtained information racial', 'information racial diversity', 'racial diversity university', 'diversity university website', 'university website known', 'website known priceonomics', 'known priceonomics website', 'priceonomics website calculates', 'website calculates herfindahlhirschman', 'calculates herfindahlhirschman index', 'herfindahlhirschman index hhi', 'index hhi combining', 'hhi combining raceethnicity', 'combining raceethnicity distribution', 'raceethnicity distribution student', 'distribution student body', 'student body different', 'body different university', 'different university data', 'university data given', 'data given department', 'given department education', 'department education hhi', 'education hhi range', 'hhi range least', 'range least diverse', 'least diverse population', 'diverse population one', 'population one type', 'one type n', 'type n diverse', 'n diverse n', 'diverse n number', 'n number different', 'number different racial', 'different racial category', 'racial category analyzed', 'category analyzed social', 'analyzed social medium', 'social medium data', 'medium data university', 'data university next', 'university next obtained', 'next obtained social', 'obtained social medium', 'social medium data', 'medium data university', 'data university specifically', 'university specifically focused', 'specifically focused social', 'focused social medium', 'social medium reddit', 'medium reddit reddit', 'reddit reddit reddit', 'reddit reddit known', 'reddit known widely', 'known widely used', 'widely used online', 'used online forum', 'online forum social', 'forum social medium', 'social medium site', 'medium site among', 'site among college', 'among college student', 'college student demographic', 'student demographic due', 'demographic due forum', 'due forum structure', 'forum structure extensively', 'structure extensively used', 'extensively used content', 'used content sharing', 'content sharing well', 'sharing well obtaining', 'well obtaining feedback', 'obtaining feedback information', 'feedback information community', 'information community interest', 'community interest reddit', 'interest reddit harbor', 'reddit harbor variety', 'harbor variety community', 'variety community known', 'community known subreddits', 'known subreddits including', 'subreddits including many', 'including many dedicated', 'many dedicated specific', 'dedicated specific university', 'specific university campus', 'university campus allows', 'campus allows large', 'allows large sample', 'large sample post', 'sample post shared', 'post shared student', 'shared student university', 'student university collected', 'university collected one', 'collected one place', 'one place preliminary', 'place preliminary manual', 'preliminary manual inspection', 'manual inspection university', 'inspection university subreddits', 'university subreddits eg', 'subreddits eg rgatech', 'eg rgatech rkstate', 'rgatech rkstate revealed', 'rkstate revealed subreddits', 'revealed subreddits appropriated', 'subreddits appropriated student', 'appropriated student discus', 'student discus college', 'discus college topic', 'college topic table', 'topic table focusing', 'table focusing public', 'focusing public reddit', 'public reddit community', 'reddit community also', 'community also doe', 'also doe require', 'doe require explicit', 'require explicit data', 'explicit data collection', 'data collection effort', 'collection effort coordinated', 'effort coordinated university', 'coordinated university site', 'university site although', 'site although student', 'although student likely', 'student likely use', 'likely use facebook', 'use facebook due', 'facebook due largely', 'due largely privately', 'largely privately shared', 'privately shared content', 'shared content challenging', 'content challenging obtain', 'challenging obtain access', 'obtain access large', 'access large dataset', 'large dataset university', 'dataset university student', 'university student next', 'student next twitter', 'next twitter also', 'twitter also widely', 'also widely adopted', 'widely adopted without', 'adopted without explicit', 'without explicit selfreported', 'explicit selfreported information', 'selfreported information challenging', 'information challenging identify', 'challenging identify college', 'identify college student', 'college student account', 'student account finally', 'account finally prior', 'finally prior work', 'prior work note', 'work note semianonymity', 'note semianonymity reddit', 'semianonymity reddit enables', 'reddit enables candid', 'enables candid self', 'candid self disclosure', 'self disclosure around', 'disclosure around stigmatized', 'around stigmatized topic', 'stigmatized topic like', 'topic like mental', 'like mental health', 'mental health initial', 'health initial data', 'initial data acquisition', 'data acquisition leveraged', 'acquisition leveraged archive', 'leveraged archive reddit', 'archive reddit data', 'reddit data made', 'data made available', 'made available google', 'available google bigquery', 'google bigquery bigquery', 'bigquery bigquery cloud', 'bigquery cloud based', 'cloud based managed', 'based managed data', 'managed data warehouse', 'data warehouse allows', 'warehouse allows third', 'allows third party', 'third party access', 'party access large', 'access large publicly', 'large publicly available', 'publicly available dataset', 'available dataset simple', 'dataset simple sqltype', 'simple sqltype query', 'sqltype query query', 'query query grabbed', 'query grabbed post', 'grabbed post ranging', 'post ranging june', 'ranging june february', 'june february available', 'february available reddit', 'available reddit data', 'reddit data archive', 'data archive included', 'archive included post', 'included post unique', 'post unique user', 'unique user across', 'user across university', 'across university mean', 'university mean post', 'mean post unique', 'post unique user', 'unique user per', 'user per subreddit', 'per subreddit filling', 'subreddit filling gap', 'filling gap subreddit', 'gap subreddit data', 'subreddit data second', 'data second step', 'second step data', 'step data collection', 'data collection process', 'collection process focused', 'process focused identifying', 'focused identifying subreddits', 'identifying subreddits insufficient', 'subreddits insufficient data', 'insufficient data supplementing', 'data supplementing additional', 'supplementing additional alternative', 'additional alternative data', 'alternative data collection', 'data collection reddits', 'collection reddits official', 'reddits official api', 'official api httpswwwredditcomdevapi', 'api httpswwwredditcomdevapi obtained', 'httpswwwredditcomdevapi obtained recent', 'obtained recent number', 'recent number subscriber', 'number subscriber university', 'subscriber university subreddits', 'university subreddits july', 'subreddits july investigate', 'july investigate extent', 'investigate extent subreddits', 'extent subreddits may', 'subreddits may unusually', 'may unusually low', 'unusually low data', 'low data given', 'data given step', 'given step determined', 'step determined median', 'determined median unique', 'median unique user', 'unique user subscriber', 'user subscriber ratio', 'subscriber ratio subreddit', 'ratio subreddit allows', 'subreddit allows u', 'allows u capture', 'u capture subreddits', 'capture subreddits subscriber', 'subreddits subscriber count', 'subscriber count high', 'count high however', 'high however data', 'however data obtained', 'data obtained sufficiently', 'obtained sufficiently representative', 'sufficiently representative subreddits', 'representative subreddits unique', 'subreddits unique user', 'unique user subscriber', 'user subscriber ratio', 'subscriber ratio median', 'ratio median performed', 'median performed onetime', 'performed onetime data', 'onetime data collection', 'data collection using', 'collection using reddit', 'using reddit api', 'reddit api gave', 'api gave u', 'gave u set', 'u set recent', 'set recent post', 'recent post subreddit', 'post subreddit total', 'subreddit total post', 'total post added', 'post added data', 'added data obtained', 'data obtained step', 'obtained step following', 'step following deduplication', 'following deduplication note', 'deduplication note procedure', 'note procedure skew', 'procedure skew yearly', 'skew yearly distribution', 'yearly distribution data', 'distribution data across', 'data across subreddits', 'across subreddits skew', 'subreddits skew yearly', 'skew yearly rate', 'yearly rate change', 'rate change data', 'change data filling', 'data filling respectively', 'filling respectively found', 'respectively found statistically', 'found statistically equivalent', 'statistically equivalent based', 'equivalent based twosample', 'based twosample equivalence', 'twosample equivalence test', 'equivalence test p', 'test p p', 'p p test', 'p test us', 'test us two', 'us two onesided', 'two onesided ttests', 'onesided ttests beforeafter', 'ttests beforeafter yearly', 'beforeafter yearly rate', 'yearly rate change', 'rate change side', 'change side chosen', 'side chosen difference', 'chosen difference interval', 'difference interval present', 'interval present methodology', 'present methodology identifying', 'methodology identifying post', 'identifying post shared', 'post shared university', 'shared university subreddits', 'university subreddits likely', 'subreddits likely mental', 'likely mental health', 'mental health expression', 'health expression note', 'expression note reddit', 'note reddit data', 'reddit data doe', 'data doe contain', 'doe contain gold', 'contain gold standard', 'gold standard information', 'standard information around', 'information around whether', 'around whether post', 'whether post shared', 'post shared university', 'shared university subreddit', 'university subreddit one', 'subreddit one mental', 'one mental health', 'mental health experience', 'health experience condition', 'experience condition proposed', 'condition proposed method', 'proposed method overcomes', 'method overcomes challenge', 'overcomes challenge employing', 'challenge employing inductive', 'employing inductive transfer', 'inductive transfer learning', 'transfer learning approach', 'learning approach first', 'approach first include', 'first include ground', 'include ground truth', 'ground truth data', 'truth data reddit', 'data reddit post', 'reddit post made', 'post made various', 'made various mental', 'various mental health', 'mental health support', 'health support community', 'support community prior', 'community prior work', 'prior work ha', 'work ha established', 'ha established community', 'established community individual', 'community individual selfdisclose', 'individual selfdisclose variety', 'selfdisclose variety mental', 'variety mental health', 'mental health challenge', 'health challenge explicitly', 'challenge explicitly parallelly', 'explicitly parallelly utilize', 'parallelly utilize another', 'utilize another set', 'another set reddit', 'set reddit post', 'reddit post made', 'post made generic', 'made generic subreddits', 'generic subreddits unrelated', 'subreddits unrelated mental', 'unrelated mental health', 'mental health control', 'health control next', 'control next build', 'next build machine', 'build machine learning', 'machine learning classifier', 'learning classifier distinguish', 'classifier distinguish two', 'distinguish two type', 'two type post', 'type post learn', 'post learn feature', 'learn feature could', 'feature could detect', 'could detect whether', 'detect whether post', 'whether post shared', 'post shared university', 'shared university subreddit', 'university subreddit could', 'subreddit could expression', 'could expression mental', 'expression mental health', 'mental health concern', 'health concern discus', 'concern discus step', 'discus step detail', 'step detail following', 'detail following subsection']",0.0,0.9984637498855591,0.0,0.0,0.0,0.0,0,0.0
https://ieeexplore.ieee.org/abstract/document/7752434,1,To train our models we require information from two different types of users: patients and non-patients. Therefore we employed a combined - manual effort and keyword matching - data collection approach to efficiently collect data for these users. For the collection of patients we manually collect the community portals relevant to both mental disorders. 2 From these portals' followers list we select the self-reported users who explicitly state in their profile description that they suffer from a mental illness; i.e. for a given user we are checking if his/her profile contains any keyword related to a target disorder (e.g. “borderline” “bpd” “bipolar”). Non-patients are referred to as random active Twitter users who are not explicitly stating that they are suffering from Bipolar disorder (hereinafter referred to as “BD”) or Borderline Personality Disorder (hereinafter referred to as “BPD”). To obtain these users we randomly sampled Twitter IDs. Thereafter we proceeded to download the tweets from the selected IDs. After the users have been identified we manually label them into one of two categories: 1) Patient: a person who is suffering from a mental disorder 2) Not-related: any user who we don't consider to be a patient. Lastly after having obtained the final list of patients we retrieve their tweets. These steps are applied for the collection of both BPD and BD patient datasets.,to train our model we require information from two different type of user patient and nonpatients therefore we employed a combined manual effort and keyword matching data collection approach to efficiently collect data for these user for the collection of patient we manually collect the community portal relevant to both mental disorder from these portal follower list we select the selfreported user who explicitly state in their profile description that they suffer from a mental illness ie for a given user we are checking if hisher profile contains any keyword related to a target disorder eg borderline bpd bipolar nonpatients are referred to a random active twitter user who are not explicitly stating that they are suffering from bipolar disorder hereinafter referred to a bd or borderline personality disorder hereinafter referred to a bpd to obtain these user we randomly sampled twitter id thereafter we proceeded to download the tweet from the selected id after the user have been identified we manually label them into one of two category patient a person who is suffering from a mental disorder notrelated any user who we dont consider to be a patient lastly after having obtained the final list of patient we retrieve their tweet these step are applied for the collection of both bpd and bd patient datasets,"['train', 'model', 'require', 'information', 'two', 'different', 'type', 'user', 'patient', 'nonpatients', 'therefore', 'employed', 'combined', 'manual', 'effort', 'keyword', 'matching', 'data', 'collection', 'approach', 'efficiently', 'collect', 'data', 'user', 'collection', 'patient', 'manually', 'collect', 'community', 'portal', 'relevant', 'mental', 'disorder', 'portal', 'follower', 'list', 'select', 'selfreported', 'user', 'explicitly', 'state', 'profile', 'description', 'suffer', 'mental', 'illness', 'ie', 'given', 'user', 'checking', 'hisher', 'profile', 'contains', 'keyword', 'related', 'target', 'disorder', 'eg', 'borderline', 'bpd', 'bipolar', 'nonpatients', 'referred', 'random', 'active', 'twitter', 'user', 'explicitly', 'stating', 'suffering', 'bipolar', 'disorder', 'hereinafter', 'referred', 'bd', 'borderline', 'personality', 'disorder', 'hereinafter', 'referred', 'bpd', 'obtain', 'user', 'randomly', 'sampled', 'twitter', 'id', 'thereafter', 'proceeded', 'download', 'tweet', 'selected', 'id', 'user', 'identified', 'manually', 'label', 'one', 'two', 'category', 'patient', 'person', 'suffering', 'mental', 'disorder', 'notrelated', 'user', 'dont', 'consider', 'patient', 'lastly', 'obtained', 'final', 'list', 'patient', 'retrieve', 'tweet', 'step', 'applied', 'collection', 'bpd', 'bd', 'patient', 'datasets']","['train model', 'model require', 'require information', 'information two', 'two different', 'different type', 'type user', 'user patient', 'patient nonpatients', 'nonpatients therefore', 'therefore employed', 'employed combined', 'combined manual', 'manual effort', 'effort keyword', 'keyword matching', 'matching data', 'data collection', 'collection approach', 'approach efficiently', 'efficiently collect', 'collect data', 'data user', 'user collection', 'collection patient', 'patient manually', 'manually collect', 'collect community', 'community portal', 'portal relevant', 'relevant mental', 'mental disorder', 'disorder portal', 'portal follower', 'follower list', 'list select', 'select selfreported', 'selfreported user', 'user explicitly', 'explicitly state', 'state profile', 'profile description', 'description suffer', 'suffer mental', 'mental illness', 'illness ie', 'ie given', 'given user', 'user checking', 'checking hisher', 'hisher profile', 'profile contains', 'contains keyword', 'keyword related', 'related target', 'target disorder', 'disorder eg', 'eg borderline', 'borderline bpd', 'bpd bipolar', 'bipolar nonpatients', 'nonpatients referred', 'referred random', 'random active', 'active twitter', 'twitter user', 'user explicitly', 'explicitly stating', 'stating suffering', 'suffering bipolar', 'bipolar disorder', 'disorder hereinafter', 'hereinafter referred', 'referred bd', 'bd borderline', 'borderline personality', 'personality disorder', 'disorder hereinafter', 'hereinafter referred', 'referred bpd', 'bpd obtain', 'obtain user', 'user randomly', 'randomly sampled', 'sampled twitter', 'twitter id', 'id thereafter', 'thereafter proceeded', 'proceeded download', 'download tweet', 'tweet selected', 'selected id', 'id user', 'user identified', 'identified manually', 'manually label', 'label one', 'one two', 'two category', 'category patient', 'patient person', 'person suffering', 'suffering mental', 'mental disorder', 'disorder notrelated', 'notrelated user', 'user dont', 'dont consider', 'consider patient', 'patient lastly', 'lastly obtained', 'obtained final', 'final list', 'list patient', 'patient retrieve', 'retrieve tweet', 'tweet step', 'step applied', 'applied collection', 'collection bpd', 'bpd bd', 'bd patient', 'patient datasets']","['train model require', 'model require information', 'require information two', 'information two different', 'two different type', 'different type user', 'type user patient', 'user patient nonpatients', 'patient nonpatients therefore', 'nonpatients therefore employed', 'therefore employed combined', 'employed combined manual', 'combined manual effort', 'manual effort keyword', 'effort keyword matching', 'keyword matching data', 'matching data collection', 'data collection approach', 'collection approach efficiently', 'approach efficiently collect', 'efficiently collect data', 'collect data user', 'data user collection', 'user collection patient', 'collection patient manually', 'patient manually collect', 'manually collect community', 'collect community portal', 'community portal relevant', 'portal relevant mental', 'relevant mental disorder', 'mental disorder portal', 'disorder portal follower', 'portal follower list', 'follower list select', 'list select selfreported', 'select selfreported user', 'selfreported user explicitly', 'user explicitly state', 'explicitly state profile', 'state profile description', 'profile description suffer', 'description suffer mental', 'suffer mental illness', 'mental illness ie', 'illness ie given', 'ie given user', 'given user checking', 'user checking hisher', 'checking hisher profile', 'hisher profile contains', 'profile contains keyword', 'contains keyword related', 'keyword related target', 'related target disorder', 'target disorder eg', 'disorder eg borderline', 'eg borderline bpd', 'borderline bpd bipolar', 'bpd bipolar nonpatients', 'bipolar nonpatients referred', 'nonpatients referred random', 'referred random active', 'random active twitter', 'active twitter user', 'twitter user explicitly', 'user explicitly stating', 'explicitly stating suffering', 'stating suffering bipolar', 'suffering bipolar disorder', 'bipolar disorder hereinafter', 'disorder hereinafter referred', 'hereinafter referred bd', 'referred bd borderline', 'bd borderline personality', 'borderline personality disorder', 'personality disorder hereinafter', 'disorder hereinafter referred', 'hereinafter referred bpd', 'referred bpd obtain', 'bpd obtain user', 'obtain user randomly', 'user randomly sampled', 'randomly sampled twitter', 'sampled twitter id', 'twitter id thereafter', 'id thereafter proceeded', 'thereafter proceeded download', 'proceeded download tweet', 'download tweet selected', 'tweet selected id', 'selected id user', 'id user identified', 'user identified manually', 'identified manually label', 'manually label one', 'label one two', 'one two category', 'two category patient', 'category patient person', 'patient person suffering', 'person suffering mental', 'suffering mental disorder', 'mental disorder notrelated', 'disorder notrelated user', 'notrelated user dont', 'user dont consider', 'dont consider patient', 'consider patient lastly', 'patient lastly obtained', 'lastly obtained final', 'obtained final list', 'final list patient', 'list patient retrieve', 'patient retrieve tweet', 'retrieve tweet step', 'tweet step applied', 'step applied collection', 'applied collection bpd', 'collection bpd bd', 'bpd bd patient', 'bd patient datasets']",0.0,0.9929949641227722,0.0,0.0,0.0,0.0,0,0.0
https://www.nature.com/articles/s41598-020-68764-y,1,We developed six binary classification models each of which categorizes a user’ specific post into one of the following subreddits: r/depression r/Anxiety r/bipolar r/BPD r/schizophrenia and r/autism. Our conjecture is that a user who suffers from a specific mental problem writes a post on the corresponding subreddit that deals with the problem. A user can write posts across multiple subreddits if he/she suffers from multiple mental health problems e.g. a user suffering from both depression and anxiety. However if the model is trained with the posts of users who have multiple symptoms like a prior study10 the classification model may suffer from noisy data. Therefore we developed six independent binary classification models for each symptom to improve the performance. By developing six independent models for each mental disorder each of which uses data where users suffer from only one particular mental problem we were able to accurately identify a user’s potential mental state. For example to develop a model for detecting depression we labeled the posts written by users who upload posts only in the r/depression as the depression class; the opposite class is referred to as the non-depression class. To address a class-imbalance issue for the collected data we applied the synthetic minority over-sampling technique (SMOTE) algorithm19. We divided our dataset into training (80%) and testing (20%) sets. Then XGBoost and convolutional neural network (CNN) were employed. Morover we excluded the posts of users who wrote posts across multiple subreddits in learning phase. To quantitatively represent each post we converted the words in the training set to numerical representations (Fig. 2). For the XGBoost classifier we used the TF-IDF vectorizer in the sckit-learn package20 to convert words into n-dimensional vectors. In the case of the CNN classifier we applied word-embedding procedures from the pre-processed texts using the word2vec API of Python Package Gensim21. The word vectors were pre-trained with the training dataset collected for the current study with continuous bag-of-words representation (CBOW) models while the size of window was set to five. Note that by using the pre-trained word2vec model for representing each post for each subreddit a language style used by users who write posts in a subreddit can be trained for the specific subreddit. An overview of the proposed CNN-based model is presented in Fig. 2. The model architecture is organized by the sequence of layers that includes an embedding layer convolutional layer max-pooling layer dense layers and the output. Fig. 2 illustrates how a post is trained in the given model. The first layer of the model is an embedding layer that represents the word embeddings of a pre-processed post with 20 dimensions and its weight is initialized by the pre-trained word2vec. Second a convolutional layer with input of word vectors has 128 filters and each filter size is five. In addition we applied a dropout rate of 0.25 to prevent over-fitting issues. The next layer is a max-pooling layer which takes the maximum values within the CNN filters and its dimension is 128. The output of the max-pooling layer is passed through two fully connected (dense) layers and the final output is the probability of the classification through the sigmoid activation function which ranges from 0 to 1. For training the neural network we used both the binary cross-entropy loss function and Adam optimizer22 with a learning rate of 0.001. Our model was trained through 50 epochs and the batch size was set to 64.,we developed six binary classification model each of which categorizes a user specific post into one of the following subreddits rdepression ranxiety rbipolar rbpd rschizophrenia and rautism our conjecture is that a user who suffers from a specific mental problem writes a post on the corresponding subreddit that deal with the problem a user can write post across multiple subreddits if heshe suffers from multiple mental health problem eg a user suffering from both depression and anxiety however if the model is trained with the post of user who have multiple symptom like a prior study the classification model may suffer from noisy data therefore we developed six independent binary classification model for each symptom to improve the performance by developing six independent model for each mental disorder each of which us data where user suffer from only one particular mental problem we were able to accurately identify a user potential mental state for example to develop a model for detecting depression we labeled the post written by user who upload post only in the rdepression a the depression class the opposite class is referred to a the nondepression class to address a classimbalance issue for the collected data we applied the synthetic minority oversampling technique smote algorithm we divided our dataset into training and testing set then xgboost and convolutional neural network cnn were employed morover we excluded the post of user who wrote post across multiple subreddits in learning phase to quantitatively represent each post we converted the word in the training set to numerical representation fig for the xgboost classifier we used the tfidf vectorizer in the sckitlearn package to convert word into ndimensional vector in the case of the cnn classifier we applied wordembedding procedure from the preprocessed text using the wordvec api of python package gensim the word vector were pretrained with the training dataset collected for the current study with continuous bagofwords representation cbow model while the size of window wa set to five note that by using the pretrained wordvec model for representing each post for each subreddit a language style used by user who write post in a subreddit can be trained for the specific subreddit an overview of the proposed cnnbased model is presented in fig the model architecture is organized by the sequence of layer that includes an embedding layer convolutional layer maxpooling layer dense layer and the output fig illustrates how a post is trained in the given model the first layer of the model is an embedding layer that represents the word embeddings of a preprocessed post with dimension and it weight is initialized by the pretrained wordvec second a convolutional layer with input of word vector ha filter and each filter size is five in addition we applied a dropout rate of to prevent overfitting issue the next layer is a maxpooling layer which take the maximum value within the cnn filter and it dimension is the output of the maxpooling layer is passed through two fully connected dense layer and the final output is the probability of the classification through the sigmoid activation function which range from to for training the neural network we used both the binary crossentropy loss function and adam optimizer with a learning rate of our model wa trained through epoch and the batch size wa set to,"['developed', 'six', 'binary', 'classification', 'model', 'categorizes', 'user', 'specific', 'post', 'one', 'following', 'subreddits', 'rdepression', 'ranxiety', 'rbipolar', 'rbpd', 'rschizophrenia', 'rautism', 'conjecture', 'user', 'suffers', 'specific', 'mental', 'problem', 'writes', 'post', 'corresponding', 'subreddit', 'deal', 'problem', 'user', 'write', 'post', 'across', 'multiple', 'subreddits', 'heshe', 'suffers', 'multiple', 'mental', 'health', 'problem', 'eg', 'user', 'suffering', 'depression', 'anxiety', 'however', 'model', 'trained', 'post', 'user', 'multiple', 'symptom', 'like', 'prior', 'study', 'classification', 'model', 'may', 'suffer', 'noisy', 'data', 'therefore', 'developed', 'six', 'independent', 'binary', 'classification', 'model', 'symptom', 'improve', 'performance', 'developing', 'six', 'independent', 'model', 'mental', 'disorder', 'us', 'data', 'user', 'suffer', 'one', 'particular', 'mental', 'problem', 'able', 'accurately', 'identify', 'user', 'potential', 'mental', 'state', 'example', 'develop', 'model', 'detecting', 'depression', 'labeled', 'post', 'written', 'user', 'upload', 'post', 'rdepression', 'depression', 'class', 'opposite', 'class', 'referred', 'nondepression', 'class', 'address', 'classimbalance', 'issue', 'collected', 'data', 'applied', 'synthetic', 'minority', 'oversampling', 'technique', 'smote', 'algorithm', 'divided', 'dataset', 'training', 'testing', 'set', 'xgboost', 'convolutional', 'neural', 'network', 'cnn', 'employed', 'morover', 'excluded', 'post', 'user', 'wrote', 'post', 'across', 'multiple', 'subreddits', 'learning', 'phase', 'quantitatively', 'represent', 'post', 'converted', 'word', 'training', 'set', 'numerical', 'representation', 'fig', 'xgboost', 'classifier', 'used', 'tfidf', 'vectorizer', 'sckitlearn', 'package', 'convert', 'word', 'ndimensional', 'vector', 'case', 'cnn', 'classifier', 'applied', 'wordembedding', 'procedure', 'preprocessed', 'text', 'using', 'wordvec', 'api', 'python', 'package', 'gensim', 'word', 'vector', 'pretrained', 'training', 'dataset', 'collected', 'current', 'study', 'continuous', 'bagofwords', 'representation', 'cbow', 'model', 'size', 'window', 'wa', 'set', 'five', 'note', 'using', 'pretrained', 'wordvec', 'model', 'representing', 'post', 'subreddit', 'language', 'style', 'used', 'user', 'write', 'post', 'subreddit', 'trained', 'specific', 'subreddit', 'overview', 'proposed', 'cnnbased', 'model', 'presented', 'fig', 'model', 'architecture', 'organized', 'sequence', 'layer', 'includes', 'embedding', 'layer', 'convolutional', 'layer', 'maxpooling', 'layer', 'dense', 'layer', 'output', 'fig', 'illustrates', 'post', 'trained', 'given', 'model', 'first', 'layer', 'model', 'embedding', 'layer', 'represents', 'word', 'embeddings', 'preprocessed', 'post', 'dimension', 'weight', 'initialized', 'pretrained', 'wordvec', 'second', 'convolutional', 'layer', 'input', 'word', 'vector', 'ha', 'filter', 'filter', 'size', 'five', 'addition', 'applied', 'dropout', 'rate', 'prevent', 'overfitting', 'issue', 'next', 'layer', 'maxpooling', 'layer', 'take', 'maximum', 'value', 'within', 'cnn', 'filter', 'dimension', 'output', 'maxpooling', 'layer', 'passed', 'two', 'fully', 'connected', 'dense', 'layer', 'final', 'output', 'probability', 'classification', 'sigmoid', 'activation', 'function', 'range', 'training', 'neural', 'network', 'used', 'binary', 'crossentropy', 'loss', 'function', 'adam', 'optimizer', 'learning', 'rate', 'model', 'wa', 'trained', 'epoch', 'batch', 'size', 'wa', 'set']","['developed six', 'six binary', 'binary classification', 'classification model', 'model categorizes', 'categorizes user', 'user specific', 'specific post', 'post one', 'one following', 'following subreddits', 'subreddits rdepression', 'rdepression ranxiety', 'ranxiety rbipolar', 'rbipolar rbpd', 'rbpd rschizophrenia', 'rschizophrenia rautism', 'rautism conjecture', 'conjecture user', 'user suffers', 'suffers specific', 'specific mental', 'mental problem', 'problem writes', 'writes post', 'post corresponding', 'corresponding subreddit', 'subreddit deal', 'deal problem', 'problem user', 'user write', 'write post', 'post across', 'across multiple', 'multiple subreddits', 'subreddits heshe', 'heshe suffers', 'suffers multiple', 'multiple mental', 'mental health', 'health problem', 'problem eg', 'eg user', 'user suffering', 'suffering depression', 'depression anxiety', 'anxiety however', 'however model', 'model trained', 'trained post', 'post user', 'user multiple', 'multiple symptom', 'symptom like', 'like prior', 'prior study', 'study classification', 'classification model', 'model may', 'may suffer', 'suffer noisy', 'noisy data', 'data therefore', 'therefore developed', 'developed six', 'six independent', 'independent binary', 'binary classification', 'classification model', 'model symptom', 'symptom improve', 'improve performance', 'performance developing', 'developing six', 'six independent', 'independent model', 'model mental', 'mental disorder', 'disorder us', 'us data', 'data user', 'user suffer', 'suffer one', 'one particular', 'particular mental', 'mental problem', 'problem able', 'able accurately', 'accurately identify', 'identify user', 'user potential', 'potential mental', 'mental state', 'state example', 'example develop', 'develop model', 'model detecting', 'detecting depression', 'depression labeled', 'labeled post', 'post written', 'written user', 'user upload', 'upload post', 'post rdepression', 'rdepression depression', 'depression class', 'class opposite', 'opposite class', 'class referred', 'referred nondepression', 'nondepression class', 'class address', 'address classimbalance', 'classimbalance issue', 'issue collected', 'collected data', 'data applied', 'applied synthetic', 'synthetic minority', 'minority oversampling', 'oversampling technique', 'technique smote', 'smote algorithm', 'algorithm divided', 'divided dataset', 'dataset training', 'training testing', 'testing set', 'set xgboost', 'xgboost convolutional', 'convolutional neural', 'neural network', 'network cnn', 'cnn employed', 'employed morover', 'morover excluded', 'excluded post', 'post user', 'user wrote', 'wrote post', 'post across', 'across multiple', 'multiple subreddits', 'subreddits learning', 'learning phase', 'phase quantitatively', 'quantitatively represent', 'represent post', 'post converted', 'converted word', 'word training', 'training set', 'set numerical', 'numerical representation', 'representation fig', 'fig xgboost', 'xgboost classifier', 'classifier used', 'used tfidf', 'tfidf vectorizer', 'vectorizer sckitlearn', 'sckitlearn package', 'package convert', 'convert word', 'word ndimensional', 'ndimensional vector', 'vector case', 'case cnn', 'cnn classifier', 'classifier applied', 'applied wordembedding', 'wordembedding procedure', 'procedure preprocessed', 'preprocessed text', 'text using', 'using wordvec', 'wordvec api', 'api python', 'python package', 'package gensim', 'gensim word', 'word vector', 'vector pretrained', 'pretrained training', 'training dataset', 'dataset collected', 'collected current', 'current study', 'study continuous', 'continuous bagofwords', 'bagofwords representation', 'representation cbow', 'cbow model', 'model size', 'size window', 'window wa', 'wa set', 'set five', 'five note', 'note using', 'using pretrained', 'pretrained wordvec', 'wordvec model', 'model representing', 'representing post', 'post subreddit', 'subreddit language', 'language style', 'style used', 'used user', 'user write', 'write post', 'post subreddit', 'subreddit trained', 'trained specific', 'specific subreddit', 'subreddit overview', 'overview proposed', 'proposed cnnbased', 'cnnbased model', 'model presented', 'presented fig', 'fig model', 'model architecture', 'architecture organized', 'organized sequence', 'sequence layer', 'layer includes', 'includes embedding', 'embedding layer', 'layer convolutional', 'convolutional layer', 'layer maxpooling', 'maxpooling layer', 'layer dense', 'dense layer', 'layer output', 'output fig', 'fig illustrates', 'illustrates post', 'post trained', 'trained given', 'given model', 'model first', 'first layer', 'layer model', 'model embedding', 'embedding layer', 'layer represents', 'represents word', 'word embeddings', 'embeddings preprocessed', 'preprocessed post', 'post dimension', 'dimension weight', 'weight initialized', 'initialized pretrained', 'pretrained wordvec', 'wordvec second', 'second convolutional', 'convolutional layer', 'layer input', 'input word', 'word vector', 'vector ha', 'ha filter', 'filter filter', 'filter size', 'size five', 'five addition', 'addition applied', 'applied dropout', 'dropout rate', 'rate prevent', 'prevent overfitting', 'overfitting issue', 'issue next', 'next layer', 'layer maxpooling', 'maxpooling layer', 'layer take', 'take maximum', 'maximum value', 'value within', 'within cnn', 'cnn filter', 'filter dimension', 'dimension output', 'output maxpooling', 'maxpooling layer', 'layer passed', 'passed two', 'two fully', 'fully connected', 'connected dense', 'dense layer', 'layer final', 'final output', 'output probability', 'probability classification', 'classification sigmoid', 'sigmoid activation', 'activation function', 'function range', 'range training', 'training neural', 'neural network', 'network used', 'used binary', 'binary crossentropy', 'crossentropy loss', 'loss function', 'function adam', 'adam optimizer', 'optimizer learning', 'learning rate', 'rate model', 'model wa', 'wa trained', 'trained epoch', 'epoch batch', 'batch size', 'size wa', 'wa set']","['developed six binary', 'six binary classification', 'binary classification model', 'classification model categorizes', 'model categorizes user', 'categorizes user specific', 'user specific post', 'specific post one', 'post one following', 'one following subreddits', 'following subreddits rdepression', 'subreddits rdepression ranxiety', 'rdepression ranxiety rbipolar', 'ranxiety rbipolar rbpd', 'rbipolar rbpd rschizophrenia', 'rbpd rschizophrenia rautism', 'rschizophrenia rautism conjecture', 'rautism conjecture user', 'conjecture user suffers', 'user suffers specific', 'suffers specific mental', 'specific mental problem', 'mental problem writes', 'problem writes post', 'writes post corresponding', 'post corresponding subreddit', 'corresponding subreddit deal', 'subreddit deal problem', 'deal problem user', 'problem user write', 'user write post', 'write post across', 'post across multiple', 'across multiple subreddits', 'multiple subreddits heshe', 'subreddits heshe suffers', 'heshe suffers multiple', 'suffers multiple mental', 'multiple mental health', 'mental health problem', 'health problem eg', 'problem eg user', 'eg user suffering', 'user suffering depression', 'suffering depression anxiety', 'depression anxiety however', 'anxiety however model', 'however model trained', 'model trained post', 'trained post user', 'post user multiple', 'user multiple symptom', 'multiple symptom like', 'symptom like prior', 'like prior study', 'prior study classification', 'study classification model', 'classification model may', 'model may suffer', 'may suffer noisy', 'suffer noisy data', 'noisy data therefore', 'data therefore developed', 'therefore developed six', 'developed six independent', 'six independent binary', 'independent binary classification', 'binary classification model', 'classification model symptom', 'model symptom improve', 'symptom improve performance', 'improve performance developing', 'performance developing six', 'developing six independent', 'six independent model', 'independent model mental', 'model mental disorder', 'mental disorder us', 'disorder us data', 'us data user', 'data user suffer', 'user suffer one', 'suffer one particular', 'one particular mental', 'particular mental problem', 'mental problem able', 'problem able accurately', 'able accurately identify', 'accurately identify user', 'identify user potential', 'user potential mental', 'potential mental state', 'mental state example', 'state example develop', 'example develop model', 'develop model detecting', 'model detecting depression', 'detecting depression labeled', 'depression labeled post', 'labeled post written', 'post written user', 'written user upload', 'user upload post', 'upload post rdepression', 'post rdepression depression', 'rdepression depression class', 'depression class opposite', 'class opposite class', 'opposite class referred', 'class referred nondepression', 'referred nondepression class', 'nondepression class address', 'class address classimbalance', 'address classimbalance issue', 'classimbalance issue collected', 'issue collected data', 'collected data applied', 'data applied synthetic', 'applied synthetic minority', 'synthetic minority oversampling', 'minority oversampling technique', 'oversampling technique smote', 'technique smote algorithm', 'smote algorithm divided', 'algorithm divided dataset', 'divided dataset training', 'dataset training testing', 'training testing set', 'testing set xgboost', 'set xgboost convolutional', 'xgboost convolutional neural', 'convolutional neural network', 'neural network cnn', 'network cnn employed', 'cnn employed morover', 'employed morover excluded', 'morover excluded post', 'excluded post user', 'post user wrote', 'user wrote post', 'wrote post across', 'post across multiple', 'across multiple subreddits', 'multiple subreddits learning', 'subreddits learning phase', 'learning phase quantitatively', 'phase quantitatively represent', 'quantitatively represent post', 'represent post converted', 'post converted word', 'converted word training', 'word training set', 'training set numerical', 'set numerical representation', 'numerical representation fig', 'representation fig xgboost', 'fig xgboost classifier', 'xgboost classifier used', 'classifier used tfidf', 'used tfidf vectorizer', 'tfidf vectorizer sckitlearn', 'vectorizer sckitlearn package', 'sckitlearn package convert', 'package convert word', 'convert word ndimensional', 'word ndimensional vector', 'ndimensional vector case', 'vector case cnn', 'case cnn classifier', 'cnn classifier applied', 'classifier applied wordembedding', 'applied wordembedding procedure', 'wordembedding procedure preprocessed', 'procedure preprocessed text', 'preprocessed text using', 'text using wordvec', 'using wordvec api', 'wordvec api python', 'api python package', 'python package gensim', 'package gensim word', 'gensim word vector', 'word vector pretrained', 'vector pretrained training', 'pretrained training dataset', 'training dataset collected', 'dataset collected current', 'collected current study', 'current study continuous', 'study continuous bagofwords', 'continuous bagofwords representation', 'bagofwords representation cbow', 'representation cbow model', 'cbow model size', 'model size window', 'size window wa', 'window wa set', 'wa set five', 'set five note', 'five note using', 'note using pretrained', 'using pretrained wordvec', 'pretrained wordvec model', 'wordvec model representing', 'model representing post', 'representing post subreddit', 'post subreddit language', 'subreddit language style', 'language style used', 'style used user', 'used user write', 'user write post', 'write post subreddit', 'post subreddit trained', 'subreddit trained specific', 'trained specific subreddit', 'specific subreddit overview', 'subreddit overview proposed', 'overview proposed cnnbased', 'proposed cnnbased model', 'cnnbased model presented', 'model presented fig', 'presented fig model', 'fig model architecture', 'model architecture organized', 'architecture organized sequence', 'organized sequence layer', 'sequence layer includes', 'layer includes embedding', 'includes embedding layer', 'embedding layer convolutional', 'layer convolutional layer', 'convolutional layer maxpooling', 'layer maxpooling layer', 'maxpooling layer dense', 'layer dense layer', 'dense layer output', 'layer output fig', 'output fig illustrates', 'fig illustrates post', 'illustrates post trained', 'post trained given', 'trained given model', 'given model first', 'model first layer', 'first layer model', 'layer model embedding', 'model embedding layer', 'embedding layer represents', 'layer represents word', 'represents word embeddings', 'word embeddings preprocessed', 'embeddings preprocessed post', 'preprocessed post dimension', 'post dimension weight', 'dimension weight initialized', 'weight initialized pretrained', 'initialized pretrained wordvec', 'pretrained wordvec second', 'wordvec second convolutional', 'second convolutional layer', 'convolutional layer input', 'layer input word', 'input word vector', 'word vector ha', 'vector ha filter', 'ha filter filter', 'filter filter size', 'filter size five', 'size five addition', 'five addition applied', 'addition applied dropout', 'applied dropout rate', 'dropout rate prevent', 'rate prevent overfitting', 'prevent overfitting issue', 'overfitting issue next', 'issue next layer', 'next layer maxpooling', 'layer maxpooling layer', 'maxpooling layer take', 'layer take maximum', 'take maximum value', 'maximum value within', 'value within cnn', 'within cnn filter', 'cnn filter dimension', 'filter dimension output', 'dimension output maxpooling', 'output maxpooling layer', 'maxpooling layer passed', 'layer passed two', 'passed two fully', 'two fully connected', 'fully connected dense', 'connected dense layer', 'dense layer final', 'layer final output', 'final output probability', 'output probability classification', 'probability classification sigmoid', 'classification sigmoid activation', 'sigmoid activation function', 'activation function range', 'function range training', 'range training neural', 'training neural network', 'neural network used', 'network used binary', 'used binary crossentropy', 'binary crossentropy loss', 'crossentropy loss function', 'loss function adam', 'function adam optimizer', 'adam optimizer learning', 'optimizer learning rate', 'learning rate model', 'rate model wa', 'model wa trained', 'wa trained epoch', 'trained epoch batch', 'epoch batch size', 'batch size wa', 'size wa set']",0.0,0.0,0.0,0.9973224401473999,0.0,0.0,0,0.0
https://aclanthology.org/W19-3013.pdf,1,We build on prior work on supervised models for mental health inference over social media data. We focus on two mental health conditions — depression and PTSD — and develop classifiers with the self-reported datasets created for CLPysch 2015 (Mitchell et al. 2015; Coppersmith et al. 2015b). These labeled datasets derive from users that have publicly disclosed on Twitter a diagnosis of depression (327 users) or PTSD (246 users) with an equal number of randomly selected demographically-matched (with respect to age and gender) users as controls. For each user the associated metadata and posting history was also collected — up to the 3000 most recent tweets per limitations of the Twitter API. The participants of the task proposed a host of methods ranging from rule-based systems to various supervised models (Pedersen 2015; PreotiucPietro et al. 2015; Coppersmith et al. 2015b). More recently the neural user-level classifier proposed by Amir et al. (2017) showed not only good performance on this task but also the ability to capture implicit similarities between users affected by the same diseases thus opening the door to more interpretable analyses2 . Hence we adopt their model for this analysis.,we build on prior work on supervised model for mental health inference over social medium data we focus on two mental health condition depression and ptsd and develop classifier with the selfreported datasets created for clpysch mitchell et al coppersmith et al b these labeled datasets derive from user that have publicly disclosed on twitter a diagnosis of depression user or ptsd user with an equal number of randomly selected demographicallymatched with respect to age and gender user a control for each user the associated metadata and posting history wa also collected up to the most recent tweet per limitation of the twitter api the participant of the task proposed a host of method ranging from rulebased system to various supervised model pedersen preotiucpietro et al coppersmith et al b more recently the neural userlevel classifier proposed by amir et al showed not only good performance on this task but also the ability to capture implicit similarity between user affected by the same disease thus opening the door to more interpretable analysis hence we adopt their model for this analysis,"['build', 'prior', 'work', 'supervised', 'model', 'mental', 'health', 'inference', 'social', 'medium', 'data', 'focus', 'two', 'mental', 'health', 'condition', 'depression', 'ptsd', 'develop', 'classifier', 'selfreported', 'datasets', 'created', 'clpysch', 'mitchell', 'et', 'al', 'coppersmith', 'et', 'al', 'b', 'labeled', 'datasets', 'derive', 'user', 'publicly', 'disclosed', 'twitter', 'diagnosis', 'depression', 'user', 'ptsd', 'user', 'equal', 'number', 'randomly', 'selected', 'demographicallymatched', 'respect', 'age', 'gender', 'user', 'control', 'user', 'associated', 'metadata', 'posting', 'history', 'wa', 'also', 'collected', 'recent', 'tweet', 'per', 'limitation', 'twitter', 'api', 'participant', 'task', 'proposed', 'host', 'method', 'ranging', 'rulebased', 'system', 'various', 'supervised', 'model', 'pedersen', 'preotiucpietro', 'et', 'al', 'coppersmith', 'et', 'al', 'b', 'recently', 'neural', 'userlevel', 'classifier', 'proposed', 'amir', 'et', 'al', 'showed', 'good', 'performance', 'task', 'also', 'ability', 'capture', 'implicit', 'similarity', 'user', 'affected', 'disease', 'thus', 'opening', 'door', 'interpretable', 'analysis', 'hence', 'adopt', 'model', 'analysis']","['build prior', 'prior work', 'work supervised', 'supervised model', 'model mental', 'mental health', 'health inference', 'inference social', 'social medium', 'medium data', 'data focus', 'focus two', 'two mental', 'mental health', 'health condition', 'condition depression', 'depression ptsd', 'ptsd develop', 'develop classifier', 'classifier selfreported', 'selfreported datasets', 'datasets created', 'created clpysch', 'clpysch mitchell', 'mitchell et', 'et al', 'al coppersmith', 'coppersmith et', 'et al', 'al b', 'b labeled', 'labeled datasets', 'datasets derive', 'derive user', 'user publicly', 'publicly disclosed', 'disclosed twitter', 'twitter diagnosis', 'diagnosis depression', 'depression user', 'user ptsd', 'ptsd user', 'user equal', 'equal number', 'number randomly', 'randomly selected', 'selected demographicallymatched', 'demographicallymatched respect', 'respect age', 'age gender', 'gender user', 'user control', 'control user', 'user associated', 'associated metadata', 'metadata posting', 'posting history', 'history wa', 'wa also', 'also collected', 'collected recent', 'recent tweet', 'tweet per', 'per limitation', 'limitation twitter', 'twitter api', 'api participant', 'participant task', 'task proposed', 'proposed host', 'host method', 'method ranging', 'ranging rulebased', 'rulebased system', 'system various', 'various supervised', 'supervised model', 'model pedersen', 'pedersen preotiucpietro', 'preotiucpietro et', 'et al', 'al coppersmith', 'coppersmith et', 'et al', 'al b', 'b recently', 'recently neural', 'neural userlevel', 'userlevel classifier', 'classifier proposed', 'proposed amir', 'amir et', 'et al', 'al showed', 'showed good', 'good performance', 'performance task', 'task also', 'also ability', 'ability capture', 'capture implicit', 'implicit similarity', 'similarity user', 'user affected', 'affected disease', 'disease thus', 'thus opening', 'opening door', 'door interpretable', 'interpretable analysis', 'analysis hence', 'hence adopt', 'adopt model', 'model analysis']","['build prior work', 'prior work supervised', 'work supervised model', 'supervised model mental', 'model mental health', 'mental health inference', 'health inference social', 'inference social medium', 'social medium data', 'medium data focus', 'data focus two', 'focus two mental', 'two mental health', 'mental health condition', 'health condition depression', 'condition depression ptsd', 'depression ptsd develop', 'ptsd develop classifier', 'develop classifier selfreported', 'classifier selfreported datasets', 'selfreported datasets created', 'datasets created clpysch', 'created clpysch mitchell', 'clpysch mitchell et', 'mitchell et al', 'et al coppersmith', 'al coppersmith et', 'coppersmith et al', 'et al b', 'al b labeled', 'b labeled datasets', 'labeled datasets derive', 'datasets derive user', 'derive user publicly', 'user publicly disclosed', 'publicly disclosed twitter', 'disclosed twitter diagnosis', 'twitter diagnosis depression', 'diagnosis depression user', 'depression user ptsd', 'user ptsd user', 'ptsd user equal', 'user equal number', 'equal number randomly', 'number randomly selected', 'randomly selected demographicallymatched', 'selected demographicallymatched respect', 'demographicallymatched respect age', 'respect age gender', 'age gender user', 'gender user control', 'user control user', 'control user associated', 'user associated metadata', 'associated metadata posting', 'metadata posting history', 'posting history wa', 'history wa also', 'wa also collected', 'also collected recent', 'collected recent tweet', 'recent tweet per', 'tweet per limitation', 'per limitation twitter', 'limitation twitter api', 'twitter api participant', 'api participant task', 'participant task proposed', 'task proposed host', 'proposed host method', 'host method ranging', 'method ranging rulebased', 'ranging rulebased system', 'rulebased system various', 'system various supervised', 'various supervised model', 'supervised model pedersen', 'model pedersen preotiucpietro', 'pedersen preotiucpietro et', 'preotiucpietro et al', 'et al coppersmith', 'al coppersmith et', 'coppersmith et al', 'et al b', 'al b recently', 'b recently neural', 'recently neural userlevel', 'neural userlevel classifier', 'userlevel classifier proposed', 'classifier proposed amir', 'proposed amir et', 'amir et al', 'et al showed', 'al showed good', 'showed good performance', 'good performance task', 'performance task also', 'task also ability', 'also ability capture', 'ability capture implicit', 'capture implicit similarity', 'implicit similarity user', 'similarity user affected', 'user affected disease', 'affected disease thus', 'disease thus opening', 'thus opening door', 'opening door interpretable', 'door interpretable analysis', 'interpretable analysis hence', 'analysis hence adopt', 'hence adopt model', 'adopt model analysis']",0.0,0.0,0.0,0.0,0.0,0.9924482107162476,0,0.0
https://link.springer.com/chapter/10.1007/978-3-319-67186-4_6,1,We analyze two datasets: (1) user communities on Reddit and (2) journals from a mental health journalling mobile app. We omit the name of the app for privacy and we refer to it as the “journalling app”. Reddit is a social media platform that was originally used for sharing and rating content such as news documentaries and music. Users post in and subscribe to self-organized communities known as subreddits; subscribing to a subreddit allows a user to view all posts from that subreddit. An advantage of analyzing Reddit data is that the subreddits are labelled according to their topics. Utilizing curated lists from volunteer Reddit users we crawled all subreddits related to mental health as well as all subreddits linked by these communities. The second dataset consists of anonymized journal posts from a mobile app designed to help people track their moods and share them anonymously if they desire. For each journal post the app requires the user to label the journal post with at least one mood selected from a pre-populated list including “happy” “sad” etc. We obtained all journals and the associated moods written between January 2016 and January 2017. This amounts to over 1.2 million journals written by approximately 75000 users. Figure 1 plots the number of journals posted over time. Most of the journals were written in the first half of 2016 although we inspected topic distributions per month and did not find seasonal effects. Towards the beginning of 2016 many new users registered on the app and eventually stopped using it. Like weight-loss and productivity apps we believe this influx is tied to users looking to improve their habits as a New Year’s resolution. Each journal can be set to be private or public (visible to all other users of the app). Roughly one third of all journals are public. Figure 2 plots the number of users on the y-axis versus the percentage of journals they posted publicly. Most users are either mostly private or mostly public. Most journals are relatively short just like Twitter posts that are at most 140 characters. The average length of a journal with text in it is 128 characters; there are roughly 100000 journal that have no text only a mood label. We observed that private users tend to write journals that are slightly but statistically significantly longer than those written by public users by approximately 10 characters. Figure 3 shows the distribution of journal lengths where the spikes correspond to 0 length (mood only) 200 characters (the default limit set by the app) and 300 characters (set as the maximum for visualization purposes). Users of the app can optionally enter their location age and gender. While most users did not enter this information we found that those who revealed their location are mostly from North America those who revealed their gender are predominantly female and those who revealed their age have an average age of 25.,we analyze two datasets user community on reddit and journal from a mental health journalling mobile app we omit the name of the app for privacy and we refer to it a the journalling app reddit is a social medium platform that wa originally used for sharing and rating content such a news documentary and music user post in and subscribe to selforganized community known a subreddits subscribing to a subreddit allows a user to view all post from that subreddit an advantage of analyzing reddit data is that the subreddits are labelled according to their topic utilizing curated list from volunteer reddit user we crawled all subreddits related to mental health a well a all subreddits linked by these community the second dataset consists of anonymized journal post from a mobile app designed to help people track their mood and share them anonymously if they desire for each journal post the app requires the user to label the journal post with at least one mood selected from a prepopulated list including happy sad etc we obtained all journal and the associated mood written between january and january this amount to over million journal written by approximately user figure plot the number of journal posted over time most of the journal were written in the first half of although we inspected topic distribution per month and did not find seasonal effect towards the beginning of many new user registered on the app and eventually stopped using it like weightloss and productivity apps we believe this influx is tied to user looking to improve their habit a a new year resolution each journal can be set to be private or public visible to all other user of the app roughly one third of all journal are public figure plot the number of user on the yaxis versus the percentage of journal they posted publicly most user are either mostly private or mostly public most journal are relatively short just like twitter post that are at most character the average length of a journal with text in it is character there are roughly journal that have no text only a mood label we observed that private user tend to write journal that are slightly but statistically significantly longer than those written by public user by approximately character figure show the distribution of journal length where the spike correspond to length mood only character the default limit set by the app and character set a the maximum for visualization purpose user of the app can optionally enter their location age and gender while most user did not enter this information we found that those who revealed their location are mostly from north america those who revealed their gender are predominantly female and those who revealed their age have an average age of,"['analyze', 'two', 'datasets', 'user', 'community', 'reddit', 'journal', 'mental', 'health', 'journalling', 'mobile', 'app', 'omit', 'name', 'app', 'privacy', 'refer', 'journalling', 'app', 'reddit', 'social', 'medium', 'platform', 'wa', 'originally', 'used', 'sharing', 'rating', 'content', 'news', 'documentary', 'music', 'user', 'post', 'subscribe', 'selforganized', 'community', 'known', 'subreddits', 'subscribing', 'subreddit', 'allows', 'user', 'view', 'post', 'subreddit', 'advantage', 'analyzing', 'reddit', 'data', 'subreddits', 'labelled', 'according', 'topic', 'utilizing', 'curated', 'list', 'volunteer', 'reddit', 'user', 'crawled', 'subreddits', 'related', 'mental', 'health', 'well', 'subreddits', 'linked', 'community', 'second', 'dataset', 'consists', 'anonymized', 'journal', 'post', 'mobile', 'app', 'designed', 'help', 'people', 'track', 'mood', 'share', 'anonymously', 'desire', 'journal', 'post', 'app', 'requires', 'user', 'label', 'journal', 'post', 'least', 'one', 'mood', 'selected', 'prepopulated', 'list', 'including', 'happy', 'sad', 'etc', 'obtained', 'journal', 'associated', 'mood', 'written', 'january', 'january', 'amount', 'million', 'journal', 'written', 'approximately', 'user', 'figure', 'plot', 'number', 'journal', 'posted', 'time', 'journal', 'written', 'first', 'half', 'although', 'inspected', 'topic', 'distribution', 'per', 'month', 'find', 'seasonal', 'effect', 'towards', 'beginning', 'many', 'new', 'user', 'registered', 'app', 'eventually', 'stopped', 'using', 'like', 'weightloss', 'productivity', 'apps', 'believe', 'influx', 'tied', 'user', 'looking', 'improve', 'habit', 'new', 'year', 'resolution', 'journal', 'set', 'private', 'public', 'visible', 'user', 'app', 'roughly', 'one', 'third', 'journal', 'public', 'figure', 'plot', 'number', 'user', 'yaxis', 'versus', 'percentage', 'journal', 'posted', 'publicly', 'user', 'either', 'mostly', 'private', 'mostly', 'public', 'journal', 'relatively', 'short', 'like', 'twitter', 'post', 'character', 'average', 'length', 'journal', 'text', 'character', 'roughly', 'journal', 'text', 'mood', 'label', 'observed', 'private', 'user', 'tend', 'write', 'journal', 'slightly', 'statistically', 'significantly', 'longer', 'written', 'public', 'user', 'approximately', 'character', 'figure', 'show', 'distribution', 'journal', 'length', 'spike', 'correspond', 'length', 'mood', 'character', 'default', 'limit', 'set', 'app', 'character', 'set', 'maximum', 'visualization', 'purpose', 'user', 'app', 'optionally', 'enter', 'location', 'age', 'gender', 'user', 'enter', 'information', 'found', 'revealed', 'location', 'mostly', 'north', 'america', 'revealed', 'gender', 'predominantly', 'female', 'revealed', 'age', 'average', 'age']","['analyze two', 'two datasets', 'datasets user', 'user community', 'community reddit', 'reddit journal', 'journal mental', 'mental health', 'health journalling', 'journalling mobile', 'mobile app', 'app omit', 'omit name', 'name app', 'app privacy', 'privacy refer', 'refer journalling', 'journalling app', 'app reddit', 'reddit social', 'social medium', 'medium platform', 'platform wa', 'wa originally', 'originally used', 'used sharing', 'sharing rating', 'rating content', 'content news', 'news documentary', 'documentary music', 'music user', 'user post', 'post subscribe', 'subscribe selforganized', 'selforganized community', 'community known', 'known subreddits', 'subreddits subscribing', 'subscribing subreddit', 'subreddit allows', 'allows user', 'user view', 'view post', 'post subreddit', 'subreddit advantage', 'advantage analyzing', 'analyzing reddit', 'reddit data', 'data subreddits', 'subreddits labelled', 'labelled according', 'according topic', 'topic utilizing', 'utilizing curated', 'curated list', 'list volunteer', 'volunteer reddit', 'reddit user', 'user crawled', 'crawled subreddits', 'subreddits related', 'related mental', 'mental health', 'health well', 'well subreddits', 'subreddits linked', 'linked community', 'community second', 'second dataset', 'dataset consists', 'consists anonymized', 'anonymized journal', 'journal post', 'post mobile', 'mobile app', 'app designed', 'designed help', 'help people', 'people track', 'track mood', 'mood share', 'share anonymously', 'anonymously desire', 'desire journal', 'journal post', 'post app', 'app requires', 'requires user', 'user label', 'label journal', 'journal post', 'post least', 'least one', 'one mood', 'mood selected', 'selected prepopulated', 'prepopulated list', 'list including', 'including happy', 'happy sad', 'sad etc', 'etc obtained', 'obtained journal', 'journal associated', 'associated mood', 'mood written', 'written january', 'january january', 'january amount', 'amount million', 'million journal', 'journal written', 'written approximately', 'approximately user', 'user figure', 'figure plot', 'plot number', 'number journal', 'journal posted', 'posted time', 'time journal', 'journal written', 'written first', 'first half', 'half although', 'although inspected', 'inspected topic', 'topic distribution', 'distribution per', 'per month', 'month find', 'find seasonal', 'seasonal effect', 'effect towards', 'towards beginning', 'beginning many', 'many new', 'new user', 'user registered', 'registered app', 'app eventually', 'eventually stopped', 'stopped using', 'using like', 'like weightloss', 'weightloss productivity', 'productivity apps', 'apps believe', 'believe influx', 'influx tied', 'tied user', 'user looking', 'looking improve', 'improve habit', 'habit new', 'new year', 'year resolution', 'resolution journal', 'journal set', 'set private', 'private public', 'public visible', 'visible user', 'user app', 'app roughly', 'roughly one', 'one third', 'third journal', 'journal public', 'public figure', 'figure plot', 'plot number', 'number user', 'user yaxis', 'yaxis versus', 'versus percentage', 'percentage journal', 'journal posted', 'posted publicly', 'publicly user', 'user either', 'either mostly', 'mostly private', 'private mostly', 'mostly public', 'public journal', 'journal relatively', 'relatively short', 'short like', 'like twitter', 'twitter post', 'post character', 'character average', 'average length', 'length journal', 'journal text', 'text character', 'character roughly', 'roughly journal', 'journal text', 'text mood', 'mood label', 'label observed', 'observed private', 'private user', 'user tend', 'tend write', 'write journal', 'journal slightly', 'slightly statistically', 'statistically significantly', 'significantly longer', 'longer written', 'written public', 'public user', 'user approximately', 'approximately character', 'character figure', 'figure show', 'show distribution', 'distribution journal', 'journal length', 'length spike', 'spike correspond', 'correspond length', 'length mood', 'mood character', 'character default', 'default limit', 'limit set', 'set app', 'app character', 'character set', 'set maximum', 'maximum visualization', 'visualization purpose', 'purpose user', 'user app', 'app optionally', 'optionally enter', 'enter location', 'location age', 'age gender', 'gender user', 'user enter', 'enter information', 'information found', 'found revealed', 'revealed location', 'location mostly', 'mostly north', 'north america', 'america revealed', 'revealed gender', 'gender predominantly', 'predominantly female', 'female revealed', 'revealed age', 'age average', 'average age']","['analyze two datasets', 'two datasets user', 'datasets user community', 'user community reddit', 'community reddit journal', 'reddit journal mental', 'journal mental health', 'mental health journalling', 'health journalling mobile', 'journalling mobile app', 'mobile app omit', 'app omit name', 'omit name app', 'name app privacy', 'app privacy refer', 'privacy refer journalling', 'refer journalling app', 'journalling app reddit', 'app reddit social', 'reddit social medium', 'social medium platform', 'medium platform wa', 'platform wa originally', 'wa originally used', 'originally used sharing', 'used sharing rating', 'sharing rating content', 'rating content news', 'content news documentary', 'news documentary music', 'documentary music user', 'music user post', 'user post subscribe', 'post subscribe selforganized', 'subscribe selforganized community', 'selforganized community known', 'community known subreddits', 'known subreddits subscribing', 'subreddits subscribing subreddit', 'subscribing subreddit allows', 'subreddit allows user', 'allows user view', 'user view post', 'view post subreddit', 'post subreddit advantage', 'subreddit advantage analyzing', 'advantage analyzing reddit', 'analyzing reddit data', 'reddit data subreddits', 'data subreddits labelled', 'subreddits labelled according', 'labelled according topic', 'according topic utilizing', 'topic utilizing curated', 'utilizing curated list', 'curated list volunteer', 'list volunteer reddit', 'volunteer reddit user', 'reddit user crawled', 'user crawled subreddits', 'crawled subreddits related', 'subreddits related mental', 'related mental health', 'mental health well', 'health well subreddits', 'well subreddits linked', 'subreddits linked community', 'linked community second', 'community second dataset', 'second dataset consists', 'dataset consists anonymized', 'consists anonymized journal', 'anonymized journal post', 'journal post mobile', 'post mobile app', 'mobile app designed', 'app designed help', 'designed help people', 'help people track', 'people track mood', 'track mood share', 'mood share anonymously', 'share anonymously desire', 'anonymously desire journal', 'desire journal post', 'journal post app', 'post app requires', 'app requires user', 'requires user label', 'user label journal', 'label journal post', 'journal post least', 'post least one', 'least one mood', 'one mood selected', 'mood selected prepopulated', 'selected prepopulated list', 'prepopulated list including', 'list including happy', 'including happy sad', 'happy sad etc', 'sad etc obtained', 'etc obtained journal', 'obtained journal associated', 'journal associated mood', 'associated mood written', 'mood written january', 'written january january', 'january january amount', 'january amount million', 'amount million journal', 'million journal written', 'journal written approximately', 'written approximately user', 'approximately user figure', 'user figure plot', 'figure plot number', 'plot number journal', 'number journal posted', 'journal posted time', 'posted time journal', 'time journal written', 'journal written first', 'written first half', 'first half although', 'half although inspected', 'although inspected topic', 'inspected topic distribution', 'topic distribution per', 'distribution per month', 'per month find', 'month find seasonal', 'find seasonal effect', 'seasonal effect towards', 'effect towards beginning', 'towards beginning many', 'beginning many new', 'many new user', 'new user registered', 'user registered app', 'registered app eventually', 'app eventually stopped', 'eventually stopped using', 'stopped using like', 'using like weightloss', 'like weightloss productivity', 'weightloss productivity apps', 'productivity apps believe', 'apps believe influx', 'believe influx tied', 'influx tied user', 'tied user looking', 'user looking improve', 'looking improve habit', 'improve habit new', 'habit new year', 'new year resolution', 'year resolution journal', 'resolution journal set', 'journal set private', 'set private public', 'private public visible', 'public visible user', 'visible user app', 'user app roughly', 'app roughly one', 'roughly one third', 'one third journal', 'third journal public', 'journal public figure', 'public figure plot', 'figure plot number', 'plot number user', 'number user yaxis', 'user yaxis versus', 'yaxis versus percentage', 'versus percentage journal', 'percentage journal posted', 'journal posted publicly', 'posted publicly user', 'publicly user either', 'user either mostly', 'either mostly private', 'mostly private mostly', 'private mostly public', 'mostly public journal', 'public journal relatively', 'journal relatively short', 'relatively short like', 'short like twitter', 'like twitter post', 'twitter post character', 'post character average', 'character average length', 'average length journal', 'length journal text', 'journal text character', 'text character roughly', 'character roughly journal', 'roughly journal text', 'journal text mood', 'text mood label', 'mood label observed', 'label observed private', 'observed private user', 'private user tend', 'user tend write', 'tend write journal', 'write journal slightly', 'journal slightly statistically', 'slightly statistically significantly', 'statistically significantly longer', 'significantly longer written', 'longer written public', 'written public user', 'public user approximately', 'user approximately character', 'approximately character figure', 'character figure show', 'figure show distribution', 'show distribution journal', 'distribution journal length', 'journal length spike', 'length spike correspond', 'spike correspond length', 'correspond length mood', 'length mood character', 'mood character default', 'character default limit', 'default limit set', 'limit set app', 'set app character', 'app character set', 'character set maximum', 'set maximum visualization', 'maximum visualization purpose', 'visualization purpose user', 'purpose user app', 'user app optionally', 'app optionally enter', 'optionally enter location', 'enter location age', 'location age gender', 'age gender user', 'gender user enter', 'user enter information', 'enter information found', 'information found revealed', 'found revealed location', 'revealed location mostly', 'location mostly north', 'mostly north america', 'north america revealed', 'america revealed gender', 'revealed gender predominantly', 'gender predominantly female', 'predominantly female revealed', 'female revealed age', 'revealed age average', 'age average age']",0.0,0.0,0.0,0.9966703057289124,0.0,0.0,0,0.0
https://dl.acm.org/doi/abs/10.1145/2556288.2557214,1,To understand how stigma impacts people’s health activities on search engines and social media we characterized each condition in terms of its level of social stigma. We used Amazon Mechanical Turk (www.mturk.com) to obtain ratings on the degree of social stigma for each condition on a three-point scale: 1 = low stigma 2 = moderate stigma and 3 = high stigma. For each condition we obtained 10 ratings from crowdworkers and three ratings from three human factors researchers. For conditions with agreement exceeding 50% (seven or more raters agreed on a single rating) we used the majority rating as the final measure of condition stigma. 126 out of the 165 conditions (76%) met this criterion. For the other conditions with no clear consensus we set stigma to moderate. This resulted in 81 conditions with low stigma (e.g. headache) 72 with moderate stigma (e.g. malaria) and 12 conditions with high stigma (e.g. AIDS).We focus on the social media platform Twitter a popular microblogging service used by 18% of U.S. Internet users and whose popularity continues to increase [28]. Twitter is particularly interesting to study since nearly all posts are public; the public nature of tweets provides an interesting counterpoint to the private nature of search engine activity. We gathered a 15-month sample of Twitter’s Firehose stream (which includes all public tweets) between November 1 2011 and March 31 2013 made available to us under contract focusing on English-language tweets. Twitter post count and unique user count were computed for each condition and aggregated over the full time period. Specifically we considered a post to belong to a certain health condition if there was a regular expression match of the condition to the text of the post (this would not permit substring matches within terms). To reduce noise we excluded posts that were retweets or contained hyperlinks since they were likely related to general news and not a user’s personal health. Using this method we obtained 125166549 tweets on the 165 health conditions from 62269225 users in the time period of interest. The median number of posts was 51687 per condition from a median of 40152 users per condition.,to understand how stigma impact people health activity on search engine and social medium we characterized each condition in term of it level of social stigma we used amazon mechanical turk wwwmturkcom to obtain rating on the degree of social stigma for each condition on a threepoint scale low stigma moderate stigma and high stigma for each condition we obtained rating from crowdworkers and three rating from three human factor researcher for condition with agreement exceeding seven or more raters agreed on a single rating we used the majority rating a the final measure of condition stigma out of the condition met this criterion for the other condition with no clear consensus we set stigma to moderate this resulted in condition with low stigma eg headache with moderate stigma eg malaria and condition with high stigma eg aidswe focus on the social medium platform twitter a popular microblogging service used by of u internet user and whose popularity continues to increase twitter is particularly interesting to study since nearly all post are public the public nature of tweet provides an interesting counterpoint to the private nature of search engine activity we gathered a month sample of twitter firehose stream which includes all public tweet between november and march made available to u under contract focusing on englishlanguage tweet twitter post count and unique user count were computed for each condition and aggregated over the full time period specifically we considered a post to belong to a certain health condition if there wa a regular expression match of the condition to the text of the post this would not permit substring match within term to reduce noise we excluded post that were retweets or contained hyperlink since they were likely related to general news and not a user personal health using this method we obtained tweet on the health condition from user in the time period of interest the median number of post wa per condition from a median of user per condition,"['understand', 'stigma', 'impact', 'people', 'health', 'activity', 'search', 'engine', 'social', 'medium', 'characterized', 'condition', 'term', 'level', 'social', 'stigma', 'used', 'amazon', 'mechanical', 'turk', 'wwwmturkcom', 'obtain', 'rating', 'degree', 'social', 'stigma', 'condition', 'threepoint', 'scale', 'low', 'stigma', 'moderate', 'stigma', 'high', 'stigma', 'condition', 'obtained', 'rating', 'crowdworkers', 'three', 'rating', 'three', 'human', 'factor', 'researcher', 'condition', 'agreement', 'exceeding', 'seven', 'raters', 'agreed', 'single', 'rating', 'used', 'majority', 'rating', 'final', 'measure', 'condition', 'stigma', 'condition', 'met', 'criterion', 'condition', 'clear', 'consensus', 'set', 'stigma', 'moderate', 'resulted', 'condition', 'low', 'stigma', 'eg', 'headache', 'moderate', 'stigma', 'eg', 'malaria', 'condition', 'high', 'stigma', 'eg', 'aidswe', 'focus', 'social', 'medium', 'platform', 'twitter', 'popular', 'microblogging', 'service', 'used', 'u', 'internet', 'user', 'whose', 'popularity', 'continues', 'increase', 'twitter', 'particularly', 'interesting', 'study', 'since', 'nearly', 'post', 'public', 'public', 'nature', 'tweet', 'provides', 'interesting', 'counterpoint', 'private', 'nature', 'search', 'engine', 'activity', 'gathered', 'month', 'sample', 'twitter', 'firehose', 'stream', 'includes', 'public', 'tweet', 'november', 'march', 'made', 'available', 'u', 'contract', 'focusing', 'englishlanguage', 'tweet', 'twitter', 'post', 'count', 'unique', 'user', 'count', 'computed', 'condition', 'aggregated', 'full', 'time', 'period', 'specifically', 'considered', 'post', 'belong', 'certain', 'health', 'condition', 'wa', 'regular', 'expression', 'match', 'condition', 'text', 'post', 'would', 'permit', 'substring', 'match', 'within', 'term', 'reduce', 'noise', 'excluded', 'post', 'retweets', 'contained', 'hyperlink', 'since', 'likely', 'related', 'general', 'news', 'user', 'personal', 'health', 'using', 'method', 'obtained', 'tweet', 'health', 'condition', 'user', 'time', 'period', 'interest', 'median', 'number', 'post', 'wa', 'per', 'condition', 'median', 'user', 'per', 'condition']","['understand stigma', 'stigma impact', 'impact people', 'people health', 'health activity', 'activity search', 'search engine', 'engine social', 'social medium', 'medium characterized', 'characterized condition', 'condition term', 'term level', 'level social', 'social stigma', 'stigma used', 'used amazon', 'amazon mechanical', 'mechanical turk', 'turk wwwmturkcom', 'wwwmturkcom obtain', 'obtain rating', 'rating degree', 'degree social', 'social stigma', 'stigma condition', 'condition threepoint', 'threepoint scale', 'scale low', 'low stigma', 'stigma moderate', 'moderate stigma', 'stigma high', 'high stigma', 'stigma condition', 'condition obtained', 'obtained rating', 'rating crowdworkers', 'crowdworkers three', 'three rating', 'rating three', 'three human', 'human factor', 'factor researcher', 'researcher condition', 'condition agreement', 'agreement exceeding', 'exceeding seven', 'seven raters', 'raters agreed', 'agreed single', 'single rating', 'rating used', 'used majority', 'majority rating', 'rating final', 'final measure', 'measure condition', 'condition stigma', 'stigma condition', 'condition met', 'met criterion', 'criterion condition', 'condition clear', 'clear consensus', 'consensus set', 'set stigma', 'stigma moderate', 'moderate resulted', 'resulted condition', 'condition low', 'low stigma', 'stigma eg', 'eg headache', 'headache moderate', 'moderate stigma', 'stigma eg', 'eg malaria', 'malaria condition', 'condition high', 'high stigma', 'stigma eg', 'eg aidswe', 'aidswe focus', 'focus social', 'social medium', 'medium platform', 'platform twitter', 'twitter popular', 'popular microblogging', 'microblogging service', 'service used', 'used u', 'u internet', 'internet user', 'user whose', 'whose popularity', 'popularity continues', 'continues increase', 'increase twitter', 'twitter particularly', 'particularly interesting', 'interesting study', 'study since', 'since nearly', 'nearly post', 'post public', 'public public', 'public nature', 'nature tweet', 'tweet provides', 'provides interesting', 'interesting counterpoint', 'counterpoint private', 'private nature', 'nature search', 'search engine', 'engine activity', 'activity gathered', 'gathered month', 'month sample', 'sample twitter', 'twitter firehose', 'firehose stream', 'stream includes', 'includes public', 'public tweet', 'tweet november', 'november march', 'march made', 'made available', 'available u', 'u contract', 'contract focusing', 'focusing englishlanguage', 'englishlanguage tweet', 'tweet twitter', 'twitter post', 'post count', 'count unique', 'unique user', 'user count', 'count computed', 'computed condition', 'condition aggregated', 'aggregated full', 'full time', 'time period', 'period specifically', 'specifically considered', 'considered post', 'post belong', 'belong certain', 'certain health', 'health condition', 'condition wa', 'wa regular', 'regular expression', 'expression match', 'match condition', 'condition text', 'text post', 'post would', 'would permit', 'permit substring', 'substring match', 'match within', 'within term', 'term reduce', 'reduce noise', 'noise excluded', 'excluded post', 'post retweets', 'retweets contained', 'contained hyperlink', 'hyperlink since', 'since likely', 'likely related', 'related general', 'general news', 'news user', 'user personal', 'personal health', 'health using', 'using method', 'method obtained', 'obtained tweet', 'tweet health', 'health condition', 'condition user', 'user time', 'time period', 'period interest', 'interest median', 'median number', 'number post', 'post wa', 'wa per', 'per condition', 'condition median', 'median user', 'user per', 'per condition']","['understand stigma impact', 'stigma impact people', 'impact people health', 'people health activity', 'health activity search', 'activity search engine', 'search engine social', 'engine social medium', 'social medium characterized', 'medium characterized condition', 'characterized condition term', 'condition term level', 'term level social', 'level social stigma', 'social stigma used', 'stigma used amazon', 'used amazon mechanical', 'amazon mechanical turk', 'mechanical turk wwwmturkcom', 'turk wwwmturkcom obtain', 'wwwmturkcom obtain rating', 'obtain rating degree', 'rating degree social', 'degree social stigma', 'social stigma condition', 'stigma condition threepoint', 'condition threepoint scale', 'threepoint scale low', 'scale low stigma', 'low stigma moderate', 'stigma moderate stigma', 'moderate stigma high', 'stigma high stigma', 'high stigma condition', 'stigma condition obtained', 'condition obtained rating', 'obtained rating crowdworkers', 'rating crowdworkers three', 'crowdworkers three rating', 'three rating three', 'rating three human', 'three human factor', 'human factor researcher', 'factor researcher condition', 'researcher condition agreement', 'condition agreement exceeding', 'agreement exceeding seven', 'exceeding seven raters', 'seven raters agreed', 'raters agreed single', 'agreed single rating', 'single rating used', 'rating used majority', 'used majority rating', 'majority rating final', 'rating final measure', 'final measure condition', 'measure condition stigma', 'condition stigma condition', 'stigma condition met', 'condition met criterion', 'met criterion condition', 'criterion condition clear', 'condition clear consensus', 'clear consensus set', 'consensus set stigma', 'set stigma moderate', 'stigma moderate resulted', 'moderate resulted condition', 'resulted condition low', 'condition low stigma', 'low stigma eg', 'stigma eg headache', 'eg headache moderate', 'headache moderate stigma', 'moderate stigma eg', 'stigma eg malaria', 'eg malaria condition', 'malaria condition high', 'condition high stigma', 'high stigma eg', 'stigma eg aidswe', 'eg aidswe focus', 'aidswe focus social', 'focus social medium', 'social medium platform', 'medium platform twitter', 'platform twitter popular', 'twitter popular microblogging', 'popular microblogging service', 'microblogging service used', 'service used u', 'used u internet', 'u internet user', 'internet user whose', 'user whose popularity', 'whose popularity continues', 'popularity continues increase', 'continues increase twitter', 'increase twitter particularly', 'twitter particularly interesting', 'particularly interesting study', 'interesting study since', 'study since nearly', 'since nearly post', 'nearly post public', 'post public public', 'public public nature', 'public nature tweet', 'nature tweet provides', 'tweet provides interesting', 'provides interesting counterpoint', 'interesting counterpoint private', 'counterpoint private nature', 'private nature search', 'nature search engine', 'search engine activity', 'engine activity gathered', 'activity gathered month', 'gathered month sample', 'month sample twitter', 'sample twitter firehose', 'twitter firehose stream', 'firehose stream includes', 'stream includes public', 'includes public tweet', 'public tweet november', 'tweet november march', 'november march made', 'march made available', 'made available u', 'available u contract', 'u contract focusing', 'contract focusing englishlanguage', 'focusing englishlanguage tweet', 'englishlanguage tweet twitter', 'tweet twitter post', 'twitter post count', 'post count unique', 'count unique user', 'unique user count', 'user count computed', 'count computed condition', 'computed condition aggregated', 'condition aggregated full', 'aggregated full time', 'full time period', 'time period specifically', 'period specifically considered', 'specifically considered post', 'considered post belong', 'post belong certain', 'belong certain health', 'certain health condition', 'health condition wa', 'condition wa regular', 'wa regular expression', 'regular expression match', 'expression match condition', 'match condition text', 'condition text post', 'text post would', 'post would permit', 'would permit substring', 'permit substring match', 'substring match within', 'match within term', 'within term reduce', 'term reduce noise', 'reduce noise excluded', 'noise excluded post', 'excluded post retweets', 'post retweets contained', 'retweets contained hyperlink', 'contained hyperlink since', 'hyperlink since likely', 'since likely related', 'likely related general', 'related general news', 'general news user', 'news user personal', 'user personal health', 'personal health using', 'health using method', 'using method obtained', 'method obtained tweet', 'obtained tweet health', 'tweet health condition', 'health condition user', 'condition user time', 'user time period', 'time period interest', 'period interest median', 'interest median number', 'median number post', 'number post wa', 'post wa per', 'wa per condition', 'per condition median', 'condition median user', 'median user per', 'user per condition']",0.0,0.0,0.0,0.0,0.0,0.9957286715507507,0,0.0
https://www.aaai.org/ocs/index.php/ICWSM/ICWSM14/paper/viewPaper/8075,1,reddit is a social news website where registered users submit content in the form of links or text posts. Users also known as “redditors” can then vote each submission “up” or “down” to rank the post and determine its position or prominence on the site’s pages. These two attributes associated with a post are referred to as “upvotes” and “downvotes”. Redditors can also comment on posts and respond back in a conversation tree of comments. Content entries that is the posts are organized by areas of interest or sub-communities called “subreddits” such as politics programming or science. As of 2013 reddit’s official statistics included 56 billion page views 731 million unique visitors 40855032 posts and 404603286 comments (http://blog.reddit.com/2013/ 12/top-posts-of-2013-stats-and-snoo-years.html). We used of reddit’s official API (http://www.reddit.com/ dev /api) to collect posts comments and associated metadata from several mental health subreddits: specifically using a Python wrapper PRAW (https://praw.readthedocs.org/en/ latest/index.html). The subreddits we crawled were: alcoholism anxiety bipolarreddit depression mentalhealth MMFB (Make Me Feel Better) socialanxiety SuicideWatch. All of these subreddits host public content. In order to arrive at a comprehensive list of subreddits to focus on we utilized reddit’s native subreddit search feature (http://www.reddit.com/reddits) and searched for subreddits on “mental health”. Two researchers familiar with reddit employed an initial filtering step on the search results returned so that we focus on high precision subreddits discussing mental health concerns and issues. Thereafter we focused on a snowball approach in which starting with a few seed subreddits (mentalhealth depression) we compiled a second list of “related” or “similar” subreddits that are listed in the profile pages of the seed subreddits. Following a second filtering step we arrived at the list of subreddits listed above. For each of these subreddits we obtained daily crawls of their posts in the New category. Corresponding to each post we collected information on the title of the post the body or textual content id timestamp when the post was made author id and the number of upvotes and downvotes it obtained. Since posts gather comments over a period of time following the time of sharing we crawled all of the comments per post that were shared over a three day period after the post was made. Qualitative examinations of the subreddits of interest revealed that 90% or more of the comments to any post were typically made in a three day window following the time the post is made—hence the choice. The crawl of the subreddits used in this paper We present some descriptive statistics of our crawled data. Our dataset contained 20411 posts with at least one comment and 97661 comments in all with 27102 unique users who made posts comments or both. A set of 7823 users (28.79%) were found to write both at least one post and comment. CDF of the user distribution over posts and comments is given in Figure 1. The figure shows the expected heavy tail trend observed in several social phenomena. Also see Figure 2 for the distribution of comments over time following post share. It illustrates the quick responsivity culture in the communities we study (peak at 3 hours). Some of the additional statistics of our dataset are given in Table 1. Further example titles of a few,reddit is a social news website where registered user submit content in the form of link or text post user also known a redditors can then vote each submission up or down to rank the post and determine it position or prominence on the site page these two attribute associated with a post are referred to a upvotes and downvotes redditors can also comment on post and respond back in a conversation tree of comment content entry that is the post are organized by area of interest or subcommunities called subreddits such a politics programming or science a of reddits official statistic included billion page view million unique visitor post and comment httpblogredditcom toppostsofstatsandsnooyearshtml we used of reddits official api httpwwwredditcom dev api to collect post comment and associated metadata from several mental health subreddits specifically using a python wrapper praw httpsprawreadthedocsorgen latestindexhtml the subreddits we crawled were alcoholism anxiety bipolarreddit depression mentalhealth mmfb make me feel better socialanxiety suicidewatch all of these subreddits host public content in order to arrive at a comprehensive list of subreddits to focus on we utilized reddits native subreddit search feature httpwwwredditcomreddits and searched for subreddits on mental health two researcher familiar with reddit employed an initial filtering step on the search result returned so that we focus on high precision subreddits discussing mental health concern and issue thereafter we focused on a snowball approach in which starting with a few seed subreddits mentalhealth depression we compiled a second list of related or similar subreddits that are listed in the profile page of the seed subreddits following a second filtering step we arrived at the list of subreddits listed above for each of these subreddits we obtained daily crawl of their post in the new category corresponding to each post we collected information on the title of the post the body or textual content id timestamp when the post wa made author id and the number of upvotes and downvotes it obtained since post gather comment over a period of time following the time of sharing we crawled all of the comment per post that were shared over a three day period after the post wa made qualitative examination of the subreddits of interest revealed that or more of the comment to any post were typically made in a three day window following the time the post is madehence the choice the crawl of the subreddits used in this paper we present some descriptive statistic of our crawled data our dataset contained post with at least one comment and comment in all with unique user who made post comment or both a set of user were found to write both at least one post and comment cdf of the user distribution over post and comment is given in figure the figure show the expected heavy tail trend observed in several social phenomenon also see figure for the distribution of comment over time following post share it illustrates the quick responsivity culture in the community we study peak at hour some of the additional statistic of our dataset are given in table further example title of a few,"['reddit', 'social', 'news', 'website', 'registered', 'user', 'submit', 'content', 'form', 'link', 'text', 'post', 'user', 'also', 'known', 'redditors', 'vote', 'submission', 'rank', 'post', 'determine', 'position', 'prominence', 'site', 'page', 'two', 'attribute', 'associated', 'post', 'referred', 'upvotes', 'downvotes', 'redditors', 'also', 'comment', 'post', 'respond', 'back', 'conversation', 'tree', 'comment', 'content', 'entry', 'post', 'organized', 'area', 'interest', 'subcommunities', 'called', 'subreddits', 'politics', 'programming', 'science', 'reddits', 'official', 'statistic', 'included', 'billion', 'page', 'view', 'million', 'unique', 'visitor', 'post', 'comment', 'httpblogredditcom', 'toppostsofstatsandsnooyearshtml', 'used', 'reddits', 'official', 'api', 'httpwwwredditcom', 'dev', 'api', 'collect', 'post', 'comment', 'associated', 'metadata', 'several', 'mental', 'health', 'subreddits', 'specifically', 'using', 'python', 'wrapper', 'praw', 'httpsprawreadthedocsorgen', 'latestindexhtml', 'subreddits', 'crawled', 'alcoholism', 'anxiety', 'bipolarreddit', 'depression', 'mentalhealth', 'mmfb', 'make', 'feel', 'better', 'socialanxiety', 'suicidewatch', 'subreddits', 'host', 'public', 'content', 'order', 'arrive', 'comprehensive', 'list', 'subreddits', 'focus', 'utilized', 'reddits', 'native', 'subreddit', 'search', 'feature', 'httpwwwredditcomreddits', 'searched', 'subreddits', 'mental', 'health', 'two', 'researcher', 'familiar', 'reddit', 'employed', 'initial', 'filtering', 'step', 'search', 'result', 'returned', 'focus', 'high', 'precision', 'subreddits', 'discussing', 'mental', 'health', 'concern', 'issue', 'thereafter', 'focused', 'snowball', 'approach', 'starting', 'seed', 'subreddits', 'mentalhealth', 'depression', 'compiled', 'second', 'list', 'related', 'similar', 'subreddits', 'listed', 'profile', 'page', 'seed', 'subreddits', 'following', 'second', 'filtering', 'step', 'arrived', 'list', 'subreddits', 'listed', 'subreddits', 'obtained', 'daily', 'crawl', 'post', 'new', 'category', 'corresponding', 'post', 'collected', 'information', 'title', 'post', 'body', 'textual', 'content', 'id', 'timestamp', 'post', 'wa', 'made', 'author', 'id', 'number', 'upvotes', 'downvotes', 'obtained', 'since', 'post', 'gather', 'comment', 'period', 'time', 'following', 'time', 'sharing', 'crawled', 'comment', 'per', 'post', 'shared', 'three', 'day', 'period', 'post', 'wa', 'made', 'qualitative', 'examination', 'subreddits', 'interest', 'revealed', 'comment', 'post', 'typically', 'made', 'three', 'day', 'window', 'following', 'time', 'post', 'madehence', 'choice', 'crawl', 'subreddits', 'used', 'paper', 'present', 'descriptive', 'statistic', 'crawled', 'data', 'dataset', 'contained', 'post', 'least', 'one', 'comment', 'comment', 'unique', 'user', 'made', 'post', 'comment', 'set', 'user', 'found', 'write', 'least', 'one', 'post', 'comment', 'cdf', 'user', 'distribution', 'post', 'comment', 'given', 'figure', 'figure', 'show', 'expected', 'heavy', 'tail', 'trend', 'observed', 'several', 'social', 'phenomenon', 'also', 'see', 'figure', 'distribution', 'comment', 'time', 'following', 'post', 'share', 'illustrates', 'quick', 'responsivity', 'culture', 'community', 'study', 'peak', 'hour', 'additional', 'statistic', 'dataset', 'given', 'table', 'example', 'title']","['reddit social', 'social news', 'news website', 'website registered', 'registered user', 'user submit', 'submit content', 'content form', 'form link', 'link text', 'text post', 'post user', 'user also', 'also known', 'known redditors', 'redditors vote', 'vote submission', 'submission rank', 'rank post', 'post determine', 'determine position', 'position prominence', 'prominence site', 'site page', 'page two', 'two attribute', 'attribute associated', 'associated post', 'post referred', 'referred upvotes', 'upvotes downvotes', 'downvotes redditors', 'redditors also', 'also comment', 'comment post', 'post respond', 'respond back', 'back conversation', 'conversation tree', 'tree comment', 'comment content', 'content entry', 'entry post', 'post organized', 'organized area', 'area interest', 'interest subcommunities', 'subcommunities called', 'called subreddits', 'subreddits politics', 'politics programming', 'programming science', 'science reddits', 'reddits official', 'official statistic', 'statistic included', 'included billion', 'billion page', 'page view', 'view million', 'million unique', 'unique visitor', 'visitor post', 'post comment', 'comment httpblogredditcom', 'httpblogredditcom toppostsofstatsandsnooyearshtml', 'toppostsofstatsandsnooyearshtml used', 'used reddits', 'reddits official', 'official api', 'api httpwwwredditcom', 'httpwwwredditcom dev', 'dev api', 'api collect', 'collect post', 'post comment', 'comment associated', 'associated metadata', 'metadata several', 'several mental', 'mental health', 'health subreddits', 'subreddits specifically', 'specifically using', 'using python', 'python wrapper', 'wrapper praw', 'praw httpsprawreadthedocsorgen', 'httpsprawreadthedocsorgen latestindexhtml', 'latestindexhtml subreddits', 'subreddits crawled', 'crawled alcoholism', 'alcoholism anxiety', 'anxiety bipolarreddit', 'bipolarreddit depression', 'depression mentalhealth', 'mentalhealth mmfb', 'mmfb make', 'make feel', 'feel better', 'better socialanxiety', 'socialanxiety suicidewatch', 'suicidewatch subreddits', 'subreddits host', 'host public', 'public content', 'content order', 'order arrive', 'arrive comprehensive', 'comprehensive list', 'list subreddits', 'subreddits focus', 'focus utilized', 'utilized reddits', 'reddits native', 'native subreddit', 'subreddit search', 'search feature', 'feature httpwwwredditcomreddits', 'httpwwwredditcomreddits searched', 'searched subreddits', 'subreddits mental', 'mental health', 'health two', 'two researcher', 'researcher familiar', 'familiar reddit', 'reddit employed', 'employed initial', 'initial filtering', 'filtering step', 'step search', 'search result', 'result returned', 'returned focus', 'focus high', 'high precision', 'precision subreddits', 'subreddits discussing', 'discussing mental', 'mental health', 'health concern', 'concern issue', 'issue thereafter', 'thereafter focused', 'focused snowball', 'snowball approach', 'approach starting', 'starting seed', 'seed subreddits', 'subreddits mentalhealth', 'mentalhealth depression', 'depression compiled', 'compiled second', 'second list', 'list related', 'related similar', 'similar subreddits', 'subreddits listed', 'listed profile', 'profile page', 'page seed', 'seed subreddits', 'subreddits following', 'following second', 'second filtering', 'filtering step', 'step arrived', 'arrived list', 'list subreddits', 'subreddits listed', 'listed subreddits', 'subreddits obtained', 'obtained daily', 'daily crawl', 'crawl post', 'post new', 'new category', 'category corresponding', 'corresponding post', 'post collected', 'collected information', 'information title', 'title post', 'post body', 'body textual', 'textual content', 'content id', 'id timestamp', 'timestamp post', 'post wa', 'wa made', 'made author', 'author id', 'id number', 'number upvotes', 'upvotes downvotes', 'downvotes obtained', 'obtained since', 'since post', 'post gather', 'gather comment', 'comment period', 'period time', 'time following', 'following time', 'time sharing', 'sharing crawled', 'crawled comment', 'comment per', 'per post', 'post shared', 'shared three', 'three day', 'day period', 'period post', 'post wa', 'wa made', 'made qualitative', 'qualitative examination', 'examination subreddits', 'subreddits interest', 'interest revealed', 'revealed comment', 'comment post', 'post typically', 'typically made', 'made three', 'three day', 'day window', 'window following', 'following time', 'time post', 'post madehence', 'madehence choice', 'choice crawl', 'crawl subreddits', 'subreddits used', 'used paper', 'paper present', 'present descriptive', 'descriptive statistic', 'statistic crawled', 'crawled data', 'data dataset', 'dataset contained', 'contained post', 'post least', 'least one', 'one comment', 'comment comment', 'comment unique', 'unique user', 'user made', 'made post', 'post comment', 'comment set', 'set user', 'user found', 'found write', 'write least', 'least one', 'one post', 'post comment', 'comment cdf', 'cdf user', 'user distribution', 'distribution post', 'post comment', 'comment given', 'given figure', 'figure figure', 'figure show', 'show expected', 'expected heavy', 'heavy tail', 'tail trend', 'trend observed', 'observed several', 'several social', 'social phenomenon', 'phenomenon also', 'also see', 'see figure', 'figure distribution', 'distribution comment', 'comment time', 'time following', 'following post', 'post share', 'share illustrates', 'illustrates quick', 'quick responsivity', 'responsivity culture', 'culture community', 'community study', 'study peak', 'peak hour', 'hour additional', 'additional statistic', 'statistic dataset', 'dataset given', 'given table', 'table example', 'example title']","['reddit social news', 'social news website', 'news website registered', 'website registered user', 'registered user submit', 'user submit content', 'submit content form', 'content form link', 'form link text', 'link text post', 'text post user', 'post user also', 'user also known', 'also known redditors', 'known redditors vote', 'redditors vote submission', 'vote submission rank', 'submission rank post', 'rank post determine', 'post determine position', 'determine position prominence', 'position prominence site', 'prominence site page', 'site page two', 'page two attribute', 'two attribute associated', 'attribute associated post', 'associated post referred', 'post referred upvotes', 'referred upvotes downvotes', 'upvotes downvotes redditors', 'downvotes redditors also', 'redditors also comment', 'also comment post', 'comment post respond', 'post respond back', 'respond back conversation', 'back conversation tree', 'conversation tree comment', 'tree comment content', 'comment content entry', 'content entry post', 'entry post organized', 'post organized area', 'organized area interest', 'area interest subcommunities', 'interest subcommunities called', 'subcommunities called subreddits', 'called subreddits politics', 'subreddits politics programming', 'politics programming science', 'programming science reddits', 'science reddits official', 'reddits official statistic', 'official statistic included', 'statistic included billion', 'included billion page', 'billion page view', 'page view million', 'view million unique', 'million unique visitor', 'unique visitor post', 'visitor post comment', 'post comment httpblogredditcom', 'comment httpblogredditcom toppostsofstatsandsnooyearshtml', 'httpblogredditcom toppostsofstatsandsnooyearshtml used', 'toppostsofstatsandsnooyearshtml used reddits', 'used reddits official', 'reddits official api', 'official api httpwwwredditcom', 'api httpwwwredditcom dev', 'httpwwwredditcom dev api', 'dev api collect', 'api collect post', 'collect post comment', 'post comment associated', 'comment associated metadata', 'associated metadata several', 'metadata several mental', 'several mental health', 'mental health subreddits', 'health subreddits specifically', 'subreddits specifically using', 'specifically using python', 'using python wrapper', 'python wrapper praw', 'wrapper praw httpsprawreadthedocsorgen', 'praw httpsprawreadthedocsorgen latestindexhtml', 'httpsprawreadthedocsorgen latestindexhtml subreddits', 'latestindexhtml subreddits crawled', 'subreddits crawled alcoholism', 'crawled alcoholism anxiety', 'alcoholism anxiety bipolarreddit', 'anxiety bipolarreddit depression', 'bipolarreddit depression mentalhealth', 'depression mentalhealth mmfb', 'mentalhealth mmfb make', 'mmfb make feel', 'make feel better', 'feel better socialanxiety', 'better socialanxiety suicidewatch', 'socialanxiety suicidewatch subreddits', 'suicidewatch subreddits host', 'subreddits host public', 'host public content', 'public content order', 'content order arrive', 'order arrive comprehensive', 'arrive comprehensive list', 'comprehensive list subreddits', 'list subreddits focus', 'subreddits focus utilized', 'focus utilized reddits', 'utilized reddits native', 'reddits native subreddit', 'native subreddit search', 'subreddit search feature', 'search feature httpwwwredditcomreddits', 'feature httpwwwredditcomreddits searched', 'httpwwwredditcomreddits searched subreddits', 'searched subreddits mental', 'subreddits mental health', 'mental health two', 'health two researcher', 'two researcher familiar', 'researcher familiar reddit', 'familiar reddit employed', 'reddit employed initial', 'employed initial filtering', 'initial filtering step', 'filtering step search', 'step search result', 'search result returned', 'result returned focus', 'returned focus high', 'focus high precision', 'high precision subreddits', 'precision subreddits discussing', 'subreddits discussing mental', 'discussing mental health', 'mental health concern', 'health concern issue', 'concern issue thereafter', 'issue thereafter focused', 'thereafter focused snowball', 'focused snowball approach', 'snowball approach starting', 'approach starting seed', 'starting seed subreddits', 'seed subreddits mentalhealth', 'subreddits mentalhealth depression', 'mentalhealth depression compiled', 'depression compiled second', 'compiled second list', 'second list related', 'list related similar', 'related similar subreddits', 'similar subreddits listed', 'subreddits listed profile', 'listed profile page', 'profile page seed', 'page seed subreddits', 'seed subreddits following', 'subreddits following second', 'following second filtering', 'second filtering step', 'filtering step arrived', 'step arrived list', 'arrived list subreddits', 'list subreddits listed', 'subreddits listed subreddits', 'listed subreddits obtained', 'subreddits obtained daily', 'obtained daily crawl', 'daily crawl post', 'crawl post new', 'post new category', 'new category corresponding', 'category corresponding post', 'corresponding post collected', 'post collected information', 'collected information title', 'information title post', 'title post body', 'post body textual', 'body textual content', 'textual content id', 'content id timestamp', 'id timestamp post', 'timestamp post wa', 'post wa made', 'wa made author', 'made author id', 'author id number', 'id number upvotes', 'number upvotes downvotes', 'upvotes downvotes obtained', 'downvotes obtained since', 'obtained since post', 'since post gather', 'post gather comment', 'gather comment period', 'comment period time', 'period time following', 'time following time', 'following time sharing', 'time sharing crawled', 'sharing crawled comment', 'crawled comment per', 'comment per post', 'per post shared', 'post shared three', 'shared three day', 'three day period', 'day period post', 'period post wa', 'post wa made', 'wa made qualitative', 'made qualitative examination', 'qualitative examination subreddits', 'examination subreddits interest', 'subreddits interest revealed', 'interest revealed comment', 'revealed comment post', 'comment post typically', 'post typically made', 'typically made three', 'made three day', 'three day window', 'day window following', 'window following time', 'following time post', 'time post madehence', 'post madehence choice', 'madehence choice crawl', 'choice crawl subreddits', 'crawl subreddits used', 'subreddits used paper', 'used paper present', 'paper present descriptive', 'present descriptive statistic', 'descriptive statistic crawled', 'statistic crawled data', 'crawled data dataset', 'data dataset contained', 'dataset contained post', 'contained post least', 'post least one', 'least one comment', 'one comment comment', 'comment comment unique', 'comment unique user', 'unique user made', 'user made post', 'made post comment', 'post comment set', 'comment set user', 'set user found', 'user found write', 'found write least', 'write least one', 'least one post', 'one post comment', 'post comment cdf', 'comment cdf user', 'cdf user distribution', 'user distribution post', 'distribution post comment', 'post comment given', 'comment given figure', 'given figure figure', 'figure figure show', 'figure show expected', 'show expected heavy', 'expected heavy tail', 'heavy tail trend', 'tail trend observed', 'trend observed several', 'observed several social', 'several social phenomenon', 'social phenomenon also', 'phenomenon also see', 'also see figure', 'see figure distribution', 'figure distribution comment', 'distribution comment time', 'comment time following', 'time following post', 'following post share', 'post share illustrates', 'share illustrates quick', 'illustrates quick responsivity', 'quick responsivity culture', 'responsivity culture community', 'culture community study', 'community study peak', 'study peak hour', 'peak hour additional', 'hour additional statistic', 'additional statistic dataset', 'statistic dataset given', 'dataset given table', 'given table example', 'table example title']",0.0,0.0,0.0,0.9971477389335632,0.0,0.0,0,0.0
https://dl.acm.org/doi/abs/10.1145/3025453.3025932,1,We utilized Instagram’s official API1 to obtain the dataset used in this paper. Each post in this dataset is public and contains post-related information such as the image caption likes comments hashtags filter and geolocation if tagged. Referring to prior literature [10] we adopted an iterative approach to first identify a set of appropriate distinguishing hashtags around different prominent mental illnesses prevalent in social media. With the seed tags we performed an initial data collection of 1.5 million posts shared on Instagram between Dec 2010 and Nov 2015. Then by leveraging an association rule mining approach we compiled the top k (k = 39 frequency ≥ 5000) co-occurring tags in the 1.5M posts and then appended them to the original seed tag list for further data collection. Table 1 lists a sample set of tags used to crawl the dataset. This final list of 45 tags was thereafter passed on to a psychiatry researcher to be categorized into different disorder types. For tags that described experiences or symptoms crosscutting across different conditions (e.g. “anxiety”) they were counted toward each disorder type. Table 2 gives a list of the ten different disorders identified in our data. We additionally consulted the Diagnostic and Statistical Manual of Mental Health Disorders (DSM-V [5]) that indicates these disorders to be prominent mental health challenges in populations. This categorization of the mental health challenges was conducted to ensure that our data used in the ensuing analysis focused on well-validated and clinically recognized conditions. At the same time it allowed us to focus on a diverse range of disorders expressed on social media rather than specific ones studied in prior work [12 13 27]; thus enabling us to discover generalized patterns in visual disclosures of mental health challenges in social media. Our final crawl included 2757044 posts from 151638 users spanning these disorders.Next we assessed the suitability and reliability of our collected corpus of Instagram posts and users for our later analyses. For the purpose we extracted n-grams (n=3) from the profile biographies of users. The top 10 uni- bi- and trigrams are shown in Table 3. They show that users are appropriating Instagram to seek and provide social and emotional support around different mental health concerns (“need someone talk” “feel free dm”). There are also explicit mentions of specific psychological challenges around mental health (“depression anxiety” “telling suicidal kids”) including warnings for profile visitors (“trigger warning”) and personal experiences of the condition (“alone alone alone”). We corroborated these observations with a licensed psychiatrist and concluded that the users in our dataset are engaging in genuine mental health disclosures tend to demonstrate disinhibition towards sharing their mental health experiences and are appropriating the platform specifically for this purpose via the chosen account.,we utilized instagrams official api to obtain the dataset used in this paper each post in this dataset is public and contains postrelated information such a the image caption like comment hashtags filter and geolocation if tagged referring to prior literature we adopted an iterative approach to first identify a set of appropriate distinguishing hashtags around different prominent mental illness prevalent in social medium with the seed tag we performed an initial data collection of million post shared on instagram between dec and nov then by leveraging an association rule mining approach we compiled the top k k frequency cooccurring tag in the m post and then appended them to the original seed tag list for further data collection table list a sample set of tag used to crawl the dataset this final list of tag wa thereafter passed on to a psychiatry researcher to be categorized into different disorder type for tag that described experience or symptom crosscutting across different condition eg anxiety they were counted toward each disorder type table give a list of the ten different disorder identified in our data we additionally consulted the diagnostic and statistical manual of mental health disorder dsmv that indicates these disorder to be prominent mental health challenge in population this categorization of the mental health challenge wa conducted to ensure that our data used in the ensuing analysis focused on wellvalidated and clinically recognized condition at the same time it allowed u to focus on a diverse range of disorder expressed on social medium rather than specific one studied in prior work thus enabling u to discover generalized pattern in visual disclosure of mental health challenge in social medium our final crawl included post from user spanning these disordersnext we assessed the suitability and reliability of our collected corpus of instagram post and user for our later analysis for the purpose we extracted ngrams n from the profile biography of user the top uni bi and trigram are shown in table they show that user are appropriating instagram to seek and provide social and emotional support around different mental health concern need someone talk feel free dm there are also explicit mention of specific psychological challenge around mental health depression anxiety telling suicidal kid including warning for profile visitor trigger warning and personal experience of the condition alone alone alone we corroborated these observation with a licensed psychiatrist and concluded that the user in our dataset are engaging in genuine mental health disclosure tend to demonstrate disinhibition towards sharing their mental health experience and are appropriating the platform specifically for this purpose via the chosen account,"['utilized', 'instagrams', 'official', 'api', 'obtain', 'dataset', 'used', 'paper', 'post', 'dataset', 'public', 'contains', 'postrelated', 'information', 'image', 'caption', 'like', 'comment', 'hashtags', 'filter', 'geolocation', 'tagged', 'referring', 'prior', 'literature', 'adopted', 'iterative', 'approach', 'first', 'identify', 'set', 'appropriate', 'distinguishing', 'hashtags', 'around', 'different', 'prominent', 'mental', 'illness', 'prevalent', 'social', 'medium', 'seed', 'tag', 'performed', 'initial', 'data', 'collection', 'million', 'post', 'shared', 'instagram', 'dec', 'nov', 'leveraging', 'association', 'rule', 'mining', 'approach', 'compiled', 'top', 'k', 'k', 'frequency', 'cooccurring', 'tag', 'post', 'appended', 'original', 'seed', 'tag', 'list', 'data', 'collection', 'table', 'list', 'sample', 'set', 'tag', 'used', 'crawl', 'dataset', 'final', 'list', 'tag', 'wa', 'thereafter', 'passed', 'psychiatry', 'researcher', 'categorized', 'different', 'disorder', 'type', 'tag', 'described', 'experience', 'symptom', 'crosscutting', 'across', 'different', 'condition', 'eg', 'anxiety', 'counted', 'toward', 'disorder', 'type', 'table', 'give', 'list', 'ten', 'different', 'disorder', 'identified', 'data', 'additionally', 'consulted', 'diagnostic', 'statistical', 'manual', 'mental', 'health', 'disorder', 'dsmv', 'indicates', 'disorder', 'prominent', 'mental', 'health', 'challenge', 'population', 'categorization', 'mental', 'health', 'challenge', 'wa', 'conducted', 'ensure', 'data', 'used', 'ensuing', 'analysis', 'focused', 'wellvalidated', 'clinically', 'recognized', 'condition', 'time', 'allowed', 'u', 'focus', 'diverse', 'range', 'disorder', 'expressed', 'social', 'medium', 'rather', 'specific', 'one', 'studied', 'prior', 'work', 'thus', 'enabling', 'u', 'discover', 'generalized', 'pattern', 'visual', 'disclosure', 'mental', 'health', 'challenge', 'social', 'medium', 'final', 'crawl', 'included', 'post', 'user', 'spanning', 'disordersnext', 'assessed', 'suitability', 'reliability', 'collected', 'corpus', 'instagram', 'post', 'user', 'later', 'analysis', 'purpose', 'extracted', 'ngrams', 'n', 'profile', 'biography', 'user', 'top', 'uni', 'bi', 'trigram', 'shown', 'table', 'show', 'user', 'appropriating', 'instagram', 'seek', 'provide', 'social', 'emotional', 'support', 'around', 'different', 'mental', 'health', 'concern', 'need', 'someone', 'talk', 'feel', 'free', 'dm', 'also', 'explicit', 'mention', 'specific', 'psychological', 'challenge', 'around', 'mental', 'health', 'depression', 'anxiety', 'telling', 'suicidal', 'kid', 'including', 'warning', 'profile', 'visitor', 'trigger', 'warning', 'personal', 'experience', 'condition', 'alone', 'alone', 'alone', 'corroborated', 'observation', 'licensed', 'psychiatrist', 'concluded', 'user', 'dataset', 'engaging', 'genuine', 'mental', 'health', 'disclosure', 'tend', 'demonstrate', 'disinhibition', 'towards', 'sharing', 'mental', 'health', 'experience', 'appropriating', 'platform', 'specifically', 'purpose', 'via', 'chosen', 'account']","['utilized instagrams', 'instagrams official', 'official api', 'api obtain', 'obtain dataset', 'dataset used', 'used paper', 'paper post', 'post dataset', 'dataset public', 'public contains', 'contains postrelated', 'postrelated information', 'information image', 'image caption', 'caption like', 'like comment', 'comment hashtags', 'hashtags filter', 'filter geolocation', 'geolocation tagged', 'tagged referring', 'referring prior', 'prior literature', 'literature adopted', 'adopted iterative', 'iterative approach', 'approach first', 'first identify', 'identify set', 'set appropriate', 'appropriate distinguishing', 'distinguishing hashtags', 'hashtags around', 'around different', 'different prominent', 'prominent mental', 'mental illness', 'illness prevalent', 'prevalent social', 'social medium', 'medium seed', 'seed tag', 'tag performed', 'performed initial', 'initial data', 'data collection', 'collection million', 'million post', 'post shared', 'shared instagram', 'instagram dec', 'dec nov', 'nov leveraging', 'leveraging association', 'association rule', 'rule mining', 'mining approach', 'approach compiled', 'compiled top', 'top k', 'k k', 'k frequency', 'frequency cooccurring', 'cooccurring tag', 'tag post', 'post appended', 'appended original', 'original seed', 'seed tag', 'tag list', 'list data', 'data collection', 'collection table', 'table list', 'list sample', 'sample set', 'set tag', 'tag used', 'used crawl', 'crawl dataset', 'dataset final', 'final list', 'list tag', 'tag wa', 'wa thereafter', 'thereafter passed', 'passed psychiatry', 'psychiatry researcher', 'researcher categorized', 'categorized different', 'different disorder', 'disorder type', 'type tag', 'tag described', 'described experience', 'experience symptom', 'symptom crosscutting', 'crosscutting across', 'across different', 'different condition', 'condition eg', 'eg anxiety', 'anxiety counted', 'counted toward', 'toward disorder', 'disorder type', 'type table', 'table give', 'give list', 'list ten', 'ten different', 'different disorder', 'disorder identified', 'identified data', 'data additionally', 'additionally consulted', 'consulted diagnostic', 'diagnostic statistical', 'statistical manual', 'manual mental', 'mental health', 'health disorder', 'disorder dsmv', 'dsmv indicates', 'indicates disorder', 'disorder prominent', 'prominent mental', 'mental health', 'health challenge', 'challenge population', 'population categorization', 'categorization mental', 'mental health', 'health challenge', 'challenge wa', 'wa conducted', 'conducted ensure', 'ensure data', 'data used', 'used ensuing', 'ensuing analysis', 'analysis focused', 'focused wellvalidated', 'wellvalidated clinically', 'clinically recognized', 'recognized condition', 'condition time', 'time allowed', 'allowed u', 'u focus', 'focus diverse', 'diverse range', 'range disorder', 'disorder expressed', 'expressed social', 'social medium', 'medium rather', 'rather specific', 'specific one', 'one studied', 'studied prior', 'prior work', 'work thus', 'thus enabling', 'enabling u', 'u discover', 'discover generalized', 'generalized pattern', 'pattern visual', 'visual disclosure', 'disclosure mental', 'mental health', 'health challenge', 'challenge social', 'social medium', 'medium final', 'final crawl', 'crawl included', 'included post', 'post user', 'user spanning', 'spanning disordersnext', 'disordersnext assessed', 'assessed suitability', 'suitability reliability', 'reliability collected', 'collected corpus', 'corpus instagram', 'instagram post', 'post user', 'user later', 'later analysis', 'analysis purpose', 'purpose extracted', 'extracted ngrams', 'ngrams n', 'n profile', 'profile biography', 'biography user', 'user top', 'top uni', 'uni bi', 'bi trigram', 'trigram shown', 'shown table', 'table show', 'show user', 'user appropriating', 'appropriating instagram', 'instagram seek', 'seek provide', 'provide social', 'social emotional', 'emotional support', 'support around', 'around different', 'different mental', 'mental health', 'health concern', 'concern need', 'need someone', 'someone talk', 'talk feel', 'feel free', 'free dm', 'dm also', 'also explicit', 'explicit mention', 'mention specific', 'specific psychological', 'psychological challenge', 'challenge around', 'around mental', 'mental health', 'health depression', 'depression anxiety', 'anxiety telling', 'telling suicidal', 'suicidal kid', 'kid including', 'including warning', 'warning profile', 'profile visitor', 'visitor trigger', 'trigger warning', 'warning personal', 'personal experience', 'experience condition', 'condition alone', 'alone alone', 'alone alone', 'alone corroborated', 'corroborated observation', 'observation licensed', 'licensed psychiatrist', 'psychiatrist concluded', 'concluded user', 'user dataset', 'dataset engaging', 'engaging genuine', 'genuine mental', 'mental health', 'health disclosure', 'disclosure tend', 'tend demonstrate', 'demonstrate disinhibition', 'disinhibition towards', 'towards sharing', 'sharing mental', 'mental health', 'health experience', 'experience appropriating', 'appropriating platform', 'platform specifically', 'specifically purpose', 'purpose via', 'via chosen', 'chosen account']","['utilized instagrams official', 'instagrams official api', 'official api obtain', 'api obtain dataset', 'obtain dataset used', 'dataset used paper', 'used paper post', 'paper post dataset', 'post dataset public', 'dataset public contains', 'public contains postrelated', 'contains postrelated information', 'postrelated information image', 'information image caption', 'image caption like', 'caption like comment', 'like comment hashtags', 'comment hashtags filter', 'hashtags filter geolocation', 'filter geolocation tagged', 'geolocation tagged referring', 'tagged referring prior', 'referring prior literature', 'prior literature adopted', 'literature adopted iterative', 'adopted iterative approach', 'iterative approach first', 'approach first identify', 'first identify set', 'identify set appropriate', 'set appropriate distinguishing', 'appropriate distinguishing hashtags', 'distinguishing hashtags around', 'hashtags around different', 'around different prominent', 'different prominent mental', 'prominent mental illness', 'mental illness prevalent', 'illness prevalent social', 'prevalent social medium', 'social medium seed', 'medium seed tag', 'seed tag performed', 'tag performed initial', 'performed initial data', 'initial data collection', 'data collection million', 'collection million post', 'million post shared', 'post shared instagram', 'shared instagram dec', 'instagram dec nov', 'dec nov leveraging', 'nov leveraging association', 'leveraging association rule', 'association rule mining', 'rule mining approach', 'mining approach compiled', 'approach compiled top', 'compiled top k', 'top k k', 'k k frequency', 'k frequency cooccurring', 'frequency cooccurring tag', 'cooccurring tag post', 'tag post appended', 'post appended original', 'appended original seed', 'original seed tag', 'seed tag list', 'tag list data', 'list data collection', 'data collection table', 'collection table list', 'table list sample', 'list sample set', 'sample set tag', 'set tag used', 'tag used crawl', 'used crawl dataset', 'crawl dataset final', 'dataset final list', 'final list tag', 'list tag wa', 'tag wa thereafter', 'wa thereafter passed', 'thereafter passed psychiatry', 'passed psychiatry researcher', 'psychiatry researcher categorized', 'researcher categorized different', 'categorized different disorder', 'different disorder type', 'disorder type tag', 'type tag described', 'tag described experience', 'described experience symptom', 'experience symptom crosscutting', 'symptom crosscutting across', 'crosscutting across different', 'across different condition', 'different condition eg', 'condition eg anxiety', 'eg anxiety counted', 'anxiety counted toward', 'counted toward disorder', 'toward disorder type', 'disorder type table', 'type table give', 'table give list', 'give list ten', 'list ten different', 'ten different disorder', 'different disorder identified', 'disorder identified data', 'identified data additionally', 'data additionally consulted', 'additionally consulted diagnostic', 'consulted diagnostic statistical', 'diagnostic statistical manual', 'statistical manual mental', 'manual mental health', 'mental health disorder', 'health disorder dsmv', 'disorder dsmv indicates', 'dsmv indicates disorder', 'indicates disorder prominent', 'disorder prominent mental', 'prominent mental health', 'mental health challenge', 'health challenge population', 'challenge population categorization', 'population categorization mental', 'categorization mental health', 'mental health challenge', 'health challenge wa', 'challenge wa conducted', 'wa conducted ensure', 'conducted ensure data', 'ensure data used', 'data used ensuing', 'used ensuing analysis', 'ensuing analysis focused', 'analysis focused wellvalidated', 'focused wellvalidated clinically', 'wellvalidated clinically recognized', 'clinically recognized condition', 'recognized condition time', 'condition time allowed', 'time allowed u', 'allowed u focus', 'u focus diverse', 'focus diverse range', 'diverse range disorder', 'range disorder expressed', 'disorder expressed social', 'expressed social medium', 'social medium rather', 'medium rather specific', 'rather specific one', 'specific one studied', 'one studied prior', 'studied prior work', 'prior work thus', 'work thus enabling', 'thus enabling u', 'enabling u discover', 'u discover generalized', 'discover generalized pattern', 'generalized pattern visual', 'pattern visual disclosure', 'visual disclosure mental', 'disclosure mental health', 'mental health challenge', 'health challenge social', 'challenge social medium', 'social medium final', 'medium final crawl', 'final crawl included', 'crawl included post', 'included post user', 'post user spanning', 'user spanning disordersnext', 'spanning disordersnext assessed', 'disordersnext assessed suitability', 'assessed suitability reliability', 'suitability reliability collected', 'reliability collected corpus', 'collected corpus instagram', 'corpus instagram post', 'instagram post user', 'post user later', 'user later analysis', 'later analysis purpose', 'analysis purpose extracted', 'purpose extracted ngrams', 'extracted ngrams n', 'ngrams n profile', 'n profile biography', 'profile biography user', 'biography user top', 'user top uni', 'top uni bi', 'uni bi trigram', 'bi trigram shown', 'trigram shown table', 'shown table show', 'table show user', 'show user appropriating', 'user appropriating instagram', 'appropriating instagram seek', 'instagram seek provide', 'seek provide social', 'provide social emotional', 'social emotional support', 'emotional support around', 'support around different', 'around different mental', 'different mental health', 'mental health concern', 'health concern need', 'concern need someone', 'need someone talk', 'someone talk feel', 'talk feel free', 'feel free dm', 'free dm also', 'dm also explicit', 'also explicit mention', 'explicit mention specific', 'mention specific psychological', 'specific psychological challenge', 'psychological challenge around', 'challenge around mental', 'around mental health', 'mental health depression', 'health depression anxiety', 'depression anxiety telling', 'anxiety telling suicidal', 'telling suicidal kid', 'suicidal kid including', 'kid including warning', 'including warning profile', 'warning profile visitor', 'profile visitor trigger', 'visitor trigger warning', 'trigger warning personal', 'warning personal experience', 'personal experience condition', 'experience condition alone', 'condition alone alone', 'alone alone alone', 'alone alone corroborated', 'alone corroborated observation', 'corroborated observation licensed', 'observation licensed psychiatrist', 'licensed psychiatrist concluded', 'psychiatrist concluded user', 'concluded user dataset', 'user dataset engaging', 'dataset engaging genuine', 'engaging genuine mental', 'genuine mental health', 'mental health disclosure', 'health disclosure tend', 'disclosure tend demonstrate', 'tend demonstrate disinhibition', 'demonstrate disinhibition towards', 'disinhibition towards sharing', 'towards sharing mental', 'sharing mental health', 'mental health experience', 'health experience appropriating', 'experience appropriating platform', 'appropriating platform specifically', 'platform specifically purpose', 'specifically purpose via', 'purpose via chosen', 'via chosen account']",0.9968833327293396,0.0,0.0,0.0,0.0,0.0,0,0.0
https://www.sciencedirect.com/science/article/pii/S0747563215300996,1,The 2000 randomly sampled tweets had similar follower and Klout distribution as the full sample (follower's median 335 inter-quartile range 139–821; Klout score median 38.4 inter-quartile range 29.8–43.9). Of the 2000 randomly sampled tweets 22 (1%) were not about depression in humans and were thus excluded from qualitative analysis. Of the 1978 tweets that were about depression 97% (n = 1910) were from unique Twitter handles. Themes identified in the 1978 randomly sampled tweets are presented in Table 1. Supportive or helpful tweets about depression was the most common theme (n = 787 40%) and included such messages as how to prevent depression supportive or inspirational quotes for individuals struggling with depression and how to help loved ones who are depressed. Nearly 1/3 of the tweets were coded by our research team as being from individuals who disclosed feeling depressed (n = 625 32%). All of the tweets expressing feelings of depression were from unique Twitter handles. The other themes identified were much less common. School or work-related pressures were mentioned in 3% of the tweets (n = 54) and substance use in the context of feeling depressed was found in 1% of the tweets (n = 26).,the randomly sampled tweet had similar follower and klout distribution a the full sample follower median interquartile range klout score median interquartile range of the randomly sampled tweet were not about depression in human and were thus excluded from qualitative analysis of the tweet that were about depression n were from unique twitter handle theme identified in the randomly sampled tweet are presented in table supportive or helpful tweet about depression wa the most common theme n and included such message a how to prevent depression supportive or inspirational quote for individual struggling with depression and how to help loved one who are depressed nearly of the tweet were coded by our research team a being from individual who disclosed feeling depressed n all of the tweet expressing feeling of depression were from unique twitter handle the other theme identified were much le common school or workrelated pressure were mentioned in of the tweet n and substance use in the context of feeling depressed wa found in of the tweet n,"['randomly', 'sampled', 'tweet', 'similar', 'follower', 'klout', 'distribution', 'full', 'sample', 'follower', 'median', 'interquartile', 'range', 'klout', 'score', 'median', 'interquartile', 'range', 'randomly', 'sampled', 'tweet', 'depression', 'human', 'thus', 'excluded', 'qualitative', 'analysis', 'tweet', 'depression', 'n', 'unique', 'twitter', 'handle', 'theme', 'identified', 'randomly', 'sampled', 'tweet', 'presented', 'table', 'supportive', 'helpful', 'tweet', 'depression', 'wa', 'common', 'theme', 'n', 'included', 'message', 'prevent', 'depression', 'supportive', 'inspirational', 'quote', 'individual', 'struggling', 'depression', 'help', 'loved', 'one', 'depressed', 'nearly', 'tweet', 'coded', 'research', 'team', 'individual', 'disclosed', 'feeling', 'depressed', 'n', 'tweet', 'expressing', 'feeling', 'depression', 'unique', 'twitter', 'handle', 'theme', 'identified', 'much', 'le', 'common', 'school', 'workrelated', 'pressure', 'mentioned', 'tweet', 'n', 'substance', 'use', 'context', 'feeling', 'depressed', 'wa', 'found', 'tweet', 'n']","['randomly sampled', 'sampled tweet', 'tweet similar', 'similar follower', 'follower klout', 'klout distribution', 'distribution full', 'full sample', 'sample follower', 'follower median', 'median interquartile', 'interquartile range', 'range klout', 'klout score', 'score median', 'median interquartile', 'interquartile range', 'range randomly', 'randomly sampled', 'sampled tweet', 'tweet depression', 'depression human', 'human thus', 'thus excluded', 'excluded qualitative', 'qualitative analysis', 'analysis tweet', 'tweet depression', 'depression n', 'n unique', 'unique twitter', 'twitter handle', 'handle theme', 'theme identified', 'identified randomly', 'randomly sampled', 'sampled tweet', 'tweet presented', 'presented table', 'table supportive', 'supportive helpful', 'helpful tweet', 'tweet depression', 'depression wa', 'wa common', 'common theme', 'theme n', 'n included', 'included message', 'message prevent', 'prevent depression', 'depression supportive', 'supportive inspirational', 'inspirational quote', 'quote individual', 'individual struggling', 'struggling depression', 'depression help', 'help loved', 'loved one', 'one depressed', 'depressed nearly', 'nearly tweet', 'tweet coded', 'coded research', 'research team', 'team individual', 'individual disclosed', 'disclosed feeling', 'feeling depressed', 'depressed n', 'n tweet', 'tweet expressing', 'expressing feeling', 'feeling depression', 'depression unique', 'unique twitter', 'twitter handle', 'handle theme', 'theme identified', 'identified much', 'much le', 'le common', 'common school', 'school workrelated', 'workrelated pressure', 'pressure mentioned', 'mentioned tweet', 'tweet n', 'n substance', 'substance use', 'use context', 'context feeling', 'feeling depressed', 'depressed wa', 'wa found', 'found tweet', 'tweet n']","['randomly sampled tweet', 'sampled tweet similar', 'tweet similar follower', 'similar follower klout', 'follower klout distribution', 'klout distribution full', 'distribution full sample', 'full sample follower', 'sample follower median', 'follower median interquartile', 'median interquartile range', 'interquartile range klout', 'range klout score', 'klout score median', 'score median interquartile', 'median interquartile range', 'interquartile range randomly', 'range randomly sampled', 'randomly sampled tweet', 'sampled tweet depression', 'tweet depression human', 'depression human thus', 'human thus excluded', 'thus excluded qualitative', 'excluded qualitative analysis', 'qualitative analysis tweet', 'analysis tweet depression', 'tweet depression n', 'depression n unique', 'n unique twitter', 'unique twitter handle', 'twitter handle theme', 'handle theme identified', 'theme identified randomly', 'identified randomly sampled', 'randomly sampled tweet', 'sampled tweet presented', 'tweet presented table', 'presented table supportive', 'table supportive helpful', 'supportive helpful tweet', 'helpful tweet depression', 'tweet depression wa', 'depression wa common', 'wa common theme', 'common theme n', 'theme n included', 'n included message', 'included message prevent', 'message prevent depression', 'prevent depression supportive', 'depression supportive inspirational', 'supportive inspirational quote', 'inspirational quote individual', 'quote individual struggling', 'individual struggling depression', 'struggling depression help', 'depression help loved', 'help loved one', 'loved one depressed', 'one depressed nearly', 'depressed nearly tweet', 'nearly tweet coded', 'tweet coded research', 'coded research team', 'research team individual', 'team individual disclosed', 'individual disclosed feeling', 'disclosed feeling depressed', 'feeling depressed n', 'depressed n tweet', 'n tweet expressing', 'tweet expressing feeling', 'expressing feeling depression', 'feeling depression unique', 'depression unique twitter', 'unique twitter handle', 'twitter handle theme', 'handle theme identified', 'theme identified much', 'identified much le', 'much le common', 'le common school', 'common school workrelated', 'school workrelated pressure', 'workrelated pressure mentioned', 'pressure mentioned tweet', 'mentioned tweet n', 'tweet n substance', 'n substance use', 'substance use context', 'use context feeling', 'context feeling depressed', 'feeling depressed wa', 'depressed wa found', 'wa found tweet', 'found tweet n']",0.0,0.0,0.0,0.0,0.0,0.0,0,0.9912457466125488
https://aclanthology.org/W15-1202.pdf,1,We follow the data acquisition and curation process of Coppersmith et al. (2014a) summarizing the major points here: Social media such as Twitter contains frequent public statements by users reporting diagnoses for various medical conditions. Many talk about physical health conditions (e.g. cancer flu) but some also discuss mental illness including schizophrenia. There are a variety of motivations for users to share this information on social media: to offer or seek support to fight the stigma of mental illness or perhaps to offer an explanation for certain behaviors.4 We obtain messages with these self-reported diagnoses using the Twitter API and filtered via (caseinsensitive) regular expression to require “schizo” or a close phonetic approximation to be present; our expression matched “schizophrenia” its subtypes and various approximations: “schizo” “skitzo” “skitso” “schizotypal” “schizoid” etc. All data we collect are public posts made between 2008 and 2015 and exclude any message marked as ‘private’ by the author. All use of the data reported in this paper has been approved by the appropriate Institutional Review Board (IRB). Each self-stated diagnosis included in this study was examined by a human annotator (one of the authors) to verify that it appeared to be a genuine statement of a schizophrenia diagnosis excluding jokes quotes or disingenuous statements. We obtained 174 users with an apparently genuine selfstated diagnosis of a schizophrenia-related condition. Note that we cannot be certain that the Twitter user was actually diagnosed with schizophrenia only that their statement of being diagnosed appears to be genuine. Previous work indicates that interannotator agreement for this task is good: κ = 0.77 (Coppersmith et al. 2014a). For each user we obtained a set of their public Twitter posts via the Twitter API collecting up to 3200 tweets.5 As we wish to focus on user-authored content we exclude from analysis all retweets and any tweets that contain a URL (which often contain text that the user did not author). We lowercase all words and convert any non-standard characters (including emoji) to a systematic ASCII representation via Unidecode.6 For our community controls we used randomlyselected Twitter users who primarily tweet in English. Specifically during a two week period in early 2014 each Twitter user who was included in Twitter’s 1% “spritzer” sample had an equal chance for inclusion in our pool of community controls. We then collected some of their historic tweets and assessed the language(s) they tweeted in according to the Chromium Compact Language Detector.7 Users were excluded from our community controls if their tweets were less than 75% English.8,we follow the data acquisition and curation process of coppersmith et al a summarizing the major point here social medium such a twitter contains frequent public statement by user reporting diagnosis for various medical condition many talk about physical health condition eg cancer flu but some also discus mental illness including schizophrenia there are a variety of motivation for user to share this information on social medium to offer or seek support to fight the stigma of mental illness or perhaps to offer an explanation for certain behavior we obtain message with these selfreported diagnosis using the twitter api and filtered via caseinsensitive regular expression to require schizo or a close phonetic approximation to be present our expression matched schizophrenia it subtypes and various approximation schizo skitzo skitso schizotypal schizoid etc all data we collect are public post made between and and exclude any message marked a private by the author all use of the data reported in this paper ha been approved by the appropriate institutional review board irb each selfstated diagnosis included in this study wa examined by a human annotator one of the author to verify that it appeared to be a genuine statement of a schizophrenia diagnosis excluding joke quote or disingenuous statement we obtained user with an apparently genuine selfstated diagnosis of a schizophreniarelated condition note that we cannot be certain that the twitter user wa actually diagnosed with schizophrenia only that their statement of being diagnosed appears to be genuine previous work indicates that interannotator agreement for this task is good coppersmith et al a for each user we obtained a set of their public twitter post via the twitter api collecting up to tweet a we wish to focus on userauthored content we exclude from analysis all retweets and any tweet that contain a url which often contain text that the user did not author we lowercase all word and convert any nonstandard character including emoji to a systematic ascii representation via unidecode for our community control we used randomlyselected twitter user who primarily tweet in english specifically during a two week period in early each twitter user who wa included in twitter spritzer sample had an equal chance for inclusion in our pool of community control we then collected some of their historic tweet and assessed the language they tweeted in according to the chromium compact language detector user were excluded from our community control if their tweet were le than english,"['follow', 'data', 'acquisition', 'curation', 'process', 'coppersmith', 'et', 'al', 'summarizing', 'major', 'point', 'social', 'medium', 'twitter', 'contains', 'frequent', 'public', 'statement', 'user', 'reporting', 'diagnosis', 'various', 'medical', 'condition', 'many', 'talk', 'physical', 'health', 'condition', 'eg', 'cancer', 'flu', 'also', 'discus', 'mental', 'illness', 'including', 'schizophrenia', 'variety', 'motivation', 'user', 'share', 'information', 'social', 'medium', 'offer', 'seek', 'support', 'fight', 'stigma', 'mental', 'illness', 'perhaps', 'offer', 'explanation', 'certain', 'behavior', 'obtain', 'message', 'selfreported', 'diagnosis', 'using', 'twitter', 'api', 'filtered', 'via', 'caseinsensitive', 'regular', 'expression', 'require', 'schizo', 'close', 'phonetic', 'approximation', 'present', 'expression', 'matched', 'schizophrenia', 'subtypes', 'various', 'approximation', 'schizo', 'skitzo', 'skitso', 'schizotypal', 'schizoid', 'etc', 'data', 'collect', 'public', 'post', 'made', 'exclude', 'message', 'marked', 'private', 'author', 'use', 'data', 'reported', 'paper', 'ha', 'approved', 'appropriate', 'institutional', 'review', 'board', 'irb', 'selfstated', 'diagnosis', 'included', 'study', 'wa', 'examined', 'human', 'annotator', 'one', 'author', 'verify', 'appeared', 'genuine', 'statement', 'schizophrenia', 'diagnosis', 'excluding', 'joke', 'quote', 'disingenuous', 'statement', 'obtained', 'user', 'apparently', 'genuine', 'selfstated', 'diagnosis', 'schizophreniarelated', 'condition', 'note', 'cannot', 'certain', 'twitter', 'user', 'wa', 'actually', 'diagnosed', 'schizophrenia', 'statement', 'diagnosed', 'appears', 'genuine', 'previous', 'work', 'indicates', 'interannotator', 'agreement', 'task', 'good', 'coppersmith', 'et', 'al', 'user', 'obtained', 'set', 'public', 'twitter', 'post', 'via', 'twitter', 'api', 'collecting', 'tweet', 'wish', 'focus', 'userauthored', 'content', 'exclude', 'analysis', 'retweets', 'tweet', 'contain', 'url', 'often', 'contain', 'text', 'user', 'author', 'lowercase', 'word', 'convert', 'nonstandard', 'character', 'including', 'emoji', 'systematic', 'ascii', 'representation', 'via', 'unidecode', 'community', 'control', 'used', 'randomlyselected', 'twitter', 'user', 'primarily', 'tweet', 'english', 'specifically', 'two', 'week', 'period', 'early', 'twitter', 'user', 'wa', 'included', 'twitter', 'spritzer', 'sample', 'equal', 'chance', 'inclusion', 'pool', 'community', 'control', 'collected', 'historic', 'tweet', 'assessed', 'language', 'tweeted', 'according', 'chromium', 'compact', 'language', 'detector', 'user', 'excluded', 'community', 'control', 'tweet', 'le', 'english']","['follow data', 'data acquisition', 'acquisition curation', 'curation process', 'process coppersmith', 'coppersmith et', 'et al', 'al summarizing', 'summarizing major', 'major point', 'point social', 'social medium', 'medium twitter', 'twitter contains', 'contains frequent', 'frequent public', 'public statement', 'statement user', 'user reporting', 'reporting diagnosis', 'diagnosis various', 'various medical', 'medical condition', 'condition many', 'many talk', 'talk physical', 'physical health', 'health condition', 'condition eg', 'eg cancer', 'cancer flu', 'flu also', 'also discus', 'discus mental', 'mental illness', 'illness including', 'including schizophrenia', 'schizophrenia variety', 'variety motivation', 'motivation user', 'user share', 'share information', 'information social', 'social medium', 'medium offer', 'offer seek', 'seek support', 'support fight', 'fight stigma', 'stigma mental', 'mental illness', 'illness perhaps', 'perhaps offer', 'offer explanation', 'explanation certain', 'certain behavior', 'behavior obtain', 'obtain message', 'message selfreported', 'selfreported diagnosis', 'diagnosis using', 'using twitter', 'twitter api', 'api filtered', 'filtered via', 'via caseinsensitive', 'caseinsensitive regular', 'regular expression', 'expression require', 'require schizo', 'schizo close', 'close phonetic', 'phonetic approximation', 'approximation present', 'present expression', 'expression matched', 'matched schizophrenia', 'schizophrenia subtypes', 'subtypes various', 'various approximation', 'approximation schizo', 'schizo skitzo', 'skitzo skitso', 'skitso schizotypal', 'schizotypal schizoid', 'schizoid etc', 'etc data', 'data collect', 'collect public', 'public post', 'post made', 'made exclude', 'exclude message', 'message marked', 'marked private', 'private author', 'author use', 'use data', 'data reported', 'reported paper', 'paper ha', 'ha approved', 'approved appropriate', 'appropriate institutional', 'institutional review', 'review board', 'board irb', 'irb selfstated', 'selfstated diagnosis', 'diagnosis included', 'included study', 'study wa', 'wa examined', 'examined human', 'human annotator', 'annotator one', 'one author', 'author verify', 'verify appeared', 'appeared genuine', 'genuine statement', 'statement schizophrenia', 'schizophrenia diagnosis', 'diagnosis excluding', 'excluding joke', 'joke quote', 'quote disingenuous', 'disingenuous statement', 'statement obtained', 'obtained user', 'user apparently', 'apparently genuine', 'genuine selfstated', 'selfstated diagnosis', 'diagnosis schizophreniarelated', 'schizophreniarelated condition', 'condition note', 'note cannot', 'cannot certain', 'certain twitter', 'twitter user', 'user wa', 'wa actually', 'actually diagnosed', 'diagnosed schizophrenia', 'schizophrenia statement', 'statement diagnosed', 'diagnosed appears', 'appears genuine', 'genuine previous', 'previous work', 'work indicates', 'indicates interannotator', 'interannotator agreement', 'agreement task', 'task good', 'good coppersmith', 'coppersmith et', 'et al', 'al user', 'user obtained', 'obtained set', 'set public', 'public twitter', 'twitter post', 'post via', 'via twitter', 'twitter api', 'api collecting', 'collecting tweet', 'tweet wish', 'wish focus', 'focus userauthored', 'userauthored content', 'content exclude', 'exclude analysis', 'analysis retweets', 'retweets tweet', 'tweet contain', 'contain url', 'url often', 'often contain', 'contain text', 'text user', 'user author', 'author lowercase', 'lowercase word', 'word convert', 'convert nonstandard', 'nonstandard character', 'character including', 'including emoji', 'emoji systematic', 'systematic ascii', 'ascii representation', 'representation via', 'via unidecode', 'unidecode community', 'community control', 'control used', 'used randomlyselected', 'randomlyselected twitter', 'twitter user', 'user primarily', 'primarily tweet', 'tweet english', 'english specifically', 'specifically two', 'two week', 'week period', 'period early', 'early twitter', 'twitter user', 'user wa', 'wa included', 'included twitter', 'twitter spritzer', 'spritzer sample', 'sample equal', 'equal chance', 'chance inclusion', 'inclusion pool', 'pool community', 'community control', 'control collected', 'collected historic', 'historic tweet', 'tweet assessed', 'assessed language', 'language tweeted', 'tweeted according', 'according chromium', 'chromium compact', 'compact language', 'language detector', 'detector user', 'user excluded', 'excluded community', 'community control', 'control tweet', 'tweet le', 'le english']","['follow data acquisition', 'data acquisition curation', 'acquisition curation process', 'curation process coppersmith', 'process coppersmith et', 'coppersmith et al', 'et al summarizing', 'al summarizing major', 'summarizing major point', 'major point social', 'point social medium', 'social medium twitter', 'medium twitter contains', 'twitter contains frequent', 'contains frequent public', 'frequent public statement', 'public statement user', 'statement user reporting', 'user reporting diagnosis', 'reporting diagnosis various', 'diagnosis various medical', 'various medical condition', 'medical condition many', 'condition many talk', 'many talk physical', 'talk physical health', 'physical health condition', 'health condition eg', 'condition eg cancer', 'eg cancer flu', 'cancer flu also', 'flu also discus', 'also discus mental', 'discus mental illness', 'mental illness including', 'illness including schizophrenia', 'including schizophrenia variety', 'schizophrenia variety motivation', 'variety motivation user', 'motivation user share', 'user share information', 'share information social', 'information social medium', 'social medium offer', 'medium offer seek', 'offer seek support', 'seek support fight', 'support fight stigma', 'fight stigma mental', 'stigma mental illness', 'mental illness perhaps', 'illness perhaps offer', 'perhaps offer explanation', 'offer explanation certain', 'explanation certain behavior', 'certain behavior obtain', 'behavior obtain message', 'obtain message selfreported', 'message selfreported diagnosis', 'selfreported diagnosis using', 'diagnosis using twitter', 'using twitter api', 'twitter api filtered', 'api filtered via', 'filtered via caseinsensitive', 'via caseinsensitive regular', 'caseinsensitive regular expression', 'regular expression require', 'expression require schizo', 'require schizo close', 'schizo close phonetic', 'close phonetic approximation', 'phonetic approximation present', 'approximation present expression', 'present expression matched', 'expression matched schizophrenia', 'matched schizophrenia subtypes', 'schizophrenia subtypes various', 'subtypes various approximation', 'various approximation schizo', 'approximation schizo skitzo', 'schizo skitzo skitso', 'skitzo skitso schizotypal', 'skitso schizotypal schizoid', 'schizotypal schizoid etc', 'schizoid etc data', 'etc data collect', 'data collect public', 'collect public post', 'public post made', 'post made exclude', 'made exclude message', 'exclude message marked', 'message marked private', 'marked private author', 'private author use', 'author use data', 'use data reported', 'data reported paper', 'reported paper ha', 'paper ha approved', 'ha approved appropriate', 'approved appropriate institutional', 'appropriate institutional review', 'institutional review board', 'review board irb', 'board irb selfstated', 'irb selfstated diagnosis', 'selfstated diagnosis included', 'diagnosis included study', 'included study wa', 'study wa examined', 'wa examined human', 'examined human annotator', 'human annotator one', 'annotator one author', 'one author verify', 'author verify appeared', 'verify appeared genuine', 'appeared genuine statement', 'genuine statement schizophrenia', 'statement schizophrenia diagnosis', 'schizophrenia diagnosis excluding', 'diagnosis excluding joke', 'excluding joke quote', 'joke quote disingenuous', 'quote disingenuous statement', 'disingenuous statement obtained', 'statement obtained user', 'obtained user apparently', 'user apparently genuine', 'apparently genuine selfstated', 'genuine selfstated diagnosis', 'selfstated diagnosis schizophreniarelated', 'diagnosis schizophreniarelated condition', 'schizophreniarelated condition note', 'condition note cannot', 'note cannot certain', 'cannot certain twitter', 'certain twitter user', 'twitter user wa', 'user wa actually', 'wa actually diagnosed', 'actually diagnosed schizophrenia', 'diagnosed schizophrenia statement', 'schizophrenia statement diagnosed', 'statement diagnosed appears', 'diagnosed appears genuine', 'appears genuine previous', 'genuine previous work', 'previous work indicates', 'work indicates interannotator', 'indicates interannotator agreement', 'interannotator agreement task', 'agreement task good', 'task good coppersmith', 'good coppersmith et', 'coppersmith et al', 'et al user', 'al user obtained', 'user obtained set', 'obtained set public', 'set public twitter', 'public twitter post', 'twitter post via', 'post via twitter', 'via twitter api', 'twitter api collecting', 'api collecting tweet', 'collecting tweet wish', 'tweet wish focus', 'wish focus userauthored', 'focus userauthored content', 'userauthored content exclude', 'content exclude analysis', 'exclude analysis retweets', 'analysis retweets tweet', 'retweets tweet contain', 'tweet contain url', 'contain url often', 'url often contain', 'often contain text', 'contain text user', 'text user author', 'user author lowercase', 'author lowercase word', 'lowercase word convert', 'word convert nonstandard', 'convert nonstandard character', 'nonstandard character including', 'character including emoji', 'including emoji systematic', 'emoji systematic ascii', 'systematic ascii representation', 'ascii representation via', 'representation via unidecode', 'via unidecode community', 'unidecode community control', 'community control used', 'control used randomlyselected', 'used randomlyselected twitter', 'randomlyselected twitter user', 'twitter user primarily', 'user primarily tweet', 'primarily tweet english', 'tweet english specifically', 'english specifically two', 'specifically two week', 'two week period', 'week period early', 'period early twitter', 'early twitter user', 'twitter user wa', 'user wa included', 'wa included twitter', 'included twitter spritzer', 'twitter spritzer sample', 'spritzer sample equal', 'sample equal chance', 'equal chance inclusion', 'chance inclusion pool', 'inclusion pool community', 'pool community control', 'community control collected', 'control collected historic', 'collected historic tweet', 'historic tweet assessed', 'tweet assessed language', 'assessed language tweeted', 'language tweeted according', 'tweeted according chromium', 'according chromium compact', 'chromium compact language', 'compact language detector', 'language detector user', 'detector user excluded', 'user excluded community', 'excluded community control', 'community control tweet', 'control tweet le', 'tweet le english']",0.0,0.2104617804288864,0.7864612936973572,0.0,0.0,0.0,0,0.0
https://dl.acm.org/doi/abs/10.1145/2700171.2791026,1,We begin by constructing a baseline as to the expected variability in posts by measuring pairs of subsequent two week periods. Deviations from these expected trends following a celebrity suicide would provide evidence for the Werther effect. Our goal is therefore to identify per celebrity a set of k consecutive two-week time period pairs in the entire timeframe of our data. We refer to the first item of the pair (i.e. the first two-week window) as the “preceding” window and the immediately following two-week window as the “succeeding” window. Collectively these baseline pairs yield an empirical distribution of the expected variation when there is not a celebrity suicide. Specifically each of the k two-week window pairs (1) have no reported celebrity suicide and (2) take periods that start on the same as the day of week. This accounts for day-ofweek related variations on SW. For the purposes of this paper we choose k as 20.,we begin by constructing a baseline a to the expected variability in post by measuring pair of subsequent two week period deviation from these expected trend following a celebrity suicide would provide evidence for the werther effect our goal is therefore to identify per celebrity a set of k consecutive twoweek time period pair in the entire timeframe of our data we refer to the first item of the pair ie the first twoweek window a the preceding window and the immediately following twoweek window a the succeeding window collectively these baseline pair yield an empirical distribution of the expected variation when there is not a celebrity suicide specifically each of the k twoweek window pair have no reported celebrity suicide and take period that start on the same a the day of week this account for dayofweek related variation on sw for the purpose of this paper we choose k a,"['begin', 'constructing', 'baseline', 'expected', 'variability', 'post', 'measuring', 'pair', 'subsequent', 'two', 'week', 'period', 'deviation', 'expected', 'trend', 'following', 'celebrity', 'suicide', 'would', 'provide', 'evidence', 'werther', 'effect', 'goal', 'therefore', 'identify', 'per', 'celebrity', 'set', 'k', 'consecutive', 'twoweek', 'time', 'period', 'pair', 'entire', 'timeframe', 'data', 'refer', 'first', 'item', 'pair', 'ie', 'first', 'twoweek', 'window', 'preceding', 'window', 'immediately', 'following', 'twoweek', 'window', 'succeeding', 'window', 'collectively', 'baseline', 'pair', 'yield', 'empirical', 'distribution', 'expected', 'variation', 'celebrity', 'suicide', 'specifically', 'k', 'twoweek', 'window', 'pair', 'reported', 'celebrity', 'suicide', 'take', 'period', 'start', 'day', 'week', 'account', 'dayofweek', 'related', 'variation', 'sw', 'purpose', 'paper', 'choose', 'k']","['begin constructing', 'constructing baseline', 'baseline expected', 'expected variability', 'variability post', 'post measuring', 'measuring pair', 'pair subsequent', 'subsequent two', 'two week', 'week period', 'period deviation', 'deviation expected', 'expected trend', 'trend following', 'following celebrity', 'celebrity suicide', 'suicide would', 'would provide', 'provide evidence', 'evidence werther', 'werther effect', 'effect goal', 'goal therefore', 'therefore identify', 'identify per', 'per celebrity', 'celebrity set', 'set k', 'k consecutive', 'consecutive twoweek', 'twoweek time', 'time period', 'period pair', 'pair entire', 'entire timeframe', 'timeframe data', 'data refer', 'refer first', 'first item', 'item pair', 'pair ie', 'ie first', 'first twoweek', 'twoweek window', 'window preceding', 'preceding window', 'window immediately', 'immediately following', 'following twoweek', 'twoweek window', 'window succeeding', 'succeeding window', 'window collectively', 'collectively baseline', 'baseline pair', 'pair yield', 'yield empirical', 'empirical distribution', 'distribution expected', 'expected variation', 'variation celebrity', 'celebrity suicide', 'suicide specifically', 'specifically k', 'k twoweek', 'twoweek window', 'window pair', 'pair reported', 'reported celebrity', 'celebrity suicide', 'suicide take', 'take period', 'period start', 'start day', 'day week', 'week account', 'account dayofweek', 'dayofweek related', 'related variation', 'variation sw', 'sw purpose', 'purpose paper', 'paper choose', 'choose k']","['begin constructing baseline', 'constructing baseline expected', 'baseline expected variability', 'expected variability post', 'variability post measuring', 'post measuring pair', 'measuring pair subsequent', 'pair subsequent two', 'subsequent two week', 'two week period', 'week period deviation', 'period deviation expected', 'deviation expected trend', 'expected trend following', 'trend following celebrity', 'following celebrity suicide', 'celebrity suicide would', 'suicide would provide', 'would provide evidence', 'provide evidence werther', 'evidence werther effect', 'werther effect goal', 'effect goal therefore', 'goal therefore identify', 'therefore identify per', 'identify per celebrity', 'per celebrity set', 'celebrity set k', 'set k consecutive', 'k consecutive twoweek', 'consecutive twoweek time', 'twoweek time period', 'time period pair', 'period pair entire', 'pair entire timeframe', 'entire timeframe data', 'timeframe data refer', 'data refer first', 'refer first item', 'first item pair', 'item pair ie', 'pair ie first', 'ie first twoweek', 'first twoweek window', 'twoweek window preceding', 'window preceding window', 'preceding window immediately', 'window immediately following', 'immediately following twoweek', 'following twoweek window', 'twoweek window succeeding', 'window succeeding window', 'succeeding window collectively', 'window collectively baseline', 'collectively baseline pair', 'baseline pair yield', 'pair yield empirical', 'yield empirical distribution', 'empirical distribution expected', 'distribution expected variation', 'expected variation celebrity', 'variation celebrity suicide', 'celebrity suicide specifically', 'suicide specifically k', 'specifically k twoweek', 'k twoweek window', 'twoweek window pair', 'window pair reported', 'pair reported celebrity', 'reported celebrity suicide', 'celebrity suicide take', 'suicide take period', 'take period start', 'period start day', 'start day week', 'day week account', 'week account dayofweek', 'account dayofweek related', 'dayofweek related variation', 'related variation sw', 'variation sw purpose', 'sw purpose paper', 'purpose paper choose', 'paper choose k']",0.0,0.0,0.0,0.9899372458457947,0.0,0.0,0,0.0
https://aclanthology.org/W17-3110.pdf,1,We briefly explain the data collection method here but we refer the interested reader with further questions on the methodology to Coppersmith et al. (2016) for the suicide attempt data and Coppersmith et al. (2014a) for all other conditions. The data for these analyses are Twitter posts collected via two methods. Most of the data come from users who have publicly discussed their mental health conditions. These users are frequently referred to as “self-stated diagnosis” users as they state publicly something like “I was diagnosed with schizophrenia” or “I’m so thankful to have survived my suicide attempt last year”. The data for users with a suicide attempt was supplemented by data from OurDataHelps.org a data donation site where people provide access to their public posts and fill out a short questionnaire about their mental health history. Data are then deidentified and made available to researchers addressing questions of interest to the mental health community. Donors provide consent for their data to be used in mental health research upon signup. Of the users who attempted suicide 146 came from OurDataHelps.org. Specifically we examine generalized anxiety disorder eating disorders panic attacks schizophrenia and attempted suicides. These conditions were selected based on the theory that there are important timing aspects to their symptoms – ebbing and flowing of symptoms as treatment is effective (especially schizophrenia) onset and exacerbation of symptoms by external events and stress and punctuated events in time of psychological symptoms (suicide attempts panic attacks and binging/purging behavior with eating disorders). We use the Twitter streaming API to collect a sample of users who used a series of mental health words or phrases in their tweet text (e.g. ‘schizophrenia‘ or ‘suicide attempt‘). Each tweet that uses one of these phrases is examined via regular expression to indicate that the user is talking about themselves. Finally those tweets that pass the regular expression are examined by a human to confirm (to the best of our ability) that their selfstatement of diagnosis appears to be genuine. This results in a dataset with users that have a self-stated diagnosis of generalized anxiety disorder (n = 2408) an eating disorder (749) panic attacks (263) schizophrenia (350) or someone who would go on to attempt suicide (423). Some of these users do not exhibit the sort of posting behavior required to create micropatterns (i.e. they rarely post multiple times within a 3 hour time window). We exclude these users from our analysis which is 5-9% of users for most conditions with the exception of those with a suicide attempt where a little over half the users do not exhibit this posting behavior. The resultant dataset used for analyses is: generalized anxiety disorder (n = 2271) eating disorders (687) panic attacks (247) schizophrenia (318) suicide attempts (157). In order to allow comparisons of each condition to control users we gather a random sample of 10000 Twitter users for whom at least 75% of their posts are identified by Twitter as English. All the users with a self-stated diagnoses and all members of this control population have their age and gender estimated according to Sap et al. (2014). For each user with a self-stated diagnosis we find a matched control through the following procedure: create a pool of users where the estimated gender matches and the estimated age is within the same 10-year bracket (the suggested accuracy of the age estimator). From that pool of age- and gender- matched users we select the user whose tweets start and end over the most similar timeframe. We will refer to these age- gender- and time-matched controls simply as “matched controls” throughout the rest of this paper. All tweets were publicly posted by their author (i.e. no users marked at “protected” or “private” were included). On average users had 2949 tweets. The distribution of estimated age and genders for users with each self-stated condition can be seen in Figure 1. For most conditions the population skews female though for schizophrenia the genders are roughly balanced. The average age tends to be in the early-to-mid 20s.,we briefly explain the data collection method here but we refer the interested reader with further question on the methodology to coppersmith et al for the suicide attempt data and coppersmith et al a for all other condition the data for these analysis are twitter post collected via two method most of the data come from user who have publicly discussed their mental health condition these user are frequently referred to a selfstated diagnosis user a they state publicly something like i wa diagnosed with schizophrenia or im so thankful to have survived my suicide attempt last year the data for user with a suicide attempt wa supplemented by data from ourdatahelpsorg a data donation site where people provide access to their public post and fill out a short questionnaire about their mental health history data are then deidentified and made available to researcher addressing question of interest to the mental health community donor provide consent for their data to be used in mental health research upon signup of the user who attempted suicide came from ourdatahelpsorg specifically we examine generalized anxiety disorder eating disorder panic attack schizophrenia and attempted suicide these condition were selected based on the theory that there are important timing aspect to their symptom ebbing and flowing of symptom a treatment is effective especially schizophrenia onset and exacerbation of symptom by external event and stress and punctuated event in time of psychological symptom suicide attempt panic attack and bingingpurging behavior with eating disorder we use the twitter streaming api to collect a sample of user who used a series of mental health word or phrase in their tweet text eg schizophrenia or suicide attempt each tweet that us one of these phrase is examined via regular expression to indicate that the user is talking about themselves finally those tweet that pas the regular expression are examined by a human to confirm to the best of our ability that their selfstatement of diagnosis appears to be genuine this result in a dataset with user that have a selfstated diagnosis of generalized anxiety disorder n an eating disorder panic attack schizophrenia or someone who would go on to attempt suicide some of these user do not exhibit the sort of posting behavior required to create micropatterns ie they rarely post multiple time within a hour time window we exclude these user from our analysis which is of user for most condition with the exception of those with a suicide attempt where a little over half the user do not exhibit this posting behavior the resultant dataset used for analysis is generalized anxiety disorder n eating disorder panic attack schizophrenia suicide attempt in order to allow comparison of each condition to control user we gather a random sample of twitter user for whom at least of their post are identified by twitter a english all the user with a selfstated diagnosis and all member of this control population have their age and gender estimated according to sap et al for each user with a selfstated diagnosis we find a matched control through the following procedure create a pool of user where the estimated gender match and the estimated age is within the same year bracket the suggested accuracy of the age estimator from that pool of age and gender matched user we select the user whose tweet start and end over the most similar timeframe we will refer to these age gender and timematched control simply a matched control throughout the rest of this paper all tweet were publicly posted by their author ie no user marked at protected or private were included on average user had tweet the distribution of estimated age and gender for user with each selfstated condition can be seen in figure for most condition the population skews female though for schizophrenia the gender are roughly balanced the average age tends to be in the earlytomid s,"['briefly', 'explain', 'data', 'collection', 'method', 'refer', 'interested', 'reader', 'question', 'methodology', 'coppersmith', 'et', 'al', 'suicide', 'attempt', 'data', 'coppersmith', 'et', 'al', 'condition', 'data', 'analysis', 'twitter', 'post', 'collected', 'via', 'two', 'method', 'data', 'come', 'user', 'publicly', 'discussed', 'mental', 'health', 'condition', 'user', 'frequently', 'referred', 'selfstated', 'diagnosis', 'user', 'state', 'publicly', 'something', 'like', 'wa', 'diagnosed', 'schizophrenia', 'im', 'thankful', 'survived', 'suicide', 'attempt', 'last', 'year', 'data', 'user', 'suicide', 'attempt', 'wa', 'supplemented', 'data', 'ourdatahelpsorg', 'data', 'donation', 'site', 'people', 'provide', 'access', 'public', 'post', 'fill', 'short', 'questionnaire', 'mental', 'health', 'history', 'data', 'deidentified', 'made', 'available', 'researcher', 'addressing', 'question', 'interest', 'mental', 'health', 'community', 'donor', 'provide', 'consent', 'data', 'used', 'mental', 'health', 'research', 'upon', 'signup', 'user', 'attempted', 'suicide', 'came', 'ourdatahelpsorg', 'specifically', 'examine', 'generalized', 'anxiety', 'disorder', 'eating', 'disorder', 'panic', 'attack', 'schizophrenia', 'attempted', 'suicide', 'condition', 'selected', 'based', 'theory', 'important', 'timing', 'aspect', 'symptom', 'ebbing', 'flowing', 'symptom', 'treatment', 'effective', 'especially', 'schizophrenia', 'onset', 'exacerbation', 'symptom', 'external', 'event', 'stress', 'punctuated', 'event', 'time', 'psychological', 'symptom', 'suicide', 'attempt', 'panic', 'attack', 'bingingpurging', 'behavior', 'eating', 'disorder', 'use', 'twitter', 'streaming', 'api', 'collect', 'sample', 'user', 'used', 'series', 'mental', 'health', 'word', 'phrase', 'tweet', 'text', 'eg', 'schizophrenia', 'suicide', 'attempt', 'tweet', 'us', 'one', 'phrase', 'examined', 'via', 'regular', 'expression', 'indicate', 'user', 'talking', 'finally', 'tweet', 'pas', 'regular', 'expression', 'examined', 'human', 'confirm', 'best', 'ability', 'selfstatement', 'diagnosis', 'appears', 'genuine', 'result', 'dataset', 'user', 'selfstated', 'diagnosis', 'generalized', 'anxiety', 'disorder', 'n', 'eating', 'disorder', 'panic', 'attack', 'schizophrenia', 'someone', 'would', 'go', 'attempt', 'suicide', 'user', 'exhibit', 'sort', 'posting', 'behavior', 'required', 'create', 'micropatterns', 'ie', 'rarely', 'post', 'multiple', 'time', 'within', 'hour', 'time', 'window', 'exclude', 'user', 'analysis', 'user', 'condition', 'exception', 'suicide', 'attempt', 'little', 'half', 'user', 'exhibit', 'posting', 'behavior', 'resultant', 'dataset', 'used', 'analysis', 'generalized', 'anxiety', 'disorder', 'n', 'eating', 'disorder', 'panic', 'attack', 'schizophrenia', 'suicide', 'attempt', 'order', 'allow', 'comparison', 'condition', 'control', 'user', 'gather', 'random', 'sample', 'twitter', 'user', 'least', 'post', 'identified', 'twitter', 'english', 'user', 'selfstated', 'diagnosis', 'member', 'control', 'population', 'age', 'gender', 'estimated', 'according', 'sap', 'et', 'al', 'user', 'selfstated', 'diagnosis', 'find', 'matched', 'control', 'following', 'procedure', 'create', 'pool', 'user', 'estimated', 'gender', 'match', 'estimated', 'age', 'within', 'year', 'bracket', 'suggested', 'accuracy', 'age', 'estimator', 'pool', 'age', 'gender', 'matched', 'user', 'select', 'user', 'whose', 'tweet', 'start', 'end', 'similar', 'timeframe', 'refer', 'age', 'gender', 'timematched', 'control', 'simply', 'matched', 'control', 'throughout', 'rest', 'paper', 'tweet', 'publicly', 'posted', 'author', 'ie', 'user', 'marked', 'protected', 'private', 'included', 'average', 'user', 'tweet', 'distribution', 'estimated', 'age', 'gender', 'user', 'selfstated', 'condition', 'seen', 'figure', 'condition', 'population', 'skews', 'female', 'though', 'schizophrenia', 'gender', 'roughly', 'balanced', 'average', 'age', 'tends', 'earlytomid']","['briefly explain', 'explain data', 'data collection', 'collection method', 'method refer', 'refer interested', 'interested reader', 'reader question', 'question methodology', 'methodology coppersmith', 'coppersmith et', 'et al', 'al suicide', 'suicide attempt', 'attempt data', 'data coppersmith', 'coppersmith et', 'et al', 'al condition', 'condition data', 'data analysis', 'analysis twitter', 'twitter post', 'post collected', 'collected via', 'via two', 'two method', 'method data', 'data come', 'come user', 'user publicly', 'publicly discussed', 'discussed mental', 'mental health', 'health condition', 'condition user', 'user frequently', 'frequently referred', 'referred selfstated', 'selfstated diagnosis', 'diagnosis user', 'user state', 'state publicly', 'publicly something', 'something like', 'like wa', 'wa diagnosed', 'diagnosed schizophrenia', 'schizophrenia im', 'im thankful', 'thankful survived', 'survived suicide', 'suicide attempt', 'attempt last', 'last year', 'year data', 'data user', 'user suicide', 'suicide attempt', 'attempt wa', 'wa supplemented', 'supplemented data', 'data ourdatahelpsorg', 'ourdatahelpsorg data', 'data donation', 'donation site', 'site people', 'people provide', 'provide access', 'access public', 'public post', 'post fill', 'fill short', 'short questionnaire', 'questionnaire mental', 'mental health', 'health history', 'history data', 'data deidentified', 'deidentified made', 'made available', 'available researcher', 'researcher addressing', 'addressing question', 'question interest', 'interest mental', 'mental health', 'health community', 'community donor', 'donor provide', 'provide consent', 'consent data', 'data used', 'used mental', 'mental health', 'health research', 'research upon', 'upon signup', 'signup user', 'user attempted', 'attempted suicide', 'suicide came', 'came ourdatahelpsorg', 'ourdatahelpsorg specifically', 'specifically examine', 'examine generalized', 'generalized anxiety', 'anxiety disorder', 'disorder eating', 'eating disorder', 'disorder panic', 'panic attack', 'attack schizophrenia', 'schizophrenia attempted', 'attempted suicide', 'suicide condition', 'condition selected', 'selected based', 'based theory', 'theory important', 'important timing', 'timing aspect', 'aspect symptom', 'symptom ebbing', 'ebbing flowing', 'flowing symptom', 'symptom treatment', 'treatment effective', 'effective especially', 'especially schizophrenia', 'schizophrenia onset', 'onset exacerbation', 'exacerbation symptom', 'symptom external', 'external event', 'event stress', 'stress punctuated', 'punctuated event', 'event time', 'time psychological', 'psychological symptom', 'symptom suicide', 'suicide attempt', 'attempt panic', 'panic attack', 'attack bingingpurging', 'bingingpurging behavior', 'behavior eating', 'eating disorder', 'disorder use', 'use twitter', 'twitter streaming', 'streaming api', 'api collect', 'collect sample', 'sample user', 'user used', 'used series', 'series mental', 'mental health', 'health word', 'word phrase', 'phrase tweet', 'tweet text', 'text eg', 'eg schizophrenia', 'schizophrenia suicide', 'suicide attempt', 'attempt tweet', 'tweet us', 'us one', 'one phrase', 'phrase examined', 'examined via', 'via regular', 'regular expression', 'expression indicate', 'indicate user', 'user talking', 'talking finally', 'finally tweet', 'tweet pas', 'pas regular', 'regular expression', 'expression examined', 'examined human', 'human confirm', 'confirm best', 'best ability', 'ability selfstatement', 'selfstatement diagnosis', 'diagnosis appears', 'appears genuine', 'genuine result', 'result dataset', 'dataset user', 'user selfstated', 'selfstated diagnosis', 'diagnosis generalized', 'generalized anxiety', 'anxiety disorder', 'disorder n', 'n eating', 'eating disorder', 'disorder panic', 'panic attack', 'attack schizophrenia', 'schizophrenia someone', 'someone would', 'would go', 'go attempt', 'attempt suicide', 'suicide user', 'user exhibit', 'exhibit sort', 'sort posting', 'posting behavior', 'behavior required', 'required create', 'create micropatterns', 'micropatterns ie', 'ie rarely', 'rarely post', 'post multiple', 'multiple time', 'time within', 'within hour', 'hour time', 'time window', 'window exclude', 'exclude user', 'user analysis', 'analysis user', 'user condition', 'condition exception', 'exception suicide', 'suicide attempt', 'attempt little', 'little half', 'half user', 'user exhibit', 'exhibit posting', 'posting behavior', 'behavior resultant', 'resultant dataset', 'dataset used', 'used analysis', 'analysis generalized', 'generalized anxiety', 'anxiety disorder', 'disorder n', 'n eating', 'eating disorder', 'disorder panic', 'panic attack', 'attack schizophrenia', 'schizophrenia suicide', 'suicide attempt', 'attempt order', 'order allow', 'allow comparison', 'comparison condition', 'condition control', 'control user', 'user gather', 'gather random', 'random sample', 'sample twitter', 'twitter user', 'user least', 'least post', 'post identified', 'identified twitter', 'twitter english', 'english user', 'user selfstated', 'selfstated diagnosis', 'diagnosis member', 'member control', 'control population', 'population age', 'age gender', 'gender estimated', 'estimated according', 'according sap', 'sap et', 'et al', 'al user', 'user selfstated', 'selfstated diagnosis', 'diagnosis find', 'find matched', 'matched control', 'control following', 'following procedure', 'procedure create', 'create pool', 'pool user', 'user estimated', 'estimated gender', 'gender match', 'match estimated', 'estimated age', 'age within', 'within year', 'year bracket', 'bracket suggested', 'suggested accuracy', 'accuracy age', 'age estimator', 'estimator pool', 'pool age', 'age gender', 'gender matched', 'matched user', 'user select', 'select user', 'user whose', 'whose tweet', 'tweet start', 'start end', 'end similar', 'similar timeframe', 'timeframe refer', 'refer age', 'age gender', 'gender timematched', 'timematched control', 'control simply', 'simply matched', 'matched control', 'control throughout', 'throughout rest', 'rest paper', 'paper tweet', 'tweet publicly', 'publicly posted', 'posted author', 'author ie', 'ie user', 'user marked', 'marked protected', 'protected private', 'private included', 'included average', 'average user', 'user tweet', 'tweet distribution', 'distribution estimated', 'estimated age', 'age gender', 'gender user', 'user selfstated', 'selfstated condition', 'condition seen', 'seen figure', 'figure condition', 'condition population', 'population skews', 'skews female', 'female though', 'though schizophrenia', 'schizophrenia gender', 'gender roughly', 'roughly balanced', 'balanced average', 'average age', 'age tends', 'tends earlytomid']","['briefly explain data', 'explain data collection', 'data collection method', 'collection method refer', 'method refer interested', 'refer interested reader', 'interested reader question', 'reader question methodology', 'question methodology coppersmith', 'methodology coppersmith et', 'coppersmith et al', 'et al suicide', 'al suicide attempt', 'suicide attempt data', 'attempt data coppersmith', 'data coppersmith et', 'coppersmith et al', 'et al condition', 'al condition data', 'condition data analysis', 'data analysis twitter', 'analysis twitter post', 'twitter post collected', 'post collected via', 'collected via two', 'via two method', 'two method data', 'method data come', 'data come user', 'come user publicly', 'user publicly discussed', 'publicly discussed mental', 'discussed mental health', 'mental health condition', 'health condition user', 'condition user frequently', 'user frequently referred', 'frequently referred selfstated', 'referred selfstated diagnosis', 'selfstated diagnosis user', 'diagnosis user state', 'user state publicly', 'state publicly something', 'publicly something like', 'something like wa', 'like wa diagnosed', 'wa diagnosed schizophrenia', 'diagnosed schizophrenia im', 'schizophrenia im thankful', 'im thankful survived', 'thankful survived suicide', 'survived suicide attempt', 'suicide attempt last', 'attempt last year', 'last year data', 'year data user', 'data user suicide', 'user suicide attempt', 'suicide attempt wa', 'attempt wa supplemented', 'wa supplemented data', 'supplemented data ourdatahelpsorg', 'data ourdatahelpsorg data', 'ourdatahelpsorg data donation', 'data donation site', 'donation site people', 'site people provide', 'people provide access', 'provide access public', 'access public post', 'public post fill', 'post fill short', 'fill short questionnaire', 'short questionnaire mental', 'questionnaire mental health', 'mental health history', 'health history data', 'history data deidentified', 'data deidentified made', 'deidentified made available', 'made available researcher', 'available researcher addressing', 'researcher addressing question', 'addressing question interest', 'question interest mental', 'interest mental health', 'mental health community', 'health community donor', 'community donor provide', 'donor provide consent', 'provide consent data', 'consent data used', 'data used mental', 'used mental health', 'mental health research', 'health research upon', 'research upon signup', 'upon signup user', 'signup user attempted', 'user attempted suicide', 'attempted suicide came', 'suicide came ourdatahelpsorg', 'came ourdatahelpsorg specifically', 'ourdatahelpsorg specifically examine', 'specifically examine generalized', 'examine generalized anxiety', 'generalized anxiety disorder', 'anxiety disorder eating', 'disorder eating disorder', 'eating disorder panic', 'disorder panic attack', 'panic attack schizophrenia', 'attack schizophrenia attempted', 'schizophrenia attempted suicide', 'attempted suicide condition', 'suicide condition selected', 'condition selected based', 'selected based theory', 'based theory important', 'theory important timing', 'important timing aspect', 'timing aspect symptom', 'aspect symptom ebbing', 'symptom ebbing flowing', 'ebbing flowing symptom', 'flowing symptom treatment', 'symptom treatment effective', 'treatment effective especially', 'effective especially schizophrenia', 'especially schizophrenia onset', 'schizophrenia onset exacerbation', 'onset exacerbation symptom', 'exacerbation symptom external', 'symptom external event', 'external event stress', 'event stress punctuated', 'stress punctuated event', 'punctuated event time', 'event time psychological', 'time psychological symptom', 'psychological symptom suicide', 'symptom suicide attempt', 'suicide attempt panic', 'attempt panic attack', 'panic attack bingingpurging', 'attack bingingpurging behavior', 'bingingpurging behavior eating', 'behavior eating disorder', 'eating disorder use', 'disorder use twitter', 'use twitter streaming', 'twitter streaming api', 'streaming api collect', 'api collect sample', 'collect sample user', 'sample user used', 'user used series', 'used series mental', 'series mental health', 'mental health word', 'health word phrase', 'word phrase tweet', 'phrase tweet text', 'tweet text eg', 'text eg schizophrenia', 'eg schizophrenia suicide', 'schizophrenia suicide attempt', 'suicide attempt tweet', 'attempt tweet us', 'tweet us one', 'us one phrase', 'one phrase examined', 'phrase examined via', 'examined via regular', 'via regular expression', 'regular expression indicate', 'expression indicate user', 'indicate user talking', 'user talking finally', 'talking finally tweet', 'finally tweet pas', 'tweet pas regular', 'pas regular expression', 'regular expression examined', 'expression examined human', 'examined human confirm', 'human confirm best', 'confirm best ability', 'best ability selfstatement', 'ability selfstatement diagnosis', 'selfstatement diagnosis appears', 'diagnosis appears genuine', 'appears genuine result', 'genuine result dataset', 'result dataset user', 'dataset user selfstated', 'user selfstated diagnosis', 'selfstated diagnosis generalized', 'diagnosis generalized anxiety', 'generalized anxiety disorder', 'anxiety disorder n', 'disorder n eating', 'n eating disorder', 'eating disorder panic', 'disorder panic attack', 'panic attack schizophrenia', 'attack schizophrenia someone', 'schizophrenia someone would', 'someone would go', 'would go attempt', 'go attempt suicide', 'attempt suicide user', 'suicide user exhibit', 'user exhibit sort', 'exhibit sort posting', 'sort posting behavior', 'posting behavior required', 'behavior required create', 'required create micropatterns', 'create micropatterns ie', 'micropatterns ie rarely', 'ie rarely post', 'rarely post multiple', 'post multiple time', 'multiple time within', 'time within hour', 'within hour time', 'hour time window', 'time window exclude', 'window exclude user', 'exclude user analysis', 'user analysis user', 'analysis user condition', 'user condition exception', 'condition exception suicide', 'exception suicide attempt', 'suicide attempt little', 'attempt little half', 'little half user', 'half user exhibit', 'user exhibit posting', 'exhibit posting behavior', 'posting behavior resultant', 'behavior resultant dataset', 'resultant dataset used', 'dataset used analysis', 'used analysis generalized', 'analysis generalized anxiety', 'generalized anxiety disorder', 'anxiety disorder n', 'disorder n eating', 'n eating disorder', 'eating disorder panic', 'disorder panic attack', 'panic attack schizophrenia', 'attack schizophrenia suicide', 'schizophrenia suicide attempt', 'suicide attempt order', 'attempt order allow', 'order allow comparison', 'allow comparison condition', 'comparison condition control', 'condition control user', 'control user gather', 'user gather random', 'gather random sample', 'random sample twitter', 'sample twitter user', 'twitter user least', 'user least post', 'least post identified', 'post identified twitter', 'identified twitter english', 'twitter english user', 'english user selfstated', 'user selfstated diagnosis', 'selfstated diagnosis member', 'diagnosis member control', 'member control population', 'control population age', 'population age gender', 'age gender estimated', 'gender estimated according', 'estimated according sap', 'according sap et', 'sap et al', 'et al user', 'al user selfstated', 'user selfstated diagnosis', 'selfstated diagnosis find', 'diagnosis find matched', 'find matched control', 'matched control following', 'control following procedure', 'following procedure create', 'procedure create pool', 'create pool user', 'pool user estimated', 'user estimated gender', 'estimated gender match', 'gender match estimated', 'match estimated age', 'estimated age within', 'age within year', 'within year bracket', 'year bracket suggested', 'bracket suggested accuracy', 'suggested accuracy age', 'accuracy age estimator', 'age estimator pool', 'estimator pool age', 'pool age gender', 'age gender matched', 'gender matched user', 'matched user select', 'user select user', 'select user whose', 'user whose tweet', 'whose tweet start', 'tweet start end', 'start end similar', 'end similar timeframe', 'similar timeframe refer', 'timeframe refer age', 'refer age gender', 'age gender timematched', 'gender timematched control', 'timematched control simply', 'control simply matched', 'simply matched control', 'matched control throughout', 'control throughout rest', 'throughout rest paper', 'rest paper tweet', 'paper tweet publicly', 'tweet publicly posted', 'publicly posted author', 'posted author ie', 'author ie user', 'ie user marked', 'user marked protected', 'marked protected private', 'protected private included', 'private included average', 'included average user', 'average user tweet', 'user tweet distribution', 'tweet distribution estimated', 'distribution estimated age', 'estimated age gender', 'age gender user', 'gender user selfstated', 'user selfstated condition', 'selfstated condition seen', 'condition seen figure', 'seen figure condition', 'figure condition population', 'condition population skews', 'population skews female', 'skews female though', 'female though schizophrenia', 'though schizophrenia gender', 'schizophrenia gender roughly', 'gender roughly balanced', 'roughly balanced average', 'balanced average age', 'average age tends', 'age tends earlytomid']",0.0,0.0,0.0,0.0,0.0,0.9976395964622498,0,0.0
https://dl.acm.org/doi/abs/10.1145/2998181.2998220,1,Our study uses publicly shared mental illness self-disclosure data collected from the social media Twitter. We started by obtaining a large sample of English language candidate selfdisclosure posts from the full archive of public Twitter data around a variety of mental health concerns. Specifically we filtered the Twitter posts shared in March 2015 containing any of the keyphrases included in Table 1. These keyphrases were collated by a combination of reference to prior work [11 12] and consultation with a trained psychiatrist practitioner. Through these keyphrases we sought to identify who publicly state that they have been diagnosed with or suffering from some form of mental illness. As noted by Coppersmith et al. users may make such a statement to seek support from others in their Twitter social network to fight the stigma of mental illness or perhaps as an explanation of some of their behavior [11]. We obtained 1319064 posts from 534829 unique users at the end of this initial data collection phase. Parallelly we obtained a candidate control data sample from Twitter’s Firehose stream so as to allow robust statistical comparisons between Twitter users who choose to self-disclose their mental illness and those who do not. This dataset included a random sample of 1513279 posts from 673898 unique users made on Twitter during March 2015 ensuring that none of these posts matched any of the keyphrases given in Table 1. Thereafter for both of the candidate mental health disclosure sample and the candidate control sample of posts we utilized Twitter’s official API3 to obtain the last 3200 posts for each of the unique users in both datasets. For the control dataset if any of the users had any post in their crawled posts matching one of the keyphrases above we disregard them from our analysis. Further employing the Google Compact Language Detector4  we disregarded any users if at least 75% of their posts were not written in English. Our final candidate disclosure sample contained 51038914 posts from 470337 users (µ = 108.5) while the control sample contained 66214850 posts from 480685 users (µ = 137.7).Finally we validated both our gender and country name inference methods based on annotations obtained from two independent raters on a sample of 100 users. We found agreement between the raters’ annotations and the one given by our method for 79% of the cases for gender and 86% of the cases for country names (κ = .77). In our candidate disclosure and candidate control datasets we were able to infer binary gender for 325873 candidate mental health (of which 59% were female) and 439224 candidate control users (of which 46% were female) respectively and country information for 131890 and 328468 users for the same two groups respectively. Within the scope of this paper we restrict our attention to four most populated countries where English is a predominant form of expression — western countries US UK (GB) and majority world countries India (IN) and South Africa (ZA). All of these countries fare in the 25 countries with most population5 . Focusing on these countries provides us with a lens to examine cross-cultural differences in the disclosures of mental illnesses on social media.We note that the candidate mental health disclosure data sample is prone to significant noise. It is possible that although a user uses one of the mental health keyphrases in their Twitter post it may not indicate a genuine disclosure (e.g. “when I have to wake up at 6am I feel like killing myself” does not indicate a person’s real intention of taking their life). To eliminate such users we adopt a semi-supervised machine learning method [58] in which we compare the language of each user in our Twitter dataset with the language of a selfidentified set of social media users suffering a from mental illness. For the purpose we obtain a large sample of 79833 posts from 44262 users made on the Reddit subcommunities r/depression r/mentalhealth and r/SuicideWatch between February and November 2014. We use this dataset a weak signal of the language used by individuals identifying with a form of mental illness. Prior work has also indicated that the disclosures made on these forums are genuine disclosures of mental illnesses and have also been validated through consultation with a psychiatrist [16]. Our approach proceeds as follows: Step 1. We create Twitter user-centric vector-representations by collating all of their posts – this would give us as many vectors as the number of users in the candidate disclosure sample. We also similarly create a single vector representation by collating all posts in our Reddit dataset. Step 2. Next we establish comparative validity across the Twitter vectors and the Reddit vector. This is an important step because the language of Twitter and Reddit cannot be directly compared due to the unique affordances of each site and the seeming differences in the demographics of the two7 . For each of these vectors we perform linguistic normalization of tokenized items in them8 . Then we compute the average automated readability index (ARI [44]) on all of the normalized Twitter vectors and the Reddit vector. We observe the ARI differential between the two to be ∼6.7%9  indicating that the languages are close to standardized internet speak [25] and hence comparable following normalization. Step 3. Next we build n-gram language models (n = 3) for both the normalized Twitter vectors and the single Reddit vector. We then determine cosine similarity scores between the language models of each normalized Twitter vector and the Reddit vector. Step 4. Finally we obtain the distribution of cosine similarities over all normalized Twitter vectors (see Figure 1(a)). We construct the “genuine disclosure dataset” of users to be those vectors (of users) for whom the cosine similarity of their language models with that of Reddit’s is greater than or equal to the median similarity across all vectors (median distance=.71 σ = .157). Our final dataset of genuine mental illness disclosures consisted of 231611 users; we will refer to this set as the MID users.Next we qualitatively verified whether posts from these users indeed were self-disclosures of mental health challenges. For the purpose we consulted a licensed psychologist and also included two researchers who were familiar with mental health content shared on social media. Over a random sample of 100 posts complied from the timeline of 100 randomly selected MID users we obtained independent binary annotations on whether a post was likely to be related to mental health. The Fleiss’ κ for interrater agreement was found to be high .87 along with an accuracy of 96% in distinguishing users who engage in genuine disclosures from those who do not. This establishes adequacy of our approach. Table 2 gives some paraphrased mental health disclosure posts of Twitter users who were identified to be genuine mental health disclosers by our approach. In Figure 2 we show the pipeline of steps involved in our approach of arriving at this final dataset.,our study us publicly shared mental illness selfdisclosure data collected from the social medium twitter we started by obtaining a large sample of english language candidate selfdisclosure post from the full archive of public twitter data around a variety of mental health concern specifically we filtered the twitter post shared in march containing any of the keyphrases included in table these keyphrases were collated by a combination of reference to prior work and consultation with a trained psychiatrist practitioner through these keyphrases we sought to identify who publicly state that they have been diagnosed with or suffering from some form of mental illness a noted by coppersmith et al user may make such a statement to seek support from others in their twitter social network to fight the stigma of mental illness or perhaps a an explanation of some of their behavior we obtained post from unique user at the end of this initial data collection phase parallelly we obtained a candidate control data sample from twitter firehose stream so a to allow robust statistical comparison between twitter user who choose to selfdisclose their mental illness and those who do not this dataset included a random sample of post from unique user made on twitter during march ensuring that none of these post matched any of the keyphrases given in table thereafter for both of the candidate mental health disclosure sample and the candidate control sample of post we utilized twitter official api to obtain the last post for each of the unique user in both datasets for the control dataset if any of the user had any post in their crawled post matching one of the keyphrases above we disregard them from our analysis further employing the google compact language detector we disregarded any user if at least of their post were not written in english our final candidate disclosure sample contained post from user while the control sample contained post from user finally we validated both our gender and country name inference method based on annotation obtained from two independent raters on a sample of user we found agreement between the raters annotation and the one given by our method for of the case for gender and of the case for country name in our candidate disclosure and candidate control datasets we were able to infer binary gender for candidate mental health of which were female and candidate control user of which were female respectively and country information for and user for the same two group respectively within the scope of this paper we restrict our attention to four most populated country where english is a predominant form of expression western country u uk gb and majority world country india in and south africa za all of these country fare in the country with most population focusing on these country provides u with a lens to examine crosscultural difference in the disclosure of mental illness on social mediawe note that the candidate mental health disclosure data sample is prone to significant noise it is possible that although a user us one of the mental health keyphrases in their twitter post it may not indicate a genuine disclosure eg when i have to wake up at am i feel like killing myself doe not indicate a person real intention of taking their life to eliminate such user we adopt a semisupervised machine learning method in which we compare the language of each user in our twitter dataset with the language of a selfidentified set of social medium user suffering a from mental illness for the purpose we obtain a large sample of post from user made on the reddit subcommunities rdepression rmentalhealth and rsuicidewatch between february and november we use this dataset a weak signal of the language used by individual identifying with a form of mental illness prior work ha also indicated that the disclosure made on these forum are genuine disclosure of mental illness and have also been validated through consultation with a psychiatrist our approach proceeds a follows step we create twitter usercentric vectorrepresentations by collating all of their post this would give u a many vector a the number of user in the candidate disclosure sample we also similarly create a single vector representation by collating all post in our reddit dataset step next we establish comparative validity across the twitter vector and the reddit vector this is an important step because the language of twitter and reddit cannot be directly compared due to the unique affordances of each site and the seeming difference in the demographic of the two for each of these vector we perform linguistic normalization of tokenized item in them then we compute the average automated readability index ari on all of the normalized twitter vector and the reddit vector we observe the ari differential between the two to be indicating that the language are close to standardized internet speak and hence comparable following normalization step next we build ngram language model n for both the normalized twitter vector and the single reddit vector we then determine cosine similarity score between the language model of each normalized twitter vector and the reddit vector step finally we obtain the distribution of cosine similarity over all normalized twitter vector see figure a we construct the genuine disclosure dataset of user to be those vector of user for whom the cosine similarity of their language model with that of reddits is greater than or equal to the median similarity across all vector median distance our final dataset of genuine mental illness disclosure consisted of user we will refer to this set a the mid usersnext we qualitatively verified whether post from these user indeed were selfdisclosures of mental health challenge for the purpose we consulted a licensed psychologist and also included two researcher who were familiar with mental health content shared on social medium over a random sample of post complied from the timeline of randomly selected mid user we obtained independent binary annotation on whether a post wa likely to be related to mental health the fleiss for interrater agreement wa found to be high along with an accuracy of in distinguishing user who engage in genuine disclosure from those who do not this establishes adequacy of our approach table give some paraphrased mental health disclosure post of twitter user who were identified to be genuine mental health disclosers by our approach in figure we show the pipeline of step involved in our approach of arriving at this final dataset,"['study', 'us', 'publicly', 'shared', 'mental', 'illness', 'selfdisclosure', 'data', 'collected', 'social', 'medium', 'twitter', 'started', 'obtaining', 'large', 'sample', 'english', 'language', 'candidate', 'selfdisclosure', 'post', 'full', 'archive', 'public', 'twitter', 'data', 'around', 'variety', 'mental', 'health', 'concern', 'specifically', 'filtered', 'twitter', 'post', 'shared', 'march', 'containing', 'keyphrases', 'included', 'table', 'keyphrases', 'collated', 'combination', 'reference', 'prior', 'work', 'consultation', 'trained', 'psychiatrist', 'practitioner', 'keyphrases', 'sought', 'identify', 'publicly', 'state', 'diagnosed', 'suffering', 'form', 'mental', 'illness', 'noted', 'coppersmith', 'et', 'al', 'user', 'may', 'make', 'statement', 'seek', 'support', 'others', 'twitter', 'social', 'network', 'fight', 'stigma', 'mental', 'illness', 'perhaps', 'explanation', 'behavior', 'obtained', 'post', 'unique', 'user', 'end', 'initial', 'data', 'collection', 'phase', 'parallelly', 'obtained', 'candidate', 'control', 'data', 'sample', 'twitter', 'firehose', 'stream', 'allow', 'robust', 'statistical', 'comparison', 'twitter', 'user', 'choose', 'selfdisclose', 'mental', 'illness', 'dataset', 'included', 'random', 'sample', 'post', 'unique', 'user', 'made', 'twitter', 'march', 'ensuring', 'none', 'post', 'matched', 'keyphrases', 'given', 'table', 'thereafter', 'candidate', 'mental', 'health', 'disclosure', 'sample', 'candidate', 'control', 'sample', 'post', 'utilized', 'twitter', 'official', 'api', 'obtain', 'last', 'post', 'unique', 'user', 'datasets', 'control', 'dataset', 'user', 'post', 'crawled', 'post', 'matching', 'one', 'keyphrases', 'disregard', 'analysis', 'employing', 'google', 'compact', 'language', 'detector', 'disregarded', 'user', 'least', 'post', 'written', 'english', 'final', 'candidate', 'disclosure', 'sample', 'contained', 'post', 'user', 'control', 'sample', 'contained', 'post', 'user', 'finally', 'validated', 'gender', 'country', 'name', 'inference', 'method', 'based', 'annotation', 'obtained', 'two', 'independent', 'raters', 'sample', 'user', 'found', 'agreement', 'raters', 'annotation', 'one', 'given', 'method', 'case', 'gender', 'case', 'country', 'name', 'candidate', 'disclosure', 'candidate', 'control', 'datasets', 'able', 'infer', 'binary', 'gender', 'candidate', 'mental', 'health', 'female', 'candidate', 'control', 'user', 'female', 'respectively', 'country', 'information', 'user', 'two', 'group', 'respectively', 'within', 'scope', 'paper', 'restrict', 'attention', 'four', 'populated', 'country', 'english', 'predominant', 'form', 'expression', 'western', 'country', 'u', 'uk', 'gb', 'majority', 'world', 'country', 'india', 'south', 'africa', 'za', 'country', 'fare', 'country', 'population', 'focusing', 'country', 'provides', 'u', 'lens', 'examine', 'crosscultural', 'difference', 'disclosure', 'mental', 'illness', 'social', 'mediawe', 'note', 'candidate', 'mental', 'health', 'disclosure', 'data', 'sample', 'prone', 'significant', 'noise', 'possible', 'although', 'user', 'us', 'one', 'mental', 'health', 'keyphrases', 'twitter', 'post', 'may', 'indicate', 'genuine', 'disclosure', 'eg', 'wake', 'feel', 'like', 'killing', 'doe', 'indicate', 'person', 'real', 'intention', 'taking', 'life', 'eliminate', 'user', 'adopt', 'semisupervised', 'machine', 'learning', 'method', 'compare', 'language', 'user', 'twitter', 'dataset', 'language', 'selfidentified', 'set', 'social', 'medium', 'user', 'suffering', 'mental', 'illness', 'purpose', 'obtain', 'large', 'sample', 'post', 'user', 'made', 'reddit', 'subcommunities', 'rdepression', 'rmentalhealth', 'rsuicidewatch', 'february', 'november', 'use', 'dataset', 'weak', 'signal', 'language', 'used', 'individual', 'identifying', 'form', 'mental', 'illness', 'prior', 'work', 'ha', 'also', 'indicated', 'disclosure', 'made', 'forum', 'genuine', 'disclosure', 'mental', 'illness', 'also', 'validated', 'consultation', 'psychiatrist', 'approach', 'proceeds', 'follows', 'step', 'create', 'twitter', 'usercentric', 'vectorrepresentations', 'collating', 'post', 'would', 'give', 'u', 'many', 'vector', 'number', 'user', 'candidate', 'disclosure', 'sample', 'also', 'similarly', 'create', 'single', 'vector', 'representation', 'collating', 'post', 'reddit', 'dataset', 'step', 'next', 'establish', 'comparative', 'validity', 'across', 'twitter', 'vector', 'reddit', 'vector', 'important', 'step', 'language', 'twitter', 'reddit', 'cannot', 'directly', 'compared', 'due', 'unique', 'affordances', 'site', 'seeming', 'difference', 'demographic', 'two', 'vector', 'perform', 'linguistic', 'normalization', 'tokenized', 'item', 'compute', 'average', 'automated', 'readability', 'index', 'ari', 'normalized', 'twitter', 'vector', 'reddit', 'vector', 'observe', 'ari', 'differential', 'two', 'indicating', 'language', 'close', 'standardized', 'internet', 'speak', 'hence', 'comparable', 'following', 'normalization', 'step', 'next', 'build', 'ngram', 'language', 'model', 'n', 'normalized', 'twitter', 'vector', 'single', 'reddit', 'vector', 'determine', 'cosine', 'similarity', 'score', 'language', 'model', 'normalized', 'twitter', 'vector', 'reddit', 'vector', 'step', 'finally', 'obtain', 'distribution', 'cosine', 'similarity', 'normalized', 'twitter', 'vector', 'see', 'figure', 'construct', 'genuine', 'disclosure', 'dataset', 'user', 'vector', 'user', 'cosine', 'similarity', 'language', 'model', 'reddits', 'greater', 'equal', 'median', 'similarity', 'across', 'vector', 'median', 'distance', 'final', 'dataset', 'genuine', 'mental', 'illness', 'disclosure', 'consisted', 'user', 'refer', 'set', 'mid', 'usersnext', 'qualitatively', 'verified', 'whether', 'post', 'user', 'indeed', 'selfdisclosures', 'mental', 'health', 'challenge', 'purpose', 'consulted', 'licensed', 'psychologist', 'also', 'included', 'two', 'researcher', 'familiar', 'mental', 'health', 'content', 'shared', 'social', 'medium', 'random', 'sample', 'post', 'complied', 'timeline', 'randomly', 'selected', 'mid', 'user', 'obtained', 'independent', 'binary', 'annotation', 'whether', 'post', 'wa', 'likely', 'related', 'mental', 'health', 'fleiss', 'interrater', 'agreement', 'wa', 'found', 'high', 'along', 'accuracy', 'distinguishing', 'user', 'engage', 'genuine', 'disclosure', 'establishes', 'adequacy', 'approach', 'table', 'give', 'paraphrased', 'mental', 'health', 'disclosure', 'post', 'twitter', 'user', 'identified', 'genuine', 'mental', 'health', 'disclosers', 'approach', 'figure', 'show', 'pipeline', 'step', 'involved', 'approach', 'arriving', 'final', 'dataset']","['study us', 'us publicly', 'publicly shared', 'shared mental', 'mental illness', 'illness selfdisclosure', 'selfdisclosure data', 'data collected', 'collected social', 'social medium', 'medium twitter', 'twitter started', 'started obtaining', 'obtaining large', 'large sample', 'sample english', 'english language', 'language candidate', 'candidate selfdisclosure', 'selfdisclosure post', 'post full', 'full archive', 'archive public', 'public twitter', 'twitter data', 'data around', 'around variety', 'variety mental', 'mental health', 'health concern', 'concern specifically', 'specifically filtered', 'filtered twitter', 'twitter post', 'post shared', 'shared march', 'march containing', 'containing keyphrases', 'keyphrases included', 'included table', 'table keyphrases', 'keyphrases collated', 'collated combination', 'combination reference', 'reference prior', 'prior work', 'work consultation', 'consultation trained', 'trained psychiatrist', 'psychiatrist practitioner', 'practitioner keyphrases', 'keyphrases sought', 'sought identify', 'identify publicly', 'publicly state', 'state diagnosed', 'diagnosed suffering', 'suffering form', 'form mental', 'mental illness', 'illness noted', 'noted coppersmith', 'coppersmith et', 'et al', 'al user', 'user may', 'may make', 'make statement', 'statement seek', 'seek support', 'support others', 'others twitter', 'twitter social', 'social network', 'network fight', 'fight stigma', 'stigma mental', 'mental illness', 'illness perhaps', 'perhaps explanation', 'explanation behavior', 'behavior obtained', 'obtained post', 'post unique', 'unique user', 'user end', 'end initial', 'initial data', 'data collection', 'collection phase', 'phase parallelly', 'parallelly obtained', 'obtained candidate', 'candidate control', 'control data', 'data sample', 'sample twitter', 'twitter firehose', 'firehose stream', 'stream allow', 'allow robust', 'robust statistical', 'statistical comparison', 'comparison twitter', 'twitter user', 'user choose', 'choose selfdisclose', 'selfdisclose mental', 'mental illness', 'illness dataset', 'dataset included', 'included random', 'random sample', 'sample post', 'post unique', 'unique user', 'user made', 'made twitter', 'twitter march', 'march ensuring', 'ensuring none', 'none post', 'post matched', 'matched keyphrases', 'keyphrases given', 'given table', 'table thereafter', 'thereafter candidate', 'candidate mental', 'mental health', 'health disclosure', 'disclosure sample', 'sample candidate', 'candidate control', 'control sample', 'sample post', 'post utilized', 'utilized twitter', 'twitter official', 'official api', 'api obtain', 'obtain last', 'last post', 'post unique', 'unique user', 'user datasets', 'datasets control', 'control dataset', 'dataset user', 'user post', 'post crawled', 'crawled post', 'post matching', 'matching one', 'one keyphrases', 'keyphrases disregard', 'disregard analysis', 'analysis employing', 'employing google', 'google compact', 'compact language', 'language detector', 'detector disregarded', 'disregarded user', 'user least', 'least post', 'post written', 'written english', 'english final', 'final candidate', 'candidate disclosure', 'disclosure sample', 'sample contained', 'contained post', 'post user', 'user control', 'control sample', 'sample contained', 'contained post', 'post user', 'user finally', 'finally validated', 'validated gender', 'gender country', 'country name', 'name inference', 'inference method', 'method based', 'based annotation', 'annotation obtained', 'obtained two', 'two independent', 'independent raters', 'raters sample', 'sample user', 'user found', 'found agreement', 'agreement raters', 'raters annotation', 'annotation one', 'one given', 'given method', 'method case', 'case gender', 'gender case', 'case country', 'country name', 'name candidate', 'candidate disclosure', 'disclosure candidate', 'candidate control', 'control datasets', 'datasets able', 'able infer', 'infer binary', 'binary gender', 'gender candidate', 'candidate mental', 'mental health', 'health female', 'female candidate', 'candidate control', 'control user', 'user female', 'female respectively', 'respectively country', 'country information', 'information user', 'user two', 'two group', 'group respectively', 'respectively within', 'within scope', 'scope paper', 'paper restrict', 'restrict attention', 'attention four', 'four populated', 'populated country', 'country english', 'english predominant', 'predominant form', 'form expression', 'expression western', 'western country', 'country u', 'u uk', 'uk gb', 'gb majority', 'majority world', 'world country', 'country india', 'india south', 'south africa', 'africa za', 'za country', 'country fare', 'fare country', 'country population', 'population focusing', 'focusing country', 'country provides', 'provides u', 'u lens', 'lens examine', 'examine crosscultural', 'crosscultural difference', 'difference disclosure', 'disclosure mental', 'mental illness', 'illness social', 'social mediawe', 'mediawe note', 'note candidate', 'candidate mental', 'mental health', 'health disclosure', 'disclosure data', 'data sample', 'sample prone', 'prone significant', 'significant noise', 'noise possible', 'possible although', 'although user', 'user us', 'us one', 'one mental', 'mental health', 'health keyphrases', 'keyphrases twitter', 'twitter post', 'post may', 'may indicate', 'indicate genuine', 'genuine disclosure', 'disclosure eg', 'eg wake', 'wake feel', 'feel like', 'like killing', 'killing doe', 'doe indicate', 'indicate person', 'person real', 'real intention', 'intention taking', 'taking life', 'life eliminate', 'eliminate user', 'user adopt', 'adopt semisupervised', 'semisupervised machine', 'machine learning', 'learning method', 'method compare', 'compare language', 'language user', 'user twitter', 'twitter dataset', 'dataset language', 'language selfidentified', 'selfidentified set', 'set social', 'social medium', 'medium user', 'user suffering', 'suffering mental', 'mental illness', 'illness purpose', 'purpose obtain', 'obtain large', 'large sample', 'sample post', 'post user', 'user made', 'made reddit', 'reddit subcommunities', 'subcommunities rdepression', 'rdepression rmentalhealth', 'rmentalhealth rsuicidewatch', 'rsuicidewatch february', 'february november', 'november use', 'use dataset', 'dataset weak', 'weak signal', 'signal language', 'language used', 'used individual', 'individual identifying', 'identifying form', 'form mental', 'mental illness', 'illness prior', 'prior work', 'work ha', 'ha also', 'also indicated', 'indicated disclosure', 'disclosure made', 'made forum', 'forum genuine', 'genuine disclosure', 'disclosure mental', 'mental illness', 'illness also', 'also validated', 'validated consultation', 'consultation psychiatrist', 'psychiatrist approach', 'approach proceeds', 'proceeds follows', 'follows step', 'step create', 'create twitter', 'twitter usercentric', 'usercentric vectorrepresentations', 'vectorrepresentations collating', 'collating post', 'post would', 'would give', 'give u', 'u many', 'many vector', 'vector number', 'number user', 'user candidate', 'candidate disclosure', 'disclosure sample', 'sample also', 'also similarly', 'similarly create', 'create single', 'single vector', 'vector representation', 'representation collating', 'collating post', 'post reddit', 'reddit dataset', 'dataset step', 'step next', 'next establish', 'establish comparative', 'comparative validity', 'validity across', 'across twitter', 'twitter vector', 'vector reddit', 'reddit vector', 'vector important', 'important step', 'step language', 'language twitter', 'twitter reddit', 'reddit cannot', 'cannot directly', 'directly compared', 'compared due', 'due unique', 'unique affordances', 'affordances site', 'site seeming', 'seeming difference', 'difference demographic', 'demographic two', 'two vector', 'vector perform', 'perform linguistic', 'linguistic normalization', 'normalization tokenized', 'tokenized item', 'item compute', 'compute average', 'average automated', 'automated readability', 'readability index', 'index ari', 'ari normalized', 'normalized twitter', 'twitter vector', 'vector reddit', 'reddit vector', 'vector observe', 'observe ari', 'ari differential', 'differential two', 'two indicating', 'indicating language', 'language close', 'close standardized', 'standardized internet', 'internet speak', 'speak hence', 'hence comparable', 'comparable following', 'following normalization', 'normalization step', 'step next', 'next build', 'build ngram', 'ngram language', 'language model', 'model n', 'n normalized', 'normalized twitter', 'twitter vector', 'vector single', 'single reddit', 'reddit vector', 'vector determine', 'determine cosine', 'cosine similarity', 'similarity score', 'score language', 'language model', 'model normalized', 'normalized twitter', 'twitter vector', 'vector reddit', 'reddit vector', 'vector step', 'step finally', 'finally obtain', 'obtain distribution', 'distribution cosine', 'cosine similarity', 'similarity normalized', 'normalized twitter', 'twitter vector', 'vector see', 'see figure', 'figure construct', 'construct genuine', 'genuine disclosure', 'disclosure dataset', 'dataset user', 'user vector', 'vector user', 'user cosine', 'cosine similarity', 'similarity language', 'language model', 'model reddits', 'reddits greater', 'greater equal', 'equal median', 'median similarity', 'similarity across', 'across vector', 'vector median', 'median distance', 'distance final', 'final dataset', 'dataset genuine', 'genuine mental', 'mental illness', 'illness disclosure', 'disclosure consisted', 'consisted user', 'user refer', 'refer set', 'set mid', 'mid usersnext', 'usersnext qualitatively', 'qualitatively verified', 'verified whether', 'whether post', 'post user', 'user indeed', 'indeed selfdisclosures', 'selfdisclosures mental', 'mental health', 'health challenge', 'challenge purpose', 'purpose consulted', 'consulted licensed', 'licensed psychologist', 'psychologist also', 'also included', 'included two', 'two researcher', 'researcher familiar', 'familiar mental', 'mental health', 'health content', 'content shared', 'shared social', 'social medium', 'medium random', 'random sample', 'sample post', 'post complied', 'complied timeline', 'timeline randomly', 'randomly selected', 'selected mid', 'mid user', 'user obtained', 'obtained independent', 'independent binary', 'binary annotation', 'annotation whether', 'whether post', 'post wa', 'wa likely', 'likely related', 'related mental', 'mental health', 'health fleiss', 'fleiss interrater', 'interrater agreement', 'agreement wa', 'wa found', 'found high', 'high along', 'along accuracy', 'accuracy distinguishing', 'distinguishing user', 'user engage', 'engage genuine', 'genuine disclosure', 'disclosure establishes', 'establishes adequacy', 'adequacy approach', 'approach table', 'table give', 'give paraphrased', 'paraphrased mental', 'mental health', 'health disclosure', 'disclosure post', 'post twitter', 'twitter user', 'user identified', 'identified genuine', 'genuine mental', 'mental health', 'health disclosers', 'disclosers approach', 'approach figure', 'figure show', 'show pipeline', 'pipeline step', 'step involved', 'involved approach', 'approach arriving', 'arriving final', 'final dataset']","['study us publicly', 'us publicly shared', 'publicly shared mental', 'shared mental illness', 'mental illness selfdisclosure', 'illness selfdisclosure data', 'selfdisclosure data collected', 'data collected social', 'collected social medium', 'social medium twitter', 'medium twitter started', 'twitter started obtaining', 'started obtaining large', 'obtaining large sample', 'large sample english', 'sample english language', 'english language candidate', 'language candidate selfdisclosure', 'candidate selfdisclosure post', 'selfdisclosure post full', 'post full archive', 'full archive public', 'archive public twitter', 'public twitter data', 'twitter data around', 'data around variety', 'around variety mental', 'variety mental health', 'mental health concern', 'health concern specifically', 'concern specifically filtered', 'specifically filtered twitter', 'filtered twitter post', 'twitter post shared', 'post shared march', 'shared march containing', 'march containing keyphrases', 'containing keyphrases included', 'keyphrases included table', 'included table keyphrases', 'table keyphrases collated', 'keyphrases collated combination', 'collated combination reference', 'combination reference prior', 'reference prior work', 'prior work consultation', 'work consultation trained', 'consultation trained psychiatrist', 'trained psychiatrist practitioner', 'psychiatrist practitioner keyphrases', 'practitioner keyphrases sought', 'keyphrases sought identify', 'sought identify publicly', 'identify publicly state', 'publicly state diagnosed', 'state diagnosed suffering', 'diagnosed suffering form', 'suffering form mental', 'form mental illness', 'mental illness noted', 'illness noted coppersmith', 'noted coppersmith et', 'coppersmith et al', 'et al user', 'al user may', 'user may make', 'may make statement', 'make statement seek', 'statement seek support', 'seek support others', 'support others twitter', 'others twitter social', 'twitter social network', 'social network fight', 'network fight stigma', 'fight stigma mental', 'stigma mental illness', 'mental illness perhaps', 'illness perhaps explanation', 'perhaps explanation behavior', 'explanation behavior obtained', 'behavior obtained post', 'obtained post unique', 'post unique user', 'unique user end', 'user end initial', 'end initial data', 'initial data collection', 'data collection phase', 'collection phase parallelly', 'phase parallelly obtained', 'parallelly obtained candidate', 'obtained candidate control', 'candidate control data', 'control data sample', 'data sample twitter', 'sample twitter firehose', 'twitter firehose stream', 'firehose stream allow', 'stream allow robust', 'allow robust statistical', 'robust statistical comparison', 'statistical comparison twitter', 'comparison twitter user', 'twitter user choose', 'user choose selfdisclose', 'choose selfdisclose mental', 'selfdisclose mental illness', 'mental illness dataset', 'illness dataset included', 'dataset included random', 'included random sample', 'random sample post', 'sample post unique', 'post unique user', 'unique user made', 'user made twitter', 'made twitter march', 'twitter march ensuring', 'march ensuring none', 'ensuring none post', 'none post matched', 'post matched keyphrases', 'matched keyphrases given', 'keyphrases given table', 'given table thereafter', 'table thereafter candidate', 'thereafter candidate mental', 'candidate mental health', 'mental health disclosure', 'health disclosure sample', 'disclosure sample candidate', 'sample candidate control', 'candidate control sample', 'control sample post', 'sample post utilized', 'post utilized twitter', 'utilized twitter official', 'twitter official api', 'official api obtain', 'api obtain last', 'obtain last post', 'last post unique', 'post unique user', 'unique user datasets', 'user datasets control', 'datasets control dataset', 'control dataset user', 'dataset user post', 'user post crawled', 'post crawled post', 'crawled post matching', 'post matching one', 'matching one keyphrases', 'one keyphrases disregard', 'keyphrases disregard analysis', 'disregard analysis employing', 'analysis employing google', 'employing google compact', 'google compact language', 'compact language detector', 'language detector disregarded', 'detector disregarded user', 'disregarded user least', 'user least post', 'least post written', 'post written english', 'written english final', 'english final candidate', 'final candidate disclosure', 'candidate disclosure sample', 'disclosure sample contained', 'sample contained post', 'contained post user', 'post user control', 'user control sample', 'control sample contained', 'sample contained post', 'contained post user', 'post user finally', 'user finally validated', 'finally validated gender', 'validated gender country', 'gender country name', 'country name inference', 'name inference method', 'inference method based', 'method based annotation', 'based annotation obtained', 'annotation obtained two', 'obtained two independent', 'two independent raters', 'independent raters sample', 'raters sample user', 'sample user found', 'user found agreement', 'found agreement raters', 'agreement raters annotation', 'raters annotation one', 'annotation one given', 'one given method', 'given method case', 'method case gender', 'case gender case', 'gender case country', 'case country name', 'country name candidate', 'name candidate disclosure', 'candidate disclosure candidate', 'disclosure candidate control', 'candidate control datasets', 'control datasets able', 'datasets able infer', 'able infer binary', 'infer binary gender', 'binary gender candidate', 'gender candidate mental', 'candidate mental health', 'mental health female', 'health female candidate', 'female candidate control', 'candidate control user', 'control user female', 'user female respectively', 'female respectively country', 'respectively country information', 'country information user', 'information user two', 'user two group', 'two group respectively', 'group respectively within', 'respectively within scope', 'within scope paper', 'scope paper restrict', 'paper restrict attention', 'restrict attention four', 'attention four populated', 'four populated country', 'populated country english', 'country english predominant', 'english predominant form', 'predominant form expression', 'form expression western', 'expression western country', 'western country u', 'country u uk', 'u uk gb', 'uk gb majority', 'gb majority world', 'majority world country', 'world country india', 'country india south', 'india south africa', 'south africa za', 'africa za country', 'za country fare', 'country fare country', 'fare country population', 'country population focusing', 'population focusing country', 'focusing country provides', 'country provides u', 'provides u lens', 'u lens examine', 'lens examine crosscultural', 'examine crosscultural difference', 'crosscultural difference disclosure', 'difference disclosure mental', 'disclosure mental illness', 'mental illness social', 'illness social mediawe', 'social mediawe note', 'mediawe note candidate', 'note candidate mental', 'candidate mental health', 'mental health disclosure', 'health disclosure data', 'disclosure data sample', 'data sample prone', 'sample prone significant', 'prone significant noise', 'significant noise possible', 'noise possible although', 'possible although user', 'although user us', 'user us one', 'us one mental', 'one mental health', 'mental health keyphrases', 'health keyphrases twitter', 'keyphrases twitter post', 'twitter post may', 'post may indicate', 'may indicate genuine', 'indicate genuine disclosure', 'genuine disclosure eg', 'disclosure eg wake', 'eg wake feel', 'wake feel like', 'feel like killing', 'like killing doe', 'killing doe indicate', 'doe indicate person', 'indicate person real', 'person real intention', 'real intention taking', 'intention taking life', 'taking life eliminate', 'life eliminate user', 'eliminate user adopt', 'user adopt semisupervised', 'adopt semisupervised machine', 'semisupervised machine learning', 'machine learning method', 'learning method compare', 'method compare language', 'compare language user', 'language user twitter', 'user twitter dataset', 'twitter dataset language', 'dataset language selfidentified', 'language selfidentified set', 'selfidentified set social', 'set social medium', 'social medium user', 'medium user suffering', 'user suffering mental', 'suffering mental illness', 'mental illness purpose', 'illness purpose obtain', 'purpose obtain large', 'obtain large sample', 'large sample post', 'sample post user', 'post user made', 'user made reddit', 'made reddit subcommunities', 'reddit subcommunities rdepression', 'subcommunities rdepression rmentalhealth', 'rdepression rmentalhealth rsuicidewatch', 'rmentalhealth rsuicidewatch february', 'rsuicidewatch february november', 'february november use', 'november use dataset', 'use dataset weak', 'dataset weak signal', 'weak signal language', 'signal language used', 'language used individual', 'used individual identifying', 'individual identifying form', 'identifying form mental', 'form mental illness', 'mental illness prior', 'illness prior work', 'prior work ha', 'work ha also', 'ha also indicated', 'also indicated disclosure', 'indicated disclosure made', 'disclosure made forum', 'made forum genuine', 'forum genuine disclosure', 'genuine disclosure mental', 'disclosure mental illness', 'mental illness also', 'illness also validated', 'also validated consultation', 'validated consultation psychiatrist', 'consultation psychiatrist approach', 'psychiatrist approach proceeds', 'approach proceeds follows', 'proceeds follows step', 'follows step create', 'step create twitter', 'create twitter usercentric', 'twitter usercentric vectorrepresentations', 'usercentric vectorrepresentations collating', 'vectorrepresentations collating post', 'collating post would', 'post would give', 'would give u', 'give u many', 'u many vector', 'many vector number', 'vector number user', 'number user candidate', 'user candidate disclosure', 'candidate disclosure sample', 'disclosure sample also', 'sample also similarly', 'also similarly create', 'similarly create single', 'create single vector', 'single vector representation', 'vector representation collating', 'representation collating post', 'collating post reddit', 'post reddit dataset', 'reddit dataset step', 'dataset step next', 'step next establish', 'next establish comparative', 'establish comparative validity', 'comparative validity across', 'validity across twitter', 'across twitter vector', 'twitter vector reddit', 'vector reddit vector', 'reddit vector important', 'vector important step', 'important step language', 'step language twitter', 'language twitter reddit', 'twitter reddit cannot', 'reddit cannot directly', 'cannot directly compared', 'directly compared due', 'compared due unique', 'due unique affordances', 'unique affordances site', 'affordances site seeming', 'site seeming difference', 'seeming difference demographic', 'difference demographic two', 'demographic two vector', 'two vector perform', 'vector perform linguistic', 'perform linguistic normalization', 'linguistic normalization tokenized', 'normalization tokenized item', 'tokenized item compute', 'item compute average', 'compute average automated', 'average automated readability', 'automated readability index', 'readability index ari', 'index ari normalized', 'ari normalized twitter', 'normalized twitter vector', 'twitter vector reddit', 'vector reddit vector', 'reddit vector observe', 'vector observe ari', 'observe ari differential', 'ari differential two', 'differential two indicating', 'two indicating language', 'indicating language close', 'language close standardized', 'close standardized internet', 'standardized internet speak', 'internet speak hence', 'speak hence comparable', 'hence comparable following', 'comparable following normalization', 'following normalization step', 'normalization step next', 'step next build', 'next build ngram', 'build ngram language', 'ngram language model', 'language model n', 'model n normalized', 'n normalized twitter', 'normalized twitter vector', 'twitter vector single', 'vector single reddit', 'single reddit vector', 'reddit vector determine', 'vector determine cosine', 'determine cosine similarity', 'cosine similarity score', 'similarity score language', 'score language model', 'language model normalized', 'model normalized twitter', 'normalized twitter vector', 'twitter vector reddit', 'vector reddit vector', 'reddit vector step', 'vector step finally', 'step finally obtain', 'finally obtain distribution', 'obtain distribution cosine', 'distribution cosine similarity', 'cosine similarity normalized', 'similarity normalized twitter', 'normalized twitter vector', 'twitter vector see', 'vector see figure', 'see figure construct', 'figure construct genuine', 'construct genuine disclosure', 'genuine disclosure dataset', 'disclosure dataset user', 'dataset user vector', 'user vector user', 'vector user cosine', 'user cosine similarity', 'cosine similarity language', 'similarity language model', 'language model reddits', 'model reddits greater', 'reddits greater equal', 'greater equal median', 'equal median similarity', 'median similarity across', 'similarity across vector', 'across vector median', 'vector median distance', 'median distance final', 'distance final dataset', 'final dataset genuine', 'dataset genuine mental', 'genuine mental illness', 'mental illness disclosure', 'illness disclosure consisted', 'disclosure consisted user', 'consisted user refer', 'user refer set', 'refer set mid', 'set mid usersnext', 'mid usersnext qualitatively', 'usersnext qualitatively verified', 'qualitatively verified whether', 'verified whether post', 'whether post user', 'post user indeed', 'user indeed selfdisclosures', 'indeed selfdisclosures mental', 'selfdisclosures mental health', 'mental health challenge', 'health challenge purpose', 'challenge purpose consulted', 'purpose consulted licensed', 'consulted licensed psychologist', 'licensed psychologist also', 'psychologist also included', 'also included two', 'included two researcher', 'two researcher familiar', 'researcher familiar mental', 'familiar mental health', 'mental health content', 'health content shared', 'content shared social', 'shared social medium', 'social medium random', 'medium random sample', 'random sample post', 'sample post complied', 'post complied timeline', 'complied timeline randomly', 'timeline randomly selected', 'randomly selected mid', 'selected mid user', 'mid user obtained', 'user obtained independent', 'obtained independent binary', 'independent binary annotation', 'binary annotation whether', 'annotation whether post', 'whether post wa', 'post wa likely', 'wa likely related', 'likely related mental', 'related mental health', 'mental health fleiss', 'health fleiss interrater', 'fleiss interrater agreement', 'interrater agreement wa', 'agreement wa found', 'wa found high', 'found high along', 'high along accuracy', 'along accuracy distinguishing', 'accuracy distinguishing user', 'distinguishing user engage', 'user engage genuine', 'engage genuine disclosure', 'genuine disclosure establishes', 'disclosure establishes adequacy', 'establishes adequacy approach', 'adequacy approach table', 'approach table give', 'table give paraphrased', 'give paraphrased mental', 'paraphrased mental health', 'mental health disclosure', 'health disclosure post', 'disclosure post twitter', 'post twitter user', 'twitter user identified', 'user identified genuine', 'identified genuine mental', 'genuine mental health', 'mental health disclosers', 'health disclosers approach', 'disclosers approach figure', 'approach figure show', 'figure show pipeline', 'show pipeline step', 'pipeline step involved', 'step involved approach', 'involved approach arriving', 'approach arriving final', 'arriving final dataset']",0.0,0.9623517990112305,0.0,0.0,0.03641965612769127,0.0,0,0.0
https://www.jmir.org/2019/6/e14199/,1,The selection of the tweets and their users was based on the filtered real-time streaming support provided by the Twitter API. In the first step we selected the users who showed potential signs of depression on Twitter on the basis of the 20 most frequent words in Spanish expressed by patients suffering from depression in clinical settings. These words were jointly identified and selected by a psychologist and a family physician with clinical experience and were based on the definition and general features of depression according to the Diagnostic and Statistical Manual of Mental Disorders [42]. The list of words used and their English translations are shown in Textbox 1. During June 2018 1470000 tweets including 1 or more occurrences of the words listed in Textbox 1 were collected. From this collection of tweets and to select the users who publicly stated in the textual description associated to their profile that they suffered from depression all the profile descriptions including 1 or more occurrences of the word “depr” and all the possible derivations related to the word depression in Spanish such as “depre” “depresión” “depresivo” “depresiva” “deprimido” and “deprimida” were considered. From the 720 users who included 1 or more of these words in their description profile 90 users who stated they suffered from depression or were receiving treatment for depression were selected for the analysis. This selection was performed by a psychologist verifying that the statements were related to real expressions of depression excluding quotes jokes or fake ones. For each of these depressed Twitter users we collected all the most recent tweets from their timeline up to a maximum of about 3200 tweets. Thus a total of 189669 tweets were collected a figure that was reduced to 140946 after discarding the retweets. These 140946 tweets constituted the depressive users dataset. Examples of sentences appearing in the user profiles that were used for selecting the depressive users are: “Paciente psiquiátrico con depresión crónica” (Psychiatric patient with chronic depression; example of a profile sentence that indicates depression). “Colecciono errores traducidos a tweets depresivos y a uno que otro impulso de amor” (I gather errors translated into depressing tweets and into one or another love impulse; example of a profile sentence that does not indicate depression). Once the users with profile sentences indicating depression had been retrieved their Twitter timelines were collected. Only those users having in their timeline at least 10 tweets that suggested signs of depression were retained for further analyses. For each user the selection of these tweets was performed by manually inspecting the tweets of the user’s complete timeline in reverse temporal order starting from the most recent one to the oldest tweet of the timeline retrieved by means of the Twitter API . Finally a total number of 1000 tweets issued by the 90 depressive users suggesting signs of depression were detected and used for the analysis. This set of tweets provided us with the depressive tweets dataset which was used to analyze linguistic features of tweets showing signs of depression. It has to be mentioned that these 1000 tweets were not to be included in the depressive users dataset (see Figure 1). At the same time more than 97500000 tweets were also collected in June 2018: such tweets were gathered by listening to the public Twitter stream during this time span by only considering tweets with Spanish textual contents (as detected by Twitter language identification support). Given that Twitter requires more restrictive filters than just the language of the tweets we used a list of the most frequently used Spanish words (stopwords) to retrieve all tweets that included 1 or more of these words. The vast majority of Spanish tweets should match this criterion. A sample of 450 users who did not mention in their profile the word depression and its derivations were selected randomly from the 97500000 tweets. The complete timelines of these users were compiled (1141021 tweets) which were reduced to 712589 once retweets were removed. These 712589 tweets constituted the control dataset. To identify the language of a tweet we relied on the language automatically identified by Twitter for each tweet selecting tweets in Spanish. It has to be noted that these data can contain some tweets from unidentified depressive users.,the selection of the tweet and their user wa based on the filtered realtime streaming support provided by the twitter api in the first step we selected the user who showed potential sign of depression on twitter on the basis of the most frequent word in spanish expressed by patient suffering from depression in clinical setting these word were jointly identified and selected by a psychologist and a family physician with clinical experience and were based on the definition and general feature of depression according to the diagnostic and statistical manual of mental disorder the list of word used and their english translation are shown in textbox during june tweet including or more occurrence of the word listed in textbox were collected from this collection of tweet and to select the user who publicly stated in the textual description associated to their profile that they suffered from depression all the profile description including or more occurrence of the word depr and all the possible derivation related to the word depression in spanish such a depre depresin depresivo depresiva deprimido and deprimida were considered from the user who included or more of these word in their description profile user who stated they suffered from depression or were receiving treatment for depression were selected for the analysis this selection wa performed by a psychologist verifying that the statement were related to real expression of depression excluding quote joke or fake one for each of these depressed twitter user we collected all the most recent tweet from their timeline up to a maximum of about tweet thus a total of tweet were collected a figure that wa reduced to after discarding the retweets these tweet constituted the depressive user dataset example of sentence appearing in the user profile that were used for selecting the depressive user are paciente psiquitrico con depresin crnica psychiatric patient with chronic depression example of a profile sentence that indicates depression colecciono errores traducidos a tweet depresivos y a uno que otro impulso de amor i gather error translated into depressing tweet and into one or another love impulse example of a profile sentence that doe not indicate depression once the user with profile sentence indicating depression had been retrieved their twitter timeline were collected only those user having in their timeline at least tweet that suggested sign of depression were retained for further analysis for each user the selection of these tweet wa performed by manually inspecting the tweet of the user complete timeline in reverse temporal order starting from the most recent one to the oldest tweet of the timeline retrieved by mean of the twitter api finally a total number of tweet issued by the depressive user suggesting sign of depression were detected and used for the analysis this set of tweet provided u with the depressive tweet dataset which wa used to analyze linguistic feature of tweet showing sign of depression it ha to be mentioned that these tweet were not to be included in the depressive user dataset see figure at the same time more than tweet were also collected in june such tweet were gathered by listening to the public twitter stream during this time span by only considering tweet with spanish textual content a detected by twitter language identification support given that twitter requires more restrictive filter than just the language of the tweet we used a list of the most frequently used spanish word stopwords to retrieve all tweet that included or more of these word the vast majority of spanish tweet should match this criterion a sample of user who did not mention in their profile the word depression and it derivation were selected randomly from the tweet the complete timeline of these user were compiled tweet which were reduced to once retweets were removed these tweet constituted the control dataset to identify the language of a tweet we relied on the language automatically identified by twitter for each tweet selecting tweet in spanish it ha to be noted that these data can contain some tweet from unidentified depressive user,"['selection', 'tweet', 'user', 'wa', 'based', 'filtered', 'realtime', 'streaming', 'support', 'provided', 'twitter', 'api', 'first', 'step', 'selected', 'user', 'showed', 'potential', 'sign', 'depression', 'twitter', 'basis', 'frequent', 'word', 'spanish', 'expressed', 'patient', 'suffering', 'depression', 'clinical', 'setting', 'word', 'jointly', 'identified', 'selected', 'psychologist', 'family', 'physician', 'clinical', 'experience', 'based', 'definition', 'general', 'feature', 'depression', 'according', 'diagnostic', 'statistical', 'manual', 'mental', 'disorder', 'list', 'word', 'used', 'english', 'translation', 'shown', 'textbox', 'june', 'tweet', 'including', 'occurrence', 'word', 'listed', 'textbox', 'collected', 'collection', 'tweet', 'select', 'user', 'publicly', 'stated', 'textual', 'description', 'associated', 'profile', 'suffered', 'depression', 'profile', 'description', 'including', 'occurrence', 'word', 'depr', 'possible', 'derivation', 'related', 'word', 'depression', 'spanish', 'depre', 'depresin', 'depresivo', 'depresiva', 'deprimido', 'deprimida', 'considered', 'user', 'included', 'word', 'description', 'profile', 'user', 'stated', 'suffered', 'depression', 'receiving', 'treatment', 'depression', 'selected', 'analysis', 'selection', 'wa', 'performed', 'psychologist', 'verifying', 'statement', 'related', 'real', 'expression', 'depression', 'excluding', 'quote', 'joke', 'fake', 'one', 'depressed', 'twitter', 'user', 'collected', 'recent', 'tweet', 'timeline', 'maximum', 'tweet', 'thus', 'total', 'tweet', 'collected', 'figure', 'wa', 'reduced', 'discarding', 'retweets', 'tweet', 'constituted', 'depressive', 'user', 'dataset', 'example', 'sentence', 'appearing', 'user', 'profile', 'used', 'selecting', 'depressive', 'user', 'paciente', 'psiquitrico', 'con', 'depresin', 'crnica', 'psychiatric', 'patient', 'chronic', 'depression', 'example', 'profile', 'sentence', 'indicates', 'depression', 'colecciono', 'errores', 'traducidos', 'tweet', 'depresivos', 'uno', 'que', 'otro', 'impulso', 'de', 'amor', 'gather', 'error', 'translated', 'depressing', 'tweet', 'one', 'another', 'love', 'impulse', 'example', 'profile', 'sentence', 'doe', 'indicate', 'depression', 'user', 'profile', 'sentence', 'indicating', 'depression', 'retrieved', 'twitter', 'timeline', 'collected', 'user', 'timeline', 'least', 'tweet', 'suggested', 'sign', 'depression', 'retained', 'analysis', 'user', 'selection', 'tweet', 'wa', 'performed', 'manually', 'inspecting', 'tweet', 'user', 'complete', 'timeline', 'reverse', 'temporal', 'order', 'starting', 'recent', 'one', 'oldest', 'tweet', 'timeline', 'retrieved', 'mean', 'twitter', 'api', 'finally', 'total', 'number', 'tweet', 'issued', 'depressive', 'user', 'suggesting', 'sign', 'depression', 'detected', 'used', 'analysis', 'set', 'tweet', 'provided', 'u', 'depressive', 'tweet', 'dataset', 'wa', 'used', 'analyze', 'linguistic', 'feature', 'tweet', 'showing', 'sign', 'depression', 'ha', 'mentioned', 'tweet', 'included', 'depressive', 'user', 'dataset', 'see', 'figure', 'time', 'tweet', 'also', 'collected', 'june', 'tweet', 'gathered', 'listening', 'public', 'twitter', 'stream', 'time', 'span', 'considering', 'tweet', 'spanish', 'textual', 'content', 'detected', 'twitter', 'language', 'identification', 'support', 'given', 'twitter', 'requires', 'restrictive', 'filter', 'language', 'tweet', 'used', 'list', 'frequently', 'used', 'spanish', 'word', 'stopwords', 'retrieve', 'tweet', 'included', 'word', 'vast', 'majority', 'spanish', 'tweet', 'match', 'criterion', 'sample', 'user', 'mention', 'profile', 'word', 'depression', 'derivation', 'selected', 'randomly', 'tweet', 'complete', 'timeline', 'user', 'compiled', 'tweet', 'reduced', 'retweets', 'removed', 'tweet', 'constituted', 'control', 'dataset', 'identify', 'language', 'tweet', 'relied', 'language', 'automatically', 'identified', 'twitter', 'tweet', 'selecting', 'tweet', 'spanish', 'ha', 'noted', 'data', 'contain', 'tweet', 'unidentified', 'depressive', 'user']","['selection tweet', 'tweet user', 'user wa', 'wa based', 'based filtered', 'filtered realtime', 'realtime streaming', 'streaming support', 'support provided', 'provided twitter', 'twitter api', 'api first', 'first step', 'step selected', 'selected user', 'user showed', 'showed potential', 'potential sign', 'sign depression', 'depression twitter', 'twitter basis', 'basis frequent', 'frequent word', 'word spanish', 'spanish expressed', 'expressed patient', 'patient suffering', 'suffering depression', 'depression clinical', 'clinical setting', 'setting word', 'word jointly', 'jointly identified', 'identified selected', 'selected psychologist', 'psychologist family', 'family physician', 'physician clinical', 'clinical experience', 'experience based', 'based definition', 'definition general', 'general feature', 'feature depression', 'depression according', 'according diagnostic', 'diagnostic statistical', 'statistical manual', 'manual mental', 'mental disorder', 'disorder list', 'list word', 'word used', 'used english', 'english translation', 'translation shown', 'shown textbox', 'textbox june', 'june tweet', 'tweet including', 'including occurrence', 'occurrence word', 'word listed', 'listed textbox', 'textbox collected', 'collected collection', 'collection tweet', 'tweet select', 'select user', 'user publicly', 'publicly stated', 'stated textual', 'textual description', 'description associated', 'associated profile', 'profile suffered', 'suffered depression', 'depression profile', 'profile description', 'description including', 'including occurrence', 'occurrence word', 'word depr', 'depr possible', 'possible derivation', 'derivation related', 'related word', 'word depression', 'depression spanish', 'spanish depre', 'depre depresin', 'depresin depresivo', 'depresivo depresiva', 'depresiva deprimido', 'deprimido deprimida', 'deprimida considered', 'considered user', 'user included', 'included word', 'word description', 'description profile', 'profile user', 'user stated', 'stated suffered', 'suffered depression', 'depression receiving', 'receiving treatment', 'treatment depression', 'depression selected', 'selected analysis', 'analysis selection', 'selection wa', 'wa performed', 'performed psychologist', 'psychologist verifying', 'verifying statement', 'statement related', 'related real', 'real expression', 'expression depression', 'depression excluding', 'excluding quote', 'quote joke', 'joke fake', 'fake one', 'one depressed', 'depressed twitter', 'twitter user', 'user collected', 'collected recent', 'recent tweet', 'tweet timeline', 'timeline maximum', 'maximum tweet', 'tweet thus', 'thus total', 'total tweet', 'tweet collected', 'collected figure', 'figure wa', 'wa reduced', 'reduced discarding', 'discarding retweets', 'retweets tweet', 'tweet constituted', 'constituted depressive', 'depressive user', 'user dataset', 'dataset example', 'example sentence', 'sentence appearing', 'appearing user', 'user profile', 'profile used', 'used selecting', 'selecting depressive', 'depressive user', 'user paciente', 'paciente psiquitrico', 'psiquitrico con', 'con depresin', 'depresin crnica', 'crnica psychiatric', 'psychiatric patient', 'patient chronic', 'chronic depression', 'depression example', 'example profile', 'profile sentence', 'sentence indicates', 'indicates depression', 'depression colecciono', 'colecciono errores', 'errores traducidos', 'traducidos tweet', 'tweet depresivos', 'depresivos uno', 'uno que', 'que otro', 'otro impulso', 'impulso de', 'de amor', 'amor gather', 'gather error', 'error translated', 'translated depressing', 'depressing tweet', 'tweet one', 'one another', 'another love', 'love impulse', 'impulse example', 'example profile', 'profile sentence', 'sentence doe', 'doe indicate', 'indicate depression', 'depression user', 'user profile', 'profile sentence', 'sentence indicating', 'indicating depression', 'depression retrieved', 'retrieved twitter', 'twitter timeline', 'timeline collected', 'collected user', 'user timeline', 'timeline least', 'least tweet', 'tweet suggested', 'suggested sign', 'sign depression', 'depression retained', 'retained analysis', 'analysis user', 'user selection', 'selection tweet', 'tweet wa', 'wa performed', 'performed manually', 'manually inspecting', 'inspecting tweet', 'tweet user', 'user complete', 'complete timeline', 'timeline reverse', 'reverse temporal', 'temporal order', 'order starting', 'starting recent', 'recent one', 'one oldest', 'oldest tweet', 'tweet timeline', 'timeline retrieved', 'retrieved mean', 'mean twitter', 'twitter api', 'api finally', 'finally total', 'total number', 'number tweet', 'tweet issued', 'issued depressive', 'depressive user', 'user suggesting', 'suggesting sign', 'sign depression', 'depression detected', 'detected used', 'used analysis', 'analysis set', 'set tweet', 'tweet provided', 'provided u', 'u depressive', 'depressive tweet', 'tweet dataset', 'dataset wa', 'wa used', 'used analyze', 'analyze linguistic', 'linguistic feature', 'feature tweet', 'tweet showing', 'showing sign', 'sign depression', 'depression ha', 'ha mentioned', 'mentioned tweet', 'tweet included', 'included depressive', 'depressive user', 'user dataset', 'dataset see', 'see figure', 'figure time', 'time tweet', 'tweet also', 'also collected', 'collected june', 'june tweet', 'tweet gathered', 'gathered listening', 'listening public', 'public twitter', 'twitter stream', 'stream time', 'time span', 'span considering', 'considering tweet', 'tweet spanish', 'spanish textual', 'textual content', 'content detected', 'detected twitter', 'twitter language', 'language identification', 'identification support', 'support given', 'given twitter', 'twitter requires', 'requires restrictive', 'restrictive filter', 'filter language', 'language tweet', 'tweet used', 'used list', 'list frequently', 'frequently used', 'used spanish', 'spanish word', 'word stopwords', 'stopwords retrieve', 'retrieve tweet', 'tweet included', 'included word', 'word vast', 'vast majority', 'majority spanish', 'spanish tweet', 'tweet match', 'match criterion', 'criterion sample', 'sample user', 'user mention', 'mention profile', 'profile word', 'word depression', 'depression derivation', 'derivation selected', 'selected randomly', 'randomly tweet', 'tweet complete', 'complete timeline', 'timeline user', 'user compiled', 'compiled tweet', 'tweet reduced', 'reduced retweets', 'retweets removed', 'removed tweet', 'tweet constituted', 'constituted control', 'control dataset', 'dataset identify', 'identify language', 'language tweet', 'tweet relied', 'relied language', 'language automatically', 'automatically identified', 'identified twitter', 'twitter tweet', 'tweet selecting', 'selecting tweet', 'tweet spanish', 'spanish ha', 'ha noted', 'noted data', 'data contain', 'contain tweet', 'tweet unidentified', 'unidentified depressive', 'depressive user']","['selection tweet user', 'tweet user wa', 'user wa based', 'wa based filtered', 'based filtered realtime', 'filtered realtime streaming', 'realtime streaming support', 'streaming support provided', 'support provided twitter', 'provided twitter api', 'twitter api first', 'api first step', 'first step selected', 'step selected user', 'selected user showed', 'user showed potential', 'showed potential sign', 'potential sign depression', 'sign depression twitter', 'depression twitter basis', 'twitter basis frequent', 'basis frequent word', 'frequent word spanish', 'word spanish expressed', 'spanish expressed patient', 'expressed patient suffering', 'patient suffering depression', 'suffering depression clinical', 'depression clinical setting', 'clinical setting word', 'setting word jointly', 'word jointly identified', 'jointly identified selected', 'identified selected psychologist', 'selected psychologist family', 'psychologist family physician', 'family physician clinical', 'physician clinical experience', 'clinical experience based', 'experience based definition', 'based definition general', 'definition general feature', 'general feature depression', 'feature depression according', 'depression according diagnostic', 'according diagnostic statistical', 'diagnostic statistical manual', 'statistical manual mental', 'manual mental disorder', 'mental disorder list', 'disorder list word', 'list word used', 'word used english', 'used english translation', 'english translation shown', 'translation shown textbox', 'shown textbox june', 'textbox june tweet', 'june tweet including', 'tweet including occurrence', 'including occurrence word', 'occurrence word listed', 'word listed textbox', 'listed textbox collected', 'textbox collected collection', 'collected collection tweet', 'collection tweet select', 'tweet select user', 'select user publicly', 'user publicly stated', 'publicly stated textual', 'stated textual description', 'textual description associated', 'description associated profile', 'associated profile suffered', 'profile suffered depression', 'suffered depression profile', 'depression profile description', 'profile description including', 'description including occurrence', 'including occurrence word', 'occurrence word depr', 'word depr possible', 'depr possible derivation', 'possible derivation related', 'derivation related word', 'related word depression', 'word depression spanish', 'depression spanish depre', 'spanish depre depresin', 'depre depresin depresivo', 'depresin depresivo depresiva', 'depresivo depresiva deprimido', 'depresiva deprimido deprimida', 'deprimido deprimida considered', 'deprimida considered user', 'considered user included', 'user included word', 'included word description', 'word description profile', 'description profile user', 'profile user stated', 'user stated suffered', 'stated suffered depression', 'suffered depression receiving', 'depression receiving treatment', 'receiving treatment depression', 'treatment depression selected', 'depression selected analysis', 'selected analysis selection', 'analysis selection wa', 'selection wa performed', 'wa performed psychologist', 'performed psychologist verifying', 'psychologist verifying statement', 'verifying statement related', 'statement related real', 'related real expression', 'real expression depression', 'expression depression excluding', 'depression excluding quote', 'excluding quote joke', 'quote joke fake', 'joke fake one', 'fake one depressed', 'one depressed twitter', 'depressed twitter user', 'twitter user collected', 'user collected recent', 'collected recent tweet', 'recent tweet timeline', 'tweet timeline maximum', 'timeline maximum tweet', 'maximum tweet thus', 'tweet thus total', 'thus total tweet', 'total tweet collected', 'tweet collected figure', 'collected figure wa', 'figure wa reduced', 'wa reduced discarding', 'reduced discarding retweets', 'discarding retweets tweet', 'retweets tweet constituted', 'tweet constituted depressive', 'constituted depressive user', 'depressive user dataset', 'user dataset example', 'dataset example sentence', 'example sentence appearing', 'sentence appearing user', 'appearing user profile', 'user profile used', 'profile used selecting', 'used selecting depressive', 'selecting depressive user', 'depressive user paciente', 'user paciente psiquitrico', 'paciente psiquitrico con', 'psiquitrico con depresin', 'con depresin crnica', 'depresin crnica psychiatric', 'crnica psychiatric patient', 'psychiatric patient chronic', 'patient chronic depression', 'chronic depression example', 'depression example profile', 'example profile sentence', 'profile sentence indicates', 'sentence indicates depression', 'indicates depression colecciono', 'depression colecciono errores', 'colecciono errores traducidos', 'errores traducidos tweet', 'traducidos tweet depresivos', 'tweet depresivos uno', 'depresivos uno que', 'uno que otro', 'que otro impulso', 'otro impulso de', 'impulso de amor', 'de amor gather', 'amor gather error', 'gather error translated', 'error translated depressing', 'translated depressing tweet', 'depressing tweet one', 'tweet one another', 'one another love', 'another love impulse', 'love impulse example', 'impulse example profile', 'example profile sentence', 'profile sentence doe', 'sentence doe indicate', 'doe indicate depression', 'indicate depression user', 'depression user profile', 'user profile sentence', 'profile sentence indicating', 'sentence indicating depression', 'indicating depression retrieved', 'depression retrieved twitter', 'retrieved twitter timeline', 'twitter timeline collected', 'timeline collected user', 'collected user timeline', 'user timeline least', 'timeline least tweet', 'least tweet suggested', 'tweet suggested sign', 'suggested sign depression', 'sign depression retained', 'depression retained analysis', 'retained analysis user', 'analysis user selection', 'user selection tweet', 'selection tweet wa', 'tweet wa performed', 'wa performed manually', 'performed manually inspecting', 'manually inspecting tweet', 'inspecting tweet user', 'tweet user complete', 'user complete timeline', 'complete timeline reverse', 'timeline reverse temporal', 'reverse temporal order', 'temporal order starting', 'order starting recent', 'starting recent one', 'recent one oldest', 'one oldest tweet', 'oldest tweet timeline', 'tweet timeline retrieved', 'timeline retrieved mean', 'retrieved mean twitter', 'mean twitter api', 'twitter api finally', 'api finally total', 'finally total number', 'total number tweet', 'number tweet issued', 'tweet issued depressive', 'issued depressive user', 'depressive user suggesting', 'user suggesting sign', 'suggesting sign depression', 'sign depression detected', 'depression detected used', 'detected used analysis', 'used analysis set', 'analysis set tweet', 'set tweet provided', 'tweet provided u', 'provided u depressive', 'u depressive tweet', 'depressive tweet dataset', 'tweet dataset wa', 'dataset wa used', 'wa used analyze', 'used analyze linguistic', 'analyze linguistic feature', 'linguistic feature tweet', 'feature tweet showing', 'tweet showing sign', 'showing sign depression', 'sign depression ha', 'depression ha mentioned', 'ha mentioned tweet', 'mentioned tweet included', 'tweet included depressive', 'included depressive user', 'depressive user dataset', 'user dataset see', 'dataset see figure', 'see figure time', 'figure time tweet', 'time tweet also', 'tweet also collected', 'also collected june', 'collected june tweet', 'june tweet gathered', 'tweet gathered listening', 'gathered listening public', 'listening public twitter', 'public twitter stream', 'twitter stream time', 'stream time span', 'time span considering', 'span considering tweet', 'considering tweet spanish', 'tweet spanish textual', 'spanish textual content', 'textual content detected', 'content detected twitter', 'detected twitter language', 'twitter language identification', 'language identification support', 'identification support given', 'support given twitter', 'given twitter requires', 'twitter requires restrictive', 'requires restrictive filter', 'restrictive filter language', 'filter language tweet', 'language tweet used', 'tweet used list', 'used list frequently', 'list frequently used', 'frequently used spanish', 'used spanish word', 'spanish word stopwords', 'word stopwords retrieve', 'stopwords retrieve tweet', 'retrieve tweet included', 'tweet included word', 'included word vast', 'word vast majority', 'vast majority spanish', 'majority spanish tweet', 'spanish tweet match', 'tweet match criterion', 'match criterion sample', 'criterion sample user', 'sample user mention', 'user mention profile', 'mention profile word', 'profile word depression', 'word depression derivation', 'depression derivation selected', 'derivation selected randomly', 'selected randomly tweet', 'randomly tweet complete', 'tweet complete timeline', 'complete timeline user', 'timeline user compiled', 'user compiled tweet', 'compiled tweet reduced', 'tweet reduced retweets', 'reduced retweets removed', 'retweets removed tweet', 'removed tweet constituted', 'tweet constituted control', 'constituted control dataset', 'control dataset identify', 'dataset identify language', 'identify language tweet', 'language tweet relied', 'tweet relied language', 'relied language automatically', 'language automatically identified', 'automatically identified twitter', 'identified twitter tweet', 'twitter tweet selecting', 'tweet selecting tweet', 'selecting tweet spanish', 'tweet spanish ha', 'spanish ha noted', 'ha noted data', 'noted data contain', 'data contain tweet', 'contain tweet unidentified', 'tweet unidentified depressive', 'unidentified depressive user']",0.0,0.9976204037666321,0.0,0.0,0.0,0.0,0,0.0
https://aclanthology.org/W18-0608.pdf,1,Data was collected from 7 Cups of Tea an anonymous online chat-based peer support community for emotional distress1 . Users agree at signup that their data may be used for the purposes of research. All the data used for the current study was anonymous and securely stored. This research was performed in line with the ethical and privacy protocols outlined in detail in (Benton et al. 2017). Data from 7 Cups takes the form of written dialogue between users of the service and volunteers who are trained as “active listeners”. A fragment of an exchange between the user of the service (U) and the volunteer (V) might go as follows: For the analyses reported in this paper we used only text generated by users of the service not the volunteers providing peer support. Users who reported depression as their primary concern at sign up were eligible for inclusion in analyses. Our original sample was comprised of 23048 conversations involving 1937 unique users. Users were excluded from the sample if they did not indicate their culture or if they selected ‘Other’. This resulted in the exclusion of 199 and 130 users respectively. The original sample also included users identifying as Native American or American Indian. This group was excluded from analyses since the majority of the data among these users was not English. This resulted in the removal of 15 users leaving a total sample size of 1593.,data wa collected from cup of tea an anonymous online chatbased peer support community for emotional distress user agree at signup that their data may be used for the purpose of research all the data used for the current study wa anonymous and securely stored this research wa performed in line with the ethical and privacy protocol outlined in detail in benton et al data from cup take the form of written dialogue between user of the service and volunteer who are trained a active listener a fragment of an exchange between the user of the service u and the volunteer v might go a follows for the analysis reported in this paper we used only text generated by user of the service not the volunteer providing peer support user who reported depression a their primary concern at sign up were eligible for inclusion in analysis our original sample wa comprised of conversation involving unique user user were excluded from the sample if they did not indicate their culture or if they selected other this resulted in the exclusion of and user respectively the original sample also included user identifying a native american or american indian this group wa excluded from analysis since the majority of the data among these user wa not english this resulted in the removal of user leaving a total sample size of,"['data', 'wa', 'collected', 'cup', 'tea', 'anonymous', 'online', 'chatbased', 'peer', 'support', 'community', 'emotional', 'distress', 'user', 'agree', 'signup', 'data', 'may', 'used', 'purpose', 'research', 'data', 'used', 'current', 'study', 'wa', 'anonymous', 'securely', 'stored', 'research', 'wa', 'performed', 'line', 'ethical', 'privacy', 'protocol', 'outlined', 'detail', 'benton', 'et', 'al', 'data', 'cup', 'take', 'form', 'written', 'dialogue', 'user', 'service', 'volunteer', 'trained', 'active', 'listener', 'fragment', 'exchange', 'user', 'service', 'u', 'volunteer', 'v', 'might', 'go', 'follows', 'analysis', 'reported', 'paper', 'used', 'text', 'generated', 'user', 'service', 'volunteer', 'providing', 'peer', 'support', 'user', 'reported', 'depression', 'primary', 'concern', 'sign', 'eligible', 'inclusion', 'analysis', 'original', 'sample', 'wa', 'comprised', 'conversation', 'involving', 'unique', 'user', 'user', 'excluded', 'sample', 'indicate', 'culture', 'selected', 'resulted', 'exclusion', 'user', 'respectively', 'original', 'sample', 'also', 'included', 'user', 'identifying', 'native', 'american', 'american', 'indian', 'group', 'wa', 'excluded', 'analysis', 'since', 'majority', 'data', 'among', 'user', 'wa', 'english', 'resulted', 'removal', 'user', 'leaving', 'total', 'sample', 'size']","['data wa', 'wa collected', 'collected cup', 'cup tea', 'tea anonymous', 'anonymous online', 'online chatbased', 'chatbased peer', 'peer support', 'support community', 'community emotional', 'emotional distress', 'distress user', 'user agree', 'agree signup', 'signup data', 'data may', 'may used', 'used purpose', 'purpose research', 'research data', 'data used', 'used current', 'current study', 'study wa', 'wa anonymous', 'anonymous securely', 'securely stored', 'stored research', 'research wa', 'wa performed', 'performed line', 'line ethical', 'ethical privacy', 'privacy protocol', 'protocol outlined', 'outlined detail', 'detail benton', 'benton et', 'et al', 'al data', 'data cup', 'cup take', 'take form', 'form written', 'written dialogue', 'dialogue user', 'user service', 'service volunteer', 'volunteer trained', 'trained active', 'active listener', 'listener fragment', 'fragment exchange', 'exchange user', 'user service', 'service u', 'u volunteer', 'volunteer v', 'v might', 'might go', 'go follows', 'follows analysis', 'analysis reported', 'reported paper', 'paper used', 'used text', 'text generated', 'generated user', 'user service', 'service volunteer', 'volunteer providing', 'providing peer', 'peer support', 'support user', 'user reported', 'reported depression', 'depression primary', 'primary concern', 'concern sign', 'sign eligible', 'eligible inclusion', 'inclusion analysis', 'analysis original', 'original sample', 'sample wa', 'wa comprised', 'comprised conversation', 'conversation involving', 'involving unique', 'unique user', 'user user', 'user excluded', 'excluded sample', 'sample indicate', 'indicate culture', 'culture selected', 'selected resulted', 'resulted exclusion', 'exclusion user', 'user respectively', 'respectively original', 'original sample', 'sample also', 'also included', 'included user', 'user identifying', 'identifying native', 'native american', 'american american', 'american indian', 'indian group', 'group wa', 'wa excluded', 'excluded analysis', 'analysis since', 'since majority', 'majority data', 'data among', 'among user', 'user wa', 'wa english', 'english resulted', 'resulted removal', 'removal user', 'user leaving', 'leaving total', 'total sample', 'sample size']","['data wa collected', 'wa collected cup', 'collected cup tea', 'cup tea anonymous', 'tea anonymous online', 'anonymous online chatbased', 'online chatbased peer', 'chatbased peer support', 'peer support community', 'support community emotional', 'community emotional distress', 'emotional distress user', 'distress user agree', 'user agree signup', 'agree signup data', 'signup data may', 'data may used', 'may used purpose', 'used purpose research', 'purpose research data', 'research data used', 'data used current', 'used current study', 'current study wa', 'study wa anonymous', 'wa anonymous securely', 'anonymous securely stored', 'securely stored research', 'stored research wa', 'research wa performed', 'wa performed line', 'performed line ethical', 'line ethical privacy', 'ethical privacy protocol', 'privacy protocol outlined', 'protocol outlined detail', 'outlined detail benton', 'detail benton et', 'benton et al', 'et al data', 'al data cup', 'data cup take', 'cup take form', 'take form written', 'form written dialogue', 'written dialogue user', 'dialogue user service', 'user service volunteer', 'service volunteer trained', 'volunteer trained active', 'trained active listener', 'active listener fragment', 'listener fragment exchange', 'fragment exchange user', 'exchange user service', 'user service u', 'service u volunteer', 'u volunteer v', 'volunteer v might', 'v might go', 'might go follows', 'go follows analysis', 'follows analysis reported', 'analysis reported paper', 'reported paper used', 'paper used text', 'used text generated', 'text generated user', 'generated user service', 'user service volunteer', 'service volunteer providing', 'volunteer providing peer', 'providing peer support', 'peer support user', 'support user reported', 'user reported depression', 'reported depression primary', 'depression primary concern', 'primary concern sign', 'concern sign eligible', 'sign eligible inclusion', 'eligible inclusion analysis', 'inclusion analysis original', 'analysis original sample', 'original sample wa', 'sample wa comprised', 'wa comprised conversation', 'comprised conversation involving', 'conversation involving unique', 'involving unique user', 'unique user user', 'user user excluded', 'user excluded sample', 'excluded sample indicate', 'sample indicate culture', 'indicate culture selected', 'culture selected resulted', 'selected resulted exclusion', 'resulted exclusion user', 'exclusion user respectively', 'user respectively original', 'respectively original sample', 'original sample also', 'sample also included', 'also included user', 'included user identifying', 'user identifying native', 'identifying native american', 'native american american', 'american american indian', 'american indian group', 'indian group wa', 'group wa excluded', 'wa excluded analysis', 'excluded analysis since', 'analysis since majority', 'since majority data', 'majority data among', 'data among user', 'among user wa', 'user wa english', 'wa english resulted', 'english resulted removal', 'resulted removal user', 'removal user leaving', 'user leaving total', 'leaving total sample', 'total sample size']",0.0,0.0,0.9933153390884399,0.0,0.0,0.0,0,0.0
https://dl.acm.org/doi/pdf/10.1145/3359169,1,"Selection Criteria and Data Scope. To understand the impact of cultural differences on how individuals use online mental health platforms we begin our analysis by creating a dataset of users from different national communities on Talklife a support platform with over half a million users [91]. For this analysis due to the fact that most research in CSCW on mental health online has been done either agnostic of cultural context [12 34] or in a Western context [60 67 88] we choose to focus on users from non-Western countries following Zhang et al. [103]. As researchers located in the Global South and with lived experience interacting with the health system and diverse explanatory models [52] of mental illness we believe that moving the focus of CSCW and CSCWadjacent mental health research away from the West is crucial to better meet the needs of people often underserved by the medical system [70]. To create these subgroups of users we choose the three non-Western countries with the highest user populations on Talklife or India Malaysia and the Philippines. Guided by the rich amount of literature on the unique nuances to mental health expression for each country [35 62 77 80] we examine the national identity linguistic and behavior-based differences of use between each user subgroup. In particular this research notes that as a result of cultural norms around the sharing of distress and alternative conceptualizations of mental illness in India Malaysia and the Philippines symptoms are often expressed in somatic and religious terms as opposed to traditionally clinical or psychiatric terms. We choose to analyze each subgroup at the national level for both theoretical and practical reasons. On a theoretical level in past work in the medical anthropology of mental health national identity has commonly been used for a approximate level of analysis for cultural identity [31 33 52]. Additionally on a more practical level each user’s country was determined using their IP address by Talklife and shared with us in an user-anonymized dataset. Inferring a more precise location could potentially compromise user anonymity as discussed in past work [47] and did not seem to have any more significant value for our analysis of cultural differences than analysis at the national level. We analyze data from 10532 Indian users 3370 Malaysian users and 3370 Filipino users as shown in Table 2. Collectively we refer to these countries as the minority sample. As a comparison set we construct a random sample of all threads on Talklife and refer to it as the majority sample. Due to the relative prevalence of users from Western English-speaking countries in Talklife most of the threads in the majority sample include posts from countries such as the USA UK and Canada. Indians are the largest non-Western minority subgroup on Talklife. Data was sampled from May 2012 to June 2018. Following this cross-national analysis to see if our broader results on Talklife generalize to a differently structured online mental health community we picked the largest Western country (the United States) and the largest non-Western country (India) represented on 7Cups a similar support platform with more than 15000 users actively using the platform each week [7]. Using 7Cups data we repeat our analysis testing for the same cultural differences we found in our Talklife sample. For this analysis we were provided a sample of data on activity from 6055 Indian users and 18581 American users as shown in Table 2. Unlike our sample of Talklife users this dataset is not a random sample. There is an upsampling of Indian users to ensure that we have data from a sufficient number of Indians in the dataset. Like on Talklife Indians are the largest non-Western minority subgroup on 7Cups. We focus on Indian users due to a lack of sufficient data on users from Malaysia or the Philippines. Data was sampled from March 2014 - August 2018. 3.1.2 Defining Cultural Identity and Use of Clinical Language. In this work we examine the relationship between cultural identity and use of online mental health support forums. To do so we leverage Tomlinson’s definition of cultural identity as “self and communal definitions based around specific usually politically inflected differentiations: gender sexuality class religion race and ethnicity nationality"" [94] particularly looking at the aspect that of modern cultural identity that runs along national lines as delineated by Hall et al. [41]. As a diverse and amorphous form of identity cultural identity can often intersect and interact with other forms of identity including religious or ethnic identity. However in the absence of direct information about religious or ethnic identity based on the data available we use national identity as a proxy for cultural identity. Additionally following Schlesinger et al’s [83] call for more intersectional analyses and methods within HCI we also include analyses of adjacent and intersecting identities when relevant including religious identity. To analyze clinical language we use a broader definition of clinical language than just specific medical diagnoses. Following methods used in past work to analyze antidepressant related language [30] we create a dataset of clinical mental health language including unigrams bigrams and trigrams from a list of mental disorders as defined by the International Classification of Diseases (ICD-10) and Diagnostic and Statistical Manual of Mental Disorders (DSM-5) [100]. We also included all unigrams from the MacMillan Dictionary list of words used to describe illnesses and diseases both specifically for mental illness and general illness [1–3]. As a result we include unigrams like “night"" (from night terrors) or sleep (from “sleep disorder"") as these are often correlated with specific symptoms of mental illness or distress such as sleep issues or being awake at night [30]. This included any clinically common abbreviations for mental disorders such as OCD for “obsessive compulsive disorder"" or BPD for “borderline personality disorder."" Shorthand for disorders commonly used by online communities such as “pro-ana” (as used in pro-eating disorder communities) [22] were not included due to the difficulty in finding an exhaustive list of these terms across disorders. We choose to use terms from and associated with DSM and ICD categorized disorders as a result of the common usage of these frameworks globally [99]. Throughout our analysis of these varied factors we use µ to represent means and σ to represent standard deviations. 3.1.3 Constraints Limitations and Tradeoffs. Cultural identity can exist at many different and intersecting levels including subcultures and subcommunities within the larger umbrella of a cultural identity. As a result for the purpose of this analysis we had to adopt some constraints in order to do a meaningful and specific analysis. One large limiting constraint that we chose for this study is to use national identity at the state level as a proxy for cultural identity. Though a major and formative part of modern cultural identity as argued by both Hall [41] and Tomlinson [94] each country we analyze is incredibly diverse with many individual cultural identities that both intersect and diverge from a greater national identity [54 64 89]. A more rich analysis of these other forms of cultural identity is beyond the scope of this work but could lead to richer conclusions about the nature of cultural identity in online mental health support communities particularly with regard to cultural differences between users with the same national identity. Additionally to stay consistent between analyses as a result of a lack of data on users from Malaysia and the Philippines we only analyze users in India on 7Cups and extend these findings to the experience of being part of a minority group on an online mental health forum. We draw validity for these exploratory findings from similar consistent patterns we observe between Indian Malaysian and Filipino users but a deeper analysis with a larger dataset is likely necessary to determine when and for which minority communities these conclusions do not hold true. Additionally while we construct clinical language through use of the commonly used DSM and ICD both frameworks of illness categorization have significant limitations particularly in the countries we have selected. For example there are both mental health disorders that are culturebound [74] as well as mental health language that is used in different ways within the specific countries we analyze such as depression often being an umbrella term for all mental illnesses [53]. Additionally it is clear that online support communities often develop their own cultural norms and language around mental health [21 72] and a deeper understanding of how this plays out on Talklife and 7Cups is neither the focus nor within the scope of this work. In this work we intentionally use standard clinical and medical terms for mental health disorders in our analysis of clinical language. As detailed in past anthropological research [52] it is theorized that the use of medical and clinical language is representative of a medicalized explanatory model of illness and we frame use of this language across cultures as a approximate signifier of a greater awareness of the presence of a mental disorder as opposed to conceptualizing distress as “stress"" “tension"" or “depression"" [25 53 98]. For our analysis we strictly analyzed posts that were in the Latin alphabet with almost all posts on both Talklife and 7Cups being in English. However as both Malay [8] and Tagalog [82] are most commonly written in the Latin script and since it is common for users from India speakers to use romanized versions of Indian languages online [79] it is possible that a small minority of posts in our analysis were text in a different language. However as confirmed by only seeing English words used in our analysis of the top n-grams among each user subgroup it is clear that English is the predominant language on both platforms. Though beyond the immediate scope of this work a greater analysis of non-English code-switching on these platforms could lead to a deeper understanding of the impact of interactions on expression between users with the same national identity but different language preferences.",selection criterion and data scope to understand the impact of cultural difference on how individual use online mental health platform we begin our analysis by creating a dataset of user from different national community on talklife a support platform with over half a million user for this analysis due to the fact that most research in cscw on mental health online ha been done either agnostic of cultural context or in a western context we choose to focus on user from nonwestern country following zhang et al a researcher located in the global south and with lived experience interacting with the health system and diverse explanatory model of mental illness we believe that moving the focus of cscw and cscwadjacent mental health research away from the west is crucial to better meet the need of people often underserved by the medical system to create these subgroup of user we choose the three nonwestern country with the highest user population on talklife or india malaysia and the philippine guided by the rich amount of literature on the unique nuance to mental health expression for each country we examine the national identity linguistic and behaviorbased difference of use between each user subgroup in particular this research note that a a result of cultural norm around the sharing of distress and alternative conceptualization of mental illness in india malaysia and the philippine symptom are often expressed in somatic and religious term a opposed to traditionally clinical or psychiatric term we choose to analyze each subgroup at the national level for both theoretical and practical reason on a theoretical level in past work in the medical anthropology of mental health national identity ha commonly been used for a approximate level of analysis for cultural identity additionally on a more practical level each user country wa determined using their ip address by talklife and shared with u in an useranonymized dataset inferring a more precise location could potentially compromise user anonymity a discussed in past work and did not seem to have any more significant value for our analysis of cultural difference than analysis at the national level we analyze data from indian user malaysian user and filipino user a shown in table collectively we refer to these country a the minority sample a a comparison set we construct a random sample of all thread on talklife and refer to it a the majority sample due to the relative prevalence of user from western englishspeaking country in talklife most of the thread in the majority sample include post from country such a the usa uk and canada indian are the largest nonwestern minority subgroup on talklife data wa sampled from may to june following this crossnational analysis to see if our broader result on talklife generalize to a differently structured online mental health community we picked the largest western country the united state and the largest nonwestern country india represented on cup a similar support platform with more than user actively using the platform each week using cup data we repeat our analysis testing for the same cultural difference we found in our talklife sample for this analysis we were provided a sample of data on activity from indian user and american user a shown in table unlike our sample of talklife user this dataset is not a random sample there is an upsampling of indian user to ensure that we have data from a sufficient number of indian in the dataset like on talklife indian are the largest nonwestern minority subgroup on cup we focus on indian user due to a lack of sufficient data on user from malaysia or the philippine data wa sampled from march august defining cultural identity and use of clinical language in this work we examine the relationship between cultural identity and use of online mental health support forum to do so we leverage tomlinsons definition of cultural identity a self and communal definition based around specific usually politically inflected differentiation gender sexuality class religion race and ethnicity nationality particularly looking at the aspect that of modern cultural identity that run along national line a delineated by hall et al a a diverse and amorphous form of identity cultural identity can often intersect and interact with other form of identity including religious or ethnic identity however in the absence of direct information about religious or ethnic identity based on the data available we use national identity a a proxy for cultural identity additionally following schlesinger et al call for more intersectional analysis and method within hci we also include analysis of adjacent and intersecting identity when relevant including religious identity to analyze clinical language we use a broader definition of clinical language than just specific medical diagnosis following method used in past work to analyze antidepressant related language we create a dataset of clinical mental health language including unigrams bigram and trigram from a list of mental disorder a defined by the international classification of disease icd and diagnostic and statistical manual of mental disorder dsm we also included all unigrams from the macmillan dictionary list of word used to describe illness and disease both specifically for mental illness and general illness a a result we include unigrams like night from night terror or sleep from sleep disorder a these are often correlated with specific symptom of mental illness or distress such a sleep issue or being awake at night this included any clinically common abbreviation for mental disorder such a ocd for obsessive compulsive disorder or bpd for borderline personality disorder shorthand for disorder commonly used by online community such a proana a used in proeating disorder community were not included due to the difficulty in finding an exhaustive list of these term across disorder we choose to use term from and associated with dsm and icd categorized disorder a a result of the common usage of these framework globally throughout our analysis of these varied factor we use to represent mean and to represent standard deviation constraint limitation and tradeoff cultural identity can exist at many different and intersecting level including subculture and subcommunities within the larger umbrella of a cultural identity a a result for the purpose of this analysis we had to adopt some constraint in order to do a meaningful and specific analysis one large limiting constraint that we chose for this study is to use national identity at the state level a a proxy for cultural identity though a major and formative part of modern cultural identity a argued by both hall and tomlinson each country we analyze is incredibly diverse with many individual cultural identity that both intersect and diverge from a greater national identity a more rich analysis of these other form of cultural identity is beyond the scope of this work but could lead to richer conclusion about the nature of cultural identity in online mental health support community particularly with regard to cultural difference between user with the same national identity additionally to stay consistent between analysis a a result of a lack of data on user from malaysia and the philippine we only analyze user in india on cup and extend these finding to the experience of being part of a minority group on an online mental health forum we draw validity for these exploratory finding from similar consistent pattern we observe between indian malaysian and filipino user but a deeper analysis with a larger dataset is likely necessary to determine when and for which minority community these conclusion do not hold true additionally while we construct clinical language through use of the commonly used dsm and icd both framework of illness categorization have significant limitation particularly in the country we have selected for example there are both mental health disorder that are culturebound a well a mental health language that is used in different way within the specific country we analyze such a depression often being an umbrella term for all mental illness additionally it is clear that online support community often develop their own cultural norm and language around mental health and a deeper understanding of how this play out on talklife and cup is neither the focus nor within the scope of this work in this work we intentionally use standard clinical and medical term for mental health disorder in our analysis of clinical language a detailed in past anthropological research it is theorized that the use of medical and clinical language is representative of a medicalized explanatory model of illness and we frame use of this language across culture a a approximate signifier of a greater awareness of the presence of a mental disorder a opposed to conceptualizing distress a stress tension or depression for our analysis we strictly analyzed post that were in the latin alphabet with almost all post on both talklife and cup being in english however a both malay and tagalog are most commonly written in the latin script and since it is common for user from india speaker to use romanized version of indian language online it is possible that a small minority of post in our analysis were text in a different language however a confirmed by only seeing english word used in our analysis of the top ngrams among each user subgroup it is clear that english is the predominant language on both platform though beyond the immediate scope of this work a greater analysis of nonenglish codeswitching on these platform could lead to a deeper understanding of the impact of interaction on expression between user with the same national identity but different language preference,"['selection', 'criterion', 'data', 'scope', 'understand', 'impact', 'cultural', 'difference', 'individual', 'use', 'online', 'mental', 'health', 'platform', 'begin', 'analysis', 'creating', 'dataset', 'user', 'different', 'national', 'community', 'talklife', 'support', 'platform', 'half', 'million', 'user', 'analysis', 'due', 'fact', 'research', 'cscw', 'mental', 'health', 'online', 'ha', 'done', 'either', 'agnostic', 'cultural', 'context', 'western', 'context', 'choose', 'focus', 'user', 'nonwestern', 'country', 'following', 'zhang', 'et', 'al', 'researcher', 'located', 'global', 'south', 'lived', 'experience', 'interacting', 'health', 'system', 'diverse', 'explanatory', 'model', 'mental', 'illness', 'believe', 'moving', 'focus', 'cscw', 'cscwadjacent', 'mental', 'health', 'research', 'away', 'west', 'crucial', 'better', 'meet', 'need', 'people', 'often', 'underserved', 'medical', 'system', 'create', 'subgroup', 'user', 'choose', 'three', 'nonwestern', 'country', 'highest', 'user', 'population', 'talklife', 'india', 'malaysia', 'philippine', 'guided', 'rich', 'amount', 'literature', 'unique', 'nuance', 'mental', 'health', 'expression', 'country', 'examine', 'national', 'identity', 'linguistic', 'behaviorbased', 'difference', 'use', 'user', 'subgroup', 'particular', 'research', 'note', 'result', 'cultural', 'norm', 'around', 'sharing', 'distress', 'alternative', 'conceptualization', 'mental', 'illness', 'india', 'malaysia', 'philippine', 'symptom', 'often', 'expressed', 'somatic', 'religious', 'term', 'opposed', 'traditionally', 'clinical', 'psychiatric', 'term', 'choose', 'analyze', 'subgroup', 'national', 'level', 'theoretical', 'practical', 'reason', 'theoretical', 'level', 'past', 'work', 'medical', 'anthropology', 'mental', 'health', 'national', 'identity', 'ha', 'commonly', 'used', 'approximate', 'level', 'analysis', 'cultural', 'identity', 'additionally', 'practical', 'level', 'user', 'country', 'wa', 'determined', 'using', 'ip', 'address', 'talklife', 'shared', 'u', 'useranonymized', 'dataset', 'inferring', 'precise', 'location', 'could', 'potentially', 'compromise', 'user', 'anonymity', 'discussed', 'past', 'work', 'seem', 'significant', 'value', 'analysis', 'cultural', 'difference', 'analysis', 'national', 'level', 'analyze', 'data', 'indian', 'user', 'malaysian', 'user', 'filipino', 'user', 'shown', 'table', 'collectively', 'refer', 'country', 'minority', 'sample', 'comparison', 'set', 'construct', 'random', 'sample', 'thread', 'talklife', 'refer', 'majority', 'sample', 'due', 'relative', 'prevalence', 'user', 'western', 'englishspeaking', 'country', 'talklife', 'thread', 'majority', 'sample', 'include', 'post', 'country', 'usa', 'uk', 'canada', 'indian', 'largest', 'nonwestern', 'minority', 'subgroup', 'talklife', 'data', 'wa', 'sampled', 'may', 'june', 'following', 'crossnational', 'analysis', 'see', 'broader', 'result', 'talklife', 'generalize', 'differently', 'structured', 'online', 'mental', 'health', 'community', 'picked', 'largest', 'western', 'country', 'united', 'state', 'largest', 'nonwestern', 'country', 'india', 'represented', 'cup', 'similar', 'support', 'platform', 'user', 'actively', 'using', 'platform', 'week', 'using', 'cup', 'data', 'repeat', 'analysis', 'testing', 'cultural', 'difference', 'found', 'talklife', 'sample', 'analysis', 'provided', 'sample', 'data', 'activity', 'indian', 'user', 'american', 'user', 'shown', 'table', 'unlike', 'sample', 'talklife', 'user', 'dataset', 'random', 'sample', 'upsampling', 'indian', 'user', 'ensure', 'data', 'sufficient', 'number', 'indian', 'dataset', 'like', 'talklife', 'indian', 'largest', 'nonwestern', 'minority', 'subgroup', 'cup', 'focus', 'indian', 'user', 'due', 'lack', 'sufficient', 'data', 'user', 'malaysia', 'philippine', 'data', 'wa', 'sampled', 'march', 'august', 'defining', 'cultural', 'identity', 'use', 'clinical', 'language', 'work', 'examine', 'relationship', 'cultural', 'identity', 'use', 'online', 'mental', 'health', 'support', 'forum', 'leverage', 'tomlinsons', 'definition', 'cultural', 'identity', 'self', 'communal', 'definition', 'based', 'around', 'specific', 'usually', 'politically', 'inflected', 'differentiation', 'gender', 'sexuality', 'class', 'religion', 'race', 'ethnicity', 'nationality', 'particularly', 'looking', 'aspect', 'modern', 'cultural', 'identity', 'run', 'along', 'national', 'line', 'delineated', 'hall', 'et', 'al', 'diverse', 'amorphous', 'form', 'identity', 'cultural', 'identity', 'often', 'intersect', 'interact', 'form', 'identity', 'including', 'religious', 'ethnic', 'identity', 'however', 'absence', 'direct', 'information', 'religious', 'ethnic', 'identity', 'based', 'data', 'available', 'use', 'national', 'identity', 'proxy', 'cultural', 'identity', 'additionally', 'following', 'schlesinger', 'et', 'al', 'call', 'intersectional', 'analysis', 'method', 'within', 'hci', 'also', 'include', 'analysis', 'adjacent', 'intersecting', 'identity', 'relevant', 'including', 'religious', 'identity', 'analyze', 'clinical', 'language', 'use', 'broader', 'definition', 'clinical', 'language', 'specific', 'medical', 'diagnosis', 'following', 'method', 'used', 'past', 'work', 'analyze', 'antidepressant', 'related', 'language', 'create', 'dataset', 'clinical', 'mental', 'health', 'language', 'including', 'unigrams', 'bigram', 'trigram', 'list', 'mental', 'disorder', 'defined', 'international', 'classification', 'disease', 'icd', 'diagnostic', 'statistical', 'manual', 'mental', 'disorder', 'dsm', 'also', 'included', 'unigrams', 'macmillan', 'dictionary', 'list', 'word', 'used', 'describe', 'illness', 'disease', 'specifically', 'mental', 'illness', 'general', 'illness', 'result', 'include', 'unigrams', 'like', 'night', 'night', 'terror', 'sleep', 'sleep', 'disorder', 'often', 'correlated', 'specific', 'symptom', 'mental', 'illness', 'distress', 'sleep', 'issue', 'awake', 'night', 'included', 'clinically', 'common', 'abbreviation', 'mental', 'disorder', 'ocd', 'obsessive', 'compulsive', 'disorder', 'bpd', 'borderline', 'personality', 'disorder', 'shorthand', 'disorder', 'commonly', 'used', 'online', 'community', 'proana', 'used', 'proeating', 'disorder', 'community', 'included', 'due', 'difficulty', 'finding', 'exhaustive', 'list', 'term', 'across', 'disorder', 'choose', 'use', 'term', 'associated', 'dsm', 'icd', 'categorized', 'disorder', 'result', 'common', 'usage', 'framework', 'globally', 'throughout', 'analysis', 'varied', 'factor', 'use', 'represent', 'mean', 'represent', 'standard', 'deviation', 'constraint', 'limitation', 'tradeoff', 'cultural', 'identity', 'exist', 'many', 'different', 'intersecting', 'level', 'including', 'subculture', 'subcommunities', 'within', 'larger', 'umbrella', 'cultural', 'identity', 'result', 'purpose', 'analysis', 'adopt', 'constraint', 'order', 'meaningful', 'specific', 'analysis', 'one', 'large', 'limiting', 'constraint', 'chose', 'study', 'use', 'national', 'identity', 'state', 'level', 'proxy', 'cultural', 'identity', 'though', 'major', 'formative', 'part', 'modern', 'cultural', 'identity', 'argued', 'hall', 'tomlinson', 'country', 'analyze', 'incredibly', 'diverse', 'many', 'individual', 'cultural', 'identity', 'intersect', 'diverge', 'greater', 'national', 'identity', 'rich', 'analysis', 'form', 'cultural', 'identity', 'beyond', 'scope', 'work', 'could', 'lead', 'richer', 'conclusion', 'nature', 'cultural', 'identity', 'online', 'mental', 'health', 'support', 'community', 'particularly', 'regard', 'cultural', 'difference', 'user', 'national', 'identity', 'additionally', 'stay', 'consistent', 'analysis', 'result', 'lack', 'data', 'user', 'malaysia', 'philippine', 'analyze', 'user', 'india', 'cup', 'extend', 'finding', 'experience', 'part', 'minority', 'group', 'online', 'mental', 'health', 'forum', 'draw', 'validity', 'exploratory', 'finding', 'similar', 'consistent', 'pattern', 'observe', 'indian', 'malaysian', 'filipino', 'user', 'deeper', 'analysis', 'larger', 'dataset', 'likely', 'necessary', 'determine', 'minority', 'community', 'conclusion', 'hold', 'true', 'additionally', 'construct', 'clinical', 'language', 'use', 'commonly', 'used', 'dsm', 'icd', 'framework', 'illness', 'categorization', 'significant', 'limitation', 'particularly', 'country', 'selected', 'example', 'mental', 'health', 'disorder', 'culturebound', 'well', 'mental', 'health', 'language', 'used', 'different', 'way', 'within', 'specific', 'country', 'analyze', 'depression', 'often', 'umbrella', 'term', 'mental', 'illness', 'additionally', 'clear', 'online', 'support', 'community', 'often', 'develop', 'cultural', 'norm', 'language', 'around', 'mental', 'health', 'deeper', 'understanding', 'play', 'talklife', 'cup', 'neither', 'focus', 'within', 'scope', 'work', 'work', 'intentionally', 'use', 'standard', 'clinical', 'medical', 'term', 'mental', 'health', 'disorder', 'analysis', 'clinical', 'language', 'detailed', 'past', 'anthropological', 'research', 'theorized', 'use', 'medical', 'clinical', 'language', 'representative', 'medicalized', 'explanatory', 'model', 'illness', 'frame', 'use', 'language', 'across', 'culture', 'approximate', 'signifier', 'greater', 'awareness', 'presence', 'mental', 'disorder', 'opposed', 'conceptualizing', 'distress', 'stress', 'tension', 'depression', 'analysis', 'strictly', 'analyzed', 'post', 'latin', 'alphabet', 'almost', 'post', 'talklife', 'cup', 'english', 'however', 'malay', 'tagalog', 'commonly', 'written', 'latin', 'script', 'since', 'common', 'user', 'india', 'speaker', 'use', 'romanized', 'version', 'indian', 'language', 'online', 'possible', 'small', 'minority', 'post', 'analysis', 'text', 'different', 'language', 'however', 'confirmed', 'seeing', 'english', 'word', 'used', 'analysis', 'top', 'ngrams', 'among', 'user', 'subgroup', 'clear', 'english', 'predominant', 'language', 'platform', 'though', 'beyond', 'immediate', 'scope', 'work', 'greater', 'analysis', 'nonenglish', 'codeswitching', 'platform', 'could', 'lead', 'deeper', 'understanding', 'impact', 'interaction', 'expression', 'user', 'national', 'identity', 'different', 'language', 'preference']","['selection criterion', 'criterion data', 'data scope', 'scope understand', 'understand impact', 'impact cultural', 'cultural difference', 'difference individual', 'individual use', 'use online', 'online mental', 'mental health', 'health platform', 'platform begin', 'begin analysis', 'analysis creating', 'creating dataset', 'dataset user', 'user different', 'different national', 'national community', 'community talklife', 'talklife support', 'support platform', 'platform half', 'half million', 'million user', 'user analysis', 'analysis due', 'due fact', 'fact research', 'research cscw', 'cscw mental', 'mental health', 'health online', 'online ha', 'ha done', 'done either', 'either agnostic', 'agnostic cultural', 'cultural context', 'context western', 'western context', 'context choose', 'choose focus', 'focus user', 'user nonwestern', 'nonwestern country', 'country following', 'following zhang', 'zhang et', 'et al', 'al researcher', 'researcher located', 'located global', 'global south', 'south lived', 'lived experience', 'experience interacting', 'interacting health', 'health system', 'system diverse', 'diverse explanatory', 'explanatory model', 'model mental', 'mental illness', 'illness believe', 'believe moving', 'moving focus', 'focus cscw', 'cscw cscwadjacent', 'cscwadjacent mental', 'mental health', 'health research', 'research away', 'away west', 'west crucial', 'crucial better', 'better meet', 'meet need', 'need people', 'people often', 'often underserved', 'underserved medical', 'medical system', 'system create', 'create subgroup', 'subgroup user', 'user choose', 'choose three', 'three nonwestern', 'nonwestern country', 'country highest', 'highest user', 'user population', 'population talklife', 'talklife india', 'india malaysia', 'malaysia philippine', 'philippine guided', 'guided rich', 'rich amount', 'amount literature', 'literature unique', 'unique nuance', 'nuance mental', 'mental health', 'health expression', 'expression country', 'country examine', 'examine national', 'national identity', 'identity linguistic', 'linguistic behaviorbased', 'behaviorbased difference', 'difference use', 'use user', 'user subgroup', 'subgroup particular', 'particular research', 'research note', 'note result', 'result cultural', 'cultural norm', 'norm around', 'around sharing', 'sharing distress', 'distress alternative', 'alternative conceptualization', 'conceptualization mental', 'mental illness', 'illness india', 'india malaysia', 'malaysia philippine', 'philippine symptom', 'symptom often', 'often expressed', 'expressed somatic', 'somatic religious', 'religious term', 'term opposed', 'opposed traditionally', 'traditionally clinical', 'clinical psychiatric', 'psychiatric term', 'term choose', 'choose analyze', 'analyze subgroup', 'subgroup national', 'national level', 'level theoretical', 'theoretical practical', 'practical reason', 'reason theoretical', 'theoretical level', 'level past', 'past work', 'work medical', 'medical anthropology', 'anthropology mental', 'mental health', 'health national', 'national identity', 'identity ha', 'ha commonly', 'commonly used', 'used approximate', 'approximate level', 'level analysis', 'analysis cultural', 'cultural identity', 'identity additionally', 'additionally practical', 'practical level', 'level user', 'user country', 'country wa', 'wa determined', 'determined using', 'using ip', 'ip address', 'address talklife', 'talklife shared', 'shared u', 'u useranonymized', 'useranonymized dataset', 'dataset inferring', 'inferring precise', 'precise location', 'location could', 'could potentially', 'potentially compromise', 'compromise user', 'user anonymity', 'anonymity discussed', 'discussed past', 'past work', 'work seem', 'seem significant', 'significant value', 'value analysis', 'analysis cultural', 'cultural difference', 'difference analysis', 'analysis national', 'national level', 'level analyze', 'analyze data', 'data indian', 'indian user', 'user malaysian', 'malaysian user', 'user filipino', 'filipino user', 'user shown', 'shown table', 'table collectively', 'collectively refer', 'refer country', 'country minority', 'minority sample', 'sample comparison', 'comparison set', 'set construct', 'construct random', 'random sample', 'sample thread', 'thread talklife', 'talklife refer', 'refer majority', 'majority sample', 'sample due', 'due relative', 'relative prevalence', 'prevalence user', 'user western', 'western englishspeaking', 'englishspeaking country', 'country talklife', 'talklife thread', 'thread majority', 'majority sample', 'sample include', 'include post', 'post country', 'country usa', 'usa uk', 'uk canada', 'canada indian', 'indian largest', 'largest nonwestern', 'nonwestern minority', 'minority subgroup', 'subgroup talklife', 'talklife data', 'data wa', 'wa sampled', 'sampled may', 'may june', 'june following', 'following crossnational', 'crossnational analysis', 'analysis see', 'see broader', 'broader result', 'result talklife', 'talklife generalize', 'generalize differently', 'differently structured', 'structured online', 'online mental', 'mental health', 'health community', 'community picked', 'picked largest', 'largest western', 'western country', 'country united', 'united state', 'state largest', 'largest nonwestern', 'nonwestern country', 'country india', 'india represented', 'represented cup', 'cup similar', 'similar support', 'support platform', 'platform user', 'user actively', 'actively using', 'using platform', 'platform week', 'week using', 'using cup', 'cup data', 'data repeat', 'repeat analysis', 'analysis testing', 'testing cultural', 'cultural difference', 'difference found', 'found talklife', 'talklife sample', 'sample analysis', 'analysis provided', 'provided sample', 'sample data', 'data activity', 'activity indian', 'indian user', 'user american', 'american user', 'user shown', 'shown table', 'table unlike', 'unlike sample', 'sample talklife', 'talklife user', 'user dataset', 'dataset random', 'random sample', 'sample upsampling', 'upsampling indian', 'indian user', 'user ensure', 'ensure data', 'data sufficient', 'sufficient number', 'number indian', 'indian dataset', 'dataset like', 'like talklife', 'talklife indian', 'indian largest', 'largest nonwestern', 'nonwestern minority', 'minority subgroup', 'subgroup cup', 'cup focus', 'focus indian', 'indian user', 'user due', 'due lack', 'lack sufficient', 'sufficient data', 'data user', 'user malaysia', 'malaysia philippine', 'philippine data', 'data wa', 'wa sampled', 'sampled march', 'march august', 'august defining', 'defining cultural', 'cultural identity', 'identity use', 'use clinical', 'clinical language', 'language work', 'work examine', 'examine relationship', 'relationship cultural', 'cultural identity', 'identity use', 'use online', 'online mental', 'mental health', 'health support', 'support forum', 'forum leverage', 'leverage tomlinsons', 'tomlinsons definition', 'definition cultural', 'cultural identity', 'identity self', 'self communal', 'communal definition', 'definition based', 'based around', 'around specific', 'specific usually', 'usually politically', 'politically inflected', 'inflected differentiation', 'differentiation gender', 'gender sexuality', 'sexuality class', 'class religion', 'religion race', 'race ethnicity', 'ethnicity nationality', 'nationality particularly', 'particularly looking', 'looking aspect', 'aspect modern', 'modern cultural', 'cultural identity', 'identity run', 'run along', 'along national', 'national line', 'line delineated', 'delineated hall', 'hall et', 'et al', 'al diverse', 'diverse amorphous', 'amorphous form', 'form identity', 'identity cultural', 'cultural identity', 'identity often', 'often intersect', 'intersect interact', 'interact form', 'form identity', 'identity including', 'including religious', 'religious ethnic', 'ethnic identity', 'identity however', 'however absence', 'absence direct', 'direct information', 'information religious', 'religious ethnic', 'ethnic identity', 'identity based', 'based data', 'data available', 'available use', 'use national', 'national identity', 'identity proxy', 'proxy cultural', 'cultural identity', 'identity additionally', 'additionally following', 'following schlesinger', 'schlesinger et', 'et al', 'al call', 'call intersectional', 'intersectional analysis', 'analysis method', 'method within', 'within hci', 'hci also', 'also include', 'include analysis', 'analysis adjacent', 'adjacent intersecting', 'intersecting identity', 'identity relevant', 'relevant including', 'including religious', 'religious identity', 'identity analyze', 'analyze clinical', 'clinical language', 'language use', 'use broader', 'broader definition', 'definition clinical', 'clinical language', 'language specific', 'specific medical', 'medical diagnosis', 'diagnosis following', 'following method', 'method used', 'used past', 'past work', 'work analyze', 'analyze antidepressant', 'antidepressant related', 'related language', 'language create', 'create dataset', 'dataset clinical', 'clinical mental', 'mental health', 'health language', 'language including', 'including unigrams', 'unigrams bigram', 'bigram trigram', 'trigram list', 'list mental', 'mental disorder', 'disorder defined', 'defined international', 'international classification', 'classification disease', 'disease icd', 'icd diagnostic', 'diagnostic statistical', 'statistical manual', 'manual mental', 'mental disorder', 'disorder dsm', 'dsm also', 'also included', 'included unigrams', 'unigrams macmillan', 'macmillan dictionary', 'dictionary list', 'list word', 'word used', 'used describe', 'describe illness', 'illness disease', 'disease specifically', 'specifically mental', 'mental illness', 'illness general', 'general illness', 'illness result', 'result include', 'include unigrams', 'unigrams like', 'like night', 'night night', 'night terror', 'terror sleep', 'sleep sleep', 'sleep disorder', 'disorder often', 'often correlated', 'correlated specific', 'specific symptom', 'symptom mental', 'mental illness', 'illness distress', 'distress sleep', 'sleep issue', 'issue awake', 'awake night', 'night included', 'included clinically', 'clinically common', 'common abbreviation', 'abbreviation mental', 'mental disorder', 'disorder ocd', 'ocd obsessive', 'obsessive compulsive', 'compulsive disorder', 'disorder bpd', 'bpd borderline', 'borderline personality', 'personality disorder', 'disorder shorthand', 'shorthand disorder', 'disorder commonly', 'commonly used', 'used online', 'online community', 'community proana', 'proana used', 'used proeating', 'proeating disorder', 'disorder community', 'community included', 'included due', 'due difficulty', 'difficulty finding', 'finding exhaustive', 'exhaustive list', 'list term', 'term across', 'across disorder', 'disorder choose', 'choose use', 'use term', 'term associated', 'associated dsm', 'dsm icd', 'icd categorized', 'categorized disorder', 'disorder result', 'result common', 'common usage', 'usage framework', 'framework globally', 'globally throughout', 'throughout analysis', 'analysis varied', 'varied factor', 'factor use', 'use represent', 'represent mean', 'mean represent', 'represent standard', 'standard deviation', 'deviation constraint', 'constraint limitation', 'limitation tradeoff', 'tradeoff cultural', 'cultural identity', 'identity exist', 'exist many', 'many different', 'different intersecting', 'intersecting level', 'level including', 'including subculture', 'subculture subcommunities', 'subcommunities within', 'within larger', 'larger umbrella', 'umbrella cultural', 'cultural identity', 'identity result', 'result purpose', 'purpose analysis', 'analysis adopt', 'adopt constraint', 'constraint order', 'order meaningful', 'meaningful specific', 'specific analysis', 'analysis one', 'one large', 'large limiting', 'limiting constraint', 'constraint chose', 'chose study', 'study use', 'use national', 'national identity', 'identity state', 'state level', 'level proxy', 'proxy cultural', 'cultural identity', 'identity though', 'though major', 'major formative', 'formative part', 'part modern', 'modern cultural', 'cultural identity', 'identity argued', 'argued hall', 'hall tomlinson', 'tomlinson country', 'country analyze', 'analyze incredibly', 'incredibly diverse', 'diverse many', 'many individual', 'individual cultural', 'cultural identity', 'identity intersect', 'intersect diverge', 'diverge greater', 'greater national', 'national identity', 'identity rich', 'rich analysis', 'analysis form', 'form cultural', 'cultural identity', 'identity beyond', 'beyond scope', 'scope work', 'work could', 'could lead', 'lead richer', 'richer conclusion', 'conclusion nature', 'nature cultural', 'cultural identity', 'identity online', 'online mental', 'mental health', 'health support', 'support community', 'community particularly', 'particularly regard', 'regard cultural', 'cultural difference', 'difference user', 'user national', 'national identity', 'identity additionally', 'additionally stay', 'stay consistent', 'consistent analysis', 'analysis result', 'result lack', 'lack data', 'data user', 'user malaysia', 'malaysia philippine', 'philippine analyze', 'analyze user', 'user india', 'india cup', 'cup extend', 'extend finding', 'finding experience', 'experience part', 'part minority', 'minority group', 'group online', 'online mental', 'mental health', 'health forum', 'forum draw', 'draw validity', 'validity exploratory', 'exploratory finding', 'finding similar', 'similar consistent', 'consistent pattern', 'pattern observe', 'observe indian', 'indian malaysian', 'malaysian filipino', 'filipino user', 'user deeper', 'deeper analysis', 'analysis larger', 'larger dataset', 'dataset likely', 'likely necessary', 'necessary determine', 'determine minority', 'minority community', 'community conclusion', 'conclusion hold', 'hold true', 'true additionally', 'additionally construct', 'construct clinical', 'clinical language', 'language use', 'use commonly', 'commonly used', 'used dsm', 'dsm icd', 'icd framework', 'framework illness', 'illness categorization', 'categorization significant', 'significant limitation', 'limitation particularly', 'particularly country', 'country selected', 'selected example', 'example mental', 'mental health', 'health disorder', 'disorder culturebound', 'culturebound well', 'well mental', 'mental health', 'health language', 'language used', 'used different', 'different way', 'way within', 'within specific', 'specific country', 'country analyze', 'analyze depression', 'depression often', 'often umbrella', 'umbrella term', 'term mental', 'mental illness', 'illness additionally', 'additionally clear', 'clear online', 'online support', 'support community', 'community often', 'often develop', 'develop cultural', 'cultural norm', 'norm language', 'language around', 'around mental', 'mental health', 'health deeper', 'deeper understanding', 'understanding play', 'play talklife', 'talklife cup', 'cup neither', 'neither focus', 'focus within', 'within scope', 'scope work', 'work work', 'work intentionally', 'intentionally use', 'use standard', 'standard clinical', 'clinical medical', 'medical term', 'term mental', 'mental health', 'health disorder', 'disorder analysis', 'analysis clinical', 'clinical language', 'language detailed', 'detailed past', 'past anthropological', 'anthropological research', 'research theorized', 'theorized use', 'use medical', 'medical clinical', 'clinical language', 'language representative', 'representative medicalized', 'medicalized explanatory', 'explanatory model', 'model illness', 'illness frame', 'frame use', 'use language', 'language across', 'across culture', 'culture approximate', 'approximate signifier', 'signifier greater', 'greater awareness', 'awareness presence', 'presence mental', 'mental disorder', 'disorder opposed', 'opposed conceptualizing', 'conceptualizing distress', 'distress stress', 'stress tension', 'tension depression', 'depression analysis', 'analysis strictly', 'strictly analyzed', 'analyzed post', 'post latin', 'latin alphabet', 'alphabet almost', 'almost post', 'post talklife', 'talklife cup', 'cup english', 'english however', 'however malay', 'malay tagalog', 'tagalog commonly', 'commonly written', 'written latin', 'latin script', 'script since', 'since common', 'common user', 'user india', 'india speaker', 'speaker use', 'use romanized', 'romanized version', 'version indian', 'indian language', 'language online', 'online possible', 'possible small', 'small minority', 'minority post', 'post analysis', 'analysis text', 'text different', 'different language', 'language however', 'however confirmed', 'confirmed seeing', 'seeing english', 'english word', 'word used', 'used analysis', 'analysis top', 'top ngrams', 'ngrams among', 'among user', 'user subgroup', 'subgroup clear', 'clear english', 'english predominant', 'predominant language', 'language platform', 'platform though', 'though beyond', 'beyond immediate', 'immediate scope', 'scope work', 'work greater', 'greater analysis', 'analysis nonenglish', 'nonenglish codeswitching', 'codeswitching platform', 'platform could', 'could lead', 'lead deeper', 'deeper understanding', 'understanding impact', 'impact interaction', 'interaction expression', 'expression user', 'user national', 'national identity', 'identity different', 'different language', 'language preference']","['selection criterion data', 'criterion data scope', 'data scope understand', 'scope understand impact', 'understand impact cultural', 'impact cultural difference', 'cultural difference individual', 'difference individual use', 'individual use online', 'use online mental', 'online mental health', 'mental health platform', 'health platform begin', 'platform begin analysis', 'begin analysis creating', 'analysis creating dataset', 'creating dataset user', 'dataset user different', 'user different national', 'different national community', 'national community talklife', 'community talklife support', 'talklife support platform', 'support platform half', 'platform half million', 'half million user', 'million user analysis', 'user analysis due', 'analysis due fact', 'due fact research', 'fact research cscw', 'research cscw mental', 'cscw mental health', 'mental health online', 'health online ha', 'online ha done', 'ha done either', 'done either agnostic', 'either agnostic cultural', 'agnostic cultural context', 'cultural context western', 'context western context', 'western context choose', 'context choose focus', 'choose focus user', 'focus user nonwestern', 'user nonwestern country', 'nonwestern country following', 'country following zhang', 'following zhang et', 'zhang et al', 'et al researcher', 'al researcher located', 'researcher located global', 'located global south', 'global south lived', 'south lived experience', 'lived experience interacting', 'experience interacting health', 'interacting health system', 'health system diverse', 'system diverse explanatory', 'diverse explanatory model', 'explanatory model mental', 'model mental illness', 'mental illness believe', 'illness believe moving', 'believe moving focus', 'moving focus cscw', 'focus cscw cscwadjacent', 'cscw cscwadjacent mental', 'cscwadjacent mental health', 'mental health research', 'health research away', 'research away west', 'away west crucial', 'west crucial better', 'crucial better meet', 'better meet need', 'meet need people', 'need people often', 'people often underserved', 'often underserved medical', 'underserved medical system', 'medical system create', 'system create subgroup', 'create subgroup user', 'subgroup user choose', 'user choose three', 'choose three nonwestern', 'three nonwestern country', 'nonwestern country highest', 'country highest user', 'highest user population', 'user population talklife', 'population talklife india', 'talklife india malaysia', 'india malaysia philippine', 'malaysia philippine guided', 'philippine guided rich', 'guided rich amount', 'rich amount literature', 'amount literature unique', 'literature unique nuance', 'unique nuance mental', 'nuance mental health', 'mental health expression', 'health expression country', 'expression country examine', 'country examine national', 'examine national identity', 'national identity linguistic', 'identity linguistic behaviorbased', 'linguistic behaviorbased difference', 'behaviorbased difference use', 'difference use user', 'use user subgroup', 'user subgroup particular', 'subgroup particular research', 'particular research note', 'research note result', 'note result cultural', 'result cultural norm', 'cultural norm around', 'norm around sharing', 'around sharing distress', 'sharing distress alternative', 'distress alternative conceptualization', 'alternative conceptualization mental', 'conceptualization mental illness', 'mental illness india', 'illness india malaysia', 'india malaysia philippine', 'malaysia philippine symptom', 'philippine symptom often', 'symptom often expressed', 'often expressed somatic', 'expressed somatic religious', 'somatic religious term', 'religious term opposed', 'term opposed traditionally', 'opposed traditionally clinical', 'traditionally clinical psychiatric', 'clinical psychiatric term', 'psychiatric term choose', 'term choose analyze', 'choose analyze subgroup', 'analyze subgroup national', 'subgroup national level', 'national level theoretical', 'level theoretical practical', 'theoretical practical reason', 'practical reason theoretical', 'reason theoretical level', 'theoretical level past', 'level past work', 'past work medical', 'work medical anthropology', 'medical anthropology mental', 'anthropology mental health', 'mental health national', 'health national identity', 'national identity ha', 'identity ha commonly', 'ha commonly used', 'commonly used approximate', 'used approximate level', 'approximate level analysis', 'level analysis cultural', 'analysis cultural identity', 'cultural identity additionally', 'identity additionally practical', 'additionally practical level', 'practical level user', 'level user country', 'user country wa', 'country wa determined', 'wa determined using', 'determined using ip', 'using ip address', 'ip address talklife', 'address talklife shared', 'talklife shared u', 'shared u useranonymized', 'u useranonymized dataset', 'useranonymized dataset inferring', 'dataset inferring precise', 'inferring precise location', 'precise location could', 'location could potentially', 'could potentially compromise', 'potentially compromise user', 'compromise user anonymity', 'user anonymity discussed', 'anonymity discussed past', 'discussed past work', 'past work seem', 'work seem significant', 'seem significant value', 'significant value analysis', 'value analysis cultural', 'analysis cultural difference', 'cultural difference analysis', 'difference analysis national', 'analysis national level', 'national level analyze', 'level analyze data', 'analyze data indian', 'data indian user', 'indian user malaysian', 'user malaysian user', 'malaysian user filipino', 'user filipino user', 'filipino user shown', 'user shown table', 'shown table collectively', 'table collectively refer', 'collectively refer country', 'refer country minority', 'country minority sample', 'minority sample comparison', 'sample comparison set', 'comparison set construct', 'set construct random', 'construct random sample', 'random sample thread', 'sample thread talklife', 'thread talklife refer', 'talklife refer majority', 'refer majority sample', 'majority sample due', 'sample due relative', 'due relative prevalence', 'relative prevalence user', 'prevalence user western', 'user western englishspeaking', 'western englishspeaking country', 'englishspeaking country talklife', 'country talklife thread', 'talklife thread majority', 'thread majority sample', 'majority sample include', 'sample include post', 'include post country', 'post country usa', 'country usa uk', 'usa uk canada', 'uk canada indian', 'canada indian largest', 'indian largest nonwestern', 'largest nonwestern minority', 'nonwestern minority subgroup', 'minority subgroup talklife', 'subgroup talklife data', 'talklife data wa', 'data wa sampled', 'wa sampled may', 'sampled may june', 'may june following', 'june following crossnational', 'following crossnational analysis', 'crossnational analysis see', 'analysis see broader', 'see broader result', 'broader result talklife', 'result talklife generalize', 'talklife generalize differently', 'generalize differently structured', 'differently structured online', 'structured online mental', 'online mental health', 'mental health community', 'health community picked', 'community picked largest', 'picked largest western', 'largest western country', 'western country united', 'country united state', 'united state largest', 'state largest nonwestern', 'largest nonwestern country', 'nonwestern country india', 'country india represented', 'india represented cup', 'represented cup similar', 'cup similar support', 'similar support platform', 'support platform user', 'platform user actively', 'user actively using', 'actively using platform', 'using platform week', 'platform week using', 'week using cup', 'using cup data', 'cup data repeat', 'data repeat analysis', 'repeat analysis testing', 'analysis testing cultural', 'testing cultural difference', 'cultural difference found', 'difference found talklife', 'found talklife sample', 'talklife sample analysis', 'sample analysis provided', 'analysis provided sample', 'provided sample data', 'sample data activity', 'data activity indian', 'activity indian user', 'indian user american', 'user american user', 'american user shown', 'user shown table', 'shown table unlike', 'table unlike sample', 'unlike sample talklife', 'sample talklife user', 'talklife user dataset', 'user dataset random', 'dataset random sample', 'random sample upsampling', 'sample upsampling indian', 'upsampling indian user', 'indian user ensure', 'user ensure data', 'ensure data sufficient', 'data sufficient number', 'sufficient number indian', 'number indian dataset', 'indian dataset like', 'dataset like talklife', 'like talklife indian', 'talklife indian largest', 'indian largest nonwestern', 'largest nonwestern minority', 'nonwestern minority subgroup', 'minority subgroup cup', 'subgroup cup focus', 'cup focus indian', 'focus indian user', 'indian user due', 'user due lack', 'due lack sufficient', 'lack sufficient data', 'sufficient data user', 'data user malaysia', 'user malaysia philippine', 'malaysia philippine data', 'philippine data wa', 'data wa sampled', 'wa sampled march', 'sampled march august', 'march august defining', 'august defining cultural', 'defining cultural identity', 'cultural identity use', 'identity use clinical', 'use clinical language', 'clinical language work', 'language work examine', 'work examine relationship', 'examine relationship cultural', 'relationship cultural identity', 'cultural identity use', 'identity use online', 'use online mental', 'online mental health', 'mental health support', 'health support forum', 'support forum leverage', 'forum leverage tomlinsons', 'leverage tomlinsons definition', 'tomlinsons definition cultural', 'definition cultural identity', 'cultural identity self', 'identity self communal', 'self communal definition', 'communal definition based', 'definition based around', 'based around specific', 'around specific usually', 'specific usually politically', 'usually politically inflected', 'politically inflected differentiation', 'inflected differentiation gender', 'differentiation gender sexuality', 'gender sexuality class', 'sexuality class religion', 'class religion race', 'religion race ethnicity', 'race ethnicity nationality', 'ethnicity nationality particularly', 'nationality particularly looking', 'particularly looking aspect', 'looking aspect modern', 'aspect modern cultural', 'modern cultural identity', 'cultural identity run', 'identity run along', 'run along national', 'along national line', 'national line delineated', 'line delineated hall', 'delineated hall et', 'hall et al', 'et al diverse', 'al diverse amorphous', 'diverse amorphous form', 'amorphous form identity', 'form identity cultural', 'identity cultural identity', 'cultural identity often', 'identity often intersect', 'often intersect interact', 'intersect interact form', 'interact form identity', 'form identity including', 'identity including religious', 'including religious ethnic', 'religious ethnic identity', 'ethnic identity however', 'identity however absence', 'however absence direct', 'absence direct information', 'direct information religious', 'information religious ethnic', 'religious ethnic identity', 'ethnic identity based', 'identity based data', 'based data available', 'data available use', 'available use national', 'use national identity', 'national identity proxy', 'identity proxy cultural', 'proxy cultural identity', 'cultural identity additionally', 'identity additionally following', 'additionally following schlesinger', 'following schlesinger et', 'schlesinger et al', 'et al call', 'al call intersectional', 'call intersectional analysis', 'intersectional analysis method', 'analysis method within', 'method within hci', 'within hci also', 'hci also include', 'also include analysis', 'include analysis adjacent', 'analysis adjacent intersecting', 'adjacent intersecting identity', 'intersecting identity relevant', 'identity relevant including', 'relevant including religious', 'including religious identity', 'religious identity analyze', 'identity analyze clinical', 'analyze clinical language', 'clinical language use', 'language use broader', 'use broader definition', 'broader definition clinical', 'definition clinical language', 'clinical language specific', 'language specific medical', 'specific medical diagnosis', 'medical diagnosis following', 'diagnosis following method', 'following method used', 'method used past', 'used past work', 'past work analyze', 'work analyze antidepressant', 'analyze antidepressant related', 'antidepressant related language', 'related language create', 'language create dataset', 'create dataset clinical', 'dataset clinical mental', 'clinical mental health', 'mental health language', 'health language including', 'language including unigrams', 'including unigrams bigram', 'unigrams bigram trigram', 'bigram trigram list', 'trigram list mental', 'list mental disorder', 'mental disorder defined', 'disorder defined international', 'defined international classification', 'international classification disease', 'classification disease icd', 'disease icd diagnostic', 'icd diagnostic statistical', 'diagnostic statistical manual', 'statistical manual mental', 'manual mental disorder', 'mental disorder dsm', 'disorder dsm also', 'dsm also included', 'also included unigrams', 'included unigrams macmillan', 'unigrams macmillan dictionary', 'macmillan dictionary list', 'dictionary list word', 'list word used', 'word used describe', 'used describe illness', 'describe illness disease', 'illness disease specifically', 'disease specifically mental', 'specifically mental illness', 'mental illness general', 'illness general illness', 'general illness result', 'illness result include', 'result include unigrams', 'include unigrams like', 'unigrams like night', 'like night night', 'night night terror', 'night terror sleep', 'terror sleep sleep', 'sleep sleep disorder', 'sleep disorder often', 'disorder often correlated', 'often correlated specific', 'correlated specific symptom', 'specific symptom mental', 'symptom mental illness', 'mental illness distress', 'illness distress sleep', 'distress sleep issue', 'sleep issue awake', 'issue awake night', 'awake night included', 'night included clinically', 'included clinically common', 'clinically common abbreviation', 'common abbreviation mental', 'abbreviation mental disorder', 'mental disorder ocd', 'disorder ocd obsessive', 'ocd obsessive compulsive', 'obsessive compulsive disorder', 'compulsive disorder bpd', 'disorder bpd borderline', 'bpd borderline personality', 'borderline personality disorder', 'personality disorder shorthand', 'disorder shorthand disorder', 'shorthand disorder commonly', 'disorder commonly used', 'commonly used online', 'used online community', 'online community proana', 'community proana used', 'proana used proeating', 'used proeating disorder', 'proeating disorder community', 'disorder community included', 'community included due', 'included due difficulty', 'due difficulty finding', 'difficulty finding exhaustive', 'finding exhaustive list', 'exhaustive list term', 'list term across', 'term across disorder', 'across disorder choose', 'disorder choose use', 'choose use term', 'use term associated', 'term associated dsm', 'associated dsm icd', 'dsm icd categorized', 'icd categorized disorder', 'categorized disorder result', 'disorder result common', 'result common usage', 'common usage framework', 'usage framework globally', 'framework globally throughout', 'globally throughout analysis', 'throughout analysis varied', 'analysis varied factor', 'varied factor use', 'factor use represent', 'use represent mean', 'represent mean represent', 'mean represent standard', 'represent standard deviation', 'standard deviation constraint', 'deviation constraint limitation', 'constraint limitation tradeoff', 'limitation tradeoff cultural', 'tradeoff cultural identity', 'cultural identity exist', 'identity exist many', 'exist many different', 'many different intersecting', 'different intersecting level', 'intersecting level including', 'level including subculture', 'including subculture subcommunities', 'subculture subcommunities within', 'subcommunities within larger', 'within larger umbrella', 'larger umbrella cultural', 'umbrella cultural identity', 'cultural identity result', 'identity result purpose', 'result purpose analysis', 'purpose analysis adopt', 'analysis adopt constraint', 'adopt constraint order', 'constraint order meaningful', 'order meaningful specific', 'meaningful specific analysis', 'specific analysis one', 'analysis one large', 'one large limiting', 'large limiting constraint', 'limiting constraint chose', 'constraint chose study', 'chose study use', 'study use national', 'use national identity', 'national identity state', 'identity state level', 'state level proxy', 'level proxy cultural', 'proxy cultural identity', 'cultural identity though', 'identity though major', 'though major formative', 'major formative part', 'formative part modern', 'part modern cultural', 'modern cultural identity', 'cultural identity argued', 'identity argued hall', 'argued hall tomlinson', 'hall tomlinson country', 'tomlinson country analyze', 'country analyze incredibly', 'analyze incredibly diverse', 'incredibly diverse many', 'diverse many individual', 'many individual cultural', 'individual cultural identity', 'cultural identity intersect', 'identity intersect diverge', 'intersect diverge greater', 'diverge greater national', 'greater national identity', 'national identity rich', 'identity rich analysis', 'rich analysis form', 'analysis form cultural', 'form cultural identity', 'cultural identity beyond', 'identity beyond scope', 'beyond scope work', 'scope work could', 'work could lead', 'could lead richer', 'lead richer conclusion', 'richer conclusion nature', 'conclusion nature cultural', 'nature cultural identity', 'cultural identity online', 'identity online mental', 'online mental health', 'mental health support', 'health support community', 'support community particularly', 'community particularly regard', 'particularly regard cultural', 'regard cultural difference', 'cultural difference user', 'difference user national', 'user national identity', 'national identity additionally', 'identity additionally stay', 'additionally stay consistent', 'stay consistent analysis', 'consistent analysis result', 'analysis result lack', 'result lack data', 'lack data user', 'data user malaysia', 'user malaysia philippine', 'malaysia philippine analyze', 'philippine analyze user', 'analyze user india', 'user india cup', 'india cup extend', 'cup extend finding', 'extend finding experience', 'finding experience part', 'experience part minority', 'part minority group', 'minority group online', 'group online mental', 'online mental health', 'mental health forum', 'health forum draw', 'forum draw validity', 'draw validity exploratory', 'validity exploratory finding', 'exploratory finding similar', 'finding similar consistent', 'similar consistent pattern', 'consistent pattern observe', 'pattern observe indian', 'observe indian malaysian', 'indian malaysian filipino', 'malaysian filipino user', 'filipino user deeper', 'user deeper analysis', 'deeper analysis larger', 'analysis larger dataset', 'larger dataset likely', 'dataset likely necessary', 'likely necessary determine', 'necessary determine minority', 'determine minority community', 'minority community conclusion', 'community conclusion hold', 'conclusion hold true', 'hold true additionally', 'true additionally construct', 'additionally construct clinical', 'construct clinical language', 'clinical language use', 'language use commonly', 'use commonly used', 'commonly used dsm', 'used dsm icd', 'dsm icd framework', 'icd framework illness', 'framework illness categorization', 'illness categorization significant', 'categorization significant limitation', 'significant limitation particularly', 'limitation particularly country', 'particularly country selected', 'country selected example', 'selected example mental', 'example mental health', 'mental health disorder', 'health disorder culturebound', 'disorder culturebound well', 'culturebound well mental', 'well mental health', 'mental health language', 'health language used', 'language used different', 'used different way', 'different way within', 'way within specific', 'within specific country', 'specific country analyze', 'country analyze depression', 'analyze depression often', 'depression often umbrella', 'often umbrella term', 'umbrella term mental', 'term mental illness', 'mental illness additionally', 'illness additionally clear', 'additionally clear online', 'clear online support', 'online support community', 'support community often', 'community often develop', 'often develop cultural', 'develop cultural norm', 'cultural norm language', 'norm language around', 'language around mental', 'around mental health', 'mental health deeper', 'health deeper understanding', 'deeper understanding play', 'understanding play talklife', 'play talklife cup', 'talklife cup neither', 'cup neither focus', 'neither focus within', 'focus within scope', 'within scope work', 'scope work work', 'work work intentionally', 'work intentionally use', 'intentionally use standard', 'use standard clinical', 'standard clinical medical', 'clinical medical term', 'medical term mental', 'term mental health', 'mental health disorder', 'health disorder analysis', 'disorder analysis clinical', 'analysis clinical language', 'clinical language detailed', 'language detailed past', 'detailed past anthropological', 'past anthropological research', 'anthropological research theorized', 'research theorized use', 'theorized use medical', 'use medical clinical', 'medical clinical language', 'clinical language representative', 'language representative medicalized', 'representative medicalized explanatory', 'medicalized explanatory model', 'explanatory model illness', 'model illness frame', 'illness frame use', 'frame use language', 'use language across', 'language across culture', 'across culture approximate', 'culture approximate signifier', 'approximate signifier greater', 'signifier greater awareness', 'greater awareness presence', 'awareness presence mental', 'presence mental disorder', 'mental disorder opposed', 'disorder opposed conceptualizing', 'opposed conceptualizing distress', 'conceptualizing distress stress', 'distress stress tension', 'stress tension depression', 'tension depression analysis', 'depression analysis strictly', 'analysis strictly analyzed', 'strictly analyzed post', 'analyzed post latin', 'post latin alphabet', 'latin alphabet almost', 'alphabet almost post', 'almost post talklife', 'post talklife cup', 'talklife cup english', 'cup english however', 'english however malay', 'however malay tagalog', 'malay tagalog commonly', 'tagalog commonly written', 'commonly written latin', 'written latin script', 'latin script since', 'script since common', 'since common user', 'common user india', 'user india speaker', 'india speaker use', 'speaker use romanized', 'use romanized version', 'romanized version indian', 'version indian language', 'indian language online', 'language online possible', 'online possible small', 'possible small minority', 'small minority post', 'minority post analysis', 'post analysis text', 'analysis text different', 'text different language', 'different language however', 'language however confirmed', 'however confirmed seeing', 'confirmed seeing english', 'seeing english word', 'english word used', 'word used analysis', 'used analysis top', 'analysis top ngrams', 'top ngrams among', 'ngrams among user', 'among user subgroup', 'user subgroup clear', 'subgroup clear english', 'clear english predominant', 'english predominant language', 'predominant language platform', 'language platform though', 'platform though beyond', 'though beyond immediate', 'beyond immediate scope', 'immediate scope work', 'scope work greater', 'work greater analysis', 'greater analysis nonenglish', 'analysis nonenglish codeswitching', 'nonenglish codeswitching platform', 'codeswitching platform could', 'platform could lead', 'could lead deeper', 'lead deeper understanding', 'deeper understanding impact', 'understanding impact interaction', 'impact interaction expression', 'interaction expression user', 'expression user national', 'user national identity', 'national identity different', 'identity different language', 'different language preference']",0.0,0.0,0.0,0.0,0.9990504384040833,0.0,0,0.0
https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-018-2197-z,1,In this section we first present the data gathered and used in our analysis. Researchers interested in the code and the data are invited to contact the authors. Reddit is a website which enables users to aggregate rate and discuss news entertainment politics and many other topics. According to Alexa it is the 8th most popular website in the world. It was estimated by the Pew research center that 6% of online adults use Reddit [26]. The site is organized into a collection of “subreddits” each focused on a particular topic and administered by a collection of moderators. The subreddit r/SuicideWatch is a forum in which online users are encouraged to post their thoughts regarding suicide. At the time of our data collection it had over 58000 subscribers. Sometimes users express a preoccupation with the thought of suicide. Other times users discuss immediate plans to take their own life. These posts often contain a description of their mental state including depression reaction to stress their feelings of being alone and having a low self-esteem. While most online sources of data are notoriously noisy this particular subreddit is remarkably clean. Given the serious nature of the subreddit individuals are less likely to post harassing comments or off-topic remarks. When users post such comments the moderators of the subreddit quickly remove them. We collected all posts from its inception in 2008 to 2016. Each post is often commented on by other individuals. In this work we focused on the original post as it most often represents the suicidal ideation of a user and comments often represent emotional support from other users. We cleaned this data. First we removed empty posts in which the content had been deleted. Second we removed links and replaced them with the word “link”. Third we concatenated the text of the post to the title as many users begin their post in the title and continue in the body of the post. Finally we removed punctuation and other special characters. After cleaning this data we had 131728 posts with 27978246 words of which 84607 words were unique posted by 63252 unique users.,in this section we first present the data gathered and used in our analysis researcher interested in the code and the data are invited to contact the author reddit is a website which enables user to aggregate rate and discus news entertainment politics and many other topic according to alexa it is the th most popular website in the world it wa estimated by the pew research center that of online adult use reddit the site is organized into a collection of subreddits each focused on a particular topic and administered by a collection of moderator the subreddit rsuicidewatch is a forum in which online user are encouraged to post their thought regarding suicide at the time of our data collection it had over subscriber sometimes user express a preoccupation with the thought of suicide other time user discus immediate plan to take their own life these post often contain a description of their mental state including depression reaction to stress their feeling of being alone and having a low selfesteem while most online source of data are notoriously noisy this particular subreddit is remarkably clean given the serious nature of the subreddit individual are le likely to post harassing comment or offtopic remark when user post such comment the moderator of the subreddit quickly remove them we collected all post from it inception in to each post is often commented on by other individual in this work we focused on the original post a it most often represents the suicidal ideation of a user and comment often represent emotional support from other user we cleaned this data first we removed empty post in which the content had been deleted second we removed link and replaced them with the word link third we concatenated the text of the post to the title a many user begin their post in the title and continue in the body of the post finally we removed punctuation and other special character after cleaning this data we had post with word of which word were unique posted by unique user,"['section', 'first', 'present', 'data', 'gathered', 'used', 'analysis', 'researcher', 'interested', 'code', 'data', 'invited', 'contact', 'author', 'reddit', 'website', 'enables', 'user', 'aggregate', 'rate', 'discus', 'news', 'entertainment', 'politics', 'many', 'topic', 'according', 'alexa', 'th', 'popular', 'website', 'world', 'wa', 'estimated', 'pew', 'research', 'center', 'online', 'adult', 'use', 'reddit', 'site', 'organized', 'collection', 'subreddits', 'focused', 'particular', 'topic', 'administered', 'collection', 'moderator', 'subreddit', 'rsuicidewatch', 'forum', 'online', 'user', 'encouraged', 'post', 'thought', 'regarding', 'suicide', 'time', 'data', 'collection', 'subscriber', 'sometimes', 'user', 'express', 'preoccupation', 'thought', 'suicide', 'time', 'user', 'discus', 'immediate', 'plan', 'take', 'life', 'post', 'often', 'contain', 'description', 'mental', 'state', 'including', 'depression', 'reaction', 'stress', 'feeling', 'alone', 'low', 'selfesteem', 'online', 'source', 'data', 'notoriously', 'noisy', 'particular', 'subreddit', 'remarkably', 'clean', 'given', 'serious', 'nature', 'subreddit', 'individual', 'le', 'likely', 'post', 'harassing', 'comment', 'offtopic', 'remark', 'user', 'post', 'comment', 'moderator', 'subreddit', 'quickly', 'remove', 'collected', 'post', 'inception', 'post', 'often', 'commented', 'individual', 'work', 'focused', 'original', 'post', 'often', 'represents', 'suicidal', 'ideation', 'user', 'comment', 'often', 'represent', 'emotional', 'support', 'user', 'cleaned', 'data', 'first', 'removed', 'empty', 'post', 'content', 'deleted', 'second', 'removed', 'link', 'replaced', 'word', 'link', 'third', 'concatenated', 'text', 'post', 'title', 'many', 'user', 'begin', 'post', 'title', 'continue', 'body', 'post', 'finally', 'removed', 'punctuation', 'special', 'character', 'cleaning', 'data', 'post', 'word', 'word', 'unique', 'posted', 'unique', 'user']","['section first', 'first present', 'present data', 'data gathered', 'gathered used', 'used analysis', 'analysis researcher', 'researcher interested', 'interested code', 'code data', 'data invited', 'invited contact', 'contact author', 'author reddit', 'reddit website', 'website enables', 'enables user', 'user aggregate', 'aggregate rate', 'rate discus', 'discus news', 'news entertainment', 'entertainment politics', 'politics many', 'many topic', 'topic according', 'according alexa', 'alexa th', 'th popular', 'popular website', 'website world', 'world wa', 'wa estimated', 'estimated pew', 'pew research', 'research center', 'center online', 'online adult', 'adult use', 'use reddit', 'reddit site', 'site organized', 'organized collection', 'collection subreddits', 'subreddits focused', 'focused particular', 'particular topic', 'topic administered', 'administered collection', 'collection moderator', 'moderator subreddit', 'subreddit rsuicidewatch', 'rsuicidewatch forum', 'forum online', 'online user', 'user encouraged', 'encouraged post', 'post thought', 'thought regarding', 'regarding suicide', 'suicide time', 'time data', 'data collection', 'collection subscriber', 'subscriber sometimes', 'sometimes user', 'user express', 'express preoccupation', 'preoccupation thought', 'thought suicide', 'suicide time', 'time user', 'user discus', 'discus immediate', 'immediate plan', 'plan take', 'take life', 'life post', 'post often', 'often contain', 'contain description', 'description mental', 'mental state', 'state including', 'including depression', 'depression reaction', 'reaction stress', 'stress feeling', 'feeling alone', 'alone low', 'low selfesteem', 'selfesteem online', 'online source', 'source data', 'data notoriously', 'notoriously noisy', 'noisy particular', 'particular subreddit', 'subreddit remarkably', 'remarkably clean', 'clean given', 'given serious', 'serious nature', 'nature subreddit', 'subreddit individual', 'individual le', 'le likely', 'likely post', 'post harassing', 'harassing comment', 'comment offtopic', 'offtopic remark', 'remark user', 'user post', 'post comment', 'comment moderator', 'moderator subreddit', 'subreddit quickly', 'quickly remove', 'remove collected', 'collected post', 'post inception', 'inception post', 'post often', 'often commented', 'commented individual', 'individual work', 'work focused', 'focused original', 'original post', 'post often', 'often represents', 'represents suicidal', 'suicidal ideation', 'ideation user', 'user comment', 'comment often', 'often represent', 'represent emotional', 'emotional support', 'support user', 'user cleaned', 'cleaned data', 'data first', 'first removed', 'removed empty', 'empty post', 'post content', 'content deleted', 'deleted second', 'second removed', 'removed link', 'link replaced', 'replaced word', 'word link', 'link third', 'third concatenated', 'concatenated text', 'text post', 'post title', 'title many', 'many user', 'user begin', 'begin post', 'post title', 'title continue', 'continue body', 'body post', 'post finally', 'finally removed', 'removed punctuation', 'punctuation special', 'special character', 'character cleaning', 'cleaning data', 'data post', 'post word', 'word word', 'word unique', 'unique posted', 'posted unique', 'unique user']","['section first present', 'first present data', 'present data gathered', 'data gathered used', 'gathered used analysis', 'used analysis researcher', 'analysis researcher interested', 'researcher interested code', 'interested code data', 'code data invited', 'data invited contact', 'invited contact author', 'contact author reddit', 'author reddit website', 'reddit website enables', 'website enables user', 'enables user aggregate', 'user aggregate rate', 'aggregate rate discus', 'rate discus news', 'discus news entertainment', 'news entertainment politics', 'entertainment politics many', 'politics many topic', 'many topic according', 'topic according alexa', 'according alexa th', 'alexa th popular', 'th popular website', 'popular website world', 'website world wa', 'world wa estimated', 'wa estimated pew', 'estimated pew research', 'pew research center', 'research center online', 'center online adult', 'online adult use', 'adult use reddit', 'use reddit site', 'reddit site organized', 'site organized collection', 'organized collection subreddits', 'collection subreddits focused', 'subreddits focused particular', 'focused particular topic', 'particular topic administered', 'topic administered collection', 'administered collection moderator', 'collection moderator subreddit', 'moderator subreddit rsuicidewatch', 'subreddit rsuicidewatch forum', 'rsuicidewatch forum online', 'forum online user', 'online user encouraged', 'user encouraged post', 'encouraged post thought', 'post thought regarding', 'thought regarding suicide', 'regarding suicide time', 'suicide time data', 'time data collection', 'data collection subscriber', 'collection subscriber sometimes', 'subscriber sometimes user', 'sometimes user express', 'user express preoccupation', 'express preoccupation thought', 'preoccupation thought suicide', 'thought suicide time', 'suicide time user', 'time user discus', 'user discus immediate', 'discus immediate plan', 'immediate plan take', 'plan take life', 'take life post', 'life post often', 'post often contain', 'often contain description', 'contain description mental', 'description mental state', 'mental state including', 'state including depression', 'including depression reaction', 'depression reaction stress', 'reaction stress feeling', 'stress feeling alone', 'feeling alone low', 'alone low selfesteem', 'low selfesteem online', 'selfesteem online source', 'online source data', 'source data notoriously', 'data notoriously noisy', 'notoriously noisy particular', 'noisy particular subreddit', 'particular subreddit remarkably', 'subreddit remarkably clean', 'remarkably clean given', 'clean given serious', 'given serious nature', 'serious nature subreddit', 'nature subreddit individual', 'subreddit individual le', 'individual le likely', 'le likely post', 'likely post harassing', 'post harassing comment', 'harassing comment offtopic', 'comment offtopic remark', 'offtopic remark user', 'remark user post', 'user post comment', 'post comment moderator', 'comment moderator subreddit', 'moderator subreddit quickly', 'subreddit quickly remove', 'quickly remove collected', 'remove collected post', 'collected post inception', 'post inception post', 'inception post often', 'post often commented', 'often commented individual', 'commented individual work', 'individual work focused', 'work focused original', 'focused original post', 'original post often', 'post often represents', 'often represents suicidal', 'represents suicidal ideation', 'suicidal ideation user', 'ideation user comment', 'user comment often', 'comment often represent', 'often represent emotional', 'represent emotional support', 'emotional support user', 'support user cleaned', 'user cleaned data', 'cleaned data first', 'data first removed', 'first removed empty', 'removed empty post', 'empty post content', 'post content deleted', 'content deleted second', 'deleted second removed', 'second removed link', 'removed link replaced', 'link replaced word', 'replaced word link', 'word link third', 'link third concatenated', 'third concatenated text', 'concatenated text post', 'text post title', 'post title many', 'title many user', 'many user begin', 'user begin post', 'begin post title', 'post title continue', 'title continue body', 'continue body post', 'body post finally', 'post finally removed', 'finally removed punctuation', 'removed punctuation special', 'punctuation special character', 'special character cleaning', 'character cleaning data', 'cleaning data post', 'data post word', 'post word word', 'word word unique', 'word unique posted', 'unique posted unique', 'posted unique user']",0.0,0.0,0.0,0.9952400922775269,0.0,0.0,0,0.0
https://ieeexplore.ieee.org/abstract/document/8609647,1,Reddit is a multilingual Online Social Network founded in 2005 and organized in subcommunities by areas of interest called subreddits. We obtained data from the Reddit's data repository4 focusing on four subreddits where people discuss issues related to mental heath disorders: Depression (/r/depression) Suicide Watch (/r/Suicide Watch) Anxiety (/r/anxiety) and Bipolar (/r/bipolar). Our dataset is comprised of user activities (posts and comments) that took place between 2011 and 201 7. Here we focus on data from January 2017 to December 2017. In total we obtained 261511 posts and 1256669 comments from 184708 unique users. Table I shows the total number of users posts and comments per subreddit. The total number of comments in each community is at least 4.2 times larger than the number of posts which suggests a supportive behavior among users.,reddit is a multilingual online social network founded in and organized in subcommunities by area of interest called subreddits we obtained data from the reddits data repository focusing on four subreddits where people discus issue related to mental heath disorder depression rdepression suicide watch rsuicide watch anxiety ranxiety and bipolar rbipolar our dataset is comprised of user activity post and comment that took place between and here we focus on data from january to december in total we obtained post and comment from unique user table i show the total number of user post and comment per subreddit the total number of comment in each community is at least time larger than the number of post which suggests a supportive behavior among user,"['reddit', 'multilingual', 'online', 'social', 'network', 'founded', 'organized', 'subcommunities', 'area', 'interest', 'called', 'subreddits', 'obtained', 'data', 'reddits', 'data', 'repository', 'focusing', 'four', 'subreddits', 'people', 'discus', 'issue', 'related', 'mental', 'heath', 'disorder', 'depression', 'rdepression', 'suicide', 'watch', 'rsuicide', 'watch', 'anxiety', 'ranxiety', 'bipolar', 'rbipolar', 'dataset', 'comprised', 'user', 'activity', 'post', 'comment', 'took', 'place', 'focus', 'data', 'january', 'december', 'total', 'obtained', 'post', 'comment', 'unique', 'user', 'table', 'show', 'total', 'number', 'user', 'post', 'comment', 'per', 'subreddit', 'total', 'number', 'comment', 'community', 'least', 'time', 'larger', 'number', 'post', 'suggests', 'supportive', 'behavior', 'among', 'user']","['reddit multilingual', 'multilingual online', 'online social', 'social network', 'network founded', 'founded organized', 'organized subcommunities', 'subcommunities area', 'area interest', 'interest called', 'called subreddits', 'subreddits obtained', 'obtained data', 'data reddits', 'reddits data', 'data repository', 'repository focusing', 'focusing four', 'four subreddits', 'subreddits people', 'people discus', 'discus issue', 'issue related', 'related mental', 'mental heath', 'heath disorder', 'disorder depression', 'depression rdepression', 'rdepression suicide', 'suicide watch', 'watch rsuicide', 'rsuicide watch', 'watch anxiety', 'anxiety ranxiety', 'ranxiety bipolar', 'bipolar rbipolar', 'rbipolar dataset', 'dataset comprised', 'comprised user', 'user activity', 'activity post', 'post comment', 'comment took', 'took place', 'place focus', 'focus data', 'data january', 'january december', 'december total', 'total obtained', 'obtained post', 'post comment', 'comment unique', 'unique user', 'user table', 'table show', 'show total', 'total number', 'number user', 'user post', 'post comment', 'comment per', 'per subreddit', 'subreddit total', 'total number', 'number comment', 'comment community', 'community least', 'least time', 'time larger', 'larger number', 'number post', 'post suggests', 'suggests supportive', 'supportive behavior', 'behavior among', 'among user']","['reddit multilingual online', 'multilingual online social', 'online social network', 'social network founded', 'network founded organized', 'founded organized subcommunities', 'organized subcommunities area', 'subcommunities area interest', 'area interest called', 'interest called subreddits', 'called subreddits obtained', 'subreddits obtained data', 'obtained data reddits', 'data reddits data', 'reddits data repository', 'data repository focusing', 'repository focusing four', 'focusing four subreddits', 'four subreddits people', 'subreddits people discus', 'people discus issue', 'discus issue related', 'issue related mental', 'related mental heath', 'mental heath disorder', 'heath disorder depression', 'disorder depression rdepression', 'depression rdepression suicide', 'rdepression suicide watch', 'suicide watch rsuicide', 'watch rsuicide watch', 'rsuicide watch anxiety', 'watch anxiety ranxiety', 'anxiety ranxiety bipolar', 'ranxiety bipolar rbipolar', 'bipolar rbipolar dataset', 'rbipolar dataset comprised', 'dataset comprised user', 'comprised user activity', 'user activity post', 'activity post comment', 'post comment took', 'comment took place', 'took place focus', 'place focus data', 'focus data january', 'data january december', 'january december total', 'december total obtained', 'total obtained post', 'obtained post comment', 'post comment unique', 'comment unique user', 'unique user table', 'user table show', 'table show total', 'show total number', 'total number user', 'number user post', 'user post comment', 'post comment per', 'comment per subreddit', 'per subreddit total', 'subreddit total number', 'total number comment', 'number comment community', 'comment community least', 'community least time', 'least time larger', 'time larger number', 'larger number post', 'number post suggests', 'post suggests supportive', 'suggests supportive behavior', 'supportive behavior among', 'behavior among user']",0.0,0.0,0.0,0.5615362524986267,0.4289599657058716,0.0,0,0.0
